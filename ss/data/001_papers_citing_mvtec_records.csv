paperId,title,publicationDate,abstract,url,refences_ids,nrefences,references_ids_incommon_mvtec_citations,nreferences_incommon_mvtec_citations,authors,authors_first,authors_list,percent_references_incommon_mvtec_citations
2895770450e9cdfa4bfa42ea035b0a2397205e95,Semi-supervised anomaly detection with dual prototypes autoencoder for industrial surface inspection,,,https://www.semanticscholar.org/paper/2895770450e9cdfa4bfa42ea035b0a2397205e95,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'd65c2cbc0980d0840b88b569516ae9c277d9d200', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '971e2f8d95617f263e1bfa7081db06f1eb6211dc', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '78e1c397fe469ae4dfce3770c8352c397d63fc43', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '0970e8f18d90223a48ad9cb85d66882104bf6a01', 'dd2612a5b720001354713be5f9a57a34013d4867', '9ad57757e4f969318c04666e1bc3e3175c686853', '31db339dfe02a42923cfab7d103a0372c5aa7ddb', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '2abde28f75a9135c8ed7c50ea16b7b9e49da0c09', '3af65fa7b6cfff74dc8eae063f9456cd3337cf05', '64a877d135db3acbc23c295367927176f332595f', 'b20e564edbef25009fa1baa2c369437c89147e61', '2edf3a49bdbbb630666c51be9b856d613c9782b3', '25757e7819eeb8829d3524474f973b79befd7b59', '5d5c1173568b09f44bab55b796ec5ca6c4057464', '707b07baa7be32483a877fcf4477b157554aa23e', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '3cdbefc533ffb8f506a798bac6fd7501f78473c7', 'd81421695d5d429a47eefe266986d197d7b313f2', '17d3f90cb63fbac50a5e49b8a46e633ec1f526fd', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'b9814a336b50a7a81ca4cc3dd91059c0f7626489', '0d3b2db9af4a72f2e0ec6f15a7f0bc6fe6e97cdb', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '46d4a2b7ccf38b80b09574cf17544ff2297a8fbf', '21d29cad997d8c5ed0ad309d23ac3f819c6feebb', '746cf281d8198310b1242048bf4fd90e0486f1a9', '9fcc1189d5b83258ed2c78b0447c96eb527fb63c'}",37,set(),0,"['Jie Liu', 'Kechen Song', 'Mingzheng Feng', 'Yunhui Yan', 'Zhibiao Tu', 'Liu Zhu']",Jie Liu,"Jie Liu, Kechen Song, Mingzheng Feng, Yunhui Yan, Zhibiao Tu, Liu Zhu",0.0
6ec00ff233c19b47ef44dd57cdb22a7385586c0c,Weakly-supervised Video Anomaly Detection with Robust Temporal Feature Magnitude Learning,2021-01-25,"Anomaly detection with weakly supervised video-level labels is typically formulated as a multiple instance learning (MIL) problem, in which we aim to identify snippets containing abnormal events, with each video represented as a bag of video snippets. Although current methods show effective detection performance, their recognition of the positive instances, i.e., rare abnormal snippets in the abnormal videos, is largely biased by the dominant negative instances, especially when the abnormal events are subtle anomalies that exhibit only small differences compared with normal events. This issue is exacerbated in many methods that ignore important video temporal dependencies. To address this issue, we introduce a novel and theoretically sound method, named Robust Temporal Feature Magnitude learning (RTFM), which trains a feature magnitude learning function to effectively recognise the positive instances, substantially improving the robustness of the MIL approach to the negative instances from abnormal videos. RTFM also adapts dilated convolutions and self-attention mechanisms to capture long- and short-range temporal dependencies to learn the feature magnitude more faithfully. Extensive experiments show that the RTFM-enabled MIL model (i) outperforms several state-of-the-art methods by a large margin on four benchmark data sets (ShanghaiTech, UCF-Crime, XD-Violence and UCSD-Peds) and (ii) achieves significantly improved subtle anomaly discriminability and sample efficiency.",https://www.semanticscholar.org/paper/6ec00ff233c19b47ef44dd57cdb22a7385586c0c,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '57b2198f9a8df773425aa6cc88c9870cb07779e2', '8899094797e82c5c185a0893896320ef77f60e64', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'e1820e33e0347c4e9e625b640c7156faefe74159', '6d4c9c923e9f145d1c01a2de2afc38ec23c44253', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', '1068f944bd00c31a0c8e2edc38886e4f596cbeb4', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '04513c7c0b3a63fde81a996dae064a28d453c17a', '1311a646fb9a7928f37dddf8df1b15a05d7ff646', '60fef33549f57f5cbb6712a510c3a444ab682429', '49133ffa30e0acaf4ea5bd8bbf68c841b02e3f2a', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '711cb048076ec8f297efe4cb2c77c1ed95c0ccc4', '7f5fc84819c0cf94b771fe15141f65b123f7b8ec', 'a0e8f4348968195c80494b7a4245edb91a252c93', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', 'b61a3f8b80bbd44f24544dc915f52fd30bbdf485', 'e6df192c9b654bc5cc371c55012cf99d85cb61df', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', '2e269d2ee60db6d09a514c4748e3fdf9202917f9', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '2cf5ff18580c6073e555cf34793d71a63b40d406', '9821102c3f41297a8bd61a55d85225c5c75a9031', '267502d21b44884570fcd95a855821cc3e86e6eb', '54c7445f319823c7dcc948c830e75e2fa7460b33', '3727443e7c0bb819846a1f98e6efd772d34824c9', 'd25c65d261ea0e6a458be4c50c40ffe5bc508f77', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'd3b614f11969127a08447c41257b3a7b58766d18', '50a93a118d5826369d2d28ed87216bde08fdb1b4', None, '41747cbdbed84762dfbfc305254c97021279dc6e', '4aadd44e7f58667c149ee9037d97cccb2ebd7815', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', '2bdc82fbdbc060ba28930a62aaf174ac14ea71ff', '1281a7ebf385c0d5e528a39e688801d7046744ed', '96d7a07237e146c28173767dfc6290a337696c04', '84ccbe667e1185b6c3ddac09a2f76baf95d97914', '599fd051c9438011ec5b581983c89e8922b4a5e6', '992847be33f4bf7afbe66e198cb20a53e00dfa76', '232b26f231122f6332d66244e5ad61d8225312a2', '8109587a56d53c6ba30fe19ba9aa4d9213ec91a0', '86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6', '8f28873be3601c5a2736996eba543cf51950a381', '9d5290fadb7625862a966e0330bd0f9e111fc99d', '1f528877c4d8d5df3b3abbfa64379677d451956b', '3c4f0260a6e35b5d5276ecd3d8c1081aacd161ff', '6af440915b8a0718c93be1cf61905e41e620484a', 'c48def9076e58095c4aea49a8daa931af1990701', 'aae932cf9c2434f52b03991fcab050a61a960d48', '0c5ed0c30375703306f36d341d31772f3bd5af47', '8381157eae4fbf8908d0312a9642f8e69e944449', '094ac7510d1723cb9c2da01db47291322aa29025', '048ef48f58156ab9f8eb4c1126e090194459e699', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '6f68ce1e03c56c186256dac689a21f6405ae8d96', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'a03bda078490e8ee991a1f86b53f27df7cf93a14', '011d9da0860b43abba7b089167937e2277e07540', 'a4c94b221062d0737ee967affa80ce2110cc50c0', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '31cbbce38417c704df5dc5f6c4bef46d38b0e190', '1442cb4613c99924f500ebdc2a7fdaf2e9080da5', 'fcadb2bac99550adcdbd8578eb246eb9e264ecf3', 'b9bdc61d63d75d82f24de21be26f61879df5a01b', '02d0ef096d3b39bb83a344393522360aaf69d694', '38d4b5a464652a4afb4f043f141976f5c71c1e6b', '08f99af9f5d6d351201ee4563e407bf37bc164fd', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', 'db20d81d40243d66ff90f11b5c6f058d43d3701f', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '84f7f9e121c1285e15cefbfc44bcb3322f73b6aa', '598fe25743f9492c5c1ba30274ea446f65426d85'}",80,"{'41747cbdbed84762dfbfc305254c97021279dc6e', 'd3b614f11969127a08447c41257b3a7b58766d18', '1f528877c4d8d5df3b3abbfa64379677d451956b'}",3,"['Yu Tian', 'Guansong Pang', 'Yuanhong Chen', 'Rajvinder Singh', 'J. Verjans', 'G. Carneiro']",Yu Tian,"Yu Tian, Guansong Pang, Yuanhong Chen, Rajvinder Singh, J. Verjans, G. Carneiro",3.75
931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04,Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection,,"Anomaly detection is a challenging task and usually formulated as an unsupervised learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and efficiency. Given a strong model pre-trained on image classification as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature alignment enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on three major benchmarks, significantly superior to the state of the art ones. In addition, it makes inferences at a very high speed (with 100 FPS for images of the size at 256×256), at least dozens of times faster than the latest counterparts.",https://www.semanticscholar.org/paper/931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '02227c94dd41fe0b439e050d377b0beb5d427cda', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '388645c44061f6e88fff0ecdad2f622936207d67', '2528a82dd2266600d4ee2b54165556a984de94d4', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'f076e4355c0facf111716dcab2837803367dd2d8', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', '9277dc70c74bcadf80dab11c28ead83fd085deec', '1a2a770d23b4a171fa81de62a78a3deb0588f238', 'c53352a4239568cc915ad968aff51c49924a3072', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'b1459748ecfa497d6f2317eed7491a396241e7fd', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a0e8f4348968195c80494b7a4245edb91a252c93', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', '45f490710b4dd6697dba4c9b385a49554501711a', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, '5f61089d3d548a515f01b473f0119137d1f340d4', '5694e46284460a648fe29117cbc55f6c9be3fa3c', '41747cbdbed84762dfbfc305254c97021279dc6e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '563143c5f4fed0184c1f3e661917da94cfed1d46', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '969fbdcd0717bec06228053788c2ff78bbb4daac', 'c08f5fa876181fc040d76c75fe2433eee3c9b001', '317c172f314f8cb634f7569ed5bf3ae7dd25c313', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",45,"{'363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e', '9277dc70c74bcadf80dab11c28ead83fd085deec'}",3,"['Guodong Wang', 'Shumin Han', 'Errui Ding', 'Di Huang']",Guodong Wang,"Guodong Wang, Shumin Han, Errui Ding, Di Huang",6.666666666666667
6993721506b6cfd4990d5f235f6b99fa3aa27f6a,Omni-frequency Channel-selection Representations for Unsupervised Anomaly Detection,2022-03-01,"Density-based and classification-based methods have ruled unsupervised anomaly detection in recent years, while reconstruction-based methods are rarely mentioned for the poor reconstruction ability and low performance. However, the latter requires no costly extra training samples for the unsupervised training that is more practical, so this paper focuses on improving this kind of method and proposes a novel Omni-frequency Channel-selection Reconstruction (OCR-GAN) network to handle anomaly detection task in a perspective of frequency. Concretely, we propose a Frequency Decoupling (FD) module to decouple the input image into different frequency components and model the reconstruction process as a combination of parallel omnifrequency image restorations, as we observe a significant difference in the frequency distribution of normal and abnormal images. Given the correlation among multiple frequencies, we further propose a Channel Selection (CS) module that performs frequency interaction among different encoders by adaptively selecting different channels. Abundant experiments demonstrate the effectiveness and superiority of our approach over different kinds of methods, e.g., achieving a new state-of-the-art 98.3 detection AUC on the MVTec AD dataset without extra training data that markedly surpasses the reconstruction-based baseline by +38.1↑ and the current SOTA method by +0.3↑. Source code will be available at https://github.com/zhangzjn/OCR-GAN.",https://www.semanticscholar.org/paper/6993721506b6cfd4990d5f235f6b99fa3aa27f6a,"{'ca74e14bc916294362cd8faac9c5288f8fbf055b', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '790eceaa2cb59fef2634dad40f628346eb07cd3d', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '3e0a7244028e303c94a33d824848d1a9555f4785', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '732c21998e251d64cd58b6a86886ee5907efeaa5', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'efdbd7af97c0fb0dbf0e302c616eda750e1772e9', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5db790198b9acf4e5efe350acdd814238fcacaa7', '19862af96b6af51e879e6e3f1d3d421af5427005', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '02b28f3b71138a06e40dbd614abf8568420ae183', '8bdfb96e2865ad0d1e263f04fc0dab134052d64e', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '94f6c36ceff963dd9a6a2b45fb3754b071bceb17', '00a1077d298f2917d764eb729ab1bc86af3bd241', '36fac56c02597f9ea7c9c05419fd7a7109de1056', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '9d5290fadb7625862a966e0330bd0f9e111fc99d', 'c53352a4239568cc915ad968aff51c49924a3072', '5435a9ab36a308cef10bc725104e8f778ed3a328', '04513c7c0b3a63fde81a996dae064a28d453c17a', 'c6af93925826c0c918f6aed7261c62f6ba5ed6df', '37595f7a51982d776e57c7280b9445474d90f0be', 'b99ce3d84e6b39a805a411a23128a406eaf0a8ca', 'b1464ca857593c049873421db2f37bf2d0ff676d', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '5b48a06ac2d2d778c09acbcae70ba6fab7f65fe8', '883c5791a627d5bf679da1b5f871ff0d51792c6d', '8c2087063ace28ce2ca8a8efdd45c637234a8450', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'ca6b11604b05fe9f84ff8f170b899839625a9246', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'da8932d53a73b8a2b6c2b39d70c789cda4acee0b', None, 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'fb8cf663a71bf31f59557a35d36aaf8c465b50af', '580396c680951b7ff93defcac7cfe085dfe1814e', '9ce5a302b3f7f9ee19434971a5e29bf58aa46c11', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '8381157eae4fbf8908d0312a9642f8e69e944449', '54323bf565cea5d2aaee88a03ec9d1d3444a9bfd', 'c992f74eb6ceddd73eb29a5113d04140484fb8fd', '6869ab1f42e30b415829de9928f7e4a606113601', '746cf281d8198310b1242048bf4fd90e0486f1a9', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', 'a4bb027dd9f9ef23244b5e0918ef427c1cbdbf1d', '598fe25743f9492c5c1ba30274ea446f65426d85', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",65,"{'62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'da8932d53a73b8a2b6c2b39d70c789cda4acee0b', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '19862af96b6af51e879e6e3f1d3d421af5427005', '41747cbdbed84762dfbfc305254c97021279dc6e', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",13,"['Yufei Liang', 'Jiangning Zhang', 'Shiwei Zhao', 'R. Wu', 'Yong Liu', 'S. Pan']",Yufei Liang,"Yufei Liang, Jiangning Zhang, Shiwei Zhao, R. Wu, Yong Liu, S. Pan",20.0
79cbac6f9502480e4a1657e4375b78ff5bcea8e0,Trustworthy Anomaly Detection: A Survey,2022-02-15,"Anomaly detection has a wide range of real-world applications, such as bank fraud detection and cyber intrusion detection. In the past decade, a variety of anomaly detection models have been developed, which lead to big progress towards accurately detecting various anomalies. Despite the successes, anomaly detection models still face many limitations. The most significant one is whether we can trust the detection results from the models. In recent years, the research community has spent a great effort to design trustworthy machine learning models, such as developing trustworthy classification models. However, the attention to anomaly detection tasks is far from sufficient. Considering that many anomaly detection tasks are life-changing tasks involving human beings, labeling someone as anomalies or fraudsters should be extremely cautious. Hence, ensuring the anomaly detection models conducted in a trustworthy fashion is an essential requirement to deploy the models to conduct automatic decisions in the real world. In this brief survey, we summarize the existing efforts and discuss open problems towards trustworthy anomaly detection from the perspectives of interpretability, fairness, robustness, and privacy-preservation.",https://www.semanticscholar.org/paper/79cbac6f9502480e4a1657e4375b78ff5bcea8e0,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6a83ce3a5604e3dad44c6b5fe992056add6c605f', 'fab510d074fd48ce08c0e12b36cbe24819898c01', 'bc153a9dab5c7f4c8aaf16ce116554dc68b6a536', '00a1077d298f2917d764eb729ab1bc86af3bd241', '76e44d72f78281ecd73c512339684efb920a0245', '02a3eab72b8eea2757227ec623afb9bffc1da635', 'c641fb8f6ff1ac0c6d0d4ad9fbb7d50d8464729b', '6e859a48115ca399d1f0ebc15bde752824f4b64f', '0c5f4909429522a968796b0d1f711f91e2f4ea58', 'cb4c2a2d7e50667914d1a648f1a9134056724780', '379a16483d59d92d69bfc506d5de5d1a066b4336', '0ec3399ea7e1d56a045252b83c40368c7ee5e0eb', 'dffbc930b456886195159ee4552ec33e6bd00032', '652107ea8161f607e3bdabc89199e9ff2fdfd015', '440d248d148f7e36dad232e48f1c5c1cbc556d86', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '2eda8c10814c8bbc5464440cc4f7f7fb4ecdd88b', '869fdb53a40290a3941fd6ab808835e9b5184d62', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '9eec64835215454c4daed1c2a3fb7c1c4af47162', '35d1cfef6640c907f89ae8f36ec33f0afddd08e9', '1ef11d531bd6ea6d924d4e06b981047e463befad', '8b365890c0224f17fffb90bf33da46fccacd9331', '5f0b03f6a6c655eecc818d5c3f425b6003fe1dae', '20f69cc41c87b8abdf36761c623d65713daeab3b', '3b1941105317edaef6ac5995089d6d916e5fb483', 'c4f92f208f8bb85ab64a0482be592b594c16ca16', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'd959bc5a4b23aa500678b44fffeb975b16d2558e', None, '8dfd3476dcedc206076893c11c38c36b25fb545e', '888dbb50bd63a94e349081b27b78c671607452f4', '88e94950ee852b710d691c6154f14ff144678cb5', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', 'efb613ee1613be308bd0d1105fd33f42266197eb', 'a7e4d5b16deb11c942068a2341e34d214865181f', '10e0303e00c0f5f8582f5097ff5e113298babc6f', 'a7c828184693a453a6c2867dee233ed054b2012e', 'e9a986c8ff6c2f381d026fe014f6aaa865f34da7', '5a1d7240fd11455168a5d7a6e510162383d5f2fd', '68d5091bcbaeacfe2478b723dbfa959fb4490d8d', 'a9ae263157e2ecc3e85e5fa5c03da0d3745bdc3d', '37eb32915b7767685ec3c9e9728ca9a50a379b8d', '0090023afc66cd2741568599057f4e82b566137c', '7aa38b85fa8cba64d6a4010543f6695dbf5f1386', '180300ff8282220c76c7c41ded4d9d8c1be4d3fc', '2324d25fcbeb11d04dd2956026a5c4d68eac54dd', '3df952d4a724655f7520ff95d4b2cef90fff0cae', '8b7fc929487bf2895a361148ff21899e4c15d313', '35e747d3d0bef4e9e3dabb1f70593b6838d26644', 'e3ab07e76fd97a6014332a8a0ffa09af02696a8e', 'bfb5225976bf3bd4bdb026621ecdf909c39eeb67'}",53,"{'16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '180300ff8282220c76c7c41ded4d9d8c1be4d3fc', '78d80c343d36baaf89f18e12d325cf6309fb6c8f'}",4,"['Shuhan Yuan', 'Xintao Wu']",Shuhan Yuan,"Shuhan Yuan, Xintao Wu",7.547169811320755
dc255acc8da3f07e8c08c7d675a4442700d94fea,Deep learning-based anomaly detection from ultrasonic images.,2022-04-01,,https://www.semanticscholar.org/paper/dc255acc8da3f07e8c08c7d675a4442700d94fea,"{'b1f40a88aed41832b32559e24ce5680fdfd0efeb', '162d958ff885f1462aeda91cd72582323fd6a1f4', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '21a53c50a7b399ce964badf8fd2e8453619da8f3', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '630a854e0670ab13ec563ae4d3a1f7c20602bf4a', '9242de04c5f2aecdcc030ea6a3ff39c13bcf6f72', '31d17543f3051d32a767b84c25c6efbbdbb5e94f', '920dc4e8d73e6ee8e146085c94a2ab771976e9c1', 'ad79883b62eadb1f3b7c08669c94d4fa5952e784', '0814dd3407670e9603594aeacc36343122e7492e', 'ed5d460e0f4b1375a337354bc3d6625723eb64b6', '1172cd9126a5f024187334b482551d62f7cd462a', 'e597dea9e64485ceae8b86551e596ce42e205b89', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'adec9e97e6079ed62447a6f31848bc953ca8a1f7', '25b6603e370347643548d6c9bd2b2f7e27a6b7c7', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'f01ab464ca98d2ffac0e76ff675b72fd653a671d', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2e9e053d25913d3404def38ef7215af18acc76a3', '68a1b0d848e027f2eb1e9e501eb4124a8c4c908d'}",23,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",2,"['L. Posilović', 'D. Medak', 'Fran Milković', 'M. Subašić', 'M. Budimir', 'S. Lončarić']",L. Posilović,"L. Posilović, D. Medak, Fran Milković, M. Subašić, M. Budimir, S. Lončarić",8.695652173913043
87e2ec6ba55ce14fdcc493a3b9a39a9d2ee29a91,Brittle Features May Help Anomaly Detection,2021-04-21,"One-class anomaly detection is challenging. A representation that clearly distinguishes anomalies from normal data is ideal, but arriving at this representation is difficult since only normal data is available at training time. We examine the performance of representations, transferred from auxiliary tasks, for anomaly detection. Our results suggest that the choice of representation is more important than the anomaly detector used with these representations, although knowledge distillation can work better than using the representations directly. In addition, separability between anomalies and normal data is important but not the sole factor for a good representation, as anomaly detection performance is also correlated with more adversarially brittle features in the representation space. Finally, we show our configuration can detect 96.4% of anomalies in a genuine X-ray security dataset, outperforming previous results.",https://www.semanticscholar.org/paper/87e2ec6ba55ce14fdcc493a3b9a39a9d2ee29a91,"{'06671547fd94c44688b10c8cd550242557e55154', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '5f81689daeda82f0b1e08da37573032b657f0c47', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '17005a1bd4189707f17d8bef9a0909c9399f7171', '1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '8201e6e687f2de477258e9be53ba7b73ee30d7de', 'c71dead165366c1e985bb4385b29bb9b07325fea', '5e3e36049ed4156f01b0133d56352af8f5020b4a', '5db790198b9acf4e5efe350acdd814238fcacaa7', '0c908739fbff75f03469d13d4a1a07de3414ee19', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', 'c53352a4239568cc915ad968aff51c49924a3072', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', 'be9a17321537d9289875fe475b71f4821457b435', '4bdf6ec7229d307d172e6cce48052b11524b8789', '1b9c6022598085dd892f360122c0fa4c630b3f18', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '38f93092ece8eee9771e61c1edaf11b1293cae1b', '964465406626125ce235faaccf25e265c56f501b', None, '4cb3fd057949624aa4f0bbe7a6dcc8777ff04758', '7fc3119ab077617e93a8b5b421857820a1ac745f', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', 'cd85a549add0c7c7def36aca29837efd24b24080', '41747cbdbed84762dfbfc305254c97021279dc6e', 'd5ed0d819bece4c08c2131bd9b8b4f9c40223ea1', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '3e2da7c1c7dfc7960d1515b61f32fdc55359eea7', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '843959ffdccf31c6694d135fad07425924f785b1', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",38,{'41747cbdbed84762dfbfc305254c97021279dc6e'},1,"['Kimberly T. Mai', 'Toby P. Davies', 'L. D. Griffin']",Kimberly T. Mai,"Kimberly T. Mai, Toby P. Davies, L. D. Griffin",2.6315789473684212
2626eb69be066d1010f99f844b3581cf2bfa04ad,A Novel Approach to Data Augmentation for Pavement Distress Segmentation,2020-10-01,,https://www.semanticscholar.org/paper/2626eb69be066d1010f99f844b3581cf2bfa04ad,"{'f723eb3e7159f07b97464c8d947d15e78612abe4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '1acb422ca7bbd2a65e78e4cd23bd7a23ebc9b235', '41f1d50c85d3180476c4c7b3eea121278b0d8474', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', 'fe9cd683c3b8ebdfd8efd1109a857cdbf9edc364', '5562a56da3a96dae82add7de705e2bd841eb00fc', '5b635705558b9ffcc973966371415b7124830007', '38f35dd624cd1cf827416e31ac5e0e0454028eca', '6045cccf284bf2d0ca407b4146ada29c1df038ad', '061afb6b8d44f4fc3f336fd3c1bd657cd1c9b677', '744fe47157477235032f7bb3777800f9f2f45e52', '6270baedeba28001cd1b563a199335720d6e0fe0', 'daf74c34f7da0695b154f645c8b78a7397a98f16', '03a5b2aac53443e6078f0f63b35d4f95d6d54c5d', 'b5c26ab8767d046cb6e32d959fdf726aee89bb62', '21b58c8aba44c173493e418a797a1f36c6dae8a9', '48e1de7d085808004d5f0493d486669a3d2930b5', 'a47f8794d88c5c27123153c4eb9e08046e2b0c9d', '36df22f68f2e8b106b0be03f61b8ce2abfa92de3', '30f113d985d876a3974838b2ead49a069b474e57', '77e8e3e578b8abd17303f13af1df22080fd6afbb', '82766702e0ee4f93e45975da12e81f1a0712421e', 'd49fe11667eaaa8d52d149c7521f6705162642f5', '231af7dc01a166cac3b5b01ca05778238f796e41', 'ab53140bf9a80fb72554ad797c5520eb09dd6f33', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'f9f19bee621faf46f90b023f8de8248b57becbc4', '4b2f126799306a8d6c293b92d92f6f2b5ebe6477', 'ce711e917b9f6a4abd2d3555714a90a280c9fa44', '82635fb63640ae95f90ee9bdc07832eb461ca881', '17555c227941654bc19d613742e2508f209c6d86', '5a434953b58c72fe2089531d6c4b4fc1325defcb', 'c552dcd51300ce5a0bb52fd078594d4b47fbcddf', 'eb42cf88027de515750f230b23b1a057dc782108', '23ffaa0fe06eae05817f527a47ac3291077f9e58', '06cdd6ccc1456ed3580430e73b5c4a2327b2e233', '2b7c208c34dd4a186f5d6d327bc94ec7397cc766', '6a97d2668187965743d1b825b306defccbabbb4c', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', '22aab110058ebbd198edb1f1e7b4f69fb13c0613', '3a6d33cb1a76fffc531e35c80be8eae20a30b2ef', '0d0eeb46fc5ec778a62bb94aa2ef261b08e6f8c6', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '9da0c0fbb14cb68957a087a9f6f98608fd5096f7'}",47,set(),0,"['Davide Mazzini', 'Paolo Napoletano', 'Flavio Piccoli', 'R. Schettini']",Davide Mazzini,"Davide Mazzini, Paolo Napoletano, Flavio Piccoli, R. Schettini",0.0
78661cecf81340be9bd5720ac5ae97dc0e037bb9,PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation,2020-10-12,"Anomaly detection methods require high-quality features. In recent years, the anomaly detection community has attempted to obtain better features using advances in deep self-supervised feature learning. Surprisingly, a very promising direction, using pre-trained deep features, has been mostly overlooked. In this paper, we first empirically establish the perhaps expected, but unreported result, that combining pre-trained features with simple anomaly detection and segmentation methods convincingly outperforms, much more complex, state-of-the-art methods.In order to obtain further performance gains in anomaly detection, we adapt pre-trained features to the target distribution. Although transfer learning methods are well established in multi-class classification problems, the one-class classification (OCC) setting is not as well explored. It turns out that naive adaptation methods, which typically work well in supervised learning, often result in catastrophic collapse (feature deterioration) and reduce performance in OCC settings. A popular OCC method, DeepSVDD, advocates using specialized architectures, but this limits the adaptation performance gain. We propose two methods for combating collapse: i) a variant of early stopping that dynamically learns the stopping iteration ii) elastic regularization inspired by continual learning. Our method, PANDA, outperforms the state-of-the-art in the OCC, outlier exposure and anomaly segmentation settings by large margins1.",https://www.semanticscholar.org/paper/78661cecf81340be9bd5720ac5ae97dc0e037bb9,"{'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '540b5b4919d345e4da3cc4f3e8a7862329bf41a2', '57b2198f9a8df773425aa6cc88c9870cb07779e2', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '5151d6cb3a4eaec14a56944d58338251fca344ab', 'aa5741c74b7fac10680c1cfbdd49d9ffb5751a68', '2cbb8de53759e75411bc528518947a3094fbce3a', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '732c21998e251d64cd58b6a86886ee5907efeaa5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '992847be33f4bf7afbe66e198cb20a53e00dfa76', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '02b28f3b71138a06e40dbd614abf8568420ae183', 'c069629a51f6c1c301eb20ed77bc6b586c24ce32', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '94559c249d204110296c39ed4af2042cc4468e68', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '04513c7c0b3a63fde81a996dae064a28d453c17a', '37595f7a51982d776e57c7280b9445474d90f0be', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', 'e5c141db4fadcded15a6c05aa9246d91ce4956ff', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', '6af440915b8a0718c93be1cf61905e41e620484a', 'cdd553c54d5769ec218a8ea921e27144a6b1aadb', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '5647fab83543536ea8424317630e6056dc94076d', None, '3039962978812c1c2a33135d60673ebdffe2ce55', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '41747cbdbed84762dfbfc305254c97021279dc6e', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '54d2b5c64a67f65c5dd812b89e07973f97699552', '4d39ee7cca8fedf792570724255a4357aa41dbf8', '576fab96d98981946fcace0384cdba8f7290a8c5', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",40,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",4,"['Tal Reiss', 'Niv Cohen', 'Liron Bergman', 'Yedid Hoshen']",Tal Reiss,"Tal Reiss, Niv Cohen, Liron Bergman, Yedid Hoshen",10.0
3e27ee18bc52ad06f7a900ceeef44eacfed430cc,Curved Geometric Networks for Visual Anomaly Recognition,2022-08-02,"—Learning a latent embedding to understand the underlying nature of data distribution is often formulated in Euclidean spaces with zero curvature. However, the success of the geometry constraints, posed in the embedding space, indicates that curved spaces might encode more structural information, leading to better discriminative power and hence richer representations. In this work, we investigate beneﬁts of the curved space for analyzing anomalies or out-of-distribution objects in data. This is achieved by considering embeddings via three geometry constraints, namely, spherical geometry (with positive curvature), hyperbolic geometry (with negative curvature) or mixed geometry (with both positive and negative curvatures). Three geometric constraints can be chosen interchangeably in a uniﬁed design given the task at hand. Tailored for the embeddings in the curved space, we also formulate functions to compute the anomaly score. Two types of geometric modules ( i.e . Geometric-in-One and Geometric-in-Two models) are proposed to plug in the original Euclidean classiﬁer, and anomaly scores are computed from the curved embeddings. We evaluate the resulting designs under a diverse set of visual recognition scenarios, including image detection (multi-class OOD detection and one-class anomaly detection) and segmentation (multi-class anomaly segmentation and one-class anomaly segmentation). The empirical results show the effectiveness of our proposal through the consistent improvement over various scenarios.",https://www.semanticscholar.org/paper/3e27ee18bc52ad06f7a900ceeef44eacfed430cc,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'db787640c9b42416ff8d7015546e667e58267177', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '904627c2d5a91ab8cb1b682e42f06f1ca192aea6', 'ab96c776f96e10f10d88ac5abbe9335afe935c81', 'e31fa9510047c0df23fb4dd37ee7c70783a3fa60', '81f86cd44c57a06d423d1265c5476e438cf4969f', 'e251bba4f9b7a4d66e077c390b8801cbbb481739', '08d579e899136b868b90663ab3737b264f3c4b08', '62b77e5cb85fc61b84edd532f6d65714be152596', '04513c7c0b3a63fde81a996dae064a28d453c17a', '863dbee808cf9b6631d1245726c5eacf2fea369f', '1c46943103bd7b7a2c7be86859995a4144d1938b', '29c887794eed2ca9462638ff853e6fe1ab91d5d8', 'c707517507873bc2cdc489b6fd9af74770468c48', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '5a05dd1e5e2859ecb845ee75e4ede22805fb22a6', '8e030e236dd831e8918d3af13fed1752558855d3', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '431ba9fae8fccad1665979d455c6307786e47318', '2932825faa4751e7246dc871355851391226b0d5', '4758baad6b22c61682e7f7182bb93723046f36f5', '4dcdae25a5e33682953f0853ee4cf7ca93be58a9', '1c4e9156ca07705531e45960b7a919dc473abb51', '307272c796743bd6d78d4ff3ea762aa2a4c238a2', 'ae9bf201f128cabaa4350b54ff6607525c736cd5', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'badbd3a3df684fc8f7032c4577fb92fb1a743243', 'abcfeb2723f30105c41ffb043f2e6c173f891e90', None, '1590bd1bca945fc6ff50b8cdf2da14ea2061c79a', 'bd8f77b7d3b9d272f7a68defc1412f73e5ac3135', '41747cbdbed84762dfbfc305254c97021279dc6e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '815fa9febd615530abccc2430ee05804427394ba', 'f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6', 'e8fa823c17aeb8d08fe9aa5fc2bc0eaacb9edcdf', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '109963adcf0696f051796dcb668a8261ac7219a8', '599fd051c9438011ec5b581983c89e8922b4a5e6', '084c55d6432265785e3ff86a2e900a49d501c00a', 'cd2202dda2f1f0b6f6ea81d398c3b619d0913a70', '74bfaacd4e86a1304d2b5e7340591cffb38d84dd', 'b20e90396af78f2dcd73994267d53f0a5bd3707a', 'b9bd435b65d8214f1bcab9268ac2fce509cfffe6', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '1673ba124ae9bef97f1f99ea04f7b2ca356b525b', '6ff2a434578ff2746b9283e45abf296887f48a2d', 'c269858a7bb34e8350f2442ccf37797856ae9bca', 'ce05ebc31e7aa8e4152673bb240b9f8d27ebea21', '5d90f06bb70a0a3dced62413346235c02b1aa086', '3433627f803953280b66ae1576d083fc9a68385a', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '08e7431c7b9bd7e54c7df71c4e9aac4a5977b5fb', '0a035f51589172562dfd18bcb7382682f0e7ceba', 'a456265138c088a894301c0433dae938705a9bec', 'cc1cc334897af613e9103de9afe23e1882e0c153', '0e4b0d177e550d365f456375781cd0e4f7a04979', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '9d4c5d5b3028fc5454b88d93b3acf12fa0085d7d', 'fd4f6e0d0a9f8ab70f423cf41c52c31447c9e7b1', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '5473119bbc10c1f210bce526b51a63b3b1d93e07', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'd40ee5dd758c525dfb9932d726bb4e844b7b8478', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '36653f8705b56e39642bcd123494eb680cd1636b', '0cb5c433cf5c974f31c53208eadd7fa94d1330ba', '73f76a40ed20aa3c6a8e27e4db4a8c102e7b4c6d', 'c2b733a79db700b971327a58ef42699fe8a416aa', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '779ad52e8c27b77c10d14d536133da61c2c1f9b2'}",79,"{'4758baad6b22c61682e7f7182bb93723046f36f5', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '41747cbdbed84762dfbfc305254c97021279dc6e', 'ab96c776f96e10f10d88ac5abbe9335afe935c81'}",10,"['Jie Hong', 'Pengfei Fang', 'Weihao Li', 'Junlin Han', 'L. Petersson', 'M. Harandi']",Jie Hong,"Jie Hong, Pengfei Fang, Weihao Li, Junlin Han, L. Petersson, M. Harandi",12.658227848101266
aee4cd951e5d5fc116ac044e28a857dd0511f735,Real-time deep learning method for automated detection and localization of structural defects in manufactured products,2022-07-01,,https://www.semanticscholar.org/paper/aee4cd951e5d5fc116ac044e28a857dd0511f735,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '465f4fe247ff2e2c607d4585b22e546ab3fdda70', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '6224055d8e1ce1e8c16c5fd56a38ac4ef637aac7', 'a538b05ebb01a40323997629e171c91aa28b8e2f', '571f9bda7fcc82361de846350cd4cf26a37d62c6', '3a32801cde1c1f066a8ae74647705a28442e6136', '988e48885347c15ba881f3d00b0a993a5de6f1af', 'd2cf96cb21c7c8cb4abec4fc54091b16a26199e3', 'e7bb9c633722afacf879a6d3f55ded7376785ff0', 'db39e209af6a83a838d6455b9f2991f2ec03414e', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'de4df9cd002f7ac04c260b657a8ba91c00ca8bfd', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', 'cd69b4cb74582a5a20963c7790fcd98a735528df', '5b6033df3f3caa510658df3db99774aa207de922', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'd48f634238bab3a1e7e16f136c55e141383bf589', '523a3a25b5da622985b82cb9c1a1a04c4e2130bc', '6b78b2cde7015539ecb0e4be4ee14ed021210753', '355d44f53428b1ac4fb2ab468d593c720640e5bd', 'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '99c41acbb4f1240944a53f6135eb36c87f98ee90', '01e78b20f7d59b8e49d8cf77c421f968dc337325', '2e06db13b5d5bbffd2184a3540ed4aa6035ab315', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '48f9a48aa5b1230b05a443d2d531e6441a541686', '17d3f90cb63fbac50a5e49b8a46e633ec1f526fd', '5d21006fa32ff69f6b0a646f26ce0db84f2f4d33', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '72e3e3401ba54f11bb5640650e589f2b5608fb5c', 'd880d303ee0bfdbc80fc34df0978088cd15ce861', '246ec2b542527d928710715cb4b36d0d0a401811', '41747cbdbed84762dfbfc305254c97021279dc6e', '858ce29261425aadeeb490ca143e26c500ceb061', 'edfd76e4ec7c88e97f7c53df3a3a4bce42adbe4f', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '132820505bb7241c3bb8a0fd4d34b48a9fa52d9d', '563e3ac27b3455221b3f947a920eece281c5a8c5', 'b52922cdd3df4b4a8a4747a6d254c2c74c83ec7f', 'cf021db5e811fd5b67ee3aa4db0a6a0351d276d2', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '1d4816c612e38dac86f2149af667a5581686cdef', 'ca4edb65a0664804e4819c5c809d0dfba9bdb2df', '17da15bc255855ae100e6b7616b4bb4dc42da62d', '50e5ca477ee8cc2b9dd58de78ceacf37cc085d18', '5954f7aee33d7334cfa0516b0b81b41bdaf7c238'}",51,"{'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'b1464ca857593c049873421db2f37bf2d0ff676d', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['D. Avola', 'Marco Cascio', 'L. Cinque', 'Alessio Fagioli', 'G. Foresti', 'Marco Raoul Marini', 'Fabrizio Rossi']",D. Avola,"D. Avola, Marco Cascio, L. Cinque, Alessio Fagioli, G. Foresti, Marco Raoul Marini, Fabrizio Rossi",17.647058823529413
1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af,Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection,2021-11-17,"Anomaly detection is commonly pursued as a one-class classification problem, where models can only learn from normal training samples, while being evaluated on both normal and abnormal test samples. Among the successful approaches for anomaly detection, a distinguished category of methods relies on predicting masked information (e.g. patches, future frames, etc.) and leveraging the reconstruction error with respect to the masked information as an abnormality score. Different from related methods, we propose to integrate the reconstruction-based functionality into a novel self-supervised predictive architectural building block. The proposed self-supervised block is generic and can easily be incorporated into various state-of-the-art anomaly detection methods. Our block starts with a convolutional layer with dilated filters, where the center area of the receptive field is masked. The resulting activation maps are passed through a channel attention module. Our block is equipped with a loss that minimizes the reconstruction error with respect to the masked area in the receptive field. We demonstrate the generality of our block by integrating it into several state-of-the-art frameworks for anomaly detection on image and video, providing empirical evidence that shows considerable performance improvements on MVTec AD, Avenue, and ShanghaiTech. We release our code as open source at: https://github.com/",https://www.semanticscholar.org/paper/1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '57b2198f9a8df773425aa6cc88c9870cb07779e2', '702bf4e263f35d3ca9e04d1d4fd6df8acef34b20', '68661cad6ee64aa0b0eea029a50b65286525a58a', 'a538b05ebb01a40323997629e171c91aa28b8e2f', 'e4667dab1f686537b66806b9061275f8ee1eba85', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '62b77e5cb85fc61b84edd532f6d65714be152596', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '711cb048076ec8f297efe4cb2c77c1ed95c0ccc4', '785a7e01267683deb54a94f6a8b4019806e3f085', '0e67f4b94716f22f02058a49068e256cd0c074f1', '2e8d62277e40d465343e8dfb32ecc246f320540e', '73ceefaa861d5e1ad6a06996fa3793a8b0417bff', '5472fc060d6d22ed3b055732013ac767eb522fa4', '6869ab1f42e30b415829de9928f7e4a606113601', 'ae37774ff871575b7799411bf87f42eb52634390', 'c84462f6cea04ee6301e306e2a2b2a70aeaa7dd3', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'e5366a704ffa3b41aacd385f3c087ec3fd566934', '3262e77099cefe24cff1308f204e673cac832451', 'a70bc416b1124525499b0ac3d5b009637dc6c187', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'c3113eaad326a955ba96c11b7b65d0c065fb2054', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'ae97c81b45780dc91e18eb84236d8a40a290b329', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '355b4e74774798c177c82943eef925d66a2bb2ce', '91e647bd24f76e56c11016c7a45e328c0ea6ae24', None, '3dab77815d36acfda913e48738ce1f63dde4b336', '41747cbdbed84762dfbfc305254c97021279dc6e', '63a8ad8721ae8f15f3ad27b2974aff2f90d10022', '6fe7585e24089abbdcf534ee4131983e38e4c1c8', '8a916608e81eea5d7494e577c8563cae44a1b8c6', '731a2844c5af6b072d3b404ecabbb488cdad9d46', '060fae6af2ca91b31be8542bf2abca91e803388b', 'fe09f7a379944444201552e952b910188c0aeaca', '96d7a07237e146c28173767dfc6290a337696c04', 'f36f8d32252679f4221c3d2afc2407a9f56b29a7', '8c81ec9f95b30e72a1140fabd689f75b1ba3cbcb', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '992847be33f4bf7afbe66e198cb20a53e00dfa76', '89b4fb65abb4a81bc492c3b686f5dfc5f175546d', 'e37daeaa20bc8cd68db07641201faf1db3b8c31d', '75958d03eef63751ab3522be685b8881f9d6bb25', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '9d5290fadb7625862a966e0330bd0f9e111fc99d', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', 'aae932cf9c2434f52b03991fcab050a61a960d48', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', '692c508e51e2b943d01caad5c06c1b1c24cb4a23', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '1df6db34c477aa43218f2efc4ec5458eaf734849', '094ac7510d1723cb9c2da01db47291322aa29025', '6f68ce1e03c56c186256dac689a21f6405ae8d96', 'c4c06578f4870e4b126e6837907929f3c900b99f', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'a4c94b221062d0737ee967affa80ce2110cc50c0', '47638197d83a8f8174cdddc44a2c7101fa8301b7', '5cccc8bab11927e5527dd5b917ed4c306a2ccf49', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '1a2a770d23b4a171fa81de62a78a3deb0588f238', 'ee1d50a0c6448253eaf8d1f7f6b00d893419589d', '241cca17a6218728064eea0505a7b8e2e5db4c87', 'b1464ca857593c049873421db2f37bf2d0ff676d', '1442cb4613c99924f500ebdc2a7fdaf2e9080da5', 'df67d46e78aae0d2fccfb6212d101a342259c01b', 'b9bdc61d63d75d82f24de21be26f61879df5a01b', '02d0ef096d3b39bb83a344393522360aaf69d694', 'c2b733a79db700b971327a58ef42699fe8a416aa', '83f6d84389dcdc25a4a1462044d7b1cbc2e75eac', '3a6b9d1743908da5f45113de4a06a3c5c9bbe9ec', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '84f7f9e121c1285e15cefbfc44bcb3322f73b6aa', '598fe25743f9492c5c1ba30274ea446f65426d85'}",84,"{'6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",10,"['Nicolae-Catalin Ristea', 'Neelu Madan', 'Radu Tudor Ionescu', 'Kamal Nasrollahi', 'F. Khan', 'T. Moeslund', 'M. Shah']",Nicolae-Catalin Ristea,"Nicolae-Catalin Ristea, Neelu Madan, Radu Tudor Ionescu, Kamal Nasrollahi, F. Khan, T. Moeslund, M. Shah",11.904761904761905
3f95b7336938d091c31cea7a07fb6292ffb7a367,CAINNFlow: Convolutional block Attention modules and Invertible Neural Networks Flow for anomaly detection and localization tasks,2022-06-04,"Detection of object anomalies is crucial in industrial processes, but unsupervised anomaly detection and localization is particularly important due to the diﬃculty of obtaining a large number of defective samples and the unpredictable types of anomalies in real life. Among the existing unsupervised anomaly detection and localization methods, the NF-based scheme has achieved better results. How-ever, the two subnets (complex functions) 𝑠 𝑖 ( 𝑢 𝑖 ) and 𝑡 𝑖 ( 𝑢 𝑖 ) in NF are usually multilayer perceptrons, which need to squeeze the input visual features from 2D ﬂattening to 1D, destroying the spatial location relationship in the feature map and losing the spatial structure information. In order to retain and eﬀectivelyextractspatialstructureinformation, wedesigninthisstudyacomplexfunctionmodelwith alternating CBAM embedded in a stacked 3∙3 full convolution, which is able to retain and eﬀectively extract spatial structure information in the normalized ﬂow model. Extensive experimental results on the MVTec AD dataset show that CAINNFlow achieves advanced levels of accuracy and inference eﬃciency based on CNN and Transformer backbone networks as feature extractors, and CAINNFlow achieves a pixel-level AUC of 98 . 64% for anomaly detection in MVTec AD.",https://www.semanticscholar.org/paper/3f95b7336938d091c31cea7a07fb6292ffb7a367,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '89b4fb65abb4a81bc492c3b686f5dfc5f175546d', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'c8b25fab5608c3e033d34b4483ec47e68ba109b7', 'de95601d9e3b20ec51aa33e1f27b1880d2c44ef2', '4758baad6b22c61682e7f7182bb93723046f36f5', '11d7a5b5b237fb3be8258661860a8245939b38b1', 'a0288be4a10f3404b1cd4ee2a886d552aeddb74a', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'b364cdb02d18b9d9a3c097f5ea446f7e9ab10325', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '04513c7c0b3a63fde81a996dae064a28d453c17a', 'b1464ca857593c049873421db2f37bf2d0ff676d', None, '5f37e206b411949ddcd8352a4f47e4b5980a0ccf', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '6c551fa9bdfb3c1e285bc9fa69e4c89a736af3e7', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', 'b4cfbefc7cc3217c133c75d48ace1cddc078d870', 'd7ddc4830c2ab415949ad09ecfbb674e9e492623', 'ad7ddcc14984caae308c397f1a589aae75d4ab71', '31b38a19d87711489786ad54a5a00d5f0b2ead43', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",25,"{'4758baad6b22c61682e7f7182bb93723046f36f5', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'b1464ca857593c049873421db2f37bf2d0ff676d', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['Rui Yan', 'Fan Zhang', 'Mengyuan Huang', 'Wu Liu', 'Dongyu Hu', 'Jinfeng Li', 'Qiangwei Liu', 'Jingrong Jiang', 'Qi Guo', 'Li-Ting Zheng']",Rui Yan,"Rui Yan, Fan Zhang, Mengyuan Huang, Wu Liu, Dongyu Hu, Jinfeng Li, Qiangwei Liu, Jingrong Jiang, Qi Guo, Li-Ting Zheng",36.0
90fb88d0f2586ac1559bd33a5f5ae0dcae7c8e94,Unsupervised Change Detection Based on Image Reconstruction Loss,2022-04-04,"To train a change detector, bi-temporal images taken at different times in the same area are used. However, collecting labeled bi-temporal images is expensive and time consuming. To solve this problem, various unsupervised change detection methods have been proposed, but they still require unlabeled bi-temporal images. In this pa-per, we propose an unsupervised change detection method based on image reconstruction loss, which uses only a single-temporal unlabeled image. The image reconstruction model was trained to reconstruct the original source image by receiving the source image and photometrically transformed source image as a pair. During inference, the model receives bi-temporal images as input and aims to reconstruct one of the inputs. The changed region between bi-temporal images shows high reconstruction loss. Our change detector demonstrated significant performance on various change detection benchmark datasets even though only a single-temporal source image was used. The code and trained models are available in https://github. com/cjf8899/CDRL",https://www.semanticscholar.org/paper/90fb88d0f2586ac1559bd33a5f5ae0dcae7c8e94,"{'8ecf9e6428edd33986e8c6a143870e57142fd5a1', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2778c4820d364ab8d0e28166de7a0045b1e8dc2f', '677a0b9915da01e738a83aa8821d13eb403870b3', '599fd051c9438011ec5b581983c89e8922b4a5e6', '098c1f4d9711d7f11a165966afc33c5a89eb22b3', '3db31580f60e7277988129cee3df16097f4d5d6b', '18755de13d2d868255bbf332fa80ec218163c74e', 'de95601d9e3b20ec51aa33e1f27b1880d2c44ef2', 'bc09595c1f68d95a41ed047c252f0d3f48b9fdaa', 'ae15e5ccccaaff44ab542003386349ef1d3b7511', 'fedf0d43fbef3d14ad5bf0703ab93aa52f449977', 'bb1bf1b45c130799ad47c20988260e43136348eb', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '59be2e766fe2cd02b150a3e469a97a53ccf9b8db', '8acbe90d5b852dadea7810345451a99608ee54c7', 'dd6d044696df5e4353ff7c92b8009e1201c85129', '9d1ccc5e9fc128742de34c86b219580b864b49c8', '53edb3776cea0e6ee4de742d7bb906355fd8279b', None, '37b6a294e495481e4fb7a4ebac8a86231c7f13ff', '390edb296680d59e121303bed4b1407212caefbf', 'b569ea0c49ee43437949702edc46eab341ab2eeb', 'b8f213521073f520b8f209e92a2eb432d673935a', 'f03b13d30654092129b18487393bec5cc51df3c2', 'e637a7d64eace9d84d4c39b6c8b96fd4f0a67911', '152954530e24e701a9a1132eba602504e718a9f2', '937b84e9544db2b64919d88d9db6eb60bee3a569', '6e48d6a447f31a4b545b924ed1482d76c4860ae7', '549fcde12d071b55f2e0f2a494de491e7fb97140', '0ef424ce5b01c8284acef2b8e30dae80429bed84', 'c93b0d1b6676395467094b2a7c4ce2a76a86f91f', '905f9de367669451ffdc7e63e614d268cbf41790', 'f6bcd71d782f4c34a19d804af0465c0391586274'}",35,{'78d80c343d36baaf89f18e12d325cf6309fb6c8f'},1,"['Hyeon-cheol Noh', 'Jin-gi Ju', 'Min-seok Seo', 'Jong-Dae Park', 'Dong-geol Choi']",Hyeon-cheol Noh,"Hyeon-cheol Noh, Jin-gi Ju, Min-seok Seo, Jong-Dae Park, Dong-geol Choi",2.857142857142857
ab96c776f96e10f10d88ac5abbe9335afe935c81,MOCCA: Multilayer One-Class Classification for Anomaly Detection,2020-12-09,"Anomalies are ubiquitous in all scientific fields and can express an unexpected event due to incomplete knowledge about the data distribution or an unknown process that suddenly comes into play and distorts the observations. Usually, due to such events’ rarity, to train deep learning (DL) models on the anomaly detection (AD) task, scientists only rely on “normal” data, i.e., nonanomalous samples. Thus, letting the neural network infer the distribution beneath the input data. In such a context, we propose a novel framework, named multilayer one-class classification (MOCCA), to train and test DL models on the AD task. Specifically, we applied our approach to autoencoders. A key novelty in our work stems from the explicit optimization of the intermediate representations for the task at hand. Indeed, differently from commonly used approaches that consider a neural network as a single computational block, i.e., using the output of the last layer only, MOCCA explicitly leverages the multilayer structure of deep architectures. Each layer’s feature space is optimized for AD during training, while in the test phase, the deep representations extracted from the trained layers are combined to detect anomalies. With MOCCA, we split the training process into two steps. First, the autoencoder is trained on the reconstruction task only. Then, we only retain the encoder tasked with minimizing the $L_{2}$ distance between the output representation and a reference point, the anomaly-free training data centroid, at each considered layer. Subsequently, we combine the deep features extracted at the various trained layers of the encoder model to detect anomalies at inference time. To assess the performance of the models trained with MOCCA, we conduct extensive experiments on publicly available datasets, namely CIFAR10, MVTec AD, and ShanghaiTech. We show that our proposed method reaches comparable or superior performance to state-of-the-art approaches available in the literature. Finally, we provide a model analysis to give insights regarding the benefits of our training procedure.",https://www.semanticscholar.org/paper/ab96c776f96e10f10d88ac5abbe9335afe935c81,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2dfa0397ce43beac275324dff781a9103ec99b1f', 'b0b2eeacea23acb05968624f130573dab32e98b3', '3ace1d1b06db1e618c4ebfdf005412d7e5d8bd18', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '3bf418882a9de772eed10b3177f92f541d1735a6', '599fd051c9438011ec5b581983c89e8922b4a5e6', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '497e1979d8587fa28c7dd349568f2703030cd000', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'ad7df5dcf5a70c5b1f53782eda629e1bc903927b', '5db790198b9acf4e5efe350acdd814238fcacaa7', '1bc042ec7a58ca8040ee08178433752f2c16f25e', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '902be4fcfb79d6e8c1a315d012dcd2d186b39eca', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '4d8abae45a5492ed2399fd5e25eeade8ac0bfa0f', 'f076e4355c0facf111716dcab2837803367dd2d8', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', '7c75203739f5f89e109b11144d170d4d3f2a6abc', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '4d129c88f65944854b88a9f88666bf9f0d855f38', '295aca7669f54cdc746c595088693bb102855b9f', 'e716698a6d28e7a47bea9b25dbc5df0da2d07158', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '71c97e7d4a529a21f32d98aad72fbbf32c9ee32e', 'd60a44ba79f79b18b2e2eac34673449e79ac2eb4', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'f7174c5c29c3904cc2d23f26be2b896a5bc715b4', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '01be7624aa0e0251182593350a984411c2e5128a', 'b508b1a9bd9350fd6063453cc2e522dfc2e3510e', 'a84bc1216f508ecdd8bb310e21d5f9bd15dc66d5', '2b50026b7b1054ef8e3643fcd7ef89d7b278a068', '1f528877c4d8d5df3b3abbfa64379677d451956b', 'd05d86db86a4ac0d95e6dcd951b42a9651939793', '6af440915b8a0718c93be1cf61905e41e620484a', '00695a31a80221c7125e49885a4767896ec2c4f7', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'd1edd4c9305cd4e080312ba28d8242a5a49cbd99', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', 'a57b50cfa4136171ef04c3ef9ed8d08acfe6ea9e', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, 'c2b733a79db700b971327a58ef42699fe8a416aa', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '261e81cba749f70271fa4b7e230328fc1a4a6c96', '41747cbdbed84762dfbfc305254c97021279dc6e', '883b811e44dfcb6ba101fbbf54534bde282e9858', '9fcadebc4fe00f033ea213a1fa974d46c2852eec', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '8381157eae4fbf8908d0312a9642f8e69e944449', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '9a679663be4981d99b79f28dc946ac24344935d6', '0936352b78a52bc5d2b5e3f04233efc56664af51', '598fe25743f9492c5c1ba30274ea446f65426d85', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",69,"{'1f528877c4d8d5df3b3abbfa64379677d451956b', '295aca7669f54cdc746c595088693bb102855b9f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', 'f7174c5c29c3904cc2d23f26be2b896a5bc715b4', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e'}",8,"['F. V. Massoli', 'F. Falchi', 'Alperen Kantarci', 'cSeymanur Akti', 'H. K. Ekenel', 'G. Amato']",F. V. Massoli,"F. V. Massoli, F. Falchi, Alperen Kantarci, cSeymanur Akti, H. K. Ekenel, G. Amato",11.594202898550725
4b987225ce76093d1fab5ddfde3bf3e2ae686f85,DCSNet: A Surface Defect Classification and Segmentation Model by One-Class Learning,,"Researches in surface defect classification and segmentation technology have been seen significant progress in recent years. However, there are few works on One-Class learning in this direction by a single model. In previous researches, some problems remain unsolved in the surface defect detection methods, e.g. the training needs a large number of samples and these models cannot classify and locate the surface defect accurately, etc. The main contribution in this work is that we summarize the overall ideas of previous research in network design and propose a multi-task model which could be trained only using a few of positive samples. Meanwhile, the experiments on AITEX detection datasets[1] which get 84.4% DR, 4.4% FAR and 34.2% MIOU, and conduct an ablation experiment in real industrial product dataset to validate the effect of different backbones on DCSNet. It’s worth mentioning that DCSNet provides a solution to the task of surface defect classification and segmentation based on One-Class learning. The code will be open source in ext-link-type=""uri"" xmlns:xlink=""http://www.w3.org/1999/xlink"" xlink:href=""https://agit.ai/wyxxx/zhengtu"">https://agit.ai/wyxxx/zhengtu.",https://www.semanticscholar.org/paper/4b987225ce76093d1fab5ddfde3bf3e2ae686f85,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'c8c494ee5488fe20e0aa01bddf3fc4632086d654', '5187df17503f78c7e063c2ea0a707e3e59c48235', '79219730ca0c4dc03e4d46019722347d02650047', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '904decf94f5495d1488e2bf22e3ed4df500ce4d5', '8950c711df55516df9183a2650c9475d87a4249e', '614d808f4115ff738c44168cb8e7784f33c8bf8a', '5b55d69c4b5f9a371f04944453283ed36ddb90ce', '5435a9ab36a308cef10bc725104e8f778ed3a328', '7342236608a62494ce357e95d5ebecdf8657c357', '8acbe90d5b852dadea7810345451a99608ee54c7', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', None, 'ba70e8f06b0d1df040363904ff8bdbc749191c62', '5f61089d3d548a515f01b473f0119137d1f340d4', 'c707517507873bc2cdc489b6fd9af74770468c48', '10ae15147d0bc0d6d06ceaae28165bf8646ae478', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'a8f3dc53e321fbb2565f5925def4365b9f68d1af', '1db6e3078597386ac4222ba6c3f4f61b61f53539', 'b0f49ada8e9454048faf17f66d5e7520d5e46e98', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539'}",25,{'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3'},1,"['W. Yuxiang', 'Mu Shiyi', 'Xie Xiang', 'Huang Shanshan']",W. Yuxiang,"W. Yuxiang, Mu Shiyi, Xie Xiang, Huang Shanshan",4.0
7b2180d7fa0d65e8756401cb077bf3dea3f9b575,Generalized Out-of-Distribution Detection: A Survey,2021-10-21,"—Out-of-distribution (OOD) detection is critical to ensuring the reliability and safety of machine learning systems. For instance, in autonomous driving, we would like the driving system to issue an alert and hand over the control to humans when it detects unusual scenes or objects that it has never seen during training time and cannot make a safe decision. The term, OOD detection, ﬁrst emerged in 2017 and since then has received increasing attention from the research community, leading to a plethora of methods developed, ranging from classiﬁcation-based to density-based to distance-based ones. Meanwhile, several other problems, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD), are closely related to OOD detection in terms of motivation and methodology. Despite common goals, these topics develop in isolation, and their subtle differences in deﬁnition and problem setting often confuse readers and practitioners. In this survey, we ﬁrst present a uniﬁed framework called generalized OOD detection , which encompasses the ﬁve aforementioned problems, i.e ., AD, ND, OSR, OOD detection, and OD. Under our framework, these ﬁve problems can be seen as special cases or sub-tasks, and are easier to distinguish. We then review each of these ﬁve areas by summarizing their recent technical developments, with a special focus on OOD detection methodologies. We conclude this survey with open challenges and potential research directions.",https://www.semanticscholar.org/paper/7b2180d7fa0d65e8756401cb077bf3dea3f9b575,set(),0,set(),0,"['Jingkang Yang', 'Kaiyang Zhou', 'Yixuan Li', 'Ziwei Liu']",Jingkang Yang,"Jingkang Yang, Kaiyang Zhou, Yixuan Li, Ziwei Liu",
ee82134086e069bb93d960ef1caa8a101966f984,About the Application of Autoencoders For Visual Defect Detection,,"Visual defect detection is a key technology in modern industrial manufacturing systems. There are many possibleappearances of product defects, including distortions in color, shape, contamination, missing or superfluous parts.For the detection of those, besides traditional image processing techniques, convolutional neural networks basedmethods have also appeared to avoid the usage of hand-crafted features and to build more efficient detectionmechanisms. In our article we deal with autoencoder convolutional networks (AEs) which do not require examplesof defects for training. Unfortunately, the manual and/or trial-and-error design of AEs is still required to achievegood performance, since there are many unknown parameters of AEs which can greatly influence the detectionabilities. For our study we have chosen a well performing AE known as structural similarity AE (SSIM-AE),where the loss function and the comparison of the output with the input is implemented via the SSIM instead ofthe often used L1 or L2 norms. Investigating the performance of SSIM-AE on different data-sets, we found that itsperformance can be improved with modified convolutional structures without modifying the size of latent space.We also show that finding a model with low reconstruction error during training does not mean good detectionabilities and denoising AEs can increase efficiency.",https://www.semanticscholar.org/paper/ee82134086e069bb93d960ef1caa8a101966f984,"{'6fa5b0c277908eab5d8b80e4894fd4ed08cc0824', '57ea5292caabc5e0d7fb1de2734b81ba5be76d27', 'f6ec4dea25e7643e44099c86291bbf82dd185818', '7e9e2006ed05fb92986ede10a62c4050afe3b351', '82b223712aa01f2261795658a6d1adeec0bb8bd3', '52482099e634fc0a298c6051f6f4cd51e4112d94', '589799bbf4c9975345478e92e4d2733df6fdf392', '354923bc917ac774438a048b87db9fabed4d757e', '7d0238c6b647d027e060193ae440e98e2a28f610', '9179e740dad4ca4c183f7677b854e5b15f9a122f', 'ed8f6ddd2d4dcac7c4a803808d2615960c94585b', '9e2bb72595f7ff0a5a5d3dc98600b8c5342c3fb4', 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', '4eaa135bcba22a0596515e8f5ee48a26ae6523ab', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '732750bec3b4d8c0108d6daed642500765d5c0ca', '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', '5c6eea437f24b9fac9487f16a9166ea9ef491e27', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539'}",23,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Richárd Rádli', 'L. Czúni']",Richárd Rádli,"Richárd Rádli, L. Czúni",4.3478260869565215
5da4eb1135d5827ce30e099bda377a19f3a52730,The MVTec 3D-AD Dataset for Unsupervised 3D Anomaly Detection and Localization,2021-12-16,": We introduce the ﬁrst comprehensive 3D dataset for the task of unsupervised anomaly detection and localization. It is inspired by real-world visual inspection scenarios in which a model has to detect various types of defects on manufactured products, even if it is trained only on anomaly-free data. There are defects that manifest themselves as anomalies in the geometric structure of an object. These cause signiﬁcant deviations in a 3D representation of the data. We employed a high-resolution industrial 3D sensor to acquire depth scans of 10 different object categories. For all object categories, we present a training and validation set, each of which solely consists of scans of anomaly-free samples. The corresponding test sets contain samples showing various defects such as scratches, dents, holes, contaminations, or deformations. Precise ground-truth annotations are provided for every anomalous test sample. An initial benchmark of 3D anomaly detection methods on our dataset indicates a considerable room for improvement.",https://www.semanticscholar.org/paper/5da4eb1135d5827ce30e099bda377a19f3a52730,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '5b589d7564dbef07ec98b3248f58a481b4ca1395', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'e52e37cd91366f07df1f98e88f87010f494dd16e', '40709121423d2d332c72057fd2268382a98fb8e9', 'b72771c316d60190aff053ef8a216ba57d62f541', '4758baad6b22c61682e7f7182bb93723046f36f5', '2094f315289ccf9b676e0790fb3dd1bc4acad98c', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', '59872ac0afd6cb32e2e2b643b53d44d176c409ab', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '1fbbe6fcf6465bab87b9ae55bc5fd23c528f24b9', '7c8a51d04522496c43db68f2582efd45eaf59fea', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'aae932cf9c2434f52b03991fcab050a61a960d48', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'dc3f8c8513441915408ab0549e9ac5f2f2f31eec', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '41747cbdbed84762dfbfc305254c97021279dc6e', '3d07e8d62961e6b25869d4d90523157dc94eb484', '219f7706e28c91dcff3d6c4273ac71868714cac2', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '9b686d76914befea66377ec79c1f9258d70ea7e3', '6c7ac8563ddd0582f7353add31b8bac52008a577', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '108291a9ac15c5384f4a55f0b6b7e89a1dbe40d8', '94be3df88de438fa8326b6ef766f538ccbebcacb', '580062407427236ced45253a2ff7df2e147a81e2', '598fe25743f9492c5c1ba30274ea446f65426d85', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '722ff8967633d0806298c22d25a845da222615f3'}",37,"{'4758baad6b22c61682e7f7182bb93723046f36f5', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '9277dc70c74bcadf80dab11c28ead83fd085deec', '48f9a48aa5b1230b05a443d2d531e6441a541686', '41747cbdbed84762dfbfc305254c97021279dc6e'}",5,"['Paul Bergmann', 'Xin Jin', 'David Sattlegger', 'C. Steger']",Paul Bergmann,"Paul Bergmann, Xin Jin, David Sattlegger, C. Steger",13.513513513513514
5bb4293f57bdc4bebda402bd4fe39ee3cf5d3e16,Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies,2021-09-21,"—Data augmentation can be a simple yet powerful tool for autonomous robots to fully utilise available data for self-supervised identiﬁcation of atypical scenes or objects. State-of- the-art augmentation methods arbitrarily embed “structural” peculiarity on typical images so that classifying these artefacts can provide guidance for learning representations for the detection of anomalous visual signals. In this paper, however, we argue that learning such structure-sensitive representations can be a suboptimal approach to some classes of anomaly (e.g., unhealthy fruits) which could be better recognised by a different type of visual element such as “colour”. We thus propose Channel Randomisation as a novel data augmentation method for restricting neural networks to learn encoding of “colour irregularity” whilst predicting channel-randomised images to ultimately build reliable fruit-monitoring robots identifying atypical fruit qualities. Our experiments show that (1) this colour-based alternative can better learn representations for consistently accurate identiﬁcation of fruit anomalies in various fruit species, and also, (2) unlike other methods, the validation accuracy can be utilised as a criterion for early stopping of training in practice due to positive correlation between the performance in the self-supervised colour-differentiation task and the subsequent detection rate of actual anomalous fruits. Also, the proposed approach is evaluated on a new agricultural dataset, Riseholme-2021 , consisting of 3 . 5 K strawberry images gathered by a mobile robot, which we share online to encourage active agri-robotics research.",https://www.semanticscholar.org/paper/5bb4293f57bdc4bebda402bd4fe39ee3cf5d3e16,"{'a970d6b162cfdde4258cc2c356190cf516927b51', '599fd051c9438011ec5b581983c89e8922b4a5e6', '732c21998e251d64cd58b6a86886ee5907efeaa5', 'db787640c9b42416ff8d7015546e667e58267177', '193f1a5b18e4dc90f54991b338e7efaf687e76e8', '3f611458b84ca8756c863916b33d12c704687127', '62b77e5cb85fc61b84edd532f6d65714be152596', '4ef6bf7578dcf3e28b462cd95a748e71c0ecf2ee', '37595f7a51982d776e57c7280b9445474d90f0be', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'a88be391948096bbb58ad1634ac0ddf67680ccef', '6af440915b8a0718c93be1cf61905e41e620484a', '164b8826b9a30adf69630e634b308046b8cec619', '039c2290e442f14771432066d2af42a14263d3b2', '48f9a48aa5b1230b05a443d2d531e6441a541686', '66d93532f450a36e01257ba9dddfdf878797a583', None, 'de55125fd720d7ccfa2640a92a8f955d72bb3d22', '053a03dad97cf7c3545ab1bfb363df343a59dba3', '360ef12906a531733b66e7e15c3d51771e7126d3', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'eb42cf88027de515750f230b23b1a057dc782108', 'eb35fdc11a325f21a8ce0ca65058f7480a2fc91f', 'e620d4642aee03a77a8ac73bb292e5bfd537cbcb', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '8381157eae4fbf8908d0312a9642f8e69e944449', 'abffc705d611f3b7451900e9e5a5b805907654d0', 'de40803a3d17dd406e25922695266d6ed580e371', 'c19f0b28aee99a47b715e6eb3cb63cdf25439393', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '6bfa8f8b09ec21fe06d4eee28c3fb6cce879be1d', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '202ce0a39dbabe27041592746cdd1a0a9b666a4c'}",33,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', '62b77e5cb85fc61b84edd532f6d65714be152596', '37595f7a51982d776e57c7280b9445474d90f0be'}",3,"['Taeyeong Choi', 'Owen Would', 'A. Gomez', 'Grzegorz Cielniak']",Taeyeong Choi,"Taeyeong Choi, Owen Would, A. Gomez, Grzegorz Cielniak",9.090909090909092
10a83f9a07c803ceef8e09e12ad606dc74ea76b8,The Fishyscapes Benchmark: Measuring Blind Spots in Semantic Segmentation,2019-04-05,,https://www.semanticscholar.org/paper/10a83f9a07c803ceef8e09e12ad606dc74ea76b8,"{'79828e6e9f137a583082b8b5a9dfce0c301989b8', 'bb66ae5f36bc84243979c522d8e3f93539cb6a9f', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '802168a81571dde28f5ddb94d84677bc007afa7b', '927ee108115e03cc14c70e567b044e66423fb54b', '5db790198b9acf4e5efe350acdd814238fcacaa7', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '904627c2d5a91ab8cb1b682e42f06f1ca192aea6', '2f7e8d0cfe601b9bb3d07d7783ecd80424994517', 'cd69b4cb74582a5a20963c7790fcd98a735528df', '1c46943103bd7b7a2c7be86859995a4144d1938b', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '67a6db6990b06b00eb4f67b1efbb8961c74be54c', 'ff7bcaa4556cb13fc7bf03e477172493546172cd', '699a2e3b653c69aff5cf7a9923793b974f8ca164', '1330d1be226904d6421c378c138bb26fb08b00c3', '63b059cdad77906ff381515b3cfac21757e5e64c', 'e9a88a25b4d6332de95d829b5a892275dc3ffcfc', 'd1ad11dda6399193ff7c3242cba9c9a2feb13e78', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '431ba9fae8fccad1665979d455c6307786e47318', 'de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42', '9e475a514f54665478aac6038c262e5a6bac5e64', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '8acbe90d5b852dadea7810345451a99608ee54c7', '70f9968a356d840040a1c9207906f60376dc6bd4', '9d67af2158807aa815b5a4485b076f7a18ce6ab4', '85d9aff092d860aebf8ea5aa255b06de25a1930e', '9335e093f439e926562270bbab87e25652da8412', None, '5712edce918859a9b22471dd0ed78ef4ea1fc724', 'ff6af0d04b36bfcf16a70e22f4815013ef2f59f0', '3c623c08329e129e784a5d03f7606ec8feba3a28', '9fcb88ec529aba79a5860e8fde76e7f4762a267d', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', 'dcae0bfe55c3e08812ee54297ef073bcf790be04', 'f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6', '4f44339001f95c7d66064a1d02024a157346cc58', '88dd006841fa16ba17f461b35d8b3e48a4f29ee4', 'd92ef81e39d65d89f2c35d63088d1950ed862e7d', 'd285fff675bf7a3d7d19516e4f53fbff15881885', 'b44313836f435c8c774f9123cc29a38ad8deb7bd', 'b0c065cd43aa7280e766b5dcbcc7e26abce59330', '2b50026b7b1054ef8e3643fcd7ef89d7b278a068', '6af440915b8a0718c93be1cf61905e41e620484a', '2c564489c40fd252c57d2944e3aebb62280499bf', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', '6ff2a434578ff2746b9283e45abf296887f48a2d', 'f4e13cd721fa7d4c44fd7613542d49f776d2b63a', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', 'ce05ebc31e7aa8e4152673bb240b9f8d27ebea21', '763aa50583ed047528ba4ef471d72bfbe34471e6', '8381157eae4fbf8908d0312a9642f8e69e944449', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', 'd65ce2b8300541414bfe51d03906fca72e93523c', '282578039c767f3d393529565cae6be56fda6242', 'af9280741ef627f0d6c8437605d002d3bfc2d1b1', '07e3db9c2034b522c3cf04399602cc7124964306', 'c8c494ee5488fe20e0aa01bddf3fc4632086d654', 'c45bfe571fc69767775c21ecef4e37f6030622a3', 'f968c45a0da4c92e76106a16f6fbd3dce229b46a', '97bb928a9db5c9546e7de8c38ba52da7695f7b65', '547c854985629cfa9404a5ba8ca29367b5f8c25f', '2da694d7f494265a8193f17dfc492c577ad4db1e', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'ea99a5535388196d0d44be5b4d7dd02029a43bb2', '8c25071e5b2045843c4cab3fb9f51b7258347236', '36653f8705b56e39642bcd123494eb680cd1636b', '9217e28b2273eb3b26e4e9b7b498b4661e6e09f5', '229e105fd4d34815e476702dd5ca4362943c475d', 'f0a0c0f0d6a7ff53abea40a8c0c678ed570bf851', '74f38e6667f52e6104ca65f51fe535df3e0c03ac', '82635fb63640ae95f90ee9bdc07832eb461ca881', '1839a2465e8793400f1a2115a496d3d0f9ea135f', 'cf7d9f4499ab8444b3b801a1e245337691397e01', 'f397d5e75e8799cebf32a9e095b4cc4f02fe7cac', 'dc8301b67f98accbb331190dd7bd987952a692af'}",78,{'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3'},1,"['Hermann Blum', 'Paul-Edouard Sarlin', 'Juan I. Nieto', 'R. Siegwart', 'César Cadena']",Hermann Blum,"Hermann Blum, Paul-Edouard Sarlin, Juan I. Nieto, R. Siegwart, César Cadena",1.2820512820512822
295aca7669f54cdc746c595088693bb102855b9f,Combining GANs and AutoEncoders for efficient anomaly detection,2020-11-16,"In this work, we propose CBiGAN - a novel method for anomaly detection in images, where a consistency constraint is introduced as a regularization term in both the encoder and decoder of a BiGAN. Our model exhibits fairly good modeling power and reconstruction consistency capability. We evaluate the proposed method on MVTec AD - a real-world benchmark for unsupervised anomaly detection on high-resolution images - and compare against standard baselines and state-of-the-art approaches. Experiments show that the proposed method improves the performance of BiGAN formulations by a large margin and performs comparably to expensive state-of-the-art iterative methods while reducing the computational cost. We also observe that our model is particularly effective in texture-type anomaly detection, as it sets a new state of the art in this category. Our code is available at https://github.com/fabiocarrara/cbigan-ad/.",https://www.semanticscholar.org/paper/295aca7669f54cdc746c595088693bb102855b9f,"{'e6abdb5bd4fcdfbcf6b10e715f5e9f531acd750a', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '571b0750085ae3d939525e62af510ee2cee9d5ea', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', '21898ef765d26d82f7d7ec290dbf7610127b1acb', '5db790198b9acf4e5efe350acdd814238fcacaa7', '1bc042ec7a58ca8040ee08178433752f2c16f25e', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '87f42406de084e60d2365adac8a159ed3e455856', 'c8aa832362422418287ff56793c780b425afa93f', '1f528877c4d8d5df3b3abbfa64379677d451956b', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', 'fcf43325529c8b1cc26aeb52fd5d7e532abb0a40', 'a57b50cfa4136171ef04c3ef9ed8d08acfe6ea9e', None, 'c2b733a79db700b971327a58ef42699fe8a416aa', 'e3d8a9d35232d7967780019f0fa93626ca1373cb', '5f61089d3d548a515f01b473f0119137d1f340d4', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '1db6e3078597386ac4222ba6c3f4f61b61f53539', '19b14bc5ca655db8b0a60eb06c6bfe681dfd30f9', '34008f26cec7fae1f60b8da38abb6b012bf83e13', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'd2c389c88828728ba4284d66d937f51257840234', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",37,"{'1f528877c4d8d5df3b3abbfa64379677d451956b', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '363c81a08858df8dd7d1bde79c6e002e3b19f900'}",6,"['F. Carrara', 'G. Amato', 'Luca Brombin', 'F. Falchi', 'Claudio Gennaro Isti Cnr', 'Pisa', 'Italy.']",F. Carrara,"F. Carrara, G. Amato, Luca Brombin, F. Falchi, Claudio Gennaro Isti Cnr, Pisa, Italy.",16.216216216216218
9a8be994e7069236d94e30c4c7b481988effc106,"When, Where, and What? A New Dataset for Anomaly Detection in Driving Videos",2020-04-06,"Video anomaly detection (VAD) has been extensively studied. However, research on egocentric traffic videos with dynamic scenes lacks large-scale benchmark datasets as well as effective evaluation metrics. This paper proposes traffic anomaly detection with a \textit{when-where-what} pipeline to detect, localize, and recognize anomalous events from egocentric videos. We introduce a new dataset called Detection of Traffic Anomaly (DoTA) containing 4,677 videos with temporal, spatial, and categorical annotations. A new spatial-temporal area under curve (STAUC) evaluation metric is proposed and used with DoTA. State-of-the-art methods are benchmarked for two VAD-related tasks.Experimental results show STAUC is an effective VAD metric. To our knowledge, DoTA is the largest traffic anomaly dataset to-date and is the first supporting traffic anomaly studies across when-where-what perspectives. Our code and dataset can be found in: this https URL",https://www.semanticscholar.org/paper/9a8be994e7069236d94e30c4c7b481988effc106,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '7a89447be0a176368926f1ef108512f4df5e27be', '67dccc9a856b60bdc4d058d83657a089b8ad4486', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', 'a7aa69b348701f8efb7bc04f36e93ef85ec8a017', 'c8c494ee5488fe20e0aa01bddf3fc4632086d654', '574ab231627eadc1056162c38d0895f372121250', '6d4c9c923e9f145d1c01a2de2afc38ec23c44253', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6', '3be602c7c3812397a29c64e544981a362de80f27', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '39b6dd39873c4508953cdb45588b4013a5fc21a6', '7ace4330a28ef74f489e581b62cfe21cc9bbc986', 'd25c65d261ea0e6a458be4c50c40ffe5bc508f77', 'db439bcc9088fb9a05c2777cf39a99eeb4e4c5cd', '4a83d9d07cbac4a8a279073e3873d01f3215f2f8', 'edd846e76cacfba5be37da99c006e3ccc9b861b0', '8b47b9c3c35b2b2a78bff7822605b3040f87d699', '792250ae660b7c25f85eeea7dcae623e4301d97c', 'c48def9076e58095c4aea49a8daa931af1990701', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', 'aae932cf9c2434f52b03991fcab050a61a960d48', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', '0b544dfe355a5070b60986319a3f51fb45d1348e', None, 'b61a3f8b80bbd44f24544dc915f52fd30bbdf485', '89c3050522a0bb9820c32dc7444e003ef0d3e2e4', 'b8b4a0bdfb561edaaed971f6e416c641b295376d', '497db84d084c34cf2db8883f95000953deeeddcc', '44d2abe2175df8153f465f6c39b68b76a0d40ab9', '2fa4fee1e09fceef59da1bcc11b6cc9bb65176cd', 'ea3d7de6c0880e14455b9acb28f1bc1234321456', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '527cc8cd2af06a9ac2e5cded806bab5c3faad9cf', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '074aed256f955648461e293d5bce1291c36c3c74', 'db20d81d40243d66ff90f11b5c6f058d43d3701f', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'b9a2361c146d977040aeab96562e6b9dfd3e59fa', 'bcaa81e2150dffcb5dc7bc785285444570443b80', '4cfd770ccecae1c0b4248bc800d7fd35c817bbbd', '1a0912bb76777469295bb2c059faee907e7f3258', '7787488d4b1c0487b4393f44bc3d0148e15cf0c5', '598fe25743f9492c5c1ba30274ea446f65426d85', '9d0907770cd4619aa6a36139a859e8f09bc9f0ef'}",47,set(),0,"['Yu Yao', 'Xizi Wang', 'Mingze Xu', 'Zelin Pu', 'E. Atkins', 'David J. Crandall']",Yu Yao,"Yu Yao, Xizi Wang, Mingze Xu, Zelin Pu, E. Atkins, David J. Crandall",0.0
62b77e5cb85fc61b84edd532f6d65714be152596,Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation,2020-06-29,,https://www.semanticscholar.org/paper/62b77e5cb85fc61b84edd532f6d65714be152596,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '3c052b0dfea5b654dd5ba6a9a7bb2f348a6b9deb', 'a970d6b162cfdde4258cc2c356190cf516927b51', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '599fd051c9438011ec5b581983c89e8922b4a5e6', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '8201e6e687f2de477258e9be53ba7b73ee30d7de', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '9a6ee80121518fadeb21227f9bd9a0f31dfe49b0', '04513c7c0b3a63fde81a996dae064a28d453c17a', '6a25e474075e26ddd18a24cd80deeb1d2ab33b42', '1c46943103bd7b7a2c7be86859995a4144d1938b', 'a2d53ef1ec784b6a126043a45067cd8667b7f7b4', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'b36a5bb1707bb9c70025294b3a310138aae8327a', '90902e16f4e8ff5e3c4bf0f971380af5753aacdd', 'f216444d4f2959b4520c61d20003fa30a199670a', '6ff2a434578ff2746b9283e45abf296887f48a2d', 'e1ffb83f9a2137c048c0f2058770f3c888f5ca4f', '5f0bc5273dec29fa6d3bbd743e0190f8de58d582', 'fd535dbf633f410533f68a39bdfffef0668869ee', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '8381157eae4fbf8908d0312a9642f8e69e944449', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '367f2c63a6f6a10b3b64b8729d601e69337ee3cc', 'c6d2b2889fbacd3b00cd9e3eef35ae897f54620e', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",35,"{'363c81a08858df8dd7d1bde79c6e002e3b19f900', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'e021d59638966a6fbb36854cc2cf1045de7a62d2'}",4,"['Jihun Yi', 'Sungroh Yoon']",Jihun Yi,"Jihun Yi, Sungroh Yoon",11.428571428571429
9277dc70c74bcadf80dab11c28ead83fd085deec,Sub-Image Anomaly Detection with Deep Pyramid Correspondences,2020-05-05,"Nearest neighbor (kNN) methods utilizing deep pre-trained features exhibit very strong anomaly detection performance when applied to entire images. A limitation of kNN methods is the lack of segmentation map describing where the anomaly lies inside the image. In this work we present a novel anomaly segmentation approach based on alignment between an anomalous image and a constant number of the similar normal images. Our method, Semantic Pyramid Anomaly Detection (SPADE) uses correspondences based on a multi-resolution feature pyramid. SPADE is shown to achieve state-of-the-art performance on unsupervised anomaly detection and localization while requiring virtually no training time.",https://www.semanticscholar.org/paper/9277dc70c74bcadf80dab11c28ead83fd085deec,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '8201e6e687f2de477258e9be53ba7b73ee30d7de', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '02b28f3b71138a06e40dbd614abf8568420ae183', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', '10aabf4c13ea57d7106cf809c9edbab63819c277', '94559c249d204110296c39ed4af2042cc4468e68', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '04513c7c0b3a63fde81a996dae064a28d453c17a', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', '6a1dafa29ba6afc4a8755c00690c6c2ccccbd103', '1f528877c4d8d5df3b3abbfa64379677d451956b', 'a48a56b0727d09f599676524fe190308d9e88bf1', '6af440915b8a0718c93be1cf61905e41e620484a', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '41747cbdbed84762dfbfc305254c97021279dc6e', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '4d39ee7cca8fedf792570724255a4357aa41dbf8', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'e99603b5b524485bcf1afb2f01acadc34dfb033c', 'c92ee6ff32fa4833fa1c2bdf29284e2a58ddb640'}",39,"{'1f528877c4d8d5df3b3abbfa64379677d451956b', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e'}",6,"['Niv Cohen', 'Yedid Hoshen']",Niv Cohen,"Niv Cohen, Yedid Hoshen",15.384615384615385
518cadf4765b5e3a84784fade5d205d6b328101f,Semi-Supervised Learning for Defect Segmentation with Autoencoder Auxiliary Module,2022-04-01,"In general, one may have access to a handful of labeled normal and defect datasets. Most unlabeled datasets contain normal samples because the defect samples occurred rarely. Thus, the majority of approaches for anomaly detection are formed as unsupervised problems. Most of the previous methods have typically chosen an autoencoder to extract the common characteristics of the unlabeled dataset, assumed as normal characteristics, and determine the unsuccessfully reconstructed area as the defect area in an image. However, we could waste the ground truth data if we leave them unused. In addition, a suitable choice of threshold value is needed for anomaly segmentation. In our study, we propose a semi-supervised setting to make use of both unlabeled and labeled samples and the network is trained to segment out defect regions automatically. We first train an autoencoder network to reconstruct defect-free images from an unlabeled dataset, mostly containing normal samples. Then, a difference map between the input and the reconstructed image is calculated and feeds along with the corresponding input image into the subsequent segmentation module. We share the ground truth for both kinds of input and train the network with binary cross-entropy loss. Additional difference images can also increase stability during training. Finally, we show extensive experimental results to prove that, with help from a handful of ground-truth segmentation maps, the result is improved overall by 3.83%.",https://www.semanticscholar.org/paper/518cadf4765b5e3a84784fade5d205d6b328101f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '64f260cac1a9b2240b748b8106d2339f25b98565', 'df8294254b229e1751de70db5988273f97e218a0', '38be3697a9cd4bf50853d0c2e226e8a5bf9aa052', '3021b6dec80e7032fd995c0dcadf4c992b7d7506', '317aee7fc081f2b137a85c4f20129007fd8e717e', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '1f528877c4d8d5df3b3abbfa64379677d451956b', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '1342c1e1684620c019972e2679d5131f1e8a4a13', None, '3b8c36b940d8e881c2ca7dc04dedca06d3dc9c6b', 'c61649e63d89e590a238f3b6a73bd0daab64e10e', 'd2e4587744a89bad95fea69e08842cad6c8ff0dd', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'ea743597a5f48babef1982259566d76a9bf66bf2', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '858808d571c3334669c48a775b2140e381eb9d78', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",25,{'1f528877c4d8d5df3b3abbfa64379677d451956b'},1,"['Bee-ing Sae-ang', 'W. Kumwilaisak', 'P. KaewTrakulPong']",Bee-ing Sae-ang,"Bee-ing Sae-ang, W. Kumwilaisak, P. KaewTrakulPong",4.0
37595f7a51982d776e57c7280b9445474d90f0be,Modeling the Distribution of Normal Data in Pre-Trained Deep Features for Anomaly Detection,2020-05-28,"Anomaly Detection (AD) in images is a fundamental computer vision problem and refers to identifying images and/or image substructures that deviate significantly from the norm. Popular AD algorithms commonly try to learn a model of normality from scratch using task specific datasets, but are limited to semi-supervised approaches employing mostly normal data due to the inaccessibility of anomalies on a large scale combined with the ambiguous nature of anomaly appearance. We follow an alternative approach and demonstrate that deep feature representations learned by discriminative models on large natural image datasets are well suited to describe normality and detect even subtle anomalies in a transfer learning setting. Our model of normality is established by fitting a multivariate Gaussian (MVG) to deep feature representations of classification networks trained on ImageNet using normal data only. By subsequently applying the Mahalanobis distance as the anomaly score we outperform the current state of the art on the public MVTec AD dataset, achieving an Area Under the Receiver Operating Characteristic curve of 95.8 ± 1.2% (mean ± SEM) over all 15 classes. We further investigate why the learned representations are discriminative to the AD task using Principal Component Analysis. We find that the principal components containing little variance in normal data are the ones crucial for discriminating between normal and anomalous instances. This gives a possible explanation to the often subpar performance of AD approaches trained from scratch using normal data only. By selectively fitting a MVG to these most relevant components only, we are able to further reduce model complexity while retaining AD performance. We also investigate setting the working point by selecting acceptable False Positive Rate thresholds based on the MVG assumption. Code is publicly available at https://github.com/ORippler/gaussian-ad-mvtec.",https://www.semanticscholar.org/paper/37595f7a51982d776e57c7280b9445474d90f0be,"{'24af0e94ddae7047cf57cc0f42fd0e34a209c4aa', 'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '02470bed70e38f6a3e69031784e802007a3a1cd3', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'c8c4ab59ac29973a00df4e5c8df3773a3c59995a', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9acc51b06f54b07836fad4cc24633187dc21317f', 'b40890f3d917379ac4bd2e0933a134d45b4dc251', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '4f57f486adea0bf95c252620a4e8af39232ef8bc', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', '15d1838111f327af5d7c7c56fb887e3cc6d95fd3', 'c53352a4239568cc915ad968aff51c49924a3072', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', 'ae9bf201f128cabaa4350b54ff6607525c736cd5', '0f366de3ea595932dad06389f6e61fe0dd8cbe74', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', '70f9968a356d840040a1c9207906f60376dc6bd4', 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '4cfd8f903506865e7ccf28b0a07ee3c551487e92', '1813ef743e31864e0a02dd5b8ede628ab508141e', 'ad45742878cd744acfb850852591608dc2f19cf0', '41747cbdbed84762dfbfc305254c97021279dc6e', '0aaa5f51faa9a5c03f788009cbf2288988880278', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'f7ed4d66199e1e192330a0ea99d08d71b7325ab8', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",47,"{'363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '9277dc70c74bcadf80dab11c28ead83fd085deec'}",4,"['Oliver Rippel', 'Patrick Mertens', 'D. Merhof']",Oliver Rippel,"Oliver Rippel, Patrick Mertens, D. Merhof",8.51063829787234
498e003901f8287e89e5064477cd22dd47e49d61,Learning and Evaluating Representations for Deep One-class Classification,2020-11-04,"We present a two-stage framework for deep one-class classification. We first learn self-supervised representations from one-class data, and then build one-class classifiers on learned representations. The framework not only allows to learn better representations, but also permits building one-class classifiers that are faithful to the target task. In particular, we present a novel distribution-augmented contrastive learning that extends training distributions via data augmentation to obstruct the uniformity of contrastive representations. Moreover, we argue that classifiers inspired by the statistical perspective in generative or discriminative models are more effective than existing approaches, such as an average of normality scores from a surrogate classifier. In experiments, we demonstrate state-of-the-art performance on visual domain one-class classification benchmarks. Finally, we present visual explanations, confirming that the decision-making process of our deep one-class classifier is intuitive to humans. The code is available at: this https URL.",https://www.semanticscholar.org/paper/498e003901f8287e89e5064477cd22dd47e49d61,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '3a6ad79622258c72d209403557760df033d60c56', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '7dbdb4209626fd92d2436a058663206216036e68', '4aea3547974399a32d7aa7c007b10bd665e93fab', 'b93661f036029c0dd367915fbdeb20bb821ab21d', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', '04513c7c0b3a63fde81a996dae064a28d453c17a', 'cd1758d3b86c4f1caf01ec222b45daf15888d1a8', '10a498003e9204f5fc1328e706510a37e514d8c7', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', '6507909a8f77c88144c3a67b9336bd1c85e84cac', 'c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '1d033b30f38642e4b6dd146bb8b464bfb58aad96', '34ab95637e7723302058f6526e33dc73857b9af2', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '1cae417456711c4da184f5efcd1b7464a7a0661a', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '9b09d296059909490096e34e9df2d95314787ad5', '17a273bbd4448083b01b5a9389b3c37f5425aac0', '3bb5a439a0d610a7eac68f73068cdd278b8c9775', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '5647d92d8e7248cd2d4770edfe0688c1c0a2181b', '00695a31a80221c7125e49885a4767896ec2c4f7', '1ee3fc3d32a0b56f6e568fb0590cf635e1249f42', None, 'e4bde6fe33b6c2cf9d1647ac0b041f7d1ba29c5b', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', 'f302e136c41db5de1d624412f68c9174cf7ae8be', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', '843959ffdccf31c6694d135fad07425924f785b1', 'faf3a22627f198ce56671b6f8a9b3d5cc3164a91', '403227333329b36183004f04db72362b604adef3', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '78ab874ad33d0764abb2fce9f0a8ce2be40c6593', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'b022f2a277a4bf5f42382e86e4380b96340b9e86', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'a504b45e2cff77abcc9d78cc95159c08305e44d1', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', '19d13084ea644842e42802ec7aac2fb977ed7584', '8dc8f3e0127adc6985d4695e9b69d04717b2fde8', '379daa0dabeffa72b9a0d8c48b361236c03fb302', '6af440915b8a0718c93be1cf61905e41e620484a', '38f93092ece8eee9771e61c1edaf11b1293cae1b', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'dd6de9423afcc0f821fee2bd0363a4091c7f8cd3', '94192bcdf3507e3543910c03b16bd06c5338fd47', '41f1d50c85d3180476c4c7b3eea121278b0d8474', '434a9621e6175164e1659bfc4ec038dda5290292', '225f78ae8a44723c136646044fd5c5d7f1d3d15a', '1a2a770d23b4a171fa81de62a78a3deb0588f238', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', '355d44f53428b1ac4fb2ab468d593c720640e5bd', '78a11b7d2d7e1b19d92d2afd51bd3624eca86c3c', '88f11ad3fe04aab7f4bcf80a079140e717357f02', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', '4b83c2ec2c5119057979ae64cf4b5d1aef04466b', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', '0936352b78a52bc5d2b5e3f04233efc56664af51'}",77,"{'363c81a08858df8dd7d1bde79c6e002e3b19f900', 'e021d59638966a6fbb36854cc2cf1045de7a62d2'}",2,"['Kihyuk Sohn', 'Chun-Liang Li', 'Jinsung Yoon', 'Minho Jin', 'Tomas Pfister']",Kihyuk Sohn,"Kihyuk Sohn, Chun-Liang Li, Jinsung Yoon, Minho Jin, Tomas Pfister",2.5974025974025974
3d3745f59c6a910ce0b4ebec35d4077792d2f486,Mean-Shifted Contrastive Loss for Anomaly Detection,2021-06-07,"Deep anomaly detection methods learn representations that separate between normal and anomalous samples. Very effective representations are obtained when powerful externally trained feature extractors (e.g. ResNets pre-trained on ImageNet) are fine-tuned on the training data which consists of normal samples and no anomalies. However, this is a difficult task that can suffer from catastrophic collapse, i.e. it is prone to learning trivial and non-specific features. In this paper, we propose a new loss function which can overcome failure modes of both center-loss and contrastive-loss methods. Furthermore, we combine it with a confidence-invariant angular center loss, which replaces the Euclidean distance used in previous work, that was sensitive to prediction confidence. Our improvements yield a new anomaly detection approach, based on Mean-Shifted Contrastive Loss, which is both more accurate and less sensitive to catastrophic collapse than previous methods. Our method achieves state-of-the-art anomaly detection performance on multiple benchmarks including 97.5% ROC-AUC on the CIFAR-10 dataset1.",https://www.semanticscholar.org/paper/3d3745f59c6a910ce0b4ebec35d4077792d2f486,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '540b5b4919d345e4da3cc4f3e8a7862329bf41a2', '5151d6cb3a4eaec14a56944d58338251fca344ab', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '732c21998e251d64cd58b6a86886ee5907efeaa5', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '8201e6e687f2de477258e9be53ba7b73ee30d7de', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '02b28f3b71138a06e40dbd614abf8568420ae183', 'c069629a51f6c1c301eb20ed77bc6b586c24ce32', '94559c249d204110296c39ed4af2042cc4468e68', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '04513c7c0b3a63fde81a996dae064a28d453c17a', '17fa1c2a24ba8f731c8b21f1244463bc4b465681', '498e003901f8287e89e5064477cd22dd47e49d61', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', '6af440915b8a0718c93be1cf61905e41e620484a', '38f93092ece8eee9771e61c1edaf11b1293cae1b', 'cdd553c54d5769ec218a8ea921e27144a6b1aadb', '88f11ad3fe04aab7f4bcf80a079140e717357f02', None, '3039962978812c1c2a33135d60673ebdffe2ce55', '0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d', 'db8c381cbaf80c4323959eccee07c85a76b54839', '8e63784bd5a24d5e3035e2a11753e65e6e56625d', 'a1b8a8df281bbaec148a897927a49ea47ea31515', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '4d39ee7cca8fedf792570724255a4357aa41dbf8', '576fab96d98981946fcace0384cdba8f7290a8c5', 'add2f205338d70e10ce5e686df4a690e2851bdfc'}",35,"{'498e003901f8287e89e5064477cd22dd47e49d61', 'db8c381cbaf80c4323959eccee07c85a76b54839'}",2,"['Tal Reiss', 'Yedid Hoshen']",Tal Reiss,"Tal Reiss, Yedid Hoshen",5.714285714285714
85e582b46f3e9f79ca2c6f5c5f2d9a13dfa19f56,MLF-SC: Incorporating multi-layer features to sparse coding for anomaly detection,2021-04-09,"Anomalies in images occur in various scales from a small hole on a carpet to a large stain. However, anomaly detection based on sparse coding, one of the widely used anomaly detection methods, has an issue in dealing with anomalies that are out of the patch size employed to sparsely represent images. A large anomaly can be considered normal if seen in a small scale, but it is not easy to determine a single scale (patch size) that works well for all images. Then, we propose to incorporate multi-scale features to sparse coding and improve the performance of anomaly detection. The proposed method, multilayer feature sparse coding (MLF-SC), employs a neural network for feature extraction, and feature maps from intermediate layers of the network are given to sparse coding, whereas the standard sparse-coding-based anomaly detection method directly works on given images. We show that MLF-SC outperforms state-of-the-art anomaly detection methods including those employing deep learning. Our target data are the texture categories of the MVTec Anomaly Detection (MVTec AD) dataset, which is a modern benchmark dataset consisting of images from the real world. Our idea can be a simple and practical option to deal with practical data.",https://www.semanticscholar.org/paper/85e582b46f3e9f79ca2c6f5c5f2d9a13dfa19f56,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '7568d13a82f7afa4be79f09c295940e48ec6db89', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'f70be98717d1ad998390745633b995e5a3803bfa', '1c7c5595dc7a1f5d360acf5c360ca1ca49536ba5', 'ccd1282aea3cc7c3d40300d82472fc5f9f54cb8e', '49f366a1bdc3807efc9899ceb2a91e758f929fc3', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'e07416eabd4ba6c69fa473756bb04ae7161177be', '0f50b7483f1b200ebf88c4dd7698de986399a0f3', 'a4ac07ddac694aefedd009c4d5122cb645f87715', 'ae37774ff871575b7799411bf87f42eb52634390', '3262e77099cefe24cff1308f204e673cac832451'}",19,set(),0,"['Ryuji Imamura', 'Kohei Azuma', 'Atsushi Hanamoto', 'A. Kanemura']",Ryuji Imamura,"Ryuji Imamura, Kohei Azuma, Atsushi Hanamoto, A. Kanemura",0.0
00b46923c31b21f59ab53cf693b6159c3dc4375d,A Multi-Scale A Contrario method for Unsupervised Image Anomaly Detection,2021-10-05,"Anomalies can be defined as any non-random structure which deviates from normality. Anomaly detection methods reported in the literature are numerous and diverse, as what is considered anomalous usually varies depending on particular scenarios and applications. In this work we propose an a contrario framework to detect anomalies in images applying statistical analysis to feature maps obtained via convolutions. We evaluate filters learned from the image under analysis via patch PCA and the feature maps obtained from a pre-trained deep neural network (Resnet). The proposed method is multi-scale and fully unsupervised, and is able to detect anomalies in a wide variety of scenarios. While the end goal of this work is the detection of subtle defects in leather samples for the automotive industry, we show that the same algorithm achieves state-of-the-art results in public anomalies datasets.",https://www.semanticscholar.org/paper/00b46923c31b21f59ab53cf693b6159c3dc4375d,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '9b5e5de11deae442531804b9491c03fe3b537975', '89a4618d9af12b98af656f9d620256e7cfcd4a1c', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'f412bb31ec9ef8bbef70eefc7ffd04420c1365d9', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '8ea22449703c0b9c1b949ed3190d2ca3a47ed1bd', 'ec76ea04ccb07048c2abb527774888b6a33c7edc', '19862af96b6af51e879e6e3f1d3d421af5427005', '89e1b679d4de5bbb6108d2c3e4b691b670bbf949', '62b77e5cb85fc61b84edd532f6d65714be152596', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'c289a21439402eb0998df46c769ce9c4971e854b', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'ca2e917e2f399010da6bb9ba989c01fd406ddcb6', '1281e443d2cf1c1dd71ed3b7b0376d408d0958af', '27ce5a120a86632dd56f869ee65656b7d7312a3a', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', None, 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'a50f88e5e335e29d71fcec97b3309671574a4576', '2e8d62277e40d465343e8dfb32ecc246f320540e', '5a554c8d22d47ac499aeb7fb0532ca9be65e5a2e', '7cd316505f52aa337ef8a2aff10bc6bf1df561d0', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c'}",32,"{'931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '498e003901f8287e89e5064477cd22dd47e49d61', '19862af96b6af51e879e6e3f1d3d421af5427005', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['Matías Tailanián', ""Pablo Mus'e"", 'Álvaro Pardo']",Matías Tailanián,"Matías Tailanián, Pablo Mus'e, Álvaro Pardo",28.125
0496e1d68b1fa12604b6a2fce31452e62b543405,Coalitional Bayesian Autoencoders - Towards explainable unsupervised deep learning,2021-10-19,,https://www.semanticscholar.org/paper/0496e1d68b1fa12604b6a2fce31452e62b543405,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'eb73aa1b023be05b5ed5e88bbf92c9a787af3671', '802168a81571dde28f5ddb94d84677bc007afa7b', 'efdaa0eada0be7ea6d79c369fea08bd528e3bf85', 'f45e0b8186f28648bf899ede02083a3ee1165ccf', 'c46035bf10977f15a7b951bb92dcea66b18b8665', '927881a5602f430ffd145d44b8c35cf7a07b464d', '961eb3e7b00bd8d97e33a6808e15286e5dee1ea1', 'c4f92f208f8bb85ab64a0482be592b594c16ca16', '45e53dbcd53ded7134b7c296e119ad455ce11dae', 'd98981ee457fe773fec6849e4247a1de9dcd471a', '2e8eb3feb2e69955b5b55651a4641145ea472ea1', '7eff70f034f19b225858593f2c1c5e7a7e9dd5f9', '413188bb98da101f61ac9e89d50cb09a8a675d70', 'b1a6eafcd22d2c17c20f3aee6f5a84b70a492a9c', 'e02379df7ea4a73ccaae5e11c26ed8b611bd68d0', 'd7ddc4830c2ab415949ad09ecfbb674e9e492623', '59d823fc9877f8d448ac4c2d90e38051026e3201', '5f614777d25efd14b7426e99cb2544f2d6be133e', 'f8a54ba839f6194198b4886097169a53905fbb37', 'f156ecbbb9243522275490d698c6825f4d2e01af', 'bd6fe463ba09f52610b55d3933f7fdc29abf6e29', 'e9d783c81b53ce967ae343a33cbbbcb4aaf3280f', '7d58e61a2791eaf8c2b7b821f7108083ff4025a0', '42a1901c9e9dae53b5ca95481d1c35211cc67c85', 'b506c83d7af32cea4a9b4ff38fdc46012489d880', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'e91ba550b9cff5fec5a94d86883370a03d205eeb', '9cac714ceef68110548c9bdcede014aed7eb8916', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'ef239a21a2f04f08a6728155faa49ae917b7c640', None, 'd95ded0f2ca2cb74606f6ab8f37211e6c57053be', 'f019696eb5af50ce38f0efa71bed7ede40c9bdfd', 'f302e136c41db5de1d624412f68c9174cf7ae8be', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', 'f1938a3a93032e346dca700505745e154e1dde31', '44858b662822d291a5e1e9e3501ad19a9f1572c2', '102c3eabbf002b80d732b025ee4c23a7e61b20e9', 'fab510d074fd48ce08c0e12b36cbe24819898c01', '17473bc2acf3675e73a26e27aeb2b35b04e0fce1', 'a05500245d9471ef376cd74777fe8bafe62c3ded', 'b2d7da1a6359b6742bc3ee7c9bdb363ed8fd60b4', '354923bc917ac774438a048b87db9fabed4d757e', 'b0ebbcf713b3ddf3f94325bc58dc39ff76fdc412', 'ec75b87ddbd9ca88fb5cea408db59aad44424296', '8f6d5685ad9e32c97880be55ec0552e734221b3f', '7b905342403681a28db24e66b5a24c398dc23b1c', 'b61157119bb5e71f216a148d44e524115bbc390c', '18c29e07f159b836125db6c7a432ba44d74f2d41', '55a258aaf0da832416254566af82512dd4b05285', '1a2118bed729579528deb51e745d58dd3629baf6', '5f1add508221511fc7e69d55edd6b554bb3bb8b8', 'd6f2f611da110b5b5061731be3fc4c7f45d8ee23', '775247047d0b56950ba5ea77d4a29772eca95c1b', '751b04d346fc9a70781bbfea23953f424ff7deec', '37b5dfe87d82ba8f310155165d5bf841dc92dea2', '21590297a1626ec65a9f63293b8f4d83b55b1316', '442e10a3c6640ded9408622005e3c2a8906ce4c2', '2d4284e3122e36ae685a5d7aa04105fc9a703723', '1f1819af398f6aaf29265d5ebb95ccd748bc0859', 'e1580397256e2d8bfaa5ca310a9b8c731320a4dd', '7c54d9b80113f637e447199d8ffbfe4b0678cc6f', '776d9e705c8d27c3a71219e72128e8285119a39e', '61d71f5711a7b99d201d904e93a190da31e90fe7', '87d2c54d5059be201f1701f2b8bc8b4dc2038ba6', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'eb84415703c70ac3ab1ac3d9a4a08f29016a5066', '8ab49b2f920056c1d145fdebd3f077768bbb9a65', '5091316bb1c6db6c6a813f4391911a5c311fdfe0', '7e834aac45ad9d7c879cddc40af70ca01a5bcdf1', 'dfa92e677d186888ef7cf40def88ddd4b7382114', '1c2efb418f79b5d29913e014a1dfd78865221c39', '12d79c508cd98fbc4bf42a710ba1f956203136a4', '62adfea3cc1cd9eb6b53e0e8a40be5dfda2adf8d', '6ae8e0ea13abfaaeed3fb4c720716e0e89667094', '8f1408d33858a78f90f9000a34856664fc639ae4'}",78,"{'16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '775247047d0b56950ba5ea77d4a29772eca95c1b'}",3,"['Bang Xiang Yong', 'A. Brintrup']",Bang Xiang Yong,"Bang Xiang Yong, A. Brintrup",3.8461538461538463
38ca689c2f916c648ea3ecb1043facbc4bea0d4f,Puzzle-AE: Novelty Detection in Images through Solving Puzzles,2020-08-29,"Autoencoder, as an essential part of many anomaly detection methods, is lacking flexibility on normal data in complex datasets. U-Net is proved to be effective for this purpose but overfits on the training data if trained by just using reconstruction error similar to other AE-based frameworks. Puzzle-solving, as a pretext task of self-supervised learning (SSL) methods, has earlier proved its ability in learning semantically meaningful features. We show that training U-Nets based on this task is an effective remedy that prevents overfitting and facilitates learning beyond pixel-level features. Shortcut solutions, however, are a big challenge in SSL tasks, including jigsaw puzzles. We propose adversarial robust training as an effective automatic shortcut removal. We achieve competitive or superior results compared to the State of the Art (SOTA) anomaly detection methods on various toy and real-world datasets. Unlike many competitors, the proposed framework is stable, fast, data-efficient, and does not require unprincipled early stopping.",https://www.semanticscholar.org/paper/38ca689c2f916c648ea3ecb1043facbc4bea0d4f,"{'01625cba9f8a783994377d4f35aa765242faab4f', '05e882679d61f4c64a68ebe21826251a39f87e98', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '571b0750085ae3d939525e62af510ee2cee9d5ea', '0d57ba12a6d958e178d83be4c84513f7e42b24e5', '6d4a87759917132913319960389f17fa1fe8b630', '1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd', '599fd051c9438011ec5b581983c89e8922b4a5e6', '8388f1be26329fa45e5807e968a641ce170ea078', 'e60dd237328bc92941e0559ab358e6186cdd41de', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '4d376d6978dad0374edfa6709c9556b42d3594d3', 'f63e917638553414526a0cc8550de4ad2d83fe7a', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '10b219619e88931fabb674037bbb633682775136', '9a700c7a7e7468e436f00c34551fbe3e0f70e42f', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '6745c95b88ff9b12401a9ba6f4007f036be591a0', '77afac8f4d7f47c8b34371d8f8355cefbea1d4f6', 'b0c065cd43aa7280e766b5dcbcc7e26abce59330', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '2abde28f75a9135c8ed7c50ea16b7b9e49da0c09', 'a86d7289c76d832e83c99539859b7b186e4ea6c8', '10a498003e9204f5fc1328e706510a37e514d8c7', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '22ed48a84b3227ff05bbc8770f7b6c823afa734a', '62f3d3015cee122bd147d7d878c85f70cc15680d', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '70f9968a356d840040a1c9207906f60376dc6bd4', None, 'c2b733a79db700b971327a58ef42699fe8a416aa', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', '155b7782dbd713982a4133df3aee7adfd0b6b304', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', '7aa38b85fa8cba64d6a4010543f6695dbf5f1386', '2c740e574eea66fdcf473e15ed2c228baef2eccd', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '843959ffdccf31c6694d135fad07425924f785b1', 'ed3ef766dbbc01cc8f33c3d9ed013f1bc8084016', 'f5b0d51ca54fd1b7268486393679dd612d482f64', '3a6d33cb1a76fffc531e35c80be8eae20a30b2ef', '746cf281d8198310b1242048bf4fd90e0486f1a9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '9dc822d8c41d1091b3ae200fe5efa6f98bd4ecf3'}",58,set(),0,"['Mohammadreza Salehi', 'Ainaz Eftekhar', 'Niousha Sadjadi', 'M. Rohban', 'H. Rabiee']",Mohammadreza Salehi,"Mohammadreza Salehi, Ainaz Eftekhar, Niousha Sadjadi, M. Rohban, H. Rabiee",0.0
3a34bc8949d42f6088fb4e668660c7031fbca23f,Image-based plant disease diagonasis with unsupervised anomaly detection based on reconstructability of colors,2020-11-29,"This paper proposes an unsupervised anomaly detection technique for image-based plant disease diagnosis. A construction of large and openly available data set on labeled images of healthy and diseased crop plants has led to growing interest in computer vision techniques for plant disease diagnosis. Although supervised image classifiers based on deep learning could be a powerful tool to identify plant diseases, they require huge amount of data set that have been labeled as healthy and disease. While, data mining techniques called anomaly detection includes unsupervised approaches that not require rare samples for training classifiers The proposed method in this study focuses on the reconstructability of colors on plant images. We expect that a deep encoder decoder network trained for reconstructing colors of healthy plant images fails to color symptomatic regions. The main contributions of this work are as follows: (i) we propose a new image-based plant disease detection framework utilising a conditional adversarial network called pix2pix,(ii) we introduce a new anomaly score calculated from CIEDE2000 color difference. Through experiments using the PlantVillage dataset, we demonstrate that our method is superior to an existing anomaly detector called AnoGAN for identifying diseased crop images in terms of accuracy, interpretability and computational efficiency.",https://www.semanticscholar.org/paper/3a34bc8949d42f6088fb4e668660c7031fbca23f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '3779c1d2059e0daa9b511bb354172a9726cce54b', '571b0750085ae3d939525e62af510ee2cee9d5ea', 'e30d9b8ce108d982169621b88a5e3fb69fec70e1', '732c21998e251d64cd58b6a86886ee5907efeaa5', '8388f1be26329fa45e5807e968a641ce170ea078', '969bc38ea067dd22a47a44bcb59c23807037c8d8', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', '57dbba9281cbd1b4dd5d1932f0dd605b8f498322', '767dcaf77f73f958cfee0f54cfcde0882e8ec50e', '8ff61b8e097ccdb784a35b466ba9e130c2502513', '74ff6d48f9c62e937023106629d27ef2d2ddf8bc', '1d4ec24a6da3be62dc5d7efbae2a101c63f187e8', '35da0a2001eea88486a5de677ab97868c93d0824', '3f611458b84ca8756c863916b33d12c704687127', 'fd0a1a2ecf69a6c1a6efcb18b8f23e4d5402f601', '8acbe90d5b852dadea7810345451a99608ee54c7', '9fcecc67da35c6af6defd6825875a49954f195e9', '2edf3a49bdbbb630666c51be9b856d613c9782b3', 'bac292286c7d12df6863c7ca8dec720ed6288302', '0ae06134ed181bedfa027f312273fcb6c68941ec', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0228810a988f6b8f06337e14f564e2fd3f6e1056', '46ac8e33cad8676bd2df8bf40e9bc9e391b25666', None, 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'b5866a5871f58470acbe0ea89d1624ee07752a0c', '3e2da7c1c7dfc7960d1515b61f32fdc55359eea7', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '84af0bbe339c1adbc9d075dee99b9d4f86a186c5', '1db6e3078597386ac4222ba6c3f4f61b61f53539', '843959ffdccf31c6694d135fad07425924f785b1', '746cf281d8198310b1242048bf4fd90e0486f1a9', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '24158c9fc293c8a998ac552b1188404a877da292'}",38,set(),0,"['Ryoya Katafuchi', 'T. Tokunaga']",Ryoya Katafuchi,"Ryoya Katafuchi, T. Tokunaga",0.0
ea68899e52526ce59c1f0b0cbc7cd992a0700383,Distance-Based Anomaly Detection for Industrial Surfaces Using Triplet Networks,2020-11-04,"Surface anomaly detection plays an important quality control role in many manufacturing industries to reduce scrap production. Machine-based visual inspections have been utilized in recent years to conduct this task instead of human experts. In particular, deep learning Convolutional Neural Networks (CNNs) have been at the forefront of these image processing-based solutions due to their predictive accuracy and efficiency. Training a CNN on a classification objective requires a sufficiently large amount of defective data, which is often not available. In this paper, we address that challenge by training the CNN on surface texture patches with a distance-based anomaly detection objective instead. A deep residual-based triplet network model is utilized, and defective training samples are synthesized exclusively from non-defective samples via random erasing techniques to directly learn a similarity metric between the same-class samples and out-of-class samples. Evaluation results demonstrate the approach's strength in detecting different types of anomalies, such as bent, broken, or cracked surfaces, for known surfaces that are part of the training data and unseen novel surfaces.",https://www.semanticscholar.org/paper/ea68899e52526ce59c1f0b0cbc7cd992a0700383,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2788a2461ed0067e2f7aaa63c449a24a237ec341', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'da2befcfacec082b798f1fdbaf4eaa510306486e', '9375729d21a344a5ccccd5f53556ddf90b957cd9', 'af7f3087e7248d2c2f2a680ca08128ac85795fa5', 'deeca6a996b9b099d56c694a4c31c92ac1c4d5e2', '3ac1a7d6630cd1c7b70c4c2c7bc92c40df1162ca', '58660654fc5aa17e55170832dd151438e7c01d5e', 'a939b55140df2d99f0575ce4ba827320f14829b1', '31630d1aa44ef8fcac8e127ed9d7ac57e3c11269', 'fc9b96b0148f36392a5e9bd13fdf6eb1f3e3022e', '25757e7819eeb8829d3524474f973b79befd7b59', '10feaba0b775fe8db12e1cecf56f4bb7a32ec1a2', '7715180856e1f4ad14e93ea38a7c36d14ab2131c', None, '17d3f90cb63fbac50a5e49b8a46e633ec1f526fd', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', '2e5d2f2dc01b150dffc163a9f457848e9b5b5c38', '46200b99c40e8586c8a0f588488ab6414119fb28'}",25,set(),0,"['Tareq Tayeh', 'Sulaiman A. Aburakhia', 'Ryan Myers', 'A. Shami']",Tareq Tayeh,"Tareq Tayeh, Sulaiman A. Aburakhia, Ryan Myers, A. Shami",0.0
373af4bf357da54b6e0d69ee2373ecb840daaeb2,Clear Memory-Augmented Auto-Encoder for Surface Defect Detection,2022-08-08,"： In surface defect detection, due to the extreme imbalance in the number of positive and negative samples, positive-samples-based anomaly detection methods have received more and more attention. Specifically, reconstruction-based methods are the most popular. However, exiting methods are either difficult to repair abnormal foregrounds or reconstruct clear backgrounds. Therefore, we propose a clear memory-augmented auto-encoder. At first, we propose a novel clear memory-augmented module, which combines the encoding and memory-encoding in a way of forgetting and inputting, thereby repairing abnormal foregrounds and preservation clear backgrounds. Secondly, a general artificial anomaly generation algorithm is proposed to simulate anomalies that are as realistic and feature-rich as possible. At last, we propose a novel multi scale feature residual detection method for defect segmentation, which makes the defect location more accurate. CMA-AE conducts comparative experiments using 11 state-of-the-art methods on five benchmark datasets, showing an average 18.6% average improvement in F1-measure.",https://www.semanticscholar.org/paper/373af4bf357da54b6e0d69ee2373ecb840daaeb2,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd67b9dafcf94017784c266e021fe29baf2ffd572', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', 'e0f73e991514450bb0f14f799878d84adc8601f9', 'be8c6c69f3e357bfad2987e45b62cff7e7474378', 'f5ada173e628caf97c25b20c16a219ed384a006e', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'eb31173dfe39ec3a9d487ba776c9933c168eded4', 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', '338e59d667e871ff4507e38c3ff9ca7d616b97cd', 'e8180ad45ed5ca732e492db32aa85e769836132e', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', '5435a9ab36a308cef10bc725104e8f778ed3a328', '29d5f0b9cc680c172009b583e59fc79663604353', 'e4b4349d19124be609622b75585d158055c1a0b3', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', 'c468bbde6a22d961829e1970e6ad5795e05418d1', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '70f9968a356d840040a1c9207906f60376dc6bd4', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', 'd81421695d5d429a47eefe266986d197d7b313f2', None, '44d2abe2175df8153f465f6c39b68b76a0d40ab9', 'a67ec1f97ded4c7165b2307850ed644570669d39', 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', '1aad901be51dcfd453de65eaaa6550eda3d0858f', '9ac074098d3c48234258b1a9ee8a0ad7e748a9e0', '5db1b742cd18678ed08a813970bfaba3527df037', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'f9c990b1b5724e50e5632b94fdb7484ece8a6ce7', '46786ce31ff75adc402cabd0df489bba43b5643b', '91336c65cddd8546745f67a1b860c2595904ac15', '66ccd943eebb652af13b6096c6edc3407eb510e5', '71ae756c75ac89e2d731c9c79649562b5768ff39', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",42,"{'d67b9dafcf94017784c266e021fe29baf2ffd572', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', '46786ce31ff75adc402cabd0df489bba43b5643b'}",6,"['Wei Luo', 'Tongzhi Niu', 'Lixin Tang', 'Wenyong Yu', 'Bin Li']",Wei Luo,"Wei Luo, Tongzhi Niu, Lixin Tang, Wenyong Yu, Bin Li",14.285714285714286
5de172c1031a38184a431b6e704f040f6f509064,CFA: Coupled-hypersphere-based Feature Adaptation for Target-Oriented Anomaly Localization,2022-06-09,"For a long time, anomaly localization has been widely used in industries. Previous studies focused on approximating the distribution of normal features without adaptation to a target dataset. However, since anomaly localization should precisely discriminate normal and abnormal features, the absence of adaptation may make the normality of abnormal features overestimated. Thus, we propose Coupled-hypersphere-based Feature Adaptation (CFA) which accomplishes sophisticated anomaly localization using features adapted to the target dataset. CFA consists of (1) a learnable patch descriptor that learns and embeds target-oriented features and (2) scalable memory bank independent of the size of the target dataset. And, CFA adopts transfer learning to increase the normal feature density so that abnormal features can be clearly distinguished by applying patch descriptor and memory bank to a pretrained CNN. The proposed method outperforms the previous methods quantitatively and qualitatively. For example, it provides an AUROC score of 99.5% in anomaly detection and 98.5% in anomaly localization of MVTec AD benchmark. In addition, this paper points out the negative effects of biased features of pre-trained CNNs and emphasizes the importance of the adaptation to the target dataset. The code is publicly available at https://github.com/ sungwool/CFA_for_anomaly_localization",https://www.semanticscholar.org/paper/5de172c1031a38184a431b6e704f040f6f509064,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd07284a6811f1b2745d91bdb06b040b57f226882', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '51cdeeef710d1c84e10beadc8480c137ffe8d328', 'd6f2f611da110b5b5061731be3fc4c7f45d8ee23', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '73d5dbfebca74e5ef8a7333c842a2a9ee5c07fd6', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '0162b26ab4099cbfdf7d6bc6ae4bf5107e3569a3', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",23,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'b1464ca857593c049873421db2f37bf2d0ff676d', '41747cbdbed84762dfbfc305254c97021279dc6e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['Sungwook Lee', 'Seunghyun Lee', 'B. Song']",Sungwook Lee,"Sungwook Lee, Seunghyun Lee, B. Song",39.130434782608695
e03b609e7123c82044336bbe0f4a235b6bcba6de,Wi-Fruit,2021-12-27,"People usually assess fruit qualities from external features such as color, shape, size, and texture. However, it is quite common that we select fruits with perfect appearances but rotten inside, especially for fruits with thick pericarps. Thus the accurate measurement is desirable to evaluate the internal conditions of fruits. As two key features of fruit internal qualities, existing methods on measuring fruit moisture and soluble solid contents (SSC) are either destructive or costly, limiting their adoption in daily life. In this paper, we propose Wi-Fruit, a non-destructive and low-cost fruit moisture and SSC measurement system leveraging Wi-Fi channel state information (CSI). First, to cope with the fruit structure dependency challenge, we propose a double-quotient model to pre-process CSI on adjacent antennas. Second, to address the fruit size and type dependency challenges, a lightweight artificial neural network (ANN) model with visual information fusion is proposed for fruit moisture and SSC estimations. Extensive evaluations are conducted on 6 types of fruits with both thick (i.e., watermelon and grapefruit) and thin pericarps (i.e., dragon fruit, apple, pear, and orange) over a month in either an empty laboratory room or a library with massive books. Results demonstrate that Wi-Fruit achieves an acceptable estimation accuracy (RMSE=0.319). It is independent of various fruit structures, sizes, and types, while also robust to time and environmental changes. The fruit internal sensing capabilities of Wi-Fruit can help fruit saving and safety in both pre-harvest and post-harvest applications.",https://www.semanticscholar.org/paper/e03b609e7123c82044336bbe0f4a235b6bcba6de,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '87c39657c376311f678320f3f1d9a316afbae42e', '0bee7610f106713e5be62ab2f81f5eab5993d980', 'ae7f7c5f72260fa432f288d296b00125ef486db5', '21628a8944d4e3aa0b48992c24f25dc29af6ef3b', '17473bc2acf3675e73a26e27aeb2b35b04e0fce1', 'ab76a93f257d1f8412fe911f52d3f5f6abdfabf0', '620716a6b619e590025f57a8b02826c243986c98', '2546d7dba7c23937a237d5ecaaeff854ab03cbad', 'ec75b87ddbd9ca88fb5cea408db59aad44424296', '15b146471af8ebeaf470458c72ff2b7b85445b52', '05ebf752134154aba0626dc5eeba3c3e9d6fc4cd', '3bc63a1a3c0a5bb66af7bb61c34e379658820f90', '347c759f37d3c10ecee51dbcc80572d06ec70fe8', '92b9829cfe7b28367c48908a20a4f3ee42cb2511', 'f3d18e94be6142e300d614c8014ae243db0959f0', '46fff63f65a138300a7e63ba416c04e16bf40293', '20c6bc0b6508db1c0fa2a47ba11a213f64893b63', '1035ac3e4b65f1bc2c160dcc912cb2e87148ae1e', 'ced8958ca9380805bca1c1a4d250b7ca1db74cb8', 'a7e2814ec5db800d2f8c4313fd436e9cf8273821', '0fbb6a545c9344d3e6e95ca55d00891679a63feb', '83508bca98a0b7159bc22dfea399f405575fabdb', 'fe4008cd733dd53e617d0878929a5ddc066243ab', '6ad039fedcf18ec0a451fcdcfd2ed597cf954bb3', 'a12f654b8eb486fec50b334f42781fa744cf99a3', '1d73e515ca38ea565935bf38c1496f4330293ccd', None, '253b18d90038037d6db07ec879f0ec9493b0d1ad', '68f67c344230e4bb59153b0bcc373c9698747021', '689f5e710a1f42d86c6ae5692f4d76f797a7d138', 'b76ce675225748346e626b2ca9f6b7f7ee9e6310', '784032edc70b7e8e3449c342728d51ea5c09fbf2', '2866f98f9d43b7595bb57deeaa612835272caf62', 'e93eb7d7795e6a191d2e8c456168d7a457e84af2', '62c901d13952b6a89ae9b0b5d3129cf15a9544cd', '86ca3dafc51386e554aee5e6acfeb8cafad07f10', '08d4b8e39d9afe8c5d0fa42e87bf0cf4b8c06378', 'b48138c4828156b340120a6c2d73d9631196afed', 'd3fa014900876c4734c9837d481a42dfee8e96a0', 'e99603b5b524485bcf1afb2f01acadc34dfb033c', '9816f48a2ee3ae7c7012af3480670b5acae46f9f', '3017129bbc3634dd44078ea022bf0da1e51716bb', '8c9203c312cc098617adb871f372471018caf5a5', '5f2f6a697dabc784bbc4375f70d86df6a5de020a'}",45,set(),0,"['Yutong Liu', 'Landu Jiang', 'L. Kong', 'Qiao Xiang', 'Xuemei Liu', 'Guihai Chen']",Yutong Liu,"Yutong Liu, Landu Jiang, L. Kong, Qiao Xiang, Xuemei Liu, Guihai Chen",0.0
ce90b0c2379b4e7822ae4d9e2c276677d885594b,Extensive framework based on novel convolutional and variational autoencoder based on maximization of mutual information for anomaly detection,2021-05-07,,https://www.semanticscholar.org/paper/ce90b0c2379b4e7822ae4d9e2c276677d885594b,"{'71df4b737c35fb3d05f44036419e78b5330b580f', 'af395b05a0c00280a446f81417febbdfb17b67bb', 'bc9293bcee13cae5cff8a088f4038c4236decd42', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'd59bab71cdcb5f11e4108491bd09c7091f278a3e', 'de66bb0b0c7a695d66b31c5bfa9c801c94c485ea', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '7d668cf7cabcca5ddeb33cb40d52953f50d63a18', 'e0058360b063fb8ce3e9a6444f5b6400defca257', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'adc2532ef79a532df59c11289a60aba4b5feb57e', 'a4731547554302b8859453ed3b8478dce99ef081', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', '269490053e0f859a3cb6af2fe0ee64f4bf7ef643', 'e1d7afefd8f1d107bce9cc5f9a4faa5d4f207264', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '0bb74a5d81e237a941129ee7a9825ba9964a340c', '1d4ec24a6da3be62dc5d7efbae2a101c63f187e8', '372bf2716c53e353be6c3f027493f1a40edb6640', 'e317110eb481fb1277459007b1455a8e5c908925', 'e3116ebb52c152deae918a04c34441ac0d956b8a', '0c9ae806059196007938f24d0327a4237ed6adf5', '9d5290fadb7625862a966e0330bd0f9e111fc99d', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', '5435a9ab36a308cef10bc725104e8f778ed3a328', '154df96b95e8b9635771442244fe48b125933bb1', 'c8aa832362422418287ff56793c780b425afa93f', 'd9f0e1c7e240597992232840f7cb96ceeefa1940', 'be9a17321537d9289875fe475b71f4821457b435', 'bf113b77224b5ec01c7f5e28b2c3cbcd863ef422', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'ec8538418bd4e0e9191336dae5b063f578fa68d5', '17eeaa7bfbadbcd92d5bacdda2e2f5760454eed9', 'd1edd4c9305cd4e080312ba28d8242a5a49cbd99', '67529adb196e5b5e003c07dc8e54a1b71247f6d5', '1cacac4f0ea9fdff3cd88c151c94115a9fddcf33', '94c83cecc357a45846d203c6401ede792e14bb0f', '84d9b8a53e4042996532943531cfdc59f3d93a39', '48f9a48aa5b1230b05a443d2d531e6441a541686', '95467a31ee53eba30e9f2554283bec6f28ccbf1c', 'eae7d5b15423a148e6bb32d24bbabedfacd0e2df', '5d90f06bb70a0a3dced62413346235c02b1aa086', '361aa865bc573e2a9e187360dc5f8a80a5e64544', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '95149454c530b9bb66f2e020c216569490687327', '3c57038f7c2d80afd1e5ada6fdc86539bed8b8d4', 'a4ac07ddac694aefedd009c4d5122cb645f87715', 'c92ee6ff32fa4833fa1c2bdf29284e2a58ddb640', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '627a51489c5e891dea1c56bb8287fabaee7f4a87', '3d76e4a420ee27ca5101648e7ea7d717e73207c6', '932a106c21a1db1e1876459c1521d27fd152caac'}",55,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Qien Yu', 'M. Kavitha', 'T. Kurita']",Qien Yu,"Qien Yu, M. Kavitha, T. Kurita",1.8181818181818181
3dc55222e395505d0a2702db274b66e530189755,Supplementary materials for “Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation”,,"1: Input normal images {x}, hyperparameter λ, encoder fθ, and classifier Cφ 2: for patch p in {x} do . Train the encoder 3: p1 ← RandomJitter(p) 4: LSVDD’ ← ‖fθ(p)− fθ(p1)‖2 5: p2, y ← RandomNeighborhood(p) . A neighborhood in the 3 × 3 grid 6: LSSL ← Cross-entropy (y, Cφ (fθ(p), fθ(p2))) 7: Backprop LPatch SVDD ← λLSVDD’ + LSSL 8: end for 9: fbig, fsmall ← fθ . Split encoders 10: Sbig, Ssmall ← ∅ . Sets of normal features 11: for patch p in {x} do . Patch size K with stride S 12: Sbig ← Sbig ∪ {fbig(p)} 13: end for 14: for patch p in {x} do . Patch size K with stride S 15: Ssmall ← Ssmall ∪ {fsmall(p)} 16: end for 17: return (Sbig, Ssmall), (fbig, fsmall) . Normal features and trained encoders",https://www.semanticscholar.org/paper/3dc55222e395505d0a2702db274b66e530189755,"{'b36a5bb1707bb9c70025294b3a310138aae8327a', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '367f2c63a6f6a10b3b64b8729d601e69337ee3cc'}",3,set(),0,['Jihun Yi'],Jihun Yi,Jihun Yi,0.0
ba26eeec0f1b27ba05cfcf66f0395135ea5fca1b,ECLAD: Extracting Concepts with Local Aggregated Descriptors,2022-06-09,"Convolutional neural networks are being increasingly used in critical systems, where ensuring their robustness and alignment is crucial. In this context, the field of explainable artificial intelligence has proposed the generation of high-level explanations through concept extraction. These methods detect whether a concept is present in an image, but are incapable of locating where. What is more, a fair comparison of approaches is difficult, as proper validation procedures are missing. To fill these gaps, we propose a novel method for automatic concept extraction and localization based on representations obtained through the pixelwise aggregations of activation maps of CNNs. Further, we introduce a process for the validation of concept-extraction techniques based on synthetic datasets with pixel-wise annotations of their main components, reducing human intervention. Through extensive experimentation on both synthetic and real-world datasets, our method achieves better performance in comparison to state-of-the-art alternatives.",https://www.semanticscholar.org/paper/ba26eeec0f1b27ba05cfcf66f0395135ea5fca1b,"{'6648728ea8257eec4740f9602d18e75329779201', 'a3bb9cad000399690fea5bedafeab686f0de8244', '5809135c6ad6d0392be20a3143f2f74ab6f64ef4', 'a05500245d9471ef376cd74777fe8bafe62c3ded', '31fd462355a72e03bc375cd6b372f35a560dd36e', '38f23fe236b152cd4983c8f30d305a568afd0d3e', '2ac3e0e4653ba39393be3a2bb67dd52752d6801f', '1c9932feb06a3b873361a3318183396214fba4b5', '3a24bfb77ed271fef948058e414850f89b0955a7', '682b9d2212258fd5edbfca589c86390c31a956b0', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'aa4ed7fcbdb52b024683313ed38e282d104ceac4', 'febda9d873d87cdc5d80a89c23e8676c487771a7', '1b04936c2599e59b120f743fbb30df2eed3fd782', '6b37f7b2c636d488d1c2a92c2c5e8cbb387d0cd7', '8194c7e308017e53f29257cf31b37d63cdbc53bd', '8dc8f3e0127adc6985d4695e9b69d04717b2fde8', 'b452a856a3e3d4d37b1de837996aa6813bedfdcf', '5fca8bbec714e403fa0f95a56b355c8ca835bcc0', 'af6af40155860ac2fd36680e63686473803b5f52', '1a2118bed729579528deb51e745d58dd3629baf6', 'c12dda55bdff2f4cebf0a274331de8d117c2b7aa', '48f9a48aa5b1230b05a443d2d531e6441a541686', '5697da09cdfd3ce7768b126ced6b5a0b82e4e884', 'd6fff78f45db5e8a6246d256d58a047c7647059f', None, '1a0e3fada30a1bb41b5e3fb4e9c2c97b2cd8e2ab', '5c3a72f47ed8d58c0554210828af1ce4bbf2dbcd', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', '1b0f4bd3872bb590d457990ac2b26b29f770fc44', '18c6547b1af98bec9ce8df3f80cea8e63a57f47d', '63bc06753e0d38b511ddc07482822c24785e8c9a', 'd2c733e34d48784a37d717fe43d9e93277a8c53e'}",34,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Andres Felipe Posada-Moreno', 'Nikita Surya', 'S. Trimpe']",Andres Felipe Posada-Moreno,"Andres Felipe Posada-Moreno, Nikita Surya, S. Trimpe",2.9411764705882355
48f9a48aa5b1230b05a443d2d531e6441a541686,The MVTec Anomaly Detection Dataset: A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection,2021-01-06,,https://www.semanticscholar.org/paper/48f9a48aa5b1230b05a443d2d531e6441a541686,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '616b246e332573af1f4859aa91440280774c183a', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '732c21998e251d64cd58b6a86886ee5907efeaa5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '3c0edd61868d0e495184f858f427c613d08d8b27', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'c8c494ee5488fe20e0aa01bddf3fc4632086d654', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '40709121423d2d332c72057fd2268382a98fb8e9', '9acc51b06f54b07836fad4cc24633187dc21317f', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'c8924e3265e3f16af3177e619cf68a5ef764442f', '47638197d83a8f8174cdddc44a2c7101fa8301b7', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a0e8f4348968195c80494b7a4245edb91a252c93', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', None, 'e8e2ca8a73a8fb52f17a52b30863d5102d360ecb', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '41747cbdbed84762dfbfc305254c97021279dc6e', '3d07e8d62961e6b25869d4d90523157dc94eb484', '35a48d7099f2fd8c40e09de61e509ea0a846cbef', '4f0b8f730273e9f11b2bfad2415485414b96299f', 'ce05ebc31e7aa8e4152673bb240b9f8d27ebea21', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'f42b865e20e61a954239f421b42007236e671f19', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",42,"{'41747cbdbed84762dfbfc305254c97021279dc6e', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3'}",2,"['Paul Bergmann', 'Kilian Batzner', 'Michael Fauser', 'David Sattlegger', 'C. Steger']",Paul Bergmann,"Paul Bergmann, Kilian Batzner, Michael Fauser, David Sattlegger, C. Steger",4.761904761904762
14eb1e6dc228053a6c12988b0c5aab050f348548,Using deep learning to detect the presence/absence of defects on leather: on the way to build an industry-driven approach,2022-04-01,"In textile/leather manufacturing environments, as in many other industrial contexts, quality inspection is an essential activity that is commonly performed by human operators. Error, fatigue, ergonomic issues, and related costs associated to this fashion of carrying out fabric validation are aspects concerning companies’ strategists, whose mission includes to watch over the physical integrity of their employees, while aiming at enhanced quality control methods implementation towards profit maximization. Considering these challenges from a technical/scientific perspective, machine/deep learning approaches have been showing great skills in adapting a wide range of contexts and, in particular, industrial environments, complementing traditional computer vision methods with characteristics such as increased accuracy while dealing with image classification and segmentation problems, capacity for continuous learning from experts input and feedback, flexibility to easily scale training for new contextualization classes – unknown types of occurrences relevant to characterize a given problem –, among other advantages. The goal of crossing deep learning strategies with fabric inspection processes is pursued in this paper. After providing a brief but representative characterization of the targeted industrial context, in which, typically, fabric rolls of raw-material mats must be processed at a relatively low latency, an Automatic Optical Inspection (AOI) system architecture designed for such environments is revisited [1], for contextualization purposes. Afterwards, a set of deep learning-oriented training methods/processes is proposed in combination with neural networks built based on Xception architecture, towards the implementation of one of the components that integrate the aforementioned system, from which is expected the identification of presence/absence of defective textile/leather raw material at a low-latency. Several models powered by Xception were trained with different tunning parameters, resorting to datasets variations that were set up from raw images of leather, following different annotation strategies (meticulous and rough). The model that performed better reached 96% of accuracy.",https://www.semanticscholar.org/paper/14eb1e6dc228053a6c12988b0c5aab050f348548,"{'24062277133f6815289bf3136ed26329f3aaff87', '48d911c96232147e93a64d062f036e4544e61505', '23450469343cc80d30d9abaa1c2d4aa1fee3d361', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '642d55aff7307e3ed7febd22ea8b9504ff041af8', '3125394b515b7e5bc106b7c636662e17408aeb16', '585cd33b3f5d2595ce893b717e91a9569b63cb0b', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '5b6ec746d309b165f9f9def873a2375b6fb40f3d', None, 'd44efdc542f2cc5e196f04bc76bc783bfd7084af', '683e201783bf76ab99791a02e3763fd3ab8dad96', 'd02230c95e678ef8c618cd6b45ecb19dd2352d70', '66b820285e55efa6d638538f914478e228a69f78', '430856425ac44b6ffa65805983a7c6bd1d78b901', '2b199ad41bfcb121e58bccdd39c37fa08e108997', 'f11d69fac609917da82f697758cd694c0f01a730'}",17,set(),0,"['T. Adão', 'Dibet Garcia Gonzalez', 'Y. Castilla', 'Jose Perez', 'Somayeh Shahrabadi', 'Nuno Sousa', 'M. Guevara', 'L. Magalhães']",T. Adão,"T. Adão, Dibet Garcia Gonzalez, Y. Castilla, Jose Perez, Somayeh Shahrabadi, Nuno Sousa, M. Guevara, L. Magalhães",0.0
cc63b87a654e28aefe60250e950572bfb3d7e2ea,DFR: Deep Feature Reconstruction for Unsupervised Anomaly Segmentation,2020-12-13,,https://www.semanticscholar.org/paper/cc63b87a654e28aefe60250e950572bfb3d7e2ea,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '732c21998e251d64cd58b6a86886ee5907efeaa5', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '4d376d6978dad0374edfa6709c9556b42d3594d3', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '85384a8871030bbd1681adee9e9956dce4d751ba', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '67107f78a84bdb2411053cb54e94fa226eea6d8e', '317aee7fc081f2b137a85c4f20129007fd8e717e', '1bbf746cca4bcafd274d197ac9fae82b245bf97b', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a0e8f4348968195c80494b7a4245edb91a252c93', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', None, 'c2b733a79db700b971327a58ef42699fe8a416aa', '41747cbdbed84762dfbfc305254c97021279dc6e', '4100414ad0763bdc91bd15bb6e0424a44d7a35fe', '17d7b57dcc5c50e3bf2dada669a7905a8f5b13ef', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'ba1f6ef20824aba161c4b3666e29e99486f20390', '2910bec6d4de87e22be5119cef3c488d2ae50e2a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb42cf88027de515750f230b23b1a057dc782108', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', '23364d3dfab309ef3af5bcfda9a222029ad22b23', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'fe09f7a379944444201552e952b910188c0aeaca', '66ccd943eebb652af13b6096c6edc3407eb510e5', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '75a838cbc1541858b9c484001cade327640dc280'}",41,"{'41747cbdbed84762dfbfc305254c97021279dc6e', 'd9d7ab13ce305ccee309c989a2341d72b1252070'}",2,"['Jie Yang', 'Yong Shi', 'Zhiquan Qi']",Jie Yang,"Jie Yang, Yong Shi, Zhiquan Qi",4.878048780487805
60f8facb6a8c866e16235333c745ae08ec6a8f86,Latent Outlier Exposure for Anomaly Detection with Contaminated Data,2022-02-16,"Anomaly detection aims at identifying data points that show systematic deviations from the major-ity of data in an unlabeled dataset. A common assumption is that clean training data (free of anomalies) is available, which is often violated in practice. We propose a strategy for training an anomaly detector in the presence of unlabeled anomalies that is compatible with a broad class of models. The idea is to jointly infer binary labels to each datum (normal vs. anomalous) while updating the model parameters. Inspired by outlier exposure (Hendrycks et al., 2018) that con-siders synthetically created, labeled anomalies, we thereby use a combination of two losses that share parameters: one for the normal and one for the anomalous data. We then iteratively proceed with block coordinate updates on the parameters and the most likely (latent) labels. Our experiments with several backbone models on three image datasets, 30 tabular data sets, and a video anomaly detection benchmark showed consistent and signiﬁcant improvements over the baselines.",https://www.semanticscholar.org/paper/60f8facb6a8c866e16235333c745ae08ec6a8f86,"{'cab70cec4944364a9f12af5036f2a5bfa6f2a4f7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'dcd9f5d61bc9a70c40be84a8d78fbee822ffcd9e', '450ae94f84eba33e2ed60a1ea9657fbe93989c51', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '41d9b4104b6d8cb8c135560b5f775bc8cd7a720d', 'db787640c9b42416ff8d7015546e667e58267177', 'c87d57da3b1f2b467ef4995d30df832ee2281107', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', 'e2de29049d62de925cf709024b92774cd82b0a5a', '16e7f96426b2c1acad5e56f25da0c0e2685beb84', 'a4c94b221062d0737ee967affa80ce2110cc50c0', '1f5edbb34d918c6c5d9478688d090289d972e798', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '04513c7c0b3a63fde81a996dae064a28d453c17a', '498e003901f8287e89e5064477cd22dd47e49d61', '297e83bc6d4498ad2e2906092e2b3df1b7621c26', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '732750bec3b4d8c0108d6daed642500765d5c0ca', '8d23d6432c27843040f51dcf0191877f7a9994e9', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '9e66b328144102f57f14b5b47620d3bc19c684b8', '6869ab1f42e30b415829de9928f7e4a606113601', '7623bf275d0682993fd40044a1c038873ec82608', 'a7d75aa3a0a9faa310fb524c350fba2093b0ec97', '84f7f9e121c1285e15cefbfc44bcb3322f73b6aa', '55d85ee670776f915736b2a64c2874efafffe233', '0b7766f216c0be8b94f5fd4361981d586d1130bc'}",40,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'a7d75aa3a0a9faa310fb524c350fba2093b0ec97', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '498e003901f8287e89e5064477cd22dd47e49d61', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",6,"['Chen Qiu', 'Aodong Li', 'M. Kloft', 'Maja R. Rudolph', 'S. Mandt']",Chen Qiu,"Chen Qiu, Aodong Li, M. Kloft, Maja R. Rudolph, S. Mandt",15.0
7d3a0fca300423684d01d5ab767f8eacdaa45f51,"A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution Detection: Solutions and Future Challenges",2021-10-26,"Machine learning models often encounter samples that are diverged from the training distribution. Failure to recognize an out-of-distribution (OOD) sample, and consequently assign that sample to an in-class label significantly compromises the reliability of a model. The problem has gained significant attention due to its importance for safety deploying models in open-world settings. Detecting OOD samples is challenging due to the intractability of modeling all possible unknown distributions. To date, several research domains tackle the problem of detecting unfamiliar samples, including anomaly detection, novelty detection, one-class learning, open set recognition, and out-of-distribution detection. Despite having similar and shared concepts, out-of-distribution, open-set, and anomaly detection have been investigated independently. Accordingly, these research avenues have not cross-pollinated, creating research barriers. While some surveys intend to provide an overview of these approaches, they seem to only focus on a specific domain without examining the relationship between different domains. This survey aims to provide a cross-domain and comprehensive review of numerous eminent works in respective areas while identifying their commonalities. Researchers can benefit from the overview of research advances in different fields and develop future methodology synergistically. Furthermore, to the best of our knowledge, while there are surveys in anomaly detection or one-class learning, there is no comprehensive or up-to-date survey on out-of-distribution detection, which our survey covers extensively. Finally, having a unified cross-domain perspective, we discuss and shed light on future lines of research, intending to bring these fields closer together.",https://www.semanticscholar.org/paper/7d3a0fca300423684d01d5ab767f8eacdaa45f51,"{'f42f87e4015f1aad3ed464b47c8644214b41748c', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6a83ce3a5604e3dad44c6b5fe992056add6c605f', 'db787640c9b42416ff8d7015546e667e58267177', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '1322719978980a831e1aee78aa80a141379c44dd', '5db790198b9acf4e5efe350acdd814238fcacaa7', '1d3258abdfdc9262a3c5736a4619869a39d17120', '468c3476b93e5e5ffa38e7fb2494bc7fd5901ae8', '86c12bb6fb6fb2956d1147bd1b15a788b6d07f6e', '820f81f4263ad84b581e2b0feec563db0c64ff9b', '7dbdb4209626fd92d2436a058663206216036e68', '38643c2926b10f6f74f122a7037e2cd20d77c0f1', '91e4d958f4c58c8d09bf9440473a26a18260d1a5', '21f7833c38db29012e082b4ce20bdaa1f9c0e59f', '525de09d3a184c2455ff68dabfd7d427a5b2e68e', '7cfa5c97164129ce3630511f639040d28db1d4b7', '9ea50b3408f993853f1c5e374690e5fbe73c2a3c', '04513c7c0b3a63fde81a996dae064a28d453c17a', '37595f7a51982d776e57c7280b9445474d90f0be', '02b1607af35b48f0bd716367caf6a7428b969369', '498e003901f8287e89e5064477cd22dd47e49d61', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', 'f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d', '67b6fd4dd2c5a5bdd87797a4b6caab253267f92b', 'a48a56b0727d09f599676524fe190308d9e88bf1', '6507909a8f77c88144c3a67b9336bd1c85e84cac', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', '275675ea82a4b35c42bea2943649cabe6f6e43ab', '1b59eea8ec4684381a885b59acd09c9151a49487', 'ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba', 'a7c828184693a453a6c2867dee233ed054b2012e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '7aa38b85fa8cba64d6a4010543f6695dbf5f1386', 'da8aa38ba087b0200b2f81f2e86e0e8036993579', 'abb6e069538588bd1214bf2744e41181d164f41b', '132a8547513c1a2a1e10e827282d50683d6542ce', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '47cbd8cfd6fcba83d3b3714faef480260bc9d5de', '31f10a6f602bef0306ac37322f84f6163c8a8ecb', '1d033b30f38642e4b6dd146bb8b464bfb58aad96', '30895c61bb836f2cae7ef5ba6516886f746a7153', '02227c94dd41fe0b439e050d377b0beb5d427cda', '05e882679d61f4c64a68ebe21826251a39f87e98', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '549e8e5eea04b301cbb805f5502afffef492d344', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', 'adaa0523a5c9d5f92aa2009a51226391d8e62380', '2ad303a88ba4fe57a4a3618aa42be90335481acc', '2b088b9b1abc84bb207396b440527219277e2718', '3b316377f1d7cbcf3c907c4d8b08c05f4521b541', '1703631a938b397ba7e858161ce16448f6046d6f', '10b219619e88931fabb674037bbb633682775136', '02b28f3b71138a06e40dbd614abf8568420ae183', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '330008af4074ef0e2b21787677783827d6a15056', '4feef0fd284feb1233399b400eb897f59ec92755', '37c3303d173c055592ef923235837e1cbc6bd986', '4dcdae25a5e33682953f0853ee4cf7ca93be58a9', '7ad9822c1de2b61708b803e8a0a548718cefdeb5', 'a98cc4d37b0af9be710c5b6f4a3579331e6fcfbe', '3471032918f2e6fd65677ad491a79ffa14b1c289', '2c7e2e4f1876eb0235e698beee5a5a365ca06d15', '54c6416eae67bce7b3f058601e0c758e39f33a62', '967d532a66dab7edcb818b0f9dc59fe8da7dc171', '99487be08cab00554c5c8db73161b2615c694f71', 'ae9bf201f128cabaa4350b54ff6607525c736cd5', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '19745a4ae79264948b168400463bfe50343a736a', 'c889d6f98e6d79b89c3a6adf8a921f88fa6ba518', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '91e36e1c6e3d4a5bdc97fa5ab5b89bdf9113413d', None, '4cfd8f903506865e7ccf28b0a07ee3c551487e92', '41747cbdbed84762dfbfc305254c97021279dc6e', '3517b9824def42f3c723c6c63eda7ade12d25538', '9fcb88ec529aba79a5860e8fde76e7f4762a267d', '2910bec6d4de87e22be5119cef3c488d2ae50e2a', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '815fa9febd615530abccc2430ee05804427394ba', 'f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6', '13f759a3a456941fe78442a258e635a2b544aee2', '8ee35ed698527d9695c872e3b76715fec4ef69ad', 'dc8301b67f98accbb331190dd7bd987952a692af', '086015aa2c44bd2ebd95ab6a1a562e57177c7fa8', '4b04b42dc57b99060a3b9a870012659dca44054f', '1af23b78166b6adbccfedff04abcc0dd23ab1bd5', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'a90226c41b79f8b06007609f39f82757073641e2', '4b83e9a048e677ff9fab226e8f7fbaa33fd32024', '14edcd37e697f0bbb495962c3b5a3c141410bf37', 'd98ec42c5bc64b06b5d6e259467528e0121ae69b', '1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'a05500245d9471ef376cd74777fe8bafe62c3ded', 'e8b8a7778ace2a02f8db6fe321a54520c6b283ca', '4c7d664761c359cffd20c9d555031271ec67ab3c', '0c908739fbff75f03469d13d4a1a07de3414ee19', '9a700c7a7e7468e436f00c34551fbe3e0f70e42f', '364128bcce9836d60e685bb717b80f30e25092e0', '6e4e75c88a0801c87f47a171aa69a9914f9129bf', '8f7ed8686fc97c4e624c8ea4f52fc48d3b03d6b7', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'ed17929e66da7f8fbc3666bf5eb613d302ddde0c', 'e24c0387fa0ec3c32ebc97c050c94b8b01eeadd2', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'c3ddd90b53dc797029c4576af01b9c35bb846a44', '45557cc70cd6989ab6b03e5aeb787e34299099f7', 'b9bd435b65d8214f1bcab9268ac2fce509cfffe6', '03a507a0876c7e1a26608358b1a9dd39f1eb08e0', '8c01d1da727b3325dc7afa226db7658f4b2d242f', '6af440915b8a0718c93be1cf61905e41e620484a', '378927c2709643934e7ee48e812e410223a73ae3', 'f30b10bb58e49138cbf33e625746c87b662a9e7d', '35b966347dae2f0d496ea713edf03a68211838a5', 'bfd94574a02fc6cce90175add58dd85a14201fad', '6ff2a434578ff2746b9283e45abf296887f48a2d', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '17d50efa0d5ad863f5939eb586bb0a5436b0adf7', 'a25b63a6a0071d7d88ff4671c1fd40f320a08533', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'eb35fdc11a325f21a8ce0ca65058f7480a2fc91f', '8381157eae4fbf8908d0312a9642f8e69e944449', '02bd9dfe5a0e8f38af6a3f5b787e52ed169f09bd', '3cf2a7f796921e01e6e794da193a244c3b793b04', '0fe615dc0a422100e85cfb7e26c9306c481f6c75', '90dc22818bd2d97d8deaff168b0137b75a962767', '06671547fd94c44688b10c8cd550242557e55154', '1e5e8106700c8dbdfa036a5a9be5e61e06c0ed02', '583d5ebc65d0c1bf3d7652d585011302e5f34cf8', '0e4b0d177e550d365f456375781cd0e4f7a04979', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '8d54db5ec8f2719fb37d98cb1d47ff48838c0370', '5b8013f4425b6b889a514e95fe6355a83c64d1ea', 'bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6', 'b110ba174df21a23a9521731d4181261ca5860ed', '00a1077d298f2917d764eb729ab1bc86af3bd241', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'f19092561296244e1dafe7d799e7906e96a63773', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '241cca17a6218728064eea0505a7b8e2e5db4c87', '36653f8705b56e39642bcd123494eb680cd1636b', '42a047ca1bc1e5c8fecafb9d1ea2cbd03aae05fb', '5c8fe9a0412a078e30eb7e5eeb0068655b673e86', '853272e90e9b9c05eaa60fbb02fad4f2a83f031a', 'd094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c', 'f538dca4def5167a32fbc12107b69a05f0c9d832', 'c2b733a79db700b971327a58ef42699fe8a416aa', '1643f48027cd18aeaf713bf7b5b18bb91a765503', '9af970dd5c03f112260254da1f9a1130e24bc1bf', '53ecb9653a4d62f29f8c96cf61c1d206780e8789', '7f9760a76e9cf424da0b72d42f75594cefc4a329', '7437fb168cea92e1df8332ac618f7f07b071aca8', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '5771af144ce1d4d783a0af70c190a74e5123d0a0', '50577b1a6aa575f401bce336e015e7a4eaf7edcb', '7fc604e1a3e45cd2d2742f96d62741930a363efa', '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', '05c2e1ee203be217f100d2da05bdcc52004f00b6', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '962dc29fdc3fbdc5930a10aba114050b82fe5a3e', '4218563e1fe927440e00bf0abe5cb1e037deaf71', 'b4637bbec842772826f04b8c75e6dab77d2d607d', '759d9a6c9206c366a8d94a06f4eb05659c2bb7f2', '2324d25fcbeb11d04dd2956026a5c4d68eac54dd', '663df917647bf527e6664dfc6cb9ea6ea3d77da0', '0ceb0778ecc49ab17f711d0a006714f5063e44ef', '0936352b78a52bc5d2b5e3f04233efc56664af51', '89a816719613e220a64ab2590c938c23bbfe187e'}",179,"{'820f81f4263ad84b581e2b0feec563db0c64ff9b', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', 'bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",14,"['Mohammadreza Salehi', 'Hossein Mirzaei', 'Dan Hendrycks', 'Yixuan Li', 'M. Rohban', 'M. Sabokrou']",Mohammadreza Salehi,"Mohammadreza Salehi, Hossein Mirzaei, Dan Hendrycks, Yixuan Li, M. Rohban, M. Sabokrou",7.82122905027933
77d0381d5bd41652ab283f4b3af84953d1aca641,Feature anomaly detection system (FADS) for intelligent manufacturing,2022-04-21,"Anomaly detection is important for industrial automation and part quality assurance, and while humans can easily detect anomalies in components given a few examples, designing a generic automated system that can perform at human or above human capabilities remains a challenge. In this work, we present a simple new anomaly detection algorithm called FADS (feature-based anomaly detection system) which leverages pretrained convolutional neural networks (CNN) to generate a statistical model of nominal inputs by observing the activation of the convolutional filters. During inference the system compares the convolutional filter activation of the new input to the statistical model and flags activations that are outside the expected range of values and therefore likely an anomaly. By using a pretrained network, FADS demonstrates excellent performance similar to or better than other machine learning approaches to anomaly detection while at the same time FADS requires no tuning of the CNN weights. We demonstrate FADS’ ability by detecting process parameter changes on a custom dataset of additively manufactured lattices. The FADS localization algorithm shows that textural differences that are visible on the surface can be used to detect process parameter changes. In addition, we test FADS on benchmark datasets, such as the MVTec Anomaly Detection dataset, and report good results. show the usefulness of the FADS algorithm (average AUC of 0.983 across 7 folds) on a new dataset comprised of additively manufactured lattices. The FADS anomaly localization algorithm showed that changes in laser power and speed in in subtle in on the the which to identify",https://www.semanticscholar.org/paper/77d0381d5bd41652ab283f4b3af84953d1aca641,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'a891379a17c87358d7f7a0897f40c8ec7d6b9c01', '32146a0f8b2676a7b1db65a8896dbba66c6e14cd', '27a2c94a310d20ccae9c98e0f38d7684a16f9e61', '3a7c0e1dfdf56077fde462345252a885ee6bfcaf', 'd67310527aa81715bff8f71e0d3492e0c5d3c006', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', 'cb1292e865965b54806eb0e62f0e9cb4b3ac3588', '281285931883f2ddc6480050e9c5581772721de9', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'f33e042dcb5db478ff4ad5f2d665594a2baf470f', '8e3f9c297bb2df253c505df20c5b2045e5dc67c7', 'ce2b00a4997581ea4deea06001da491fc381120b', 'f6a7f7058a73b2b2ad58c8de9a82a5e462871baa', '18d026ec5d0eebd17ee2c762da89540c0b3d7bde', '820f81f4263ad84b581e2b0feec563db0c64ff9b', 'b110ba174df21a23a9521731d4181261ca5860ed', 'b699aaa0d53cd31d011ba09edf9061e80ed40ea1', 'f6971d3b31d825e54451d41c851e87eaf134aea2', '108805c5f6680e69fd4d621c54b6a5b5096bdc27', '7072c92d4a42fa9a63b89b80c43c02ce31822b70', 'a14d0102e05b34fb0caec09013f0f9ce0f0fa26d', '5096d5817c4ed89635d9f065c79a44a2601e939f', 'a5411d72ddba750c2ddb9f5e73a42c91d9677f41', '50dd894a36018590e4887af270c9f4d06889d10b', '6cdf9db061e2fe0054aa0bc91b1027ece68b4b46', '11ff9c1b05a0493190651eb484ca70114609f1d9', '6af440915b8a0718c93be1cf61905e41e620484a', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '7ac43d9f677013b992472d1d11c7a0f1b8c9154e', '54f75e66ac7d6eafe374e693f272b428bbffd79d', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '0e4f9904977318e21c9b4014b639b6ef114a999f', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '95d6bc77355626f1b3e0b2d0353f0dc9fd9f1645', 'ce0c54469201eabe6a46465042c320fbcb11deb7', 'b04db132c033b31010281baa44ce547463367453', '0f84a81f431b18a78bd97f59ed4b9d8eda390970', '7514967d5675e50563a1a72130f9d2390c23627c', '9235d511dea04aa563a577ab236506b8eb8242ff', '5c6eea437f24b9fac9487f16a9166ea9ef491e27', '577625c10ff83280d2d72cf65343e5cb814d56a5', '0f1500944e3da349c3fc959f21d38d01254da1e7', '14fbb67fb629dd025cb72067d161315736bc8db9', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",47,"{'820f81f4263ad84b581e2b0feec563db0c64ff9b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '48f9a48aa5b1230b05a443d2d531e6441a541686', '54f75e66ac7d6eafe374e693f272b428bbffd79d'}",4,"['Anthony P. Garland', 'Kevin M. Potter', 'Matt Smith']",Anthony P. Garland,"Anthony P. Garland, Kevin M. Potter, Matt Smith",8.51063829787234
cd382609f0029aae042e91a5a46b3dc2ba58a321,Anomaly Detection in 3D Point Clouds using Deep Geometric Descriptors,2022-02-23,"We present a new method for the unsupervised detection of geometric anomalies in highresolution 3D point clouds. In particular, we propose an adaptation of the established student-teacher anomaly detection framework to three dimensions. A student network is trained to match the output of a pretrained teacher network on anomaly-free point clouds. When applied to test data, regression errors between the teacher and the student allow reliable localization of anomalous structures. To construct an expressive teacher network that extracts dense local geometric descriptors, we introduce a novel self-supervised pretraining strategy. The teacher is trained by reconstructing local receptive fields and does not require annotations. Extensive experiments on the comprehensive MVTec 3D Anomaly Detection dataset highlight the effectiveness of our approach, which outperforms the next-best method by a large margin. Ablation studies show that our approach meets the requirements of practical applications regarding performance, runtime, and memory consumption.",https://www.semanticscholar.org/paper/cd382609f0029aae042e91a5a46b3dc2ba58a321,"{'93ff162855c388691bebe841eac81332340183e6', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '5b589d7564dbef07ec98b3248f58a481b4ca1395', '04258f92294d5dea89adb3e8607ae22eadb5332d', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '40709121423d2d332c72057fd2268382a98fb8e9', 'c8924e3265e3f16af3177e619cf68a5ef764442f', '168c80dc822fb30fdf98be13267c9dbfc8a7dde0', 'b72771c316d60190aff053ef8a216ba57d62f541', 'de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42', '5da4eb1135d5827ce30e099bda377a19f3a52730', '2094f315289ccf9b676e0790fb3dd1bc4acad98c', '295aca7669f54cdc746c595088693bb102855b9f', 'ef8a1fb0934d5574d89e610a1dbf3240e0384088', '410fb9c0a527b8dbae034e2a8e25dc325fdd5e74', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'b37b3086add419e4679255366d61d4e70896651e', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', 'f7174c5c29c3904cc2d23f26be2b896a5bc715b4', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '44b28261c137db7d4c474f3726e1000f5e42ff6a', '985e7d47d3d41753900ddffb1af585221bf3d8ec', '1fbbe6fcf6465bab87b9ae55bc5fd23c528f24b9', '358a97112cc60d6bfefb352b863fec8a86a39e28', '491188ac198663094537cb4c38ac1c8808ef7440', '7c8a51d04522496c43db68f2582efd45eaf59fea', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'a0e8f4348968195c80494b7a4245edb91a252c93', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', '6345842ec06145ac397b8b46d5f64113162a9268', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '48f9a48aa5b1230b05a443d2d531e6441a541686', '587110558b1744b912108dd0b74970f131317e0d', None, '41747cbdbed84762dfbfc305254c97021279dc6e', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '260b70120f1b58f2d85aa19a3f2e2b3799d04e65', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '108291a9ac15c5384f4a55f0b6b7e89a1dbe40d8', '9ccef6c69e5c16ac2ce9da4f1411415e402dd59c', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '580062407427236ced45253a2ff7df2e147a81e2', '29eddac19e736100e31aae759ad10028ac1e28eb', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1'}",47,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '5da4eb1135d5827ce30e099bda377a19f3a52730', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '295aca7669f54cdc746c595088693bb102855b9f', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', '410fb9c0a527b8dbae034e2a8e25dc325fdd5e74', '9277dc70c74bcadf80dab11c28ead83fd085deec', '48f9a48aa5b1230b05a443d2d531e6441a541686', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'f7174c5c29c3904cc2d23f26be2b896a5bc715b4', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",15,"['Paul Bergmann', 'David Sattlegger']",Paul Bergmann,"Paul Bergmann, David Sattlegger",31.914893617021278
4ed1320ac567f7adbfc05b614b410d87c5247205,Improving the Efficiency of Autoencoders for Visual Defect Detection with Orientation Normalization,,"Autoencoders (AE) can have an important role in visual inspection since they are capable of unsupervised learning of normal visual appearance and detection of visual defects as anomalies. Reducing the variability of incoming structures can result in more efficient representation in latent space and better reconstruction quality for defect free inputs. In our paper we investigate the utilization of spatial transformer networks (STN) to improve the efficiency of AEs in reconstruction and defect detection. We found that the simultaneous training of the convolutional layers of the AEs and the weights of STNs doesn’t result in satisfactory reconstructions by the decoder. Instead, the STN can be trained to normalize the orientation of the input images. We evaluate the performance of the proposed mechanism, on three classes of input patterns, by reconstruction error and standard anomaly detection metrics.",https://www.semanticscholar.org/paper/4ed1320ac567f7adbfc05b614b410d87c5247205,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '7e9e2006ed05fb92986ede10a62c4050afe3b351', '82b223712aa01f2261795658a6d1adeec0bb8bd3', 'a63404bc4fbad758836f1be75f50737637278e9b', 'a6d2708685e9d78068e2abcd800e6bb1c886d2b6', '9179e740dad4ca4c183f7677b854e5b15f9a122f', 'ee82134086e069bb93d960ef1caa8a101966f984', 'b4707ed22750ed56a345b0a18a035b933eac0b66', '7244d1b863f0d00f15d9668914437271cf218d14', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '732750bec3b4d8c0108d6daed642500765d5c0ca', 'fe87ea16d5eb1c7509da9a0314bbf4c7b0676506', '5c6eea437f24b9fac9487f16a9166ea9ef491e27', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'b917ee6234db2cf50a4a9aa9402e90e544892dd6', '7799d596f07ab001922220d88a86cace69663902'}",19,"{'ee82134086e069bb93d960ef1caa8a101966f984', '48f9a48aa5b1230b05a443d2d531e6441a541686'}",2,"['Richárd Rádli', 'L. Czúni']",Richárd Rádli,"Richárd Rádli, L. Czúni",10.526315789473685
d70765afccf7125ed408310ca4ba4b5dd0b80520,Contrastive Predictive Coding for Anomaly Detection,2021-07-16,"Reliable detection of anomalies is crucial when deploying machine learning models in practice, but remains challenging due to the lack of labeled data. To tackle this challenge, contrastive learning approaches are becoming increasingly popular, given the impressive results they have achieved in self-supervised representation learning settings. However, while most existing contrastive anomaly detection and segmentation approaches have been applied to images, none of them can use the contrastive losses directly for both anomaly detection and segmentation. In this paper, we close this gap by making use of the Contrastive Predictive Coding model (Oord et al., 2019). We show that its patch-wise contrastive loss can directly be interpreted as an anomaly score, and how this allows for the creation of anomaly segmentation masks. The resulting model achieves promising results for both anomaly detection and segmentation on the challenging MVTec-AD dataset.",https://www.semanticscholar.org/paper/d70765afccf7125ed408310ca4ba4b5dd0b80520,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '1cae417456711c4da184f5efcd1b7464a7a0661a', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '77f0a39b8e02686fd85b01971f8feb7f60971f80', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '56b49a52057cd8e5497fd5618f031ad701bf6526', 'd3b614f11969127a08447c41257b3a7b58766d18', 'e3ce36b9deb47aa6bb2aa19c4bfa71283b505025', None, '41747cbdbed84762dfbfc305254c97021279dc6e', 'eae7d5b15423a148e6bb32d24bbabedfacd0e2df', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '155b7782dbd713982a4133df3aee7adfd0b6b304', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '09bd55b7ea6bbe1c352ca4b04c86fcf1e7d677cb', '94192bcdf3507e3543910c03b16bd06c5338fd47', 'add2f205338d70e10ce5e686df4a690e2851bdfc'}",25,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'd3b614f11969127a08447c41257b3a7b58766d18', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",8,"['Puck de Haan', 'Sindy Löwe']",Puck de Haan,"Puck de Haan, Sindy Löwe",32.0
2e8d62277e40d465343e8dfb32ecc246f320540e,PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization,2020-11-17,,https://www.semanticscholar.org/paper/2e8d62277e40d465343e8dfb32ecc246f320540e,"{'d03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'cac33f91e59f0a137b46176d74cee55c7010c3f8', '1c4e9156ca07705531e45960b7a919dc473abb51', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', '5435a9ab36a308cef10bc725104e8f778ed3a328', '04513c7c0b3a63fde81a996dae064a28d453c17a', '37595f7a51982d776e57c7280b9445474d90f0be', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', '70f9968a356d840040a1c9207906f60376dc6bd4', '964465406626125ce235faaccf25e265c56f501b', None, '41747cbdbed84762dfbfc305254c97021279dc6e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '8381157eae4fbf8908d0312a9642f8e69e944449', '0efb841403aa6252b39ae6975c1cc5410554ef7b', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'ca2841bf2e9ba0a6217c070b93da3e9513a1f089', 'd2c733e34d48784a37d717fe43d9e93277a8c53e'}",33,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e'}",7,"['Thomas Defard', 'Aleksandr Setkov', 'Angelique Loesch', 'Romaric Audigier']",Thomas Defard,"Thomas Defard, Aleksandr Setkov, Angelique Loesch, Romaric Audigier",21.21212121212121
44e5c681bed1b4c08a745b199e353ce7bafd8a92,PEDENet: Image Anomaly Localization via Patch Embedding and Density Estimation,2021-10-29,,https://www.semanticscholar.org/paper/44e5c681bed1b4c08a745b199e353ce7bafd8a92,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '72afa0fd1263d4ec60be39ed31be6755fdbaafa1', 'ffd743cdef874446ea3bae04cad34d1ec309fa6e', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '3f466c276cc237759eb2d078ce03c82940d3d30c', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'eebd8bfdb2929dfdb1110cf9fbf8d0d008c8edca', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', 'b20e564edbef25009fa1baa2c369437c89147e61', '24d48ebc062f05f9883f1b9c36f81b91be6f3221', '6af440915b8a0718c93be1cf61905e41e620484a', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '90902e16f4e8ff5e3c4bf0f971380af5753aacdd', '785a7e01267683deb54a94f6a8b4019806e3f085', 'd6f2f611da110b5b5061731be3fc4c7f45d8ee23', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '746cf281d8198310b1242048bf4fd90e0486f1a9', '37257b1e003d97f617f41a5ccf982566ce0a208b', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",31,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '37257b1e003d97f617f41a5ccf982566ce0a208b', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f'}",13,"['Kaitai Zhang', 'Bin Wang', 'C.-C. Jay Kuo']",Kaitai Zhang,"Kaitai Zhang, Bin Wang, C.-C. Jay Kuo",41.935483870967744
9180eab9ea90e1057c440e1941dc8a5bf578d061,Anomaly localization in regular textures based on deep convolutional generative adversarial networks,2021-05-24,,https://www.semanticscholar.org/paper/9180eab9ea90e1057c440e1941dc8a5bf578d061,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '67b9052fdace3ed74297baaae14578246576ec0a', '2673354bc246e65962a6dca32d5f41cc8f11a249', '2bf3a05467939fcb00de606cc1bcc9353ad288cb', '028bde86424faec4294070a0c7be6dbed3ed0b02', '87d1116dc6f9925b606040496f774c0678402b65', 'dd8502990c6a7c40e95237be1f22c0fc3ac64e39', 'fcce5755177b26211ec8e7c72d8cea10c0984ef2', '375b98f955774e5438b76dd51e9a94ac68955258', '4dee7f0bd46fbdd2a96f265977d732ff4348b0d2', 'eef543b14296249a911472142606bf082c714b81', 'f01fc9022b44a5413ecb3765ca0b86cff2cc8589', '3f8976a36c12173a0a1b458b8c8c4fee01fe9a1c', '355b4e74774798c177c82943eef925d66a2bb2ce', '730966f44d4e7eda143f3cb4dcb8e4a01581aae8', 'e572f7aaf4596808161b435fda71a5b8f7a30f79', 'c2c22632e31758135a615cd3360a23a63be91adc', '7d7bb32924303174c4c358dd07dfbde1cf908ced', '6c5d34d91bcc02b43b62e84d8c6ce7678f07fc9e', '483c85d9ce1e6068158be8a3395f9c570b916d58', '523a3a25b5da622985b82cb9c1a1a04c4e2130bc', 'e50e1e9d9f436b707a899e40c884af529cc13cd1', 'e0e11a3459e2848bac92f67ae1c7acc00d38bdc9', '2c9bb4e243bcbaa4933203a4fe23b230d4cd2d97', 'ee7aaa99233effc9d4b2720be6b3841044d7fb60', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'd880d303ee0bfdbc80fc34df0978088cd15ce861', '7fc3119ab077617e93a8b5b421857820a1ac745f', '85aefb7a0c0e0f7a60b7c453d1767c9dd6b7964a', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '0fba409648eb6087a1e7d741655967815b9f0377', '24046c62be024695e9c73768ef6bcf870ca383c0', '2bc87d8dddb3fa232bfa2fcce56c9a2a41f67e01', 'e63c0991e699f65d1e3d241c190a739439e490f7', 'c992f74eb6ceddd73eb29a5113d04140484fb8fd', '2421f55ec4e9bc24d2a7ccb902bbab12fb05d1fe', 'a134f6a43147245f02036d8993edbe46af258a14', 'dfd99e17b5d49954a9740bd5b94f3b1e2b958e0b', '7b17689f9e3e63e47fe19be3b9a43acac264369c', '7e8da325521b013c93d9ab88fcae1ec5220b96c1', '9fcc1189d5b83258ed2c78b0447c96eb527fb63c', '80468c597cbec6244fa7df27c5bc31f3fd76bf95', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",43,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', '24046c62be024695e9c73768ef6bcf870ca383c0'}",2,"['Muhammed Ali Nur Oz', 'M. Mercimek', 'O. Kaymakci']",Muhammed Ali Nur Oz,"Muhammed Ali Nur Oz, M. Mercimek, O. Kaymakci",4.651162790697675
f40b83fddae574937199a857504d84ebe8fce418,Discriminative Feature Learning Framework with Gradient Preference for Anomaly Detection,2022-04-23,"Unsupervised representation learning has been ex-tensively employed in anomaly detection, achieving impressive performance. Extracting valuable feature vectors that can remarkably improve the performance of anomaly detection are essential in unsupervised representation learning. To this end, we propose a novel discriminative feature learning framework with gradient preference for anomaly detection. Speciﬁcally, we ﬁrstly design a gradient preference based selector to store powerful feature points in space and then construct a feature repository, which alleviate the interference of redundant feature vectors and improve inference efﬁciency. To overcome the looseness of feature vectors, sec-ondly, we present a discriminative feature learning with center constrain to map the feature repository to a compact subspace, so that the anomalous samples are more distinguishable from the normal ones. Moreover, our method can be easily extended to anomaly localization. Extensive experiments on popular industrial and medical anomaly detection datasets demonstrate our proposed framework can achieve competitive results in both anomaly detection and localization. More important, our method outperforms the state-of-the-art in few shot anomaly detection.",https://www.semanticscholar.org/paper/f40b83fddae574937199a857504d84ebe8fce418,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '5db790198b9acf4e5efe350acdd814238fcacaa7', '8bdfb96e2865ad0d1e263f04fc0dab134052d64e', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', '8fec178e2a9b8b626ad89d34cd7b5a4a2db9ef1d', '182d11020bf2842f135f1ec1dcac20237e0dc8b7', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'b1464ca857593c049873421db2f37bf2d0ff676d', '10a498003e9204f5fc1328e706510a37e514d8c7', '7edbd1ee743632893de81d117c05120774dc36f4', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', None, 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'a08cf46861c057fbab685d486218c3829b221e3d'}",23,"{'182d11020bf2842f135f1ec1dcac20237e0dc8b7', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'b1464ca857593c049873421db2f37bf2d0ff676d', '41747cbdbed84762dfbfc305254c97021279dc6e', '8fec178e2a9b8b626ad89d34cd7b5a4a2db9ef1d', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",11,"['Muhao Xu', 'Xueying Zhou', 'Xizhan Gao', 'Wei-Xiong He', 'Sijie Niu']",Muhao Xu,"Muhao Xu, Xueying Zhou, Xizhan Gao, Wei-Xiong He, Sijie Niu",47.82608695652174
aba6679e907422f74f99ec9590aef87af947f4fa,Cell Anomaly Localisation using Structured Uncertainty Prediction Networks,,"This paper proposes an unsupervised approach to anomaly detection in bright-field or fluorescence cell microscopy, where our goal is to localise malaria parasites. This is achieved by building a generative model (a variational autoencoder) that describes healthy cell images, where we additionally model the structure of the predicted image uncertainty, rather than assuming pixelwise independence in the likelihood function. This provides a “whitened” residual representation, where the anticipated structured mistakes by the generative model are reduced, but distinctive structures that did not occur in the training distribution, e.g. parasites are highlighted. We employ the recently published Structured Uncertainty Prediction Networks approach to enable tractable learning of the uncertainty structure. Here, the residual covariance matrix is efficiently approximated using a sparse Cholesky parameterisation. We demonstrate that our proposed approach is more effective for detecting real and synthetic structured image perturbations compared to diagonal Gaussian likelihoods.",https://www.semanticscholar.org/paper/aba6679e907422f74f99ec9590aef87af947f4fa,"{'9a9389b0ed5433674cc49f53c5913ccf5175b0da', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '1322719978980a831e1aee78aa80a141379c44dd', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '8f1a8b82c7be223f195b4f03ffa1943391fd428b', '52a19b5bbe47b52926a2671fb100b2b804021737', '53c8532e37da9be2d79f76e7ba8860cf0d2c4128', '484ad17c926292fbe0d5211540832a8c8a8e958b', '1ce512c9897e46c692c9fcd69b9664a68264a5e1', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'a759c9cc7d2839e8b227acf6514ec0f7c50ce434', '3926c80eb33d12ba2838e0890c372431192f42a6', '3bb5a439a0d610a7eac68f73068cdd278b8c9775', 'd82800c79dd335297336fe10b1a60d47706e4296', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '18dac971330f0783c6a61a8482add835100ffa66', '6507909a8f77c88144c3a67b9336bd1c85e84cac', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '231af7dc01a166cac3b5b01ca05778238f796e41', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '2e8d62277e40d465343e8dfb32ecc246f320540e', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '6f24d7a6e1c88828e18d16c6db20f5329f6a6827', 'd30e8f3e565d4a9df831875c383687507606d4f0', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",27,"{'11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '9277dc70c74bcadf80dab11c28ead83fd085deec', '48f9a48aa5b1230b05a443d2d531e6441a541686', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",5,"['Boyko Vodenicharski', 'Samuel McDermott']",Boyko Vodenicharski,"Boyko Vodenicharski, Samuel McDermott",18.51851851851852
0a74b0a59b7c6b731c08c67392041ca88e07c422,Leather Defect Segmentation Using Semantic Segmentation Algorithms,2022-07-20,"Leather is one of the essential materials in our life. It can be used widely to make different industrial products. Products made from leather are strong, expensive and durable which lasts for decades. So, It is very important for the industry to make a defect free product for their maximum profit and good customer feedback. Quality inspection is one of the important processes in the textile industry. It is done manually in most of the industry which is time taking, expensive, less accurate and requires lots of people. The main aim of our research work is to replace the manual process with automatic leather defect detection techniques which can save both time and money and increase the rate of production in the company. In this article, we proposed a deep learning-based semantic segmentation model that detects defects in leather images and highlights the defect with proper defect type. The experiments were carried out using the MVTEC leather dataset. The input images are changed into 256*256 pixels and then converted to gray-scale image and finally a semantic segmentation algorithm is applied to detect the leather defects. The experimental results are evaluated and compared using various semantic segmentation algorithms. We obtained the satisfactory result with evaluation metrics of 72.1% Intersection of Union (IOU) with 82.59% F1 Score on one of the semantic segmentation architectures Mobilenet_unet.",https://www.semanticscholar.org/paper/0a74b0a59b7c6b731c08c67392041ca88e07c422,"{'2c03df8b48bf3fa39054345bafabfeff15bfd11d', '32a4e56fe9f633c9c499eaed5c2fc35e72d177cf', '0e90653de7770b245a20151d4b9409f2530a551e', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '5dbd7c2ba7bc494e94e840241d7d5468b230e78f', 'd19c36c06d21da70c1330070c0a848052d14856b', 'b0c065cd43aa7280e766b5dcbcc7e26abce59330', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'd639ad7a1fe8339dab84efb5cec1bc3bba2f8a81', 'e482b1e12da0f712eebdfe8a10458e95fbb473f7', '5b3859e9fdeb8fc434bf5f74fe0f71d52112c552', '85010a8cabb9838dcb213fe57e2b8d8e5d53cb7f'}",12,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Aashish Ghimire', 'Aman Mahaseth', 'Ramesh Thapa', 'Suraj Ale Magar Ale Magar', 'Sushil Kumar Singh', 'Salik Ram Khanal']",Aashish Ghimire,"Aashish Ghimire, Aman Mahaseth, Ramesh Thapa, Suraj Ale Magar Ale Magar, Sushil Kumar Singh, Salik Ram Khanal",8.333333333333334
0f23a44418aabe3344c6f3809d6a8ab898292813,Data Invariants to Understand Unsupervised Out-of-Distribution Detection,2021-11-26,". Unsupervised out-of-distribution (U-OOD) detection has recently attracted much attention due to its importance in mission-critical systems and broader applicability over its supervised counterpart. Despite this increased attention, U-OOD methods suffer from important shortcomings. By performing a large-scale evaluation on different benchmarks and image modalities, we show in this work that most popular state-of-the-art methods are unable to consistently outperform a simple anomaly detector based on pre-trained features and the Mahalanobis distance (MahaAD). A key reason for the inconsistencies of these methods is the lack of a formal description of U-OOD. Motivated by a simple thought experiment, we propose a characterization of U-OOD based on the invariants of the training dataset. We show how this characterization is unknowingly embodied in the top-scoring MahaAD method, thereby explaining its quality. Furthermore, our approach can be used to inter-pret predictions of U-OOD detectors and provides insights into good practices for evaluating future U-OOD methods.",https://www.semanticscholar.org/paper/0f23a44418aabe3344c6f3809d6a8ab898292813,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '76db40c6e2aeccda1531ba68097d82b573128d15', 'db787640c9b42416ff8d7015546e667e58267177', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '1322719978980a831e1aee78aa80a141379c44dd', '5db790198b9acf4e5efe350acdd814238fcacaa7', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '94c951bb90d0b86e056668aaadd2d5459ace5bc3', '66386a946a04534275bd466862364d139790f41f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '07bb831923e7dc066788d8c8c0b004ff52f44944', '04513c7c0b3a63fde81a996dae064a28d453c17a', '37595f7a51982d776e57c7280b9445474d90f0be', '498e003901f8287e89e5064477cd22dd47e49d61', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '35d894043b67cd11285dcf08fa28affaa1d50746', '10a498003e9204f5fc1328e706510a37e514d8c7', '6507909a8f77c88144c3a67b9336bd1c85e84cac', 'eae7d5b15423a148e6bb32d24bbabedfacd0e2df', 'a7c828184693a453a6c2867dee233ed054b2012e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '3217278e346fefbd34f0727321059c7ea5792612', '2c74ef3a7f9464da32a3caad0823b3261659e24e', 'bf2c5af22cd3e210ab560885cb295a9782321ae1', 'f5b0d51ca54fd1b7268486393679dd612d482f64', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '47cbd8cfd6fcba83d3b3714faef480260bc9d5de', '02227c94dd41fe0b439e050d377b0beb5d427cda', '05e882679d61f4c64a68ebe21826251a39f87e98', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '9de3e6f471552fade7e17daa9f15df4eb92410af', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '10b219619e88931fabb674037bbb633682775136', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '2c7e2e4f1876eb0235e698beee5a5a365ca06d15', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'ae9bf201f128cabaa4350b54ff6607525c736cd5', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '5647d92d8e7248cd2d4770edfe0688c1c0a2181b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '61a41a428fa2cc3d7967f4454621ac2d115388ae', 'e86f71ca2948d17b003a5f068db1ecb2b77827f7', None, '4cfd8f903506865e7ccf28b0a07ee3c551487e92', '41747cbdbed84762dfbfc305254c97021279dc6e', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', '0d79c6737849bea78d5bd96c0894d9ec61190089', '9a679663be4981d99b79f28dc946ac24344935d6', '599fd051c9438011ec5b581983c89e8922b4a5e6', '70472c97e0460cbc04bc0148b0fc59392edb3c50', 'ac2a8e4ae9b6dfa3c9c7e9135abafd5136f837c7', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '6ff2a434578ff2746b9283e45abf296887f48a2d', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '206c2e79b5f1b4541b85f47517666961ed49500e', '5d90f06bb70a0a3dced62413346235c02b1aa086', '54d2b5c64a67f65c5dd812b89e07973f97699552', '346c6a63abb31c8e4219c8e27912a91be69f2b37', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '6b66d111d2d6bcb35c546f6cffd4404990227d07', '0fe615dc0a422100e85cfb7e26c9306c481f6c75', '06671547fd94c44688b10c8cd550242557e55154', 'af395b05a0c00280a446f81417febbdfb17b67bb', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6', 'b110ba174df21a23a9521731d4181261ca5860ed', '00a1077d298f2917d764eb729ab1bc86af3bd241', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '99ba9a59bc7a1fb20892d4709d96f676a604d845', 'c2b733a79db700b971327a58ef42699fe8a416aa', '4b83c2ec2c5119057979ae64cf4b5d1aef04466b', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '25761fd27d2ffad21329e85987dffa57a13de39f'}",83,"{'6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'ac2a8e4ae9b6dfa3c9c7e9135abafd5136f837c7', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6', '93040f8a5d10e8fde279e18d353aa3dca2873900', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '37595f7a51982d776e57c7280b9445474d90f0be', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '206c2e79b5f1b4541b85f47517666961ed49500e', '498e003901f8287e89e5064477cd22dd47e49d61', '41747cbdbed84762dfbfc305254c97021279dc6e', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",18,"['Lars Doorenbos', 'R. Sznitman', ""Pablo M'arquez-Neila""]",Lars Doorenbos,"Lars Doorenbos, R. Sznitman, Pablo M'arquez-Neila",21.686746987951807
180300ff8282220c76c7c41ded4d9d8c1be4d3fc,Explainable Deep Few-shot Anomaly Detection with Deviation Networks,2021-08-01,"Existing anomaly detection paradigms overwhelmingly focus on training detection models using exclusively normal data or unlabeled data (mostly normal samples), assuming no access to any labeled anomaly data. One notorious issue with these approaches is that they are weak in discriminating anomalies from normal samples due to the lack of the knowledge about the anomalies. Here, we study the problem of few-shot anomaly detection, in which we aim at using a few labeled anomaly examples to train sample-efficient discriminative detection models. To address this problem, we introduce a novel weakly-supervised few-shot anomaly detection framework that can make use of the limited anomaly examples to train detection models without assuming the examples illustrating all possible classes of anomaly. Specifically, the proposed approach learns discriminative normality (regularity) by leveraging the labeled anomalies and a prior probability to enforce expressive representations of normality and unbounded deviated representations of abnormality. This is achieved by an end-to-end optimization of anomaly scores with a neural deviation learning, in which the anomaly scores of (anomaly-contaminated) normal samples are imposed to approximate scalar scores drawn from the prior while that of anomaly examples is enforced to have statistically significant deviations from these sampled scores in the upper tail. Furthermore, our model is optimized to learn fine-grained normality and abnormality by top-K multiple-instance-learning-based feature subspace deviation learning, in which each data point is represented as a bag of multiple instances in different feature subspaces, allowing more generalized representations. Comprehensive experiments on nine real-world image anomaly detection benchmarks show that our model is substantially more sample-efficient and robust, and performs significantly better than state-of-the-art competing methods in both closed-set and open-set settings. Our model can also offer explanation capability as a result of its prior-driven anomaly score learning. Code and datasets are available at: https://git.io/DevNet.",https://www.semanticscholar.org/paper/180300ff8282220c76c7c41ded4d9d8c1be4d3fc,"{'6ec00ff233c19b47ef44dd57cdb22a7385586c0c', 'c4bc3d8703ced63750a5b9ac3ddd4514fada596c', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '57b2198f9a8df773425aa6cc88c9870cb07779e2', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'a48a8b2085262a7f9658368088eca756e400d5ae', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', 'a1850e377567259b3f38a404e5d8f28e7babee5a', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', 'dcd9f5d61bc9a70c40be84a8d78fbee822ffcd9e', '732c21998e251d64cd58b6a86886ee5907efeaa5', '53ab91cf735af3589c58bf6af09de4e799a6bebb', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', '355b4e74774798c177c82943eef925d66a2bb2ce', 'a4c94b221062d0737ee967affa80ce2110cc50c0', '3a712fe261cbc40089048b60b36e5bb99781552e', 'bc5a67aa59bf49850d702dc5aecfa231d0952f6c', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '182d11020bf2842f135f1ec1dcac20237e0dc8b7', '62b77e5cb85fc61b84edd532f6d65714be152596', 'c8e4d8ded0624f13cd7763b8e7a62fe7e36da6d3', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'a154e688baa929c335dd9a673592797ec3c27281', 'fc70fa3bedc32c0f49c42f0822788638c5847c79', '0820ccfdba775c304bedb9c3d82ee8758e0a416b', '04513c7c0b3a63fde81a996dae064a28d453c17a', '267502d21b44884570fcd95a855821cc3e86e6eb', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '7e6de4d7bc8f9a74e6ce6c6a9e781443e19abd9d', '83fcb78e3b58c230a051914daac3bfb00482b34c', 'cdfff974b7f35f0f54c00f1b8412b5b4703a52b7', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', 'fff09ec5380f72dd67a26439e8e5fe7132ecb242', '6af440915b8a0718c93be1cf61905e41e620484a', 'c48def9076e58095c4aea49a8daa931af1990701', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '240e0dbf41db7514fae926e0996c4cf649e7f403', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '5f61089d3d548a515f01b473f0119137d1f340d4', '41747cbdbed84762dfbfc305254c97021279dc6e', 'eef9ae8246cba89679e3ca7b554d5d5e3295019f', '10ae15147d0bc0d6d06ceaae28165bf8646ae478', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '72564a69bf339ff1d16a639c86a764db2321caab', '8381157eae4fbf8908d0312a9642f8e69e944449', '8ed98bd58c799718d6fd389e2218bb89b1ecb9d7', '736018160f8e6f6bd9b2a9101cd13ee67e573097', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', '086015aa2c44bd2ebd95ab6a1a562e57177c7fa8', '759d9a6c9206c366a8d94a06f4eb05659c2bb7f2', '3df952d4a724655f7520ff95d4b2cef90fff0cae', '3adcfd254b271bcc2fb7e2a62d750db17e6c2c08', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '882e06d18c0fc0645ae559633eb178a7a41cfe79', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '491b149544eff61778c216a4eb869ec0b008f346', '598fe25743f9492c5c1ba30274ea446f65426d85', '6a7364f6ed2846ea2b705336a4c49dd287102a50'}",71,"{'6ec00ff233c19b47ef44dd57cdb22a7385586c0c', '182d11020bf2842f135f1ec1dcac20237e0dc8b7', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '41747cbdbed84762dfbfc305254c97021279dc6e', '62b77e5cb85fc61b84edd532f6d65714be152596', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'cdfff974b7f35f0f54c00f1b8412b5b4703a52b7'}",8,"['Guansong Pang', 'Choubo Ding', 'Chunhua Shen', 'A. V. Hengel']",Guansong Pang,"Guansong Pang, Choubo Ding, Chunhua Shen, A. V. Hengel",11.267605633802816
2c1837be2e4e6c4f47d51c42773e398897c372a6,SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation,2022-07-28,". Visual anomaly detection is commonly used in industrial quality inspection. In this paper, we present a new dataset as well as a new self-supervised learning method for ImageNet pre-training to improve anomaly detection and segmentation in 1-class and 2-class 5/10/high-shot training setups. We release the Visual Anomaly (VisA) Dataset con-sisting of 10,821 high-resolution color images (9,621 normal and 1,200 anomalous samples) covering 12 objects in 3 domains, making it the largest industrial anomaly detection dataset to date. Both image and pixel-level labels are provided. We also propose a new self-supervised framework - SPot-the-difference (SPD) - which can regularize contrastive self-supervised pre-training, such as SimSiam, MoCo and SimCLR, to be more suitable for anomaly detection tasks. Our experiments on VisA and MVTec-AD dataset show that SPD consistently improves these contrastive pre-training baselines and even the supervised pre-training. For example, SPD improves Area Under the Precision-Recall curve (AU-PR) for anomaly segmentation by 5.9% and 6.8% over SimSiam and supervised pre-training respectively in the 2-class high-shot regime. We open-source the project at http://github.com/amazon-research/spot-diff .",https://www.semanticscholar.org/paper/2c1837be2e4e6c4f47d51c42773e398897c372a6,"{'69ea434ab0cef7ba4e27d9926a88079040337db6', '5cb1698663b125ed0abaf72960397cfb77fb21bb', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', 'aa62d5e43cb151cd574e4df058b4c6a509d62644', '8201e6e687f2de477258e9be53ba7b73ee30d7de', '904627c2d5a91ab8cb1b682e42f06f1ca192aea6', '1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af', '3b3aefbbdb64e5812f133f220b3f129a36a30065', '461fd0f9ac786febccb0f59761da6521e9ee1d89', '5b0f6e90243a07464c42bc18ba0007331ab1fbe6', '67ffdc7d1f66231d43ddb0d28094a85b89f29ee2', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '1c4e9156ca07705531e45960b7a919dc473abb51', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '4f7a77d04e7e1cff1f6e306f082217be78203643', '498e003901f8287e89e5064477cd22dd47e49d61', '6f92dcefc5f6b4346f619ae7546a8bd2d6decade', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '54036f43acc6c9b49b334270c7237217685f52fb', '6af440915b8a0718c93be1cf61905e41e620484a', '10161d83d29fc968c4612c9e9e2b61a2fc25842e', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '38f93092ece8eee9771e61c1edaf11b1293cae1b', '73f76a40ed20aa3c6a8e27e4db4a8c102e7b4c6d', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d', '41747cbdbed84762dfbfc305254c97021279dc6e', '7062b5de5fddb298823cf8969c7dfa6165ea933e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '72564a69bf339ff1d16a639c86a764db2321caab', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '77f188254b81fd9d3789404a6ea02591d4173123', 'add2f205338d70e10ce5e686df4a690e2851bdfc', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",45,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '48f9a48aa5b1230b05a443d2d531e6441a541686', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '498e003901f8287e89e5064477cd22dd47e49d61', '41747cbdbed84762dfbfc305254c97021279dc6e', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af', '3b3aefbbdb64e5812f133f220b3f129a36a30065', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",13,"['Yang Zou', 'Jongheon Jeong', 'Latha Pemula', 'Dongqing Zhang', 'O. Dabeer']",Yang Zou,"Yang Zou, Jongheon Jeong, Latha Pemula, Dongqing Zhang, O. Dabeer",28.88888888888889
a7d75aa3a0a9faa310fb524c350fba2093b0ec97,Self-Trained One-class Classification for Unsupervised Anomaly Detection,2021-06-11,"Anomaly detection (AD), separating anomalies from normal data, has various applications across domains, from manufacturing to healthcare. While most previous works have shown to be effective for cases with fully or partially labeled data, they are less practical for AD applications due to tedious data labeling processes. In this work, we focus on unsupervised AD problems whose entire training data are unlabeled and may contain both normal and anomalous samples. To tackle this problem, we build a robust one-class classification framework via data refinement. To refine the data accurately, we propose an ensemble of one-class classifiers, each of which is trained on a disjoint subset of training data. Moreover, we propose a self-training of deep representation one-class classifiers (STOC) that iteratively refines the data and deep representations. In experiments, we show the efficacy of our method for unsupervised anomaly detection on benchmarks from image and tabular data domains. For example, with a 10% anomaly ratio on CIFAR-10 data, the proposed method outperforms state-of-the-art one-class classification method by 6.3 AUC and 12.5 average precision.",https://www.semanticscholar.org/paper/a7d75aa3a0a9faa310fb524c350fba2093b0ec97,"{'14c277610ce63372fb44163140d6457be84663e8', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '759ed411e5f3bbeacc84cf4d70e07da6a4a158e0', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'e061d23b68e7d4aac5aece4794c044c80e638dca', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '8c7e9d9bc9009fd5ca7028af6e37f3851af1ad6b', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '20ba55ee3229db5cb190a00e788c59f08d2a767d', '299847adf3ee558a760475ffa364facac3ebbb16', '99475e45a843e85d726d0877a4951cf8823927b6', '5db790198b9acf4e5efe350acdd814238fcacaa7', '00a1077d298f2917d764eb729ab1bc86af3bd241', '0aa29099a0afca6a46df4ab6c9db8cd99ccaddc4', '7313c770c84af50aa8e34ec21c8e50413f99c89f', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'd612d7c21d4130a457968273d79c2c2f6946953d', 'e7c883497fd3e9838ead70ce97b1f53331cebc70', '04513c7c0b3a63fde81a996dae064a28d453c17a', '498e003901f8287e89e5064477cd22dd47e49d61', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', 'c3c0aaa9f961f0c81d664b0f9a030871de215b79', '6af440915b8a0718c93be1cf61905e41e620484a', '8b45e9e795079abcd1b75e7d5dadb5eb00e3b78a', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'a7c828184693a453a6c2867dee233ed054b2012e', '59da587c46f695a0b7867b68a22d832ca92999f3', '5d90f06bb70a0a3dced62413346235c02b1aa086', '278841ab0cb24c1abcb75e363aeed1fa741c8cc4', 'ce435482acc0e195be8d8f002b2655b4c7b08be6', '1152d9bfb6cbfda1b919ff6e9013f48344f9926f', '3cbc2d53063794a45b41c75c246fea7eb2857a98', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '8cb44f06586f609a29d9b496cc752ec01475dffe', 'c42816f497d663c681df20d48a6e66a5632600d8', 'fd9c9077eaaaa4381ff9751bacdd898fa7a4f5c0', '17a620afc87f5266e3fd8b3f308c883cc2c2b7c7', 'ca4edb65a0664804e4819c5c809d0dfba9bdb2df', 'd7b968f3c9356e0a8d6d295d5eb37cdc748e64b9', 'c0d30aa1b12a9bceda14ab1d1f2489a2dddc8277'}",48,"{'498e003901f8287e89e5064477cd22dd47e49d61', '78d80c343d36baaf89f18e12d325cf6309fb6c8f'}",2,"['Jinsung Yoon', 'Kihyuk Sohn', 'Chun-Liang Li', 'Sercan Ö. Arik', 'Chen-Yu Lee', 'Tomas Pfister']",Jinsung Yoon,"Jinsung Yoon, Kihyuk Sohn, Chun-Liang Li, Sercan Ö. Arik, Chen-Yu Lee, Tomas Pfister",4.166666666666667
13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6,GAN-based anomaly detection: A review,2022-01-01,,https://www.semanticscholar.org/paper/13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6,"{'c753f63433fbaa7ae4ecc82a8b6175ed2d9ad878', '162d958ff885f1462aeda91cd72582323fd6a1f4', '2895770450e9cdfa4bfa42ea035b0a2397205e95', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '42e8506e2a728a7ee2bf9ecdd2bea681b4115384', 'fb0e6b7786d4e5cf40b664fe6fe2498bc53edb72', '21af4ed208ea3ecdb20b75aa27cddd0bfe683eec', '316cad5b86f7eb13e1d024acb63968714c53d5d2', '90f08d42f51bca0624cd914ac69d2ddfb864ad7a', 'c921c197a620504f8ce14e8a6f7577241096233e', '5e0e26621c53a21de448e2309faf4be18318e1c9', '194cf02f568470439eb9d27a64dcc99ef9799ab2', '9a334566b79bc6c6906e2b5285d5ea50b9b99479', 'a662d1666ea9f4ec7d375baeedf4f364e698986c', '0d2818f1070fa5a6cf5d14a87a5d71b4107b4d60', '1c125949603054332399b196187b7391f793b59d', '5db790198b9acf4e5efe350acdd814238fcacaa7', '6a64568a9d4493378a42e23551d118df43733e07', 'b17c8f38fff8b6dc87fa0e946ac5d1afb3d76163', 'db787640c9b42416ff8d7015546e667e58267177', '1d3258abdfdc9262a3c5736a4619869a39d17120', '9436440748a52254deb7d7391bfd564bbf139286', 'e31fa9510047c0df23fb4dd37ee7c70783a3fa60', 'a358e432f02874d9d50be5ab01cb4f76e62e8faa', 'c5e845468d0185be59c8c38b84e7a265f42fa47d', '2a28b9e66d1b65805f90e101fcba71c1af813be8', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', 'aa2ddae22760249729ac2c2c4e24c8b665bcd40e', 'facf56ab4cd06ac2970530a0c425df7a6a8a3d45', '62b77e5cb85fc61b84edd532f6d65714be152596', 'db2f85b3ed4752675cf8824beedaa12c801d814d', '912b0b7879ca99bf654a26bbb0d50d4b8e0ed6c0', '37595f7a51982d776e57c7280b9445474d90f0be', '18f207d8dab7357f4f674211ec4f150de1c93a0e', 'b7ba7b9e0db986a90d4e245fe7598dc89531b76d', '619d6bcb13fe070c7558bd7dbad3e32a56501ae6', 'a7a46c0bb4b42abb992431d1a9ff158d1d461965', '670f9d0d8cafaeaeea564c88645b9816b1146cef', '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'eb1582dd2cdf4ef835fb6e3bc9ac0ea070f92a97', '1db9bd18681b96473f3c82b21edc9240b44dc329', 'ea1356239d23b237251b0a74b71a82ed15829f3a', '68c95a1e7e2752b3f67377f0876fab3f7c25cf71', '6e15e66899c7e86bc99ae210b6110d0b12fde731', '79f85457eb8e03fce11d2cd9a79a91aedb9d565f', '8e19265e4e20575c292c89a2d9faa85780498709', 'ce711e917b9f6a4abd2d3555714a90a280c9fa44', '91d7a634288acf07a5d2cef021e1f1ba5ea1662e', 'c552dcd51300ce5a0bb52fd078594d4b47fbcddf', '2e8d62277e40d465343e8dfb32ecc246f320540e', '353ecf7b66b3e9ff5e9f41145a147e899a2eea5c', '7778b2b6ee67df2a0a06fe82e79acfdf714c7399', '0fb1d1d6466fad4c566249008265f0b0a215ea4a', '34a0a27cd78f9ba82581c27c72d62f1c484b336e', '6927cba3142019121a90d7a8c30b74a18ed9fd3c', '3ae930c4272b1b6d93754e1f8fa79f494d7bb867', '9180eab9ea90e1057c440e1941dc8a5bf578d061', '37eb32915b7767685ec3c9e9728ca9a50a379b8d', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'c1b1bc4c9383da16ee9adb2ba442c2d3f391a628', '91336c65cddd8546745f67a1b860c2595904ac15', 'dc0668754e95da573cd64dbe5e2fed07ac9ddf97', '043bfc87afb16d80808dded02b22270fc4665c07', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'add2f205338d70e10ce5e686df4a690e2851bdfc', 'c10fc2e7ae62209320fb779235615c2b8f4ac2c0', 'ca4edb65a0664804e4819c5c809d0dfba9bdb2df', '46e817725317d3580836d5678dcc8d010a8cde26', 'c3124b0491d479e8a869c61f059ffa08dad49362', 'aafaae9e26ac16365209a230ea1fd9f7c8eb70c6', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '4fee69cf3608caaf093c07ce998dc646714ffed1', '0e96b0a586e3acfcf1602c0e246c04c6080e2315', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '275aaca7621b2ee4ff81cd37162f6c9a90f306e4', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'da03859f37eb44b4fbdc85453f6a366e574c5bc6', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'ffe28f6bf0e9e6bbca6313319aa1a5409d283d9b', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'bb63e3c51b78da88852dac0c67411c8dc930993e', '26089bb2c46581863e1b2139511d495c44632c3d', '2e90c9ea5ec64485a68da1f5994e196a75d707ba', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9acc51b06f54b07836fad4cc24633187dc21317f', '21b7dea0b9751c6bc7db2086109b6b1a4f9e60b5', 'e95cf80f757bf25c14e7767d70d400fff19b04dc', '1ff64cee66e66cf9c402ad754a63175e8e578c7a', 'a228ce656599fe1413ed0671c260b5dad1190e3e', '2d81914c1855f2d2873fd5cc26897330b42c0472', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', 'aff949ea59c71369b662d07fdc80f85579ae36cd', 'bc27cd49fbbead76a4a9d8d42c007d690986b6c6', 'f03cc2a79a748b5e93b28aff362b3c250e72f6b7', '71f5e48323ab65bd93579b2b0ca48a5660c86cc3', 'ae9bf201f128cabaa4350b54ff6607525c736cd5', '8acbe90d5b852dadea7810345451a99608ee54c7', 'b6fec9aa7fb4d4abdbf9504a582236c652404218', 'e954b2ace4a3fec3cb94b017c2f7f7842b596482', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '3402d5f39a44ac3a99594bb9a6e29305a07252e7', '62f3d3015cee122bd147d7d878c85f70cc15680d', 'b9e4469ef36e3ce41e1052563e8dbce1d4762368', '923c6d86a01ad032e977207ed9280b6c97be0813', 'af5b1a35271efd17ff3d5ddd152bacc96dff0e81', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '7850db75a21c6c33baa70875e53373aa79a15013', '70f9968a356d840040a1c9207906f60376dc6bd4', '96e8cbfd34e3a34da75bfdf15a504984aa3b4d2a', '21eac8b9491b92718222fb53b34abd8346fa9d5e', '7e2154362728f05e56ec52bdff26a67d8f5237ad', '94618b949f8f18a18f7289dc742162996d376433', '835cf582be0b6572ef44ae1f7f547f1c2ad28dd4', 'c10d8d6838f82ffe3e11060f47ce3bee2e87f318', None, '20f0357688876fa4662f806f985779dce6e24f3c', '85aefb7a0c0e0f7a60b7c453d1767c9dd6b7964a', '41747cbdbed84762dfbfc305254c97021279dc6e', '9fcadebc4fe00f033ea213a1fa974d46c2852eec', 'b0143bb7b906c9d02c8f31c338740b99e685e40a', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'd51fe51185e9d2174d56e6067f476883dc039e3c', 'e63c0991e699f65d1e3d241c190a739439e490f7', 'd14114eddd4df1fdfbb5dd7eee499ea16cd84c9c', '0614e38aec4e676f138fc0f7e07304359bdc78b5', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '052680f7631080fcfedcbb83aa98df2617724528', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '7ee3ff7e1c8b9f458baa99a27b3a1411fe1ecd64', '5e0db2ff53e5f3bb3e3a2e24fb4897e4881bf073', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '38a74a12fbdf3bb4f857d1b8780a94547c0ce3ac', '41476bd33b0572dae91f518ce1213b44f2e8e686', '7ff3f12f27ef8e9e7d754c23b1eeb09b664223bd', 'd3744325106b2c15b17786b3447bd55d874b54f8', '7568d13a82f7afa4be79f09c295940e48ec6db89', '599fd051c9438011ec5b581983c89e8922b4a5e6', '732c21998e251d64cd58b6a86886ee5907efeaa5', '5fcf9041aa65c39c792172f984c0fe2d48a08169', '1078f20d2c4ae111c9ae0d641ed1a89498ecf917', '1ba1de0f143bd3166c9961acc869e123651d9836', 'ff83aade985b981fbf2233efbbd749600e97454c', '8109587a56d53c6ba30fe19ba9aa4d9213ec91a0', '2fd0bdea80322bb3520904abc4c07829b5028f13', 'a73657709ba26eb6a2ebbe37fdd728c9d9ac544a', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', '87d20958bf14d5e1da833aeac0da99b5e7be6b73', '75f78ba34a663e0565cb9c0983f5a6e5331c1523', 'a3e34b548e2a5413bdcb4b048979e3f64c9bc45c', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '9d5290fadb7625862a966e0330bd0f9e111fc99d', '81804d7e422785f90e6ebf08c7f0c0b5b5851da5', 'b9bd435b65d8214f1bcab9268ac2fce509cfffe6', '355692eb86b06a0a23af45c106cfb02c95bf380e', '6ca2b9310532fdec72841585d6ef61c42c839ec5', 'fa50c6a155c75f6a35c3dc3c3a78178e26ce10e0', '6af440915b8a0718c93be1cf61905e41e620484a', 'a738f169b6229fd2e28fcb24a736675c9106baaa', '437cdb30e526ee6ee3ce4df6fbc8560359014638', '47f7ec3d0a5e6e83b6768ece35206a94dc81919c', '84d8c6fb32dbdc8f184974cce6979e6f4a0e7ccc', 'd5c9112bef6b9afbc8633bfa742d53e247244a19', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '8978cf7574ceb35f4c3096be768c7547b28a35d0', 'f17a84ece090574263485b1d851b787a4530e71a', '24cb3d272a34b9cfc866dddde990e13b307a78f3', '61ac32651cfda41ef219b0acfdd50bb37d62ac39', 'e8a5f27e7805f8de84ea008d59452ff864271696', '775247047d0b56950ba5ea77d4a29772eca95c1b', 'a1da80cca297f7f47a36dd2d68a3f16cbd1f6c36', '8381157eae4fbf8908d0312a9642f8e69e944449', 'cb3356cafc087a48c5302066911d492add56d7a7', '28c567057b9bdde9ec21ee4e97117783344a3488', 'a3354a71d3c4529cdd9a63bbb3153f7e80919aa4', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'ddc1c9d9afc84bfa72ba6036a93214f275158625', '5644937b4844490aa2702b88df1f2411e910451c', 'd255934eeb52a6b499c0d39754ed7e29e22d213d', '2f922e6596c7c5ee8fc1483383f76b45ed28a107', '08a6c811d70b5ad29f8f93ab41570b0ec23f6bdd', 'dffbbeb757d1d79ce40920c168c49071f32d73ae', '7b0ab21f58015f3baf5f0574fab23954a5d409af', '74923519ccf712f0b6dcbe04438cebcfcc4b4e16', '506f3a85f73d5ba3d3c4c78f1dcd14a759cc88f9', '941f76e46901649fcd73e2316a219f3bced7b75d', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '0ae22bfcc4d04209fc01f9e362d5ac88c4e35814', 'dc0092d06ab76465431edfd51b08d823b7d1ff3f', 'cbad76941d480e1b0d8675b5ed9ce076457ef74e', '6f1dae149cc7c310f0ce59c2ca865e36ce048956', '8201e6e687f2de477258e9be53ba7b73ee30d7de', '2b1fbf14de0381a48c736e625fbb1329d71c798c', '48aa9fe54fac6ea37aad22cca0c22943822c2219', 'b110ba174df21a23a9521731d4181261ca5860ed', '1a82a874a2b1739db29842f85706c25942ad12e1', '1a00dc525da31292e3734cbae2de681f114e30b1', '35da0a2001eea88486a5de677ab97868c93d0824', 'f5b9b024b3e3d7207225365bd52a4a0666e0f9a6', 'fc05a56b30ec4630556621c0b24e982259f898b5', '64c0e34abb2eb6f897dd700f592a00e8100f60a9', 'd8ab3a2825cbd9c6a3683b850d07510b9ebec7fe', '9b09e05e4b1893d2f354580c66edf41acc9fed6a', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'bcc122aaebc89a6d6667307c2ac14d405c7acf6c', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'e399a626ba21fafb19b3661603ec9724058e951b', '5435a9ab36a308cef10bc725104e8f778ed3a328', '7342236608a62494ce357e95d5ebecdf8657c357', '8a510e109adee98ef5f513fb44b758e075dd9916', 'df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3', 'acbeebdfd9dd3456628604eefcd53f50f974b132', 'f11d69fac609917da82f697758cd694c0f01a730', '62d43f751659e7bd1f869768e7f392da68d7ee15', '2690c6e2af03a42222adb46bfc70dd35c8d9ade3', '3cdbefc533ffb8f506a798bac6fd7501f78473c7', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', 'dd87fcfda2e555ba3e1772526a695adcdc88c57f', '5694e46284460a648fe29117cbc55f6c9be3fa3c', '706dfa3ddc4ae139d067986b4627176b59b7ddbd', 'e6c7c0ad83c94b72c68668ad141e629449b98d03', '7437fb168cea92e1df8332ac618f7f07b071aca8', 'ef3c1f6c177e37f1d0d2a61702b60c766971700b', 'a7a54fd569c955cd639d34809d95fa485691bf4c', '9c131f92bea583c33daa94fc5e647de67ef9a96d', 'cde35c87aaabbc617d38f9cfaa2721a2e166d750', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '3fdfd243f2c1c8ea974ed661dc06b35849b9ead9', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '6d9a86b22a612bad44dee0481b33970bfa556cc2', '8fb554c6aec8d815f83f86f71fe85bd92a32a690', '1a59bcbb28145ea976795ba9a6c4ee568379d65e', '6dfaad062d757eec3b4b6c4b29eb3506bcb03d49', 'c92ee6ff32fa4833fa1c2bdf29284e2a58ddb640', '938b0ff4976f212091a0a2a558fc777eb0a08d98', '16a7896884841497415b05c0f63373cedca26e80', '94d07e35f93e0b62dc50353e503e15305cdf6e4a', '2ba77abca2ebcb8f040e8ba392a0acbdceb419f4'}",241,"{'2895770450e9cdfa4bfa42ea035b0a2397205e95', '775247047d0b56950ba5ea77d4a29772eca95c1b', '9180eab9ea90e1057c440e1941dc8a5bf578d061', '1ff64cee66e66cf9c402ad754a63175e8e578c7a', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",15,"['X. Xia', 'Xizhou Pan', 'Nan Li', 'Xing He', 'Lin Ma', 'Xiaoguang Zhang', 'N. Ding']",X. Xia,"X. Xia, Xizhou Pan, Nan Li, Xing He, Lin Ma, Xiaoguang Zhang, N. Ding",6.224066390041494
e5349e937545d3f3d18d254bd21d695e7350ea8e,Focus Your Distribution: Coarse-to-Fine Non-Contrastive Learning for Anomaly Detection and Localization,2021-10-09,"The essence of unsupervised anomaly detection is to learn the compact distribution of normal samples and detect outliers as anomalies in testing. Meanwhile, the anomalies in real-world are usually subtle and ﬁne-grained in a high-resolution image especially for industrial applications. Towards this end, we pro- pose a novel framework for unsupervised anomaly detection and localization. Our method aims at learning dense and com- pact distribution from normal images with a coarse-to-ﬁne alignment process. The coarse alignment stage standardizes the pixel-wise position of objects in both image and feature levels. The ﬁne alignment stage then densely maximizes the similarity of features among all corresponding locations in a batch. To facilitate the learning with only normal images, we propose a new pretext task called non-contrastive learning for the ﬁne alignment stage. Non-contrastive learning extracts robust and discriminating normal image representations without making assumptions on abnormal samples, and it thus empowers our model to generalize to various anomalous scenarios. Extensive experiments on two typical industrial datasets of MVTec AD and BenTech AD demonstrate that our framework is effective in detecting various real-world defects and achieves a new state-of-the-art in industrial unsupervised anomaly detection.",https://www.semanticscholar.org/paper/e5349e937545d3f3d18d254bd21d695e7350ea8e,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '599fd051c9438011ec5b581983c89e8922b4a5e6', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'db787640c9b42416ff8d7015546e667e58267177', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', 'de28c165623adabcdba0fdb18b65eba685aaf31d', 'ed17929e66da7f8fbc3666bf5eb613d302ddde0c', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '04513c7c0b3a63fde81a996dae064a28d453c17a', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '37595f7a51982d776e57c7280b9445474d90f0be', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'd9f0e1c7e240597992232840f7cb96ceeefa1940', '6af440915b8a0718c93be1cf61905e41e620484a', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '70f9968a356d840040a1c9207906f60376dc6bd4', '45f490710b4dd6697dba4c9b385a49554501711a', '88f11ad3fe04aab7f4bcf80a079140e717357f02', None, '74f4ecc3e4e5b91fbb54330b285ed5214afe2001', '0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d', 'fe87ea16d5eb1c7509da9a0314bbf4c7b0676506', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '8381157eae4fbf8908d0312a9642f8e69e944449', 'eb35fdc11a325f21a8ce0ca65058f7480a2fc91f', '6869ab1f42e30b415829de9928f7e4a606113601', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '598fe25743f9492c5c1ba30274ea446f65426d85', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",45,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '37595f7a51982d776e57c7280b9445474d90f0be', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",11,"['Ye Zheng', 'Xiang Wang', 'Rui Deng', 'Tianpeng Bao', 'Rui Zhao', 'Liwei Wu']",Ye Zheng,"Ye Zheng, Xiang Wang, Rui Deng, Tianpeng Bao, Rui Zhao, Liwei Wu",24.444444444444443
211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d,Attention Guided Anomaly Localization in Images,2019-11-19,,https://www.semanticscholar.org/paper/211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '5e3aa4b6a85d396394bbf7e12b14f37bca17753d', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '37a18be8c599b781cc28b6a62d8f11e8a6a75169', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '8388f1be26329fa45e5807e968a641ce170ea078', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', 'e8b8a7778ace2a02f8db6fe321a54520c6b283ca', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '39972fb3a9cbac1e25b2c096e3e28bba2eee7aa4', '94bbc4ea271c918705876b60d98d227a0ab55a43', 'f7b032a4df721d4ed2bab97f6acd33d62477b7a5', '1856809b8bcd0ba7b2c294201718018ead419cb7', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'a1f2ff5daca7c0e7fd1c1cf8e6e5766c327fff68', '1a00dc525da31292e3734cbae2de681f114e30b1', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '15d1838111f327af5d7c7c56fb887e3cc6d95fd3', 'e399a626ba21fafb19b3661603ec9724058e951b', '2622d2467f19bc60427f8ea495515e7da82316c9', '2f95858858ad0c811738dee8ae921b81de94a961', '46d5cf70365d48ad38ed549fb44cf76810e8f8da', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'f538dca4def5167a32fbc12107b69a05f0c9d832', '7800c02a555ac0e80f41c17754191efe418c8127', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'c2b733a79db700b971327a58ef42699fe8a416aa', None, 'bd8f77b7d3b9d272f7a68defc1412f73e5ac3135', '410ad524c2d9b0f833e2aee87a35dc2efc9c8b01', '35a48d7099f2fd8c40e09de61e509ea0a846cbef', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '5f4bee489f595bd3d3dda7fd88de8d79b006aa52', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', '8381157eae4fbf8908d0312a9642f8e69e944449', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '0f84a81f431b18a78bd97f59ed4b9d8eda390970', '1695e0392c3ad1c867f8518eb43fcccf815718e6', '8ad9e4b45d9750a3644dbe037c45313bd8683a45', 'c661d1940518445f350aa5e49ed16f815d90bec2', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '2421f55ec4e9bc24d2a7ccb902bbab12fb05d1fe', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'f5b0d51ca54fd1b7268486393679dd612d482f64', '22aab110058ebbd198edb1f1e7b4f69fb13c0613', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'ec679c45e88fa25fec32c30bc7c1b7d7fd0facec', '317c172f314f8cb634f7569ed5bf3ae7dd25c313', '97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f', 'a90226c41b79f8b06007609f39f82757073641e2'}",66,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070'}",2,"['Shashanka Venkataramanan', 'Kuan-Chuan Peng', 'Rajat Vikram Singh', 'Abhijit Mahalanobis']",Shashanka Venkataramanan,"Shashanka Venkataramanan, Kuan-Chuan Peng, Rajat Vikram Singh, Abhijit Mahalanobis",3.0303030303030303
9775d372bfaf889a395dc714e283b6a179e62537,Anomaly localization by modeling perceptual features,2020-08-12,"Although unsupervised generative modeling of an image dataset using a Variational AutoEncoder (VAE) has been used to detect anomalous images, or anomalous regions in images, recent works have shown that this method often identifies images or regions that do not concur with human perception, even questioning the usability of generative models for robust anomaly detection. Here, we argue that those issues can emerge from having a simplistic model of the anomaly distribution and we propose a new VAE-based model expressing a more complex anomaly model that is also closer to human perception. This Feature-Augmented VAE is trained by not only reconstructing the input image in pixel space, but also in several different feature spaces, which are computed by a convolutional neural network trained beforehand on a large image dataset. It achieves clear improvement over state-of-the-art methods on the MVTec anomaly detection and localization datasets.",https://www.semanticscholar.org/paper/9775d372bfaf889a395dc714e283b6a179e62537,"{'7c1cfab6b60466c13f07fe028e5085a949ec8b30', '02227c94dd41fe0b439e050d377b0beb5d427cda', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'd3dd00e24f96bae7ad780ac5fdb0c14194d5cb74', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'e858bcc487cea96695102db9bdafe3c5d4269d04', 'c53352a4239568cc915ad968aff51c49924a3072', 'c468bbde6a22d961829e1970e6ad5795e05418d1', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a0e8f4348968195c80494b7a4245edb91a252c93', None, '41747cbdbed84762dfbfc305254c97021279dc6e', 'eb42cf88027de515750f230b23b1a057dc782108', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '2c740e574eea66fdcf473e15ed2c228baef2eccd', 'd4254d9a938d238182ae55eabd79367404d6ea2b', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",27,"{'41747cbdbed84762dfbfc305254c97021279dc6e', 'd9d7ab13ce305ccee309c989a2341d72b1252070'}",2,"['David Dehaene', 'P. Eline']",David Dehaene,"David Dehaene, P. Eline",7.407407407407407
a2d2c830934bbb7e205e8b789fe56736d30c1c80,Split-Brain Autoencoder Approach for Surface Defect Detection,2020-06-01,"Visual inspection systems (VISs) are one of the key technologies needed for mass production in the manufacturing industry. Fast and accurate algorithms are required for quality control of large quantities of products. If the manufactured products change over time inspection of the products becomes a challenging task. In this paper, Split-Brain Convolutional Autoencoder approach to detect and localize defects without defective samples is proposed. Two disjointed Convolutional Autoencoder networks are employed to predict the subchannel of the image from another subchannel. The reconstruction residual maps generated from each subchannel are combined and then thresholded to produce the segmented out image patches as the ultimate result. This approach greatly alters the reconstruction abilities of Convolutional Autoencoders. Experimental results achieved using a challenging dataset have shown that this approach can achieve good defect detection and defective region segmentation results.",https://www.semanticscholar.org/paper/a2d2c830934bbb7e205e8b789fe56736d30c1c80,"{'1dd3faf5488751c9de10977528ab96be24616138', '5db1b742cd18678ed08a813970bfaba3527df037', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '62f3d3015cee122bd147d7d878c85f70cc15680d', '656d86b2593f87575bcc4f056dad3d18db29eb0c', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '3cdbefc533ffb8f506a798bac6fd7501f78473c7', 'a393282eeada87ec5eee170ffbb3d1ecd6a2c72b', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', '31c29e75478ec0e3632d7b9eafea02c42feb1a6f', 'dd8502990c6a7c40e95237be1f22c0fc3ac64e39', '6f822a234800bb3841851804e4b32e5209350b45', '6cf2a49ca49caf78ba85ad5cae5cbb35419da32e', 'c09a4d90754628015c311e9c51f4b3ab888c796e', '99436caa4a0ad48889316e2484ff9f8c3c2f8c76', '3f8976a36c12173a0a1b458b8c8c4fee01fe9a1c', '124734ec84a90cf32bad32e9cbbf33421ed6ea54'}",17,set(),0,"['Tolga Ulutas', 'Muhammed Ali Nur Oz', 'M. Mercimek', 'O. Kaymakci']",Tolga Ulutas,"Tolga Ulutas, Muhammed Ali Nur Oz, M. Mercimek, O. Kaymakci",0.0
5a5906c4b87d3615a9dacbfa24708e4a90617b8a,Rethinking Assumptions in Deep Anomaly Detection,2020-05-30,"Though anomaly detection (AD) can be viewed as a classification problem (nominal vs. anomalous) it is usually treated in an unsupervised manner since one typically does not have access to, or it is infeasible to utilize, a dataset that sufficiently characterizes what it means to be ""anomalous."" In this paper we present results demonstrating that this intuition surprisingly does not extend to deep AD on images. For a recent AD benchmark on ImageNet, classifiers trained to discern between normal samples and just a few (64) random natural images are able to outperform the current state of the art in deep AD. We find that this approach is also very effective at other common image AD benchmarks. Experimentally we discover that the multiscale structure of image data makes example anomalies exceptionally informative.",https://www.semanticscholar.org/paper/5a5906c4b87d3615a9dacbfa24708e4a90617b8a,"{'2b1a3d7e6045dc6b544a548b372c1f8492b85967', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'ac0a59165ee2ac666b1880316eefe349b87f6ba0', '3c052b0dfea5b654dd5ba6a9a7bb2f348a6b9deb', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '599fd051c9438011ec5b581983c89e8922b4a5e6', '732c21998e251d64cd58b6a86886ee5907efeaa5', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '16a365950dcb89a4b4232ce1634784a0bc8f7b86', 'd5051890e501117097eeffbd8ded87694f0d8063', 'db787640c9b42416ff8d7015546e667e58267177', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '87f40e6f3022adbc1f1905e3e506abad05a9964f', '5db790198b9acf4e5efe350acdd814238fcacaa7', '8c2a9f6c7721d3f39ed13be8ef1bb80670ed2282', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '4d376d6978dad0374edfa6709c9556b42d3594d3', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9acc51b06f54b07836fad4cc24633187dc21317f', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', 'f076e4355c0facf111716dcab2837803367dd2d8', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '1c4e9156ca07705531e45960b7a919dc473abb51', '0372728b9a2def008ef3240a62362f0afbfb5d43', '03ce834859d360b030829249c068fdda9939fb90', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '1a2a770d23b4a171fa81de62a78a3deb0588f238', '99487be08cab00554c5c8db73161b2615c694f71', 'e7c883497fd3e9838ead70ce97b1f53331cebc70', '04513c7c0b3a63fde81a996dae064a28d453c17a', '4f8d648c52edf74e41b0996128aa536e13cc7e82', '3febb2bed8865945e7fddc99efd791887bb7e14f', 'cf03fdf52dd6e4249cbbdbd0bffbbbe5ca389feb', 'f30b10bb58e49138cbf33e625746c87b662a9e7d', 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', '4308c744c96b31b5c731419181606da6e4cbbb35', '10a498003e9204f5fc1328e706510a37e514d8c7', 'd8566c59824db615bece24944e0aba09eda303f3', '20f69cc41c87b8abdf36761c623d65713daeab3b', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '6af440915b8a0718c93be1cf61905e41e620484a', '66ad2fbc8b73242a889699868611fcf239e3435d', '46918f499b2c5dbd177eb9da124da6806060d6e4', '70f9968a356d840040a1c9207906f60376dc6bd4', '45f490710b4dd6697dba4c9b385a49554501711a', '8012c4a1e2ca663f1a04e80cbb19631a00cbab27', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '964465406626125ce235faaccf25e265c56f501b', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '5712edce918859a9b22471dd0ed78ef4ea1fc724', 'dd8eb6662c515381ad78059d59c85a1e70fa35ab', '5e665a933a408d39ba3a432ac537e6673f3b0cd1', '880acd4b5291300ae9141b3d5a712b14f497c070', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '72564a69bf339ff1d16a639c86a764db2321caab', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '54d2b5c64a67f65c5dd812b89e07973f97699552', '8381157eae4fbf8908d0312a9642f8e69e944449', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', 'fbf26e1085ac3b038f47d4d1945ebda45d5e57fb', '82a3fd4b689f386b3f4158fc767c1848d09abd7d', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '5807477169d05218e3fe401b0e09742cb670f936', '90d91bad87a53d82f45a0153dc0f82c3e6036741', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '153a99ad39e85eb09f6ae56b1eb72795265cb8a0', 'a9d83b30c3e615286d3e24b6a2e2228872b39bc8', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '869a75dc4a7c54b940dcb07ada1a845c027e7350'}",76,"{'363c81a08858df8dd7d1bde79c6e002e3b19f900', 'e021d59638966a6fbb36854cc2cf1045de7a62d2'}",2,"['Lukas Ruff', 'Robert A. Vandermeulen', 'Billy Joe Franks', 'K. Muller', 'M. Kloft']",Lukas Ruff,"Lukas Ruff, Robert A. Vandermeulen, Billy Joe Franks, K. Muller, M. Kloft",2.6315789473684212
d05c1d3d0176407d2c38f7f740a33af9c429c457,A Survey on Proactive Customer Care: Enabling Science and Steps to Realize it,2021-10-11,"In recent times, advances in artificial intelligence (AI) and IoT have enabled seamless and viable maintenance of appliances in home and building environments. Several studies have shown that AI has the potential to provide personalized customer support which could predict and avoid errors more reliably than ever before. In this paper, we have analyzed the various building blocks needed to enable a successful AI-driven predictive maintenance use-case. Unlike, existing surveys which mostly provide a deep dive into the recent AI algorithms for Predictive Maintenance (PdM), our survey provides the complete view; starting from business impact to recent technology advancements in algorithms as well as systems research and model deployment. Furthermore, we provide exemplar use-cases on predictive maintenance of appliances using publicly available data sets. Our survey can serve as a template needed to design a successful predictive maintenance use-case. Finally, we touch upon existing public data sources and provide a step-wise breakdown of an AI-driven proactive customer care (PCC) use-case, starting from generic anomaly detection to fault prediction and finally root-cause analysis. We highlight how such a step-wise approach can be advantageous for accurate model building and helpful for gaining insights into predictive maintenance of electromechanical appliances.",https://www.semanticscholar.org/paper/d05c1d3d0176407d2c38f7f740a33af9c429c457,"{'2895770450e9cdfa4bfa42ea035b0a2397205e95', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '220e21003dd10c2564e2eda6fcc09f1c3bfbdee4', 'b609c8e9ec6a2b8c642810953ef6dffe5766f7c1', '95f5870b18d5f894e4f6ec8490d1a39e0963e79e', '81bd29acc7e6c3a387d2556140796eb56375a91b', '94f6c36ceff963dd9a6a2b45fb3754b071bceb17', 'b9d8e2f4337371581e712bf7f3024821dcee9748', '9ad57757e4f969318c04666e1bc3e3175c686853', '04513c7c0b3a63fde81a996dae064a28d453c17a', '36089b937a5f29e5ca8df93508e5cb8b9f42b6a5', 'bee2aeac46f73e14105a3205502de9879692d3fe', '67529adb196e5b5e003c07dc8e54a1b71247f6d5', 'e47b740efd6544aeba00d5345391dae03355bdcd', 'a393282eeada87ec5eee170ffbb3d1ecd6a2c72b', '7cad19a569461df23761f59d97bc7b9efa709832', '08f1c9578854e8ca3425f8d616cebe1fa0f10adf', '56eb2327a8f97008e7f59ac728e620397cc110ef', 'a5bd811e5358e477c079278ee2a0066dc81a386f', '7920674d9c9bbdf9893194ff4fc9c3b28f4cc1ef', '0af2bd670dfcb6252c603a21540f7ba58600c806', 'ed8cc2c872d24a2b6a40dce08ed7ad72fdae73bb', '5fa24abd7ca1c200afb89781eb01c05146d71fcb', 'a536bfd8939c43ee3e2d239a514d8847b4d3076a', 'f36391b1b0efc832208e2ea4b47bbb6b929d3303', '680746b97c20552e8cd305c065d811b1cd96c6e1', 'f37399ebf7df5a8282f44ec3a6100c33a5d80df4', '6bfc934c8a316230929ff1ea67a1777c8ccda26e', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '184d770ef86cf302836bc8873ea9c03acc454bf1', '614d808f4115ff738c44168cb8e7784f33c8bf8a', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', '82fea984dca4c69e8c3c73f674ea5793d49aa0a9', '3784b73a1f392160523400ec0309191c0a96d86f', '9891d654cd4fd53086e9ec939cc38c27a0fc1ffe', '62df84d6a4d26f95e4714796c2337c9848cc13b5', 'c6e5041db3ef73ccb1ff3f9433d615264617855e', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '3bc2c75296bfc3186cbf96a87c69af32918f5602', None, 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', 'c448fc6e79d98953cc2c349839d6831bd92fd1ec', 'bd6cbb96c28a3cd179a5e77ce17a46069b42fb3e', '92936ad88a5412bc48b86900da94b08fb7a3eefb', '02d5c8be02e367f514624d1fe0da4cdad938b8f3', '46200b99c40e8586c8a0f588488ab6414119fb28', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'c69bbda01bc97c3a1b6ff179cd242de24b675e21', 'd152df717d61207212dc5e85726cd950e55af9cc', 'd7bedfa95b4760ee9727eacd16320123fff3501a', '6010268605e32afc63d5ff035162271a80a46610', '089ea450742e95237082fde7117dda161be132e2', '6dd618c439fa893a62c339933635da72531ff804', '31bc0d4ec9a5bfc2152c4928ac2c3864959c0342', '89f57741a47cde722487dbbc8d067dfcbaa28cf2', '2e14145c2d33ea244a68c2489214c76ca8ad28d8', '6568517b91c18e64ebae5dbcd82d3bd9c1b797f2', '975a9eb18929faf31c653d3d6d923fc07c3806d2', '5048eb4319bdb22dc8932d1506045d3e27f64e5b', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '672134ce39b01b9f6a52a162f9f4c2ce0d1d3c48', '7965a3dc43107217eaabca1cbaed1011e0d09312', '8d719bcc746b59de1427e1398f29591ad4a39c90', '0f449f26897fe7aa65bd14dc790d887b52431e24', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '3429ede7bfcdfb31a3542b80c46025f0030932db', '05889b98bcd33a4f7f1d075ba862a70b2e28ec42', '60d8e3ccd7c53f3f7870699df5852ca11c5ae075', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '688158f4f5ce5b19ded29af176c5ed5d6c5fe804', '302fcae2798ebfc6c83edc323caad461cc7ab6d4', '56187544ed08e62a47ddc5be18d9312378897305', '4366ef4e8f0ea4988000dbed7810c2ce6fc82c7d', 'ec348eebcc919d89174c292b6ff3b7f2d54537f5', '375b98f955774e5438b76dd51e9a94ac68955258', 'c7cc6914acae1708da12f9ce1cfe260b71d483b7', '4660a218c77a0cc17a99277b464c278a29d4c630', '3ede8a1014f2df00218fdb3e78ec4796ca2a49f4', '2cf37672f7225284936cd50da0452a830b950643', 'b110ba174df21a23a9521731d4181261ca5860ed', '0533f1080c71e58e8db8670574f09ee7a1d14932', 'b9b0baf3d67f5e68bf4966824d2968e1b178ad88', 'fd9ea05d1104bf9a17bfae99cbb3d091825a9ed4', '6929f729194c6aba159d97921c77dc4077e40466', '9b6665f6e3e84c5607cb8e86b284aa51d3053822', 'b1464ca857593c049873421db2f37bf2d0ff676d', '968bceefa13c8fbf313992ec3b82cac471dfef1d', 'f96387ded62fb1de483bfed08522a3edf56fb757', '4bdf6ec7229d307d172e6cce48052b11524b8789', '0c9913dcf8287eadd2879b73c027b34d2f38458f', '0602f1b6c43fc944253dfc6deabbba1495e7db74', '103bdc0e62bc820c142247e0e65501cddc03ed3c', '0dd92c69e6e4c0be385a2262d422b27e0f28455b', '1d2105616d122389efbd1b0ac7c04c0c2f8ac996', 'ab7af7023418c77edfae7d2ee25fa796c926d5ea', 'd6b6878b081817f7e717254bdb62f5a42eba1840', '0b658d7b70a1445c12f03f1006762300bba4d956', 'e5514c75d9cbd8c971d21051085a3d1f7e278cb6', '7ea692f3ca356533122c35a152866c98b52d645e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'f7b3bec1ce39eee9fed79034dc78892e2da0c835', 'ca5627280f84bbe8a83109a77355f0b7fec82599', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '36306a48c0098f6aafb3a20504e650b448689961', '986fd224302b1eeb0d6422f81cc0cbdd91d54514', 'f6383d91d9976cb81a3c13d6f6675da3505fca0d'}",112,"{'2895770450e9cdfa4bfa42ea035b0a2397205e95', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '5048eb4319bdb22dc8932d1506045d3e27f64e5b', 'b1464ca857593c049873421db2f37bf2d0ff676d'}",4,"['Viswanath Ganapathy', 'S. Dhar', 'Olimpiya Saha', 'Pelin Kurt Garberson', 'Javad Heydari', 'Mohak Shah']",Viswanath Ganapathy,"Viswanath Ganapathy, S. Dhar, Olimpiya Saha, Pelin Kurt Garberson, Javad Heydari, Mohak Shah",3.5714285714285716
23ad8fc48530ce366f8192dfb48d0f7df1dba277,Towards Total Recall in Industrial Anomaly Detection,2021-06-15,"Being able to spot defective parts is a critical component in large-scale industrial manufacturing. A particular chal-lenge that we address in this work is the cold-start problem: ﬁt a model using nominal (non-defective) example images only. While handcrafted solutions per class are possible, the goal is to build systems that work well simultaneously on many different tasks automatically. The best peform-ing approaches combine embeddings from ImageNet models with an outlier detection model. In this paper, we extend on this line of work and propose PatchCore , which uses a maximally representative memory bank of nominal patch-features. PatchCore offers competitive inference times while achieving state-of-the-art performance for both detection and localization. On the challenging, widely used MVTec AD benchmark PatchCore achieves an image-level anomaly detection AUROC score of up to 99 . 6% , more than halving the error compared to the next best competitor. We further report competitive results on two additional datasets and also ﬁnd competitive results in the few samples regime.",https://www.semanticscholar.org/paper/23ad8fc48530ce366f8192dfb48d0f7df1dba277,"{'faf3a22627f198ce56671b6f8a9b3d5cc3164a91', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '56f66951145444036cb6ec748d90a04ffc487cc1', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '2cbb8de53759e75411bc528518947a3094fbce3a', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '599fd051c9438011ec5b581983c89e8922b4a5e6', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'c342c71cb23199f112d0bc644fcce56a7306bf94', '5db790198b9acf4e5efe350acdd814238fcacaa7', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '4de3ad300efdafef428cce497af6d306442e59f0', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '0c908739fbff75f03469d13d4a1a07de3414ee19', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '1c4e9156ca07705531e45960b7a919dc473abb51', '9d713f1f79554a28b9788c0299cb07d34d782022', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'c53352a4239568cc915ad968aff51c49924a3072', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '2d59c898ef2f5402574401e84ae2958dfed339ec', 'f6e0856b4a9199fa968ac00da612a9407b5cb85c', '37595f7a51982d776e57c7280b9445474d90f0be', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'fc1d1ba95d4b1ce49d50ac82f553b6236305b0b6', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '10a498003e9204f5fc1328e706510a37e514d8c7', 'b62b66b224470d3a79faf9d03734fc53482878ed', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', '70f9968a356d840040a1c9207906f60376dc6bd4', '964465406626125ce235faaccf25e265c56f501b', None, '52113c06f0da6002d80bb11fb9c47260f4ebbbe1', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '8381157eae4fbf8908d0312a9642f8e69e944449', '85330ea63af2838e08412bdc7690a463f868ef93', '4d39ee7cca8fedf792570724255a4357aa41dbf8', 'f55238913918c61b0dad87974699d05a5d71e709', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '15d7fe8bdeec9391cfaabb73d1c155b2615d84d1', '810ae452a3a1f673ea241bd540f9551b2996ed5b', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73'}",59,"{'6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",11,"['Karsten Roth', 'Latha Pemula', 'J. Zepeda', 'B. Schölkopf', 'T. Brox', 'P. Gehler']",Karsten Roth,"Karsten Roth, Latha Pemula, J. Zepeda, B. Schölkopf, T. Brox, P. Gehler",18.64406779661017
15f8588a8ef28df4934be4f3328fb32db17bd86f,Visual inspection via anomaly detection by automated uncertainty propagation,2022-05-20,"The visual quality inspection of test objects having a complex geometry is a challenging task for automated artificial vision systems. Even for systems where the illumination and image acquisition setups are specifically tailored with respect to the properties of the test object, captured images often show unwanted signal components, e.g., surface reflections, which complicate the detection of present material defects. One way to mitigate this problem is to have an expert define image regions by hand which are excluded from the automated defect detection. Besides being a time-consuming procedure, this also results in the system being blind at the respective regions. Another approach is based on acquiring image value statistics (e.g., mean value and standard deviation) for every pixel of an image series captured from a set of defect-free test objects. This information can then be exploited during the inspection process by comparing image values with respect to the previously calculated statistics. Pixels whose image values lie outside the distribution for the defect-free case might indicate a material defect. Unfortunately, the calculated statistics are invalidated as soon as further preprocessing steps like smoothing or edge detection are applied. The statistics would have to be recalculated by applying the respective preprocessing steps to the images of the defect-free test objects. To resolve this drawback, this contribution presents a novel approach capable of adequately updating the calculated statistics with respect to the chain of required image processing steps. This is achieved by interpreting the statistics as uncertainties and by propagating them through the single processing steps via Gaussian uncertainty propagation. The required gradients are obtained via automated differentiation of the image processing steps. The effectiveness of the proposed approach is demonstrated by means of empirical experiments.",https://www.semanticscholar.org/paper/15f8588a8ef28df4934be4f3328fb32db17bd86f,"{'fb6f82211d665bc42163bf0b1e82256b58d90820', '2895770450e9cdfa4bfa42ea035b0a2397205e95', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '24046c62be024695e9c73768ef6bcf870ca383c0', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '7eeb730524a8e980f91c923b8e1d026b17883e38', '23b4d8f85ef16e7d3d3b7132e0c9a553c3d58e8a', '693fb18d5d4f3892eb3062b2e6ff9fb5720323e8', None, '24cb69b24d343d6f3966008cecfd183fc15b3e37', '5854487c67e1b9ad1a97ecbda23ed90da70f09f3', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",12,"{'2895770450e9cdfa4bfa42ea035b0a2397205e95', '24046c62be024695e9c73768ef6bcf870ca383c0'}",2,"['Johannes Meyer', 'Matthias Hartrumpf', 'T. Längle', 'J. Beyerer']",Johannes Meyer,"Johannes Meyer, Matthias Hartrumpf, T. Längle, J. Beyerer",16.666666666666668
76a936ae537d79a1078135f692c1728ab40ef663,S2Looking: A Satellite Side-Looking Dataset for Building Change Detection,2021-07-20,"Building-change detection underpins many important applications, especially in the military and crisis-management domains. Recent methods used for change detection have shifted towards deep learning, which depends on the quality of its training data. The assembly of large-scale annotated satellite imagery datasets is therefore essential for global building-change surveillance. Existing datasets almost exclusively offer near-nadir viewing angles. This limits the range of changes that can be detected. By offering larger observation ranges, the scroll imaging mode of optical satellites presents an opportunity to overcome this restriction. This paper therefore introduces S2Looking, a building-change-detection dataset that contains large-scale side-looking satellite images captured at various off-nadir angles. The dataset consists of 5000 bitemporal image pairs of rural areas and more than 65,920 annotated instances of changes throughout the world. The dataset can be used to train deep-learning-based change-detection algorithms. It expands upon existing datasets by providing (1) larger viewing angles; (2) large illumination variances; and (3) the added complexity of rural images. To facilitate the use of the dataset, a benchmark task has been established, and preliminary tests suggest that deep-learning algorithms find the dataset significantly more challenging than the closest-competing near-nadir dataset, LEVIR-CD+. S2Looking may therefore promote important advances in existing building-change-detection algorithms.",https://www.semanticscholar.org/paper/76a936ae537d79a1078135f692c1728ab40ef663,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '059ff92f1bf0b33fdf2aa5bbe449b0fe0fce4a53', '2778c4820d364ab8d0e28166de7a0045b1e8dc2f', '32877f911e7649e8450d6061378e65bdf9ab629f', '40ad052f62d76b7db6818aa2285414d93c77cf50', '4ea89b189e398e843b248dc353760363685c0052', '677a0b9915da01e738a83aa8821d13eb403870b3', '71925b3f67f500f74b66d702fc37f077345cf7c6', '96cdfbd9440b87a85994ba8c074bd5184ab54dd2', 'a7043df15f897141e57b7b2df8c132fde8021f14', 'd567e8c06d6688ead92186c88ab8d58d61f681cc', '36194c76ce53be8e8fba71acbf8d235c7b39342b', '18755de13d2d868255bbf332fa80ec218163c74e', 'cd85e081c9cee5484ed06a6843d205266eea5aa0', '000a7fd18740b3badd608bb5f806255e47e45217', '9ca0e9ec056ea1b1a19bc95bd9ff8011a1803113', 'af67534690d2973c469dab79a79a23ed19447a97', 'f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b', 'fedf0d43fbef3d14ad5bf0703ab93aa52f449977', '8d3b99608e4dce76ac87ebfe67a1c8c9fd105370', 'd311d7d078b2e67cb2b9006491100147d86a2b81', '902a0d2f62f9f7b420aa0ea96a3788a80facdbd5', '9aa412ab19fcbbfcd7db221a39ee27775dcd1ddb', '8750bee9b12d76c060768e5aed2cb975f85602c4', '482ca824b96d18e061f4187a6ef9d1729a323a4c', '41536f53016ec7124fbddecef62b484369b9e982', '1d385debcb66dc259119093e9a390b0870e10037', '243e4b8f209953b62d78b6e381238f6c9ac8bb32', '6d3c2dc63ff0deec10f60e5a515c93af4f8676f2', '3b0a39f50dc841e57fe5f92a3e4d609ab9572e7b', 'f4e61d31666087d850a9f45f187254366d0a6419', '13b5e856f3e22072bc916ff45248a3d68100ce88', '71b7178df5d2b112d07e45038cb5637208659ff7', '33bca87f1b20c10935836303b89e645d11741c7b', 'a3b42cac06fddf045de26fcba136bd2ea99704aa', 'bddff90e618ed850300e1250b2e6e097095e00a5', '2060fa23185747294541f428c39640177450b8fb', '15bc476f6811fbfb9e6849cee0d2c029024677c0', 'a72ccbf4ccfa39388abd233344321679cc91d90a', '0ecd8b34e9dc7df9635821b9329bbe54a19bf5fc', '58139ebda484a3b857db2d08f94ad7e8f7cc7686', 'c5ff974a69fd0c760b4855b819e61e89f31cfffe', 'e8b251a42bd5a542793adef1fd9071122c5d03ff', '53edb3776cea0e6ee4de742d7bb906355fd8279b', 'b702cf22afb725b1bf9d633ffdd96cfb00a87253', '2d447e917558da491a41f1237891897d2ae1ba86', '4cab9c4b571761203ed4c3a4c5a07dd615f57a91', 'f96c4fec04c8a98401543f9787d2bcd3485afd36', None, 'f9a6cdd21eaa0036380c51c7f2bfe2b8fda02792', '68b181d030c24a4dbbe806de456c48309c65f0ba', '5c1680927fdbe638976207bfbbfb006e5bcecfbc', 'a71503ac83cd62519c3e4004dc25c8f98764b184', 'e58161e8dc4edaa2cf13d3fa355193549c6a341a', '9bb4cfeaad4c79baa47a1b51d7f4b50103984955', '92e4ef5575f3f22f3f22526cd1fdfd2d0397d094', '40d1baf1564adb1f20a4572387d5d0899ab7b614', '37b6a294e495481e4fb7a4ebac8a86231c7f13ff', '93e151d53c366d7e0ae44766d606c8614d88afaf', 'ec06764a9496e351440a5f806f1f40b0a6a72505', 'f1ada1c7ef5595d0b044e109a2723c40abd23122', '870b887ad2f17ea722f0c27fd4e195cce691792b', '152954530e24e701a9a1132eba602504e718a9f2', '937b84e9544db2b64919d88d9db6eb60bee3a569', 'cb7991758fb06a7e2de4dfd72bd10fbe14e7a81c', '94e251552b86c6fb78fe11bf5c91314c508c7164', '8ff012756ecebe6af52bdd382520df5902d02d14', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '8fbf011af21921a553bd8b20cd6eb16897f07801', '15a148957469bc8b91bd7cc31aa1f0c6584a1571'}",70,set(),0,"['Li Shen', 'Yao Lu', 'Hao Chen', 'Hao Wei', 'Donghai Xie', 'Jiabao Yue', 'Rui Chen', 'Y. Zhang', 'Ao Zhang', 'Shouye Lv', 'Bitao Jiang']",Li Shen,"Li Shen, Yao Lu, Hao Chen, Hao Wei, Donghai Xie, Jiabao Yue, Rui Chen, Y. Zhang, Ao Zhang, Shouye Lv, Bitao Jiang",0.0
fc306287c6a7fd72791cd97c767fbc6d4c43d590,Ensemble Convolutional Neural Networks With Knowledge Transfer for Leather Defect Classification in Industrial Settings,,"Leather defect analysis is important for leather quality grading which directly effects the leather exports. Automated leather sample classification is vital due to slow and subjective nature of the manual process. The major challenges that exist in visual inspection of leather samples for categorization are: the morphology of defects significantly differs and their close examples are not available for transfer learning, unavailability of publicly available data and a benchmark. In this paper, we discuss three important aspects in the identification of industrial leather defects, i.e. the creation of an annotated wet-blue leather image dataset, the transfer of information from different domains to the leather image domain and the design of ensemble networks tailored to the task. We are therefore introducing a new database of wet-blue leather images (Wet-blue Leather Image Dataset (WBLID)) for the classification of defects along with expert annotation data. We proposed a new network EfficientNet-B3+ ResNext-101. The proposed EfficientNet-B3+ ResNext-101 ensemble architecture significantly outperforms all other state-of-the-art methods in terms of AUC and F1-score.",https://www.semanticscholar.org/paper/fc306287c6a7fd72791cd97c767fbc6d4c43d590,"{'112cfffeea4ba8e951040a9d453f8a5c4afb7e95', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'a53983c73809b3d27ac775e3c3c1b4347c180ae3', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', 'e9be61afe33ba9e2166a3c301d54c229b6756273', 'f8de25118af2abc4c48afb947d6ec298e05ef1e5', 'db4c0e36f8f1e773b6d4cd440b5430a9dc485c93', 'e1ec11a1cb3d9745fb18d3bf74247f95a6663d08', '2f4df08d9072fc2ac181b7fced6a245315ce05c8', 'c0aaee2337e5af680e5dca1bfc349a737dfec573', 'cff4cb74f4466bd0407977e40ef0be9f444c63ea', '7e1291583873fb890e7922ec0dfefd4846df46c9', '482df10d0a25eff0d24afc22c6097eb5dc4682ce', '89bcfab917c073371548c4ebc2fdedcb974d94c6', '0ac46d88c9b883802dfda25aa12c068ef3b7c570', '2b73f023765f784a5e8bc943875777d2a26e06fa', '95c3bd4f7513b4e5a853f9f93d609fc52646cf8b', '1c8a3a4f1b763e807ba528d07d9fef819c017dbf', 'aa873bb67cc952f89116e29073e34484c1ef4ef5', 'f6e0856b4a9199fa968ac00da612a9407b5cb85c', 'f95f5b715eb0441ca4ee1b0fac6b4bcaaba65556', '7e50deaa917178c6469898ae37142ba531f130c9', 'b04db3e90defb2c34daca6383c3aea2e3f42ca70', 'd1ee87290fa827f1217b8fa2bccb3485da1a300e', '1c46943103bd7b7a2c7be86859995a4144d1938b', '7340f090f8a0df5b109682e9f6d57e4b8ca1a2f7', '6cef4ea1928287ee59ec188570ade799c54ab44f', 'a25fbcbbae1e8f79c4360d26aa11a3abf1a11972', 'fa18a454c5e8354d10b0191f747ffd85dd0ccd9b', None, '3d08696a08c77cd2d25138d01dd701210bdee3cc', '414170e0f6959ec452c6da866a61a2a557682f56', '5694e46284460a648fe29117cbc55f6c9be3fa3c', '35ade512bb5ea4bfe0f03a14974e9e380dcf7100', '2fb636dd87d0c93b0fa07c4dfb306bc55e11ed2a', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '2ccf2cbc169167628abaca8e69f480d6a3137ab8', 'b2d952fbd6951cbed68ea13003a045300970731a', 'ce950fdeac1b5a48e6190e6879f9728fc2bc1bbf', '96a517339078de910f0b722acdd873df9de70d20', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', 'ce21d170002520e16263c514491d37b53bb42677', '23ffaa0fe06eae05817f527a47ac3291077f9e58', 'fc70a20224a2cab03243a386cd6871af77f2e036', '5b6ec746d309b165f9f9def873a2375b6fb40f3d', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '31f10a6f602bef0306ac37322f84f6163c8a8ecb'}",48,set(),0,"['Masood Aslam', 'T. M. Khan', 'S. Naqvi', 'Geoff Holmes', 'Rafea Naffa']",Masood Aslam,"Masood Aslam, T. M. Khan, S. Naqvi, Geoff Holmes, Rafea Naffa",0.0
d67b9dafcf94017784c266e021fe29baf2ffd572,A Novel Pixel-Wise Defect Inspection Method Based on Stable Background Reconstruction,2020-11-17,"In this article, an anomaly detection method based on background reconstruction is proposed to perform defect inspection on the texture surface of the industrial products. This method consists of two modules: 1) an autoencoder integrated with a generative adversarial network is utilized to reconstruct the textured background of the original image as a defect-free reference. Specifically, extra anomalous images are introduced and a mapping method of anomaly is given to improve the stability of reconstruction. 2) A U-net based inspection network is trained to perform pixel-wise analysis of the differences between the original and the reconstructed defect-free image. During these processes, only artificial synthesized defective images are utilized to train the model without any real defective samples. A series of experiments are conducted on several texture image data sets and the industrial production line. The experimental results reveal the effectiveness and versatility of the proposed method.",https://www.semanticscholar.org/paper/d67b9dafcf94017784c266e021fe29baf2ffd572,"{'d03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '732c21998e251d64cd58b6a86886ee5907efeaa5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'b5943c566e67545dba80db54e1a28c28e3a44c1e', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'f076e4355c0facf111716dcab2837803367dd2d8', 'fb8e2adf906990107791b49489ede76ea33f21aa', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '36653f8705b56e39642bcd123494eb680cd1636b', '5dafad7418d5329b0033eaad0b41296cc27bcfb0', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'bfe284e4338e62f0a61bb33398353efd687f206f', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', 'b4262bb2978d359d92707273972cd5bb81177848', 'd81421695d5d429a47eefe266986d197d7b313f2', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '23ae911ceb9134f3a27719faab5d5d297a2f4e8e', '0d3b2db9af4a72f2e0ec6f15a7f0bc6fe6e97cdb', '22161e2b4b4a0e27dd7d0b3c3386393fc4320240', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '5db1b742cd18678ed08a813970bfaba3527df037', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '8381157eae4fbf8908d0312a9642f8e69e944449', '46d4a2b7ccf38b80b09574cf17544ff2297a8fbf', 'e70ad663247611dfbeda0416b1d6a3871363b5a1', '22aab110058ebbd198edb1f1e7b4f69fb13c0613', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",37,"{'16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '23ae911ceb9134f3a27719faab5d5d297a2f4e8e', 'd9d7ab13ce305ccee309c989a2341d72b1252070'}",3,"['Chengkan Lv', 'Fei Shen', 'Zhengtao Zhang', 'De Xu', 'Yonghao He']",Chengkan Lv,"Chengkan Lv, Fei Shen, Zhengtao Zhang, De Xu, Yonghao He",8.108108108108109
9cd70ca81b4653aa2048002273c5ac9c36641390,Anomalib: A Deep Learning Library for Anomaly Detection,2022-02-16,"This paper introduces anomalib1, a novel library for unsupervised anomaly detection and localization. With reproducibility and modularity in mind, this open-source library provides algorithms from the literature and a set of tools to design custom anomaly detection algorithms via a plug-andplay approach. Anomalib comprises state-of-the-art anomaly detection algorithms that achieve top performance on the benchmarks and that can be used off-the-shelf. In addition, the library provides components to design custom algorithms that could be tailored towards specific needs. Additional tools, including experiment trackers, visualizers, and hyperparameter optimizers, make it simple to design and implement anomaly detection models. The library also supports OpenVINO model-optimization and quantization for realtime deployment. Overall, anomalib is an extensive library for the design, implementation, and deployment of unsupervised anomaly detection models from data to the edge.",https://www.semanticscholar.org/paper/9cd70ca81b4653aa2048002273c5ac9c36641390,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '2c948ab13b9ecfa35374913710f849e806297e18', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', 'c342c71cb23199f112d0bc644fcce56a7306bf94', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '89f57741a47cde722487dbbc8d067dfcbaa28cf2', '66cb331ba7f145f470869bd39dcef8ff535503a9', None, '17555c227941654bc19d613742e2508f209c6d86', '2e8d62277e40d465343e8dfb32ecc246f320540e', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', '5239f449210b089b75ab335fc74720dbf2e02b58', '9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d', 'c2c083df88e88223e1a411e61040b94c233b1b63', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",21,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",5,"['S. Akçay', 'Dick Ameln', 'Ashwin Vaidya', 'B. Lakshmanan', 'Nilesh A. Ahuja', 'Ergin Utku Genc']",S. Akçay,"S. Akçay, Dick Ameln, Ashwin Vaidya, B. Lakshmanan, Nilesh A. Ahuja, Ergin Utku Genc",23.80952380952381
5ea7869451f38b9f590b53cf5a19c4675d039f13,Weakly-supervised Video Anomaly Detection with Contrastive Learning of Long and Short-range Temporal Features,,"In this paper, we address the problem of weaklysupervised video anomaly detection, in which given videolevel labels for training, we aim to identify in test videos, the snippets containing abnormal events. Although current methods based on multiple instance learning (MIL) show effective detection performance, they ignore important video temporal dependencies. Also, the number of abnormal snippets can vary per anomaly video, which complicates the training process of MIL-based methods because they tend to focus on the most abnormal snippet – this can cause it to mistakenly select a normal snippet instead of an abnormal snippet, and also to fail to select all abnormal snippets available. We propose a novel method, named Multiscale Temporal Network trained with top-K Contrastive Multiple Instance Learning (MTN-KMIL), to address the issues above. The main contributions of MTN-KMIL are: 1) a novel synthesis of a pyramid of dilated convolutions and a self-attention mechanism, with the former capturing the multi-scale short-range temporal dependencies between snippets and the latter capturing long-range temporal dependencies; and 2) a novel contrastive MIL learning method that enforces large margins between the top-K normal and abnormal video snippets at the feature representation level and anomaly score level, resulting in accurate anomaly discrimination. Extensive experiments show that our method outperforms several state-of-the-art methods by a large margin on three benchmark data sets (ShanghaiTech, UCF-Crime and XD-Violence). Code is available at https://github.com/tianyu0207/MTNKMIL.",https://www.semanticscholar.org/paper/5ea7869451f38b9f590b53cf5a19c4675d039f13,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'cd8ddaaf56e38dddafdeac3f9643b9b5e9d35d54', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', '8899094797e82c5c185a0893896320ef77f60e64', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', '599fd051c9438011ec5b581983c89e8922b4a5e6', '2e269d2ee60db6d09a514c4748e3fdf9202917f9', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '992847be33f4bf7afbe66e198cb20a53e00dfa76', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '4d8f2d14af5991d4f0d050d22216825cac3157bd', '5db790198b9acf4e5efe350acdd814238fcacaa7', '8109587a56d53c6ba30fe19ba9aa4d9213ec91a0', 'e1820e33e0347c4e9e625b640c7156faefe74159', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9821102c3f41297a8bd61a55d85225c5c75a9031', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '011d9da0860b43abba7b089167937e2277e07540', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', 'a03bda078490e8ee991a1f86b53f27df7cf93a14', 'a4c94b221062d0737ee967affa80ce2110cc50c0', '2c1890864c1c2b750f48316dc8b650ba4772adc5', '86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '8f28873be3601c5a2736996eba543cf51950a381', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9d5290fadb7625862a966e0330bd0f9e111fc99d', '04513c7c0b3a63fde81a996dae064a28d453c17a', '267502d21b44884570fcd95a855821cc3e86e6eb', '60fef33549f57f5cbb6712a510c3a444ab682429', '49133ffa30e0acaf4ea5bd8bbf68c841b02e3f2a', '31cbbce38417c704df5dc5f6c4bef46d38b0e190', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '3727443e7c0bb819846a1f98e6efd772d34824c9', '54c7445f319823c7dcc948c830e75e2fa7460b33', '1442cb4613c99924f500ebdc2a7fdaf2e9080da5', 'df67d46e78aae0d2fccfb6212d101a342259c01b', 'fcadb2bac99550adcdbd8578eb246eb9e264ecf3', 'b9bdc61d63d75d82f24de21be26f61879df5a01b', '711cb048076ec8f297efe4cb2c77c1ed95c0ccc4', '1f528877c4d8d5df3b3abbfa64379677d451956b', '6af440915b8a0718c93be1cf61905e41e620484a', '7f5fc84819c0cf94b771fe15141f65b123f7b8ec', 'a0e8f4348968195c80494b7a4245edb91a252c93', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'c48def9076e58095c4aea49a8daa931af1990701', '50a93a118d5826369d2d28ed87216bde08fdb1b4', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', 'd3b614f11969127a08447c41257b3a7b58766d18', 'b61a3f8b80bbd44f24544dc915f52fd30bbdf485', '77d30cf9a34fb6b50979c6a68863099da9a060ad', '41747cbdbed84762dfbfc305254c97021279dc6e', '38d4b5a464652a4afb4f043f141976f5c71c1e6b', '08f99af9f5d6d351201ee4563e407bf37bc164fd', '4aadd44e7f58667c149ee9037d97cccb2ebd7815', '96d7a07237e146c28173767dfc6290a337696c04', '8381157eae4fbf8908d0312a9642f8e69e944449', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', 'e6df192c9b654bc5cc371c55012cf99d85cb61df', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', 'db20d81d40243d66ff90f11b5c6f058d43d3701f', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '094ac7510d1723cb9c2da01db47291322aa29025', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', '84f7f9e121c1285e15cefbfc44bcb3322f73b6aa', '048ef48f58156ab9f8eb4c1126e090194459e699', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '6f68ce1e03c56c186256dac689a21f6405ae8d96', '598fe25743f9492c5c1ba30274ea446f65426d85', '4a73a1840945e87583d89ca0216a2c449d50a4a3'}",72,"{'41747cbdbed84762dfbfc305254c97021279dc6e', 'd3b614f11969127a08447c41257b3a7b58766d18', '1f528877c4d8d5df3b3abbfa64379677d451956b'}",3,"['Yu Tian', 'Guansong Pang', 'Yuanhong Chen', 'Rajvinder Singh', 'J. Verjans', 'G. Carneiro']",Yu Tian,"Yu Tian, Guansong Pang, Yuanhong Chen, Rajvinder Singh, J. Verjans, G. Carneiro",4.166666666666667
aa7799a2551b506301fafb5cfaee5ca62bb484b2,Synthetic Data Set Generation for the Evaluation of Image Acquisition Strategies Applied to Deep Learning Based Industrial Component Inspection Systems,,"Automated visual inspection is an ongoing machine vision challenge for industry. Faced with increasingly demanding quality standards it is reasonable to address the transition from a manual inspection system to an automatic one using some advanced machine learning approaches such as deep learning models. However, the introduction of neural models in environments such as the manufacturing industry find certain impairments or limitations. Indeed, due to the harsh conditions of manufacturing environments, there is usually the limitation of collecting a high quality database for training neural models. Also, the imbalance between non-defective and defective samples is very common issue in this type of scenarios. To alleviate these problems, this work proposes a pipeline to generate rendered images from CAD models of industrial components, to subsequently feed an anomaly detection model based on Deep Learning. Our approach can simulate the potential geometric and photometric transformations in which the parts could be presented to a real camera to faithfully reproduce the image acquisition behavior of an automatic inspection system. We evaluated the accuracy of several neural models trained with different synthetically generated data set simulating different transformations such as part temperature or part position and orientation with respect to a given camera. The results shows the feasibility of the proposed approach during the design and evaluation process of the image acquisition setup and to guarantee the success of the real future application. CCS Concepts • Computing methodologies → Quality Inspection; Industrial Manufacturing; Photo-realistic Rendering; CAD Models; Anomaly Detection; Deep Learning; Generative Adversarial Networks;",https://www.semanticscholar.org/paper/aa7799a2551b506301fafb5cfaee5ca62bb484b2,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '282578039c767f3d393529565cae6be56fda6242', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'fdc5bf6737105628e63d2f462bd6fd89acea089a', '92e4bccf9ab17244dcefc50a547e87a23e1fd3bb', '2e76361957c8cdbeec4f617c356e50336fdda682', 'd8919d5a81d079b1119477b79db7572aaf3f32ea', 'd5f5fec8397e4d7e3bdcaaab091550a783adeccd', '8495faedf3da3b9f639fa97904931ecb96017101', 'e95cf80f757bf25c14e7767d70d400fff19b04dc', 'd5c4a0d3da58ed31223d543207beabbcbe55f293', '97f403cfc932c137af78f83afdcf377c6f04b144', '31630d1aa44ef8fcac8e127ed9d7ac57e3c11269', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'bc27cd49fbbead76a4a9d8d42c007d690986b6c6', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', 'e78e271fe39f1e279a16558cdca4a5137389c870', 'c299a47d3472ec236bad4e7d91e29540d3572177', 'f11d69fac609917da82f697758cd694c0f01a730', '25757e7819eeb8829d3524474f973b79befd7b59', 'bc7d49fcd26042c755f1ab663f8b93351e6768fa', 'ea68899e52526ce59c1f0b0cbc7cd992a0700383', 'a5ae7436b5946bd37d17fc1ed26374389a86deff', 'dd37d38bd4163eec1e24a83f282c862e1de71cf1', 'f8a9dcf96f390ae76fb744cc8c3935fa3ddb2468', '4fbcd0dab5b09d5118e4fb7c27eaa961f28b39fd', '6ff2a434578ff2746b9283e45abf296887f48a2d', None, '9b6e4cbf1f8d6fbf09017769ae65ff90234e0aa0', 'dcc183f37a0a8d37deed5ee60c03164391d05d07', '3c667ab03a4e8842847f78227816d944a66afb32', 'd7945a233c112431b21dc751dafb59921e043959', '5b177049fa543661e5bb741c3338deffd64982eb', '55eef0c2811fd90479ce0d4bbe2c4a342459fc78', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '752771510a40076d47fd2952b72c4ae820c66081', 'eb7ddda1bfa709497af9d0b2010d61d659a1816f', 'aab32d98d8b415fe06af4c9e90a2f3c5af23af31'}",39,"{'ea68899e52526ce59c1f0b0cbc7cd992a0700383', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', 'c299a47d3472ec236bad4e7d91e29540d3572177'}",3,"['Fátima A. Saiz', 'Garazi Alfaro', 'Iñigo Barandiaran', 'Sara García', 'M. P. Carretero', 'M. Graña']",Fátima A. Saiz,"Fátima A. Saiz, Garazi Alfaro, Iñigo Barandiaran, Sara García, M. P. Carretero, M. Graña",7.6923076923076925
1ef4df731e17f0644c129779de2019fd4573bcca,Fake It Till You Make It: Near-Distribution Novelty Detection by Score-Based Generative Models,2022-05-28,"We aim for image-based novelty detection. Despite considerable progress, existing models either fail or face a dramatic drop under the so-called “near-distribution"" setting, where the differences between normal and anomalous samples are subtle. We ﬁrst demonstrate existing methods experience up to 20% decrease in performance in the near-distribution setting. Next, we propose to exploit a score-based generative model to produce synthetic near-distribution anomalous data. Our model is then ﬁne-tuned to distinguish such data from the normal samples. We provide a quantitative as well as qualitative evaluation of this strategy, and compare the results with a variety of GAN-based models. Effectiveness of our method for both the near-distribution and standard novelty detection is assessed through extensive experiments on datasets in diverse applications such as medical images, object classiﬁcation, and quality control. This reveals that our method considerably improves over existing models, and consistently decreases the gap between the near-distribution and standard novelty detection performance. Overall, our method improves the near-distribution novelty detection by 6% and passes the state-of-the-art by 1% to 5% across nine novelty detection benchmarks. The code repository is available at https://github.com/rohban-lab/FITYMI.",https://www.semanticscholar.org/paper/1ef4df731e17f0644c129779de2019fd4573bcca,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', 'eb90986ff64e3b5e7b5e33dc9501032058c6738e', '70472c97e0460cbc04bc0148b0fc59392edb3c50', 'db787640c9b42416ff8d7015546e667e58267177', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '4c7d664761c359cffd20c9d555031271ec67ab3c', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '10b219619e88931fabb674037bbb633682775136', '02b28f3b71138a06e40dbd614abf8568420ae183', '330008af4074ef0e2b21787677783827d6a15056', 'c069629a51f6c1c301eb20ed77bc6b586c24ce32', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', 'c3ddd90b53dc797029c4576af01b9c35bb846a44', 'd4d7063dab04985c8f4c355d0931b1cfb79da18f', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '6af440915b8a0718c93be1cf61905e41e620484a', '29858b40a15704398aecdca6bd2820f2fcc99891', None, '3039962978812c1c2a33135d60673ebdffe2ce55', '23ae911ceb9134f3a27719faab5d5d297a2f4e8e', '1643f48027cd18aeaf713bf7b5b18bb91a765503', '7d3a0fca300423684d01d5ab767f8eacdaa45f51', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'c8c422850207355cfd4433d7b4f95cfee3d3525e', '522d65a3db7431015aeaa201a7fc4450a57e40c3', '815fa9febd615530abccc2430ee05804427394ba', '3cf2a7f796921e01e6e794da193a244c3b793b04', '633e2fbfc0b21e959a244100937c5853afca4853', '94192bcdf3507e3543910c03b16bd06c5338fd47', 'a83cec6a91701bd8500f8c43ad731d4353c71d55', '30895c61bb836f2cae7ef5ba6516886f746a7153', 'a090711c5e17f0d9907f243c05251350215c088f'}",39,"{'6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '23ae911ceb9134f3a27719faab5d5d297a2f4e8e', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'd4d7063dab04985c8f4c355d0931b1cfb79da18f', '7d3a0fca300423684d01d5ab767f8eacdaa45f51', '41747cbdbed84762dfbfc305254c97021279dc6e', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', 'a090711c5e17f0d9907f243c05251350215c088f'}",10,"['Hossein Mirzaei', 'Mohammadreza Salehi', 'Sajjad Shahabi', 'E. Gavves', 'Cees G. M. Snoek', 'M. Sabokrou', 'M. Rohban']",Hossein Mirzaei,"Hossein Mirzaei, Mohammadreza Salehi, Sajjad Shahabi, E. Gavves, Cees G. M. Snoek, M. Sabokrou, M. Rohban",25.641025641025642
73cd41517018945fc17300adeb91447bfede6a53,A Survey on Unsupervised Industrial Anomaly Detection Algorithms,2022-04-24,"In line with the development of Industry 4.0, more and more attention is attracted to the ﬁeld of surface defect detection. Improving eﬃciency as well as saving labor costs has steadily become a matter of great concern in industry ﬁeld, where deep learning-based algorithms performs better than traditional vision inspection methods in recent years. While existing deep learning-based algorithms are biased towards supervised learning, which not only necessitates a huge amount of labeled data and a signiﬁcant amount of labor, but it is also inef-ﬁcient and has certain limitations. In contrast, recent research shows that unsupervised learning has great potential in tackling above disadvantages for visual anomaly detection. In this survey, we summarize current challenges and provide a thorough overview of recently proposed unsupervised algorithms for visual anomaly detection covering ﬁve categories, whose innovation points and frameworks are described in detail. Meanwhile, information on publicly available datasets containing surface image samples are provided. By comparing diﬀerent classes of methods, the advantages and disadvantages of anomaly detection algorithms are summarized. It is expected to assist both the research community and industry in developing a broader and cross-domain perspective.",https://www.semanticscholar.org/paper/73cd41517018945fc17300adeb91447bfede6a53,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af', 'ab96c776f96e10f10d88ac5abbe9335afe935c81', '820f81f4263ad84b581e2b0feec563db0c64ff9b', '9ab7cd49f5245f24858698db737bb93544134f14', '693310e6ba626c82935af0ad690a94930e20c2ad', '3e3fdd4bc3c7fd160ddb90fe1a3000f2bcdeebba', 'c9f3404e7315ac7782faa780216f826cd5066049', 'f7993e55257f535c1d4be65da933949cd56e574b', '42ce75f5e11b6949e4fe676ad495a6969b34232b', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '3e3096f62bba9531a2d35c77738c31175b4a0af0', '37595f7a51982d776e57c7280b9445474d90f0be', 'e47c0c0ecc351b14217837367474272c54cc9771', '498e003901f8287e89e5064477cd22dd47e49d61', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', 'cc4c8b3ef52594f996807e85c01831ceae7ba8ed', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '9b83bcc497f7ca36a5b379cd72225dd7b305611b', '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', '7d3a0fca300423684d01d5ab767f8eacdaa45f51', '2e8d62277e40d465343e8dfb32ecc246f320540e', '1c802eecedcbe651560905085dd3d59083aaa1d5', 'bb48ed21ffc9399db166a0c58d1e7a9b784a58d7', 'ff9ee76b5243dd36155acca9313a29f398857f3b', 'ff63077f0786167a0f7bcf75c48277f7988e972f', 'cfabbbf52fca4d872293e8301bb958c60766dc6d', 'c3ece3d8acd827aae9c30afb737d957267c411a3', 'bb0ba74be5248c3ec684e164b4c2cb92f04c1c0b', 'd65c660dd8ed7190ebb29e337881041359245538', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '99f012eb6a8842258dd2c2fdbcb117e8551938ef', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '57ea5292caabc5e0d7fb1de2734b81ba5be76d27', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '19862af96b6af51e879e6e3f1d3d421af5427005', '533ce0ecba0151ee95529b71da300263b106f585', '4758baad6b22c61682e7f7182bb93723046f36f5', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', '3140d274512081b7778e584f57ef89961061943a', '58258fdcdee57410c20ce33980fea494b5bdda40', 'a56b66cbccbaf70e062b6a03de3bde54ddd89894', '428caa6e7b9aa570245888a78267064bb62ca7c7', '67f2d17418e6f4a147aa8b5a5006a47da227faf7', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', 'bed674e60ec6c51ae98d893bf3e410922928197f', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '12552121793b8e8826d912d31964d4c6087a1d67', '43895b6b935c87dd28ae6c9c9709e9d75f3646d1', 'f3e7f64f8552eab9d5bf4670a92662fa24a1a339', 'c02a08d30aa070a5039ec4a7d92b3e7419b85976', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '762ca3aa087f25a96547cb453b9178e4f6316230', '4936c8c03c7d9720530ce29b47b5266a7d79efd9', None, 'cb43e19231c1696ecd67eedf41fe648d7af1871d', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '8912bbda251b8294379067312794289a9ef0d490', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '43a25280e1271f0b24725c37211fc14553f4709a', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '0ce519bd595f174514302abd3dc9232dfd5e00a0', '2db34372d9ca2f3f3383227a241ae33f0e28c6fd', '1f01fc226913ab74e4b1b67d19721ed8d9fce4cb', '845533e69456e8d52996acb550cc50d2aabc3d8e', '6223ca525d821eb291fd8b801f83ee55061e7ade', '3d76e4a420ee27ca5101648e7ea7d717e73207c6', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'fdc5bf6737105628e63d2f462bd6fd89acea089a', '81b500a21bb1923af2ead727d5d140a3613d5161', 'dbe1a661691aa63bea84303d8f3a20be701e97a9', 'd91828ea066654803d0876e35e279a42de56cfcc', 'd84c62734eb07141495421da1fdf9ed211ea4f93', '6517f92d519fc126cc18924231bafd8945a554d1', 'c439b9ab7e7a92ea76513d3899986824e72f2125', '8fec178e2a9b8b626ad89d34cd7b5a4a2db9ef1d', '09fec6170aefe3c903c4a116b8f18e93d392ae6b', '3a5c939dd7ec651428a97073d5a238cd02fb62a1', '51e03cdabca21f377261509c9d6e126168c5f41b', 'c61462b32b30bfe00ecf95ca2f39be46f6308f87', 'f7b41cc0e1972d914e3f2cea29372555fb228453', 'c7ecc47b4c982e1127c8742c6715ea099b3a799a', '656d86b2593f87575bcc4f056dad3d18db29eb0c', '7edbd1ee743632893de81d117c05120774dc36f4', '6af440915b8a0718c93be1cf61905e41e620484a', 'd3b94b38a58c9e7c229064e6a4ae5cc3f1c77964', '01b6affe3ea4eae1978aec54e87087feb76d9215', '7f3b0d696f593874774041d97c47ad188e6d25dc', '4c51542629fded42eb4e6aa38c2879fc8f250165', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'a4ac751a601bdf54dc2b513730de6e525a2bb97b', '86b7988bbdd63053d0bb17b3d5b1384b6853c3f3', '6063c738f244c9707ec0b31d17cc20e841c51d1a', '5dbd7c2ba7bc494e94e840241d7d5468b230e78f', 'a450fb0ab67a836bf933bc5a4546c6cafd673a36', '1bbe9c0526e4627a8708d103629bfb4662c925fb', '7cb2bedc49377b3cab3ddfbd3aff13e57af49880', 'fa1aa090d09dc5d420d0cce37cea72c21e99d36b', '491b149544eff61778c216a4eb869ec0b008f346', 'c229bcaf9ec5eff3fb2891f4447e2a25161ad7c5', 'bd35961cb173b4b6a086b3dc42e8087dc6b8dfba', 'ac17a42f3eb63b8c7267f4cc00151ad3af47064d', 'f5b9b024b3e3d7207225365bd52a4a0666e0f9a6', '69c688be83d4de5f1550bb1462474b19b4546b76', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'b1464ca857593c049873421db2f37bf2d0ff676d', '348806a5f9b13f05f62b597069ece50916b9fcd9', '3e0d8667c6cfb58ecdb5f495f30a6c6894d7d86e', 'f11d69fac609917da82f697758cd694c0f01a730', '50ce2066fd34ea8a3b37beb141ba32aab8210fed', 'f8a9dcf96f390ae76fb744cc8c3935fa3ddb2468', 'fa0ced12da555bdceb1d421324c5746ec2ebc4c4', '10ae15147d0bc0d6d06ceaae28165bf8646ae478', '6bb2951a790400e88e7eb3754f5af2daee245afb', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '19cf47dab2d40a41e55bd4319810c9641d0429b3', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', 'c19dc2dfd3794cbb52e47c950f9658c6d7d7c630'}",125,"{'931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'd84c62734eb07141495421da1fdf9ed211ea4f93', '6517f92d519fc126cc18924231bafd8945a554d1', '19862af96b6af51e879e6e3f1d3d421af5427005', '1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af', 'ab96c776f96e10f10d88ac5abbe9335afe935c81', '8fec178e2a9b8b626ad89d34cd7b5a4a2db9ef1d', '820f81f4263ad84b581e2b0feec563db0c64ff9b', '4758baad6b22c61682e7f7182bb93723046f36f5', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', '62b77e5cb85fc61b84edd532f6d65714be152596', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '50ce2066fd34ea8a3b37beb141ba32aab8210fed', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '7d3a0fca300423684d01d5ab767f8eacdaa45f51', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'fa1aa090d09dc5d420d0cce37cea72c21e99d36b', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",33,"['Yajie Cui', 'Zhaoxiang Liu', 'Shiguo Lian']",Yajie Cui,"Yajie Cui, Zhaoxiang Liu, Shiguo Lian",26.4
b9bf84e316d9dbfc478ccf142c89c0592acd9d88,Microcalcification localization and cluster detection using unsupervised convolutional autoencoders and structural similarity index,2020-03-16,"Detecting microcalcification clusters in mammograms is important to the diagnosis of breast diseases. Previous studies which mainly focused on supervised methods require abundant annotated training data but these data are usually hard to acquire. In this work, we leverage unsupervised convolutional autoencoders and structural similarity (SSIM) based post-processing to detect and localize microcalcification clusters in full-field digital mammograms (FFDMs). Our models were trained by patches extracted from 3,632 normal cases, in total with 16,702 mammograms. Evaluations were conducted in three aspects, including patch-based anomaly detection, pixel-wise microcalcification localization, and microcalcification cluster detection. Specifically, the receiver operating characteristic (ROC) analysis was used for patch-based anomaly detection. Then, a pixel-wise ROC analysis and a cluster-based free-response ROC (FROC) analysis were performed to assess our detection algorithms of individual microcalcifications and microcalcification clusters, respectively. We achieved a pixel-wise AUC of 0.97 as well as a cluster-based sensitivity of 0.62 at 1 false positive per image and 0.75 at 2.5 false positives per image. Both qualitative and quantitative results demonstrated the effectiveness of our method.",https://www.semanticscholar.org/paper/b9bf84e316d9dbfc478ccf142c89c0592acd9d88,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '4085e536b5d6b4bb6913a467c7b0e4995662587c', '2c922a216c9684d539ffaf858cace091b2a2f7c7', 'be5ebd6313605b95e104ca72b984a4025c5a8fdb', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'ad27d550c2ffc42df1130775ffafa0615cee2b83', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40'}",7,set(),0,"['Yifan Peng', 'Rui Hou', 'Yinhao Ren', 'L. Grimm', 'J. Marks', 'E. S. Hwang', 'J. Lo']",Yifan Peng,"Yifan Peng, Rui Hou, Yinhao Ren, L. Grimm, J. Marks, E. S. Hwang, J. Lo",0.0
95a26eafabf06b1fc5dec6c460a927cf5964e97e,DRÆM – A discriminatively trained reconstruction embedding for surface anomaly detection,2021-08-17,"Visual surface anomaly detection aims to detect local image regions that significantly deviate from normal appearance. Recent surface anomaly detection methods rely on generative models to accurately reconstruct the normal areas and to fail on anomalies. These methods are trained only on anomaly-free images, and often require hand-crafted post-processing steps to localize the anomalies, which prohibits optimizing the feature extraction for maximal detection capability. In addition to reconstructive approach, we cast surface anomaly detection primarily as a discriminative problem and propose a discriminatively trained reconstruction anomaly embedding model (DRÆM). The proposed method learns a joint representation of an anomalous image and its anomaly-free reconstruction, while simultaneously learning a decision boundary between normal and anomalous examples. The method enables direct anomaly localization without the need for additional complicated post-processing of the network output and can be trained using simple and general anomaly simulations. On the challenging MVTec anomaly detection dataset, DRÆM outperforms the current state-of-the-art unsupervised methods by a large margin and even de-livers detection performance close to the fully-supervised methods on the widely used DAGM surface-defect detection dataset, while substantially outperforming them in localization accuracy. Code at github.com/VitjanZ/DRAEM.",https://www.semanticscholar.org/paper/95a26eafabf06b1fc5dec6c460a927cf5964e97e,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'ee4a012a4b12d11d7ab8c0e79c61e807927a163c', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'efdbd7af97c0fb0dbf0e302c616eda750e1772e9', '94f6c36ceff963dd9a6a2b45fb3754b071bceb17', '79cfb51a51fc093f66aac8e858afe2e14d4a1f20', '62b77e5cb85fc61b84edd532f6d65714be152596', '5435a9ab36a308cef10bc725104e8f778ed3a328', '37595f7a51982d776e57c7280b9445474d90f0be', 'e5014a547281b5d64c89cb14825757c565f02639', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '17d3f90cb63fbac50a5e49b8a46e633ec1f526fd', None, '41747cbdbed84762dfbfc305254c97021279dc6e', '18c125ce0f64e85577f7d30132cf0e92ec664bf4', '2e8d62277e40d465343e8dfb32ecc246f320540e', '6bbd51697c25493ea15f4cac830e28eeac143898', 'a414c2111a042c0e53f4cb4297ddb39a3801fc1e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '72564a69bf339ff1d16a639c86a764db2321caab', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'f93bdba4177051d3cb285e65dc911dc77d332d11', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",32,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '41747cbdbed84762dfbfc305254c97021279dc6e', '62b77e5cb85fc61b84edd532f6d65714be152596', '2e8d62277e40d465343e8dfb32ecc246f320540e', '37595f7a51982d776e57c7280b9445474d90f0be', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '4dd78b8d466b4cfe55a1bbdc694291197ce62541'}",8,"['Vitjan Zavrtanik', 'M. Kristan', 'D. Skočaj']",Vitjan Zavrtanik,"Vitjan Zavrtanik, M. Kristan, D. Skočaj",25.0
00ec1d0b26dd0221ee0c89a5bcb25e1855825ab3,Anomaly Detection By Autoencoder Based On Weighted Frequency Domain Loss,2021-05-21,"In image anomaly detection, Autoencoders are the popular methods that reconstruct the input image that might contain anomalies and output a clean image with no abnormalities. These Autoencoder-based methods usually calculate the anomaly score from the reconstruction error, the difference between the input image and the reconstructed image. On the other hand, the accuracy of the reconstruction is insufficient in many of these methods, so it leads to degraded accuracy of anomaly detection. To improve the accuracy of the reconstruction, we consider defining loss function in the frequency domain. In general, we know that natural images contain many low-frequency components and few high-frequency components. Hence, to improve the accuracy of the reconstruction of highfrequency components, we introduce a new loss function named weighted frequency domain loss(WFDL). WFDL provides a sharper reconstructed image, which contributes to improving the accuracy of anomaly detection. In this paper, we show our method’s superiority over the conventional Autoencoder methods by comparing it with AUROC on the MVTec AD dataset[1].",https://www.semanticscholar.org/paper/00ec1d0b26dd0221ee0c89a5bcb25e1855825ab3,"{'2c03df8b48bf3fa39054345bafabfeff15bfd11d', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '843a1f76a0c82dd0f883fb1bdafae6ad2c8feb5b', '67529adb196e5b5e003c07dc8e54a1b71247f6d5', '8381157eae4fbf8908d0312a9642f8e69e944449', '9acc51b06f54b07836fad4cc24633187dc21317f', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '86a5d0e86e7b340cfc8ce73c15137e3c5181a813', '8388f1be26329fa45e5807e968a641ce170ea078', '510a24375b5166842cae47f2e54052846704e8f4', '5435a9ab36a308cef10bc725104e8f778ed3a328', None, 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '5759a53418ae3fe74ce96c531617914e7656e45e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",16,set(),0,"['M. Nakanishi', 'Kazuki Sato', 'Hideo Terada']",M. Nakanishi,"M. Nakanishi, Kazuki Sato, Hideo Terada",0.0
8d153ec33fe81d74b24ad3bb3c6db918a3d193ed,Dual Attention-Based Industrial Surface Defect Detection with Consistency Loss,2022-07-01,"In industrial production, flaws and defects inevitably appear on surfaces, resulting in unqualified products. Therefore, surface defect detection plays a key role in ensuring industrial product quality and maintaining industrial production lines. However, surface defects on different products have different manifestations, so it is difficult to regard all defective products as being within one category that has common characteristics. Defective products are also often rare in industrial production, making it difficult to collect enough samples. Therefore, it is appropriate to view the surface defect detection problem as a semi-supervised anomaly detection problem. In this paper, we propose an anomaly detection method that is based on dual attention and consistency loss to accomplish the task of surface defect detection. At the reconstruction stage, we employed both channel attention and pixel attention so that the network could learn more robust normal image reconstruction, which could in turn help to separate images of defects from defect-free images. Moreover, we proposed a consistency loss function that could exploit the differences between the multiple modalities of the images to improve the performance of the anomaly detection. Our experimental results showed that the proposed method could achieve a superior performance compared to the existing anomaly detection-based methods using the Magnetic Tile and MVTec AD datasets.",https://www.semanticscholar.org/paper/8d153ec33fe81d74b24ad3bb3c6db918a3d193ed,"{'33667aea67898e114ca100ee3e2b2a613b8a943a', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '326060ad338da99d5225a9a1cb382ff37f060593', '2788a2461ed0067e2f7aaa63c449a24a237ec341', '81b500a21bb1923af2ead727d5d140a3613d5161', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '00ec1d0b26dd0221ee0c89a5bcb25e1855825ab3', 'b5943c566e67545dba80db54e1a28c28e3a44c1e', '04c141495ef378e568a6aedec3034a0ed554af8c', '793805a752cccf7fc38e50ba4a5c3081a4c12d2c', 'f681389d9f8090a8525f0078a53cc62f0a637d8b', 'f7ab68a4eae1a8d554d41e31f21493633c392593', '846e3fd32ddd0f8edb79d7a87a02cd513797790a', 'fb8e2adf906990107791b49489ede76ea33f21aa', '295aca7669f54cdc746c595088693bb102855b9f', 'aac4e10128a7234a9288b3a777f8487fef18394b', '5435a9ab36a308cef10bc725104e8f778ed3a328', '8086d054446bb816b11098b300b9c426a78e512f', 'e4f64fa70b05470f9d14674e15437e398f7a76e1', '8d7aa1e9c135c6998e9abe098c9478874a73f357', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'bc27cd49fbbead76a4a9d8d42c007d690986b6c6', 'b6fec9aa7fb4d4abdbf9504a582236c652404218', 'b92a3d2b02b0ea3682da9be57851b76c5f1b3719', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '0c760f678c99b4a7eacc4b0ef7a42d4e6c734983', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '8e8e9f63c82a4bf4d00657e58935e3a3dd7a641f', '41a22d944f7258439baf96da8315aa4d9ec5f676', '57fa261e2b0d961aa9408ee64fd5ccc6382c99b6', '6de9eb6cb68185dd311be3093375527e5b56330d', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '48f9a48aa5b1230b05a443d2d531e6441a541686', '5c47886056f97f505494abd24717f374d18ccaae', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '6b225e6ce776593b6f7d038f0806616ac6c9325b', '5f61089d3d548a515f01b473f0119137d1f340d4', None, 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '21c8d0baf01c6b2207e4748cac54321b8fc1f456', '41747cbdbed84762dfbfc305254c97021279dc6e', 'aa6f7ad0a06b52a8be89dbd8d056561418276ff2', '5b80ae6e02143f4acba412b788c07428bd84877c', 'dbb994b95dcdb8f180f8b7558e3b4cd254e66da5', '2aa05911320e4ead8c087a344a7594ca9f98a35c', '775247047d0b56950ba5ea77d4a29772eca95c1b', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b98fcbec3362797c16f32918164e9ed0959c5140', '1db6e3078597386ac4222ba6c3f4f61b61f53539', '4786f811fdf3d6d1dad3bbb78f6f04e3b00de508', '9fbef8f3f426662a33f8a21d8209b48f665505a7', 'c557a7079a885c1bbc0b21057a0e16f927179ac7', 'ebbc7e09095c13766058796d00552c3df00ed05f', 'f75e73d5c9075d63bec5fe210472ab905dcf732f', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '861abe60155aa137a31a0716fd29d796b7308af6', '598fe25743f9492c5c1ba30274ea446f65426d85', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",59,"{'775247047d0b56950ba5ea77d4a29772eca95c1b', '295aca7669f54cdc746c595088693bb102855b9f', '41747cbdbed84762dfbfc305254c97021279dc6e', '00ec1d0b26dd0221ee0c89a5bcb25e1855825ab3', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'e4f64fa70b05470f9d14674e15437e398f7a76e1', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c'}",8,"['Xuyang Li', 'Yu Zheng', 'Bei Chen', 'En-rang Zheng']",Xuyang Li,"Xuyang Li, Yu Zheng, Bei Chen, En-rang Zheng",13.559322033898304
e0cf13101ad1c8abe594a9341e040cb208b533ac,Ultrasound Image Quality Evaluation using a Structural Similarity Based Autoencoder,2021-11-01,"Ultrasound (US) imaging is a widely used clinical technique that requires extensive training to use correctly. Good quality US images are essential for effective interpretation of the results, however numerous sources of error can impair quality. Currently, image quality assessment is performed by an experienced sonographer through visual inspection, however this is usually unachievable by inexperienced users. An autoencoder (AE) is a machine learning technique that has been shown to be effective at anomaly detection and could be used for fast and effective image quality assessment. In this study, we explored the use of an AE to distinguish between good and poor-quality US images (caused by artifacts and noise) by using the reconstruction error to train and test a random forest classifier (RFC) for classification. Good and poor-quality ultrasound images were obtained from forty-nine healthy subjects and were used to train an AE using two different loss functions, with one based on the structural similarity index measure (SSIM) and the other on the mean squared error (MSE). The resulting reconstruction errors of each image were then used to classify the images into two groups based on quality by training and testing an RFC. Using the SSIM based AE, the classifier showed an average accuracy of 71%±4.0% when classifying images based on user errors and an accuracy of 91%±1.0% when sorting images based on noise. The respective accuracies obtained from the AE using the MSE function were 76%±2.0% and 83%±2.0%. The results of this study demonstrate that an AE has the potential to differentiate good quality US images from those with poor quality, which could be used to help less experienced researchers and clinicians obtain a more objective measure of image quality when using US.",https://www.semanticscholar.org/paper/e0cf13101ad1c8abe594a9341e040cb208b533ac,"{'c9a716791eabf3ccc58eb61845f1f22053348ec8', '0efc7dee2cbc4f6c82db9c93774cfb9a65decaa3', '2676540843915141bcbb046a3f89da954f43bc09', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '77a75206bb566fc2ab0f12729e459cb65784745a', '5b8371d5df62f1bd58dca956c7732bbb59520757', '7eaf80b949c97e6c438038d8ed5f37f9e8aa6bdb', '4248027da3c1d9285791cfe9eb168baf96b5a62c', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '711da936e556674660e5d44e02977d1e5636bf6a', '1d4816c612e38dac86f2149af667a5581686cdef', '2abde28f75a9135c8ed7c50ea16b7b9e49da0c09', 'b7c54e4aceb9a77b5b68105df75a49600d64930a', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '13eb5c34d9c4c2374b982897a3d762c7d58fa3aa', '0d49091e1676856162d9f7914c4dc472267c476d', '9f777a47d76ee5cecfb0a695bdacfaeb107bf542'}",17,set(),0,"['Karlo Nesovic', 'Ryan G. L. Koh', 'Azadeh Aghamohammadi Sereshki', 'Fatemeh Shomal Zadeh', 'M. Popovic', 'D. Kumbhare']",Karlo Nesovic,"Karlo Nesovic, Ryan G. L. Koh, Azadeh Aghamohammadi Sereshki, Fatemeh Shomal Zadeh, M. Popovic, D. Kumbhare",0.0
058a9794434289470683a4beb591d2e167b10078,A Semi-supervised Generalized VAE Framework for Abnormality Detection using One-Class Classification,2022-01-01,"Abnormality detection is a one-class classification (OCC) problem where the methods learn either a generative model of the inlier class (e.g., in the variants of kernel principal component analysis) or a decision boundary to encapsulate the inlier class (e.g., in the one-class variants of the support vector machine). Learning schemes for OCC typically train on data solely from the inlier class, but some recent OCC methods have proposed semi-supervised extensions that also leverage a small amount of training data from outlier classes. Other recent methods extend existing principles to employ deep neural network (DNN) models for learning (for the inlier class) either latent-space distributions or autoencoders, but not both. We propose a semi-supervised variational formulation, leveraging generalized-Gaussian (GG) models leading to data-adaptive, robust, and uncertainty-aware distribution modeling in both latent space and image space. We propose a reparameterization for sampling from the latent-space GG to enable backpropagation-based optimization. Results on many publicly available real-world image sets and a synthetic image set show the benefits of our method over existing methods.",https://www.semanticscholar.org/paper/058a9794434289470683a4beb591d2e167b10078,"{'9acae3f022da73b4868a56127bfa74d4c82d62c5', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '27222787908c3a1c6fb6c4b5cb5ef8b2542f1b3c', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'd100f625580dd6df123c69abff1d094e2d745613', '2ab5330706c6b12942a212b6d72ed1221b578729', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '7e99ce2002650b45d291df90c64ad586833a3c2a', '902293180a5a4f99bfad6f81c8115e917d0334e1', 'f076e4355c0facf111716dcab2837803367dd2d8', 'aa89dfd9d94f2da9234fd3e30ac026ef720c7009', '706bfdaffb2c66415ca9fe74edf574d2d0476f59', '1d4ec24a6da3be62dc5d7efbae2a101c63f187e8', '157ef382aa99fbbbb72960bf76b3728d0b59885b', '5c8fe9a0412a078e30eb7e5eeb0068655b673e86', 'ff8a3d41bf4a3a6415d77a84ba58cd9b0b2c4869', '1c46943103bd7b7a2c7be86859995a4144d1938b', '6af440915b8a0718c93be1cf61905e41e620484a', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, 'f4f8260995ad4b8b0478779c65778076c9a83076', 'e58ba87465e9073f57fbda54f23ef6e14fe2ad1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', 'f109a683e9a54d9a6bc24cac73ca0a8f7bc09082', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', 'ae3add995c52bc808b7d03768a44d0023b303243', '3f600e6c6cf93e78c9e6e690443d6d22c4bf18b9', '450e2decdba98cbaaa403d433df53be775389b9e', '6f11daad0a6a1e5540e47047928152d11d7f05a3', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",35,set(),0,"['Renuka Sharma', 'Satvik Mashkaria', 'Suyash P. Awate']",Renuka Sharma,"Renuka Sharma, Satvik Mashkaria, Suyash P. Awate",0.0
19862af96b6af51e879e6e3f1d3d421af5427005,Inpainting Transformer for Anomaly Detection,2021-04-28,,https://www.semanticscholar.org/paper/19862af96b6af51e879e6e3f1d3d421af5427005,"{'a39398f68ae7e042f2ef5009e31b4e6a20fd5736', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'a70bc416b1124525499b0ac3d5b009637dc6c187', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'eb73aa1b023be05b5ed5e88bbf92c9a787af3671', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'c6d2b2889fbacd3b00cd9e3eef35ae897f54620e', '07b056a23b225fa4fc54cda80a8e6c2c74760541', '3bc63a1a3c0a5bb66af7bb61c34e379658820f90', '1c4e9156ca07705531e45960b7a919dc473abb51', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '5c3a21ac6c275fc0795318d2c49fd845ca74d090', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '4ed4dc4df5dbde2677852c33080e3c893bf0a5ba', '5435a9ab36a308cef10bc725104e8f778ed3a328', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'f69f237073ef04043fdbd5bb6844b5b2da8e0930', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', '366244acdd930e488ae224ab6e2a92dc24aa7e06', '927881a5602f430ffd145d44b8c35cf7a07b464d', '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'e0c6abdbdecf04ffac65c440da77fb9d66bb474c', '1db9bd18681b96473f3c82b21edc9240b44dc329', '6af440915b8a0718c93be1cf61905e41e620484a', '7f5fc84819c0cf94b771fe15141f65b123f7b8ec', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', '91a73e9c6cbba422ee50e287f1bfa9ba30f6922b', None, 'cb3d43139c682518b1e05e64df6239b7c26527ff', '714d48570351de99eb755735b543c7b84bd9fb46', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '1dd3faf5488751c9de10977528ab96be24616138', '43df2947f2b4df35dda50b7182d2995bc64352b1', '9405cc0d6169988371b2755e573cc28650d14dfe', 'd21ebaab3f715dc7178966ff146711882e6a6fee', '24046c62be024695e9c73768ef6bcf870ca383c0', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', '76a9f336481b39515d6cea2920696f11fb686451', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539'}",51,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '24046c62be024695e9c73768ef6bcf870ca383c0', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'b1464ca857593c049873421db2f37bf2d0ff676d', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",6,"['J. Pirnay', 'K. Chai']",J. Pirnay,"J. Pirnay, K. Chai",11.764705882352942
363c81a08858df8dd7d1bde79c6e002e3b19f900,Attribute Restoration Framework for Anomaly Detection,2019-11-25,"With the recent advances in deep neural networks, anomaly detection in multimedia has received much attention in the computer vision community. While reconstruction-based methods have recently shown great promise for anomaly detection, the information equivalence among input and supervision for reconstruction tasks can not effectively force the network to learn semantic feature embeddings. We here propose to break this equivalence by erasing selected attributes from the original data and reformulate it as a restoration task, where the normal and the anomalous data are expected to be distinguishable based on restoration errors. Through forcing the network to restore the original image, the semantic feature embeddings related to the erased attributes are learned by the network. During testing phases, because anomalous data are restored with the attribute learned from the normal data, the restoration error is expected to be large. Extensive experiments have demonstrated that the proposed method significantly outperforms several state-of-the-arts on multiple benchmark datasets, especially on ImageNet, increasing the AUROC of the top-performing baseline by 10.1%. We also evaluate our method on a real-world anomaly detection dataset MVTec AD.",https://www.semanticscholar.org/paper/363c81a08858df8dd7d1bde79c6e002e3b19f900,"{'01625cba9f8a783994377d4f35aa765242faab4f', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'd100f625580dd6df123c69abff1d094e2d745613', '599fd051c9438011ec5b581983c89e8922b4a5e6', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '74ce29833fba25a02ba74c2d60b18acfeb5b4766', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '6139ed57b3fe91915991897723aed6a98cd32f82', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', 'e8b8a7778ace2a02f8db6fe321a54520c6b283ca', '5db790198b9acf4e5efe350acdd814238fcacaa7', '9acc51b06f54b07836fad4cc24633187dc21317f', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '59bb8d6c3eec8f925710db4d2488e2a23167d3e8', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '941b0be328d6eb370121828acff3acf300e0745a', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'ba10c37a6a24276f5e67a22a71d0d511c01cf5e1', '8acbe90d5b852dadea7810345451a99608ee54c7', '10a498003e9204f5fc1328e706510a37e514d8c7', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '5694e46284460a648fe29117cbc55f6c9be3fa3c', '580396c680951b7ff93defcac7cfe085dfe1814e', '41747cbdbed84762dfbfc305254c97021279dc6e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '6d3b00381c619912337c60897307322ba4edff3b', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '84af0bbe339c1adbc9d075dee99b9d4f86a186c5', '5b2193c44f2925807c5978a24da3381324969c40', 'cb2367f93e3bd7b228f271904bd61a5723094a96', '843959ffdccf31c6694d135fad07425924f785b1', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'fbc6562814e08e416e28a268ce7beeaa3d0708c8', 'f198043a866e9187925a8d8db9a55e3bfdd47f2c'}",46,{'41747cbdbed84762dfbfc305254c97021279dc6e'},1,"['Fei Ye', 'Chaoqin Huang', 'Jinkun Cao', 'Maosen Li', 'Ya Zhang', 'Cewu Lu']",Fei Ye,"Fei Ye, Chaoqin Huang, Jinkun Cao, Maosen Li, Ya Zhang, Cewu Lu",2.1739130434782608
f82fcd01440a6f3ffd39def804526ff3f8623206,Image Denoising for Efficient Anomaly Detection in Videos,2020-11-01,"Video anomaly detection is tasked with the identification of events that do not conform to expected events. Currently, most methods tackle this problem by mining common normal patterns from training data and minimizing the generative errors. In inference phase, a large generative error is assigned to an abnormal event and a small one is for a normal event. However, because these methods only focus on the error intensity but ignore the error pattern, partial abnormal events will own similar generative error intensities to the normal ones. Thus, we propose to tackle the anomaly detection within an efficient image denoising framework. In this framework, the generative errors are treated as a kind of artificial noise, which will be superimposed on the current frame. Then, the contaminated frame is fed into a denoising network, which is trained to output a frame close to the current frame. In the denoising network, the common patterns of training data and the error patterns of each training frame can be learned jointly. It will benefit anomaly detection by restraining the generative errors of normal frames. The results on several challenging benchmark datasets demonstrate the effectiveness of our proposed method.",https://www.semanticscholar.org/paper/f82fcd01440a6f3ffd39def804526ff3f8623206,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '898a12f14553bf5d5cb18458719b963c14bb81c8', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', '5c8a6874011640981e4103d120957802fa28f004', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'fef2f7ceae4c537c656122fee00fefb62f2679a6', '44f3ac3277c2eb6e5599739eb875888c46e21d4c', '992847be33f4bf7afbe66e198cb20a53e00dfa76', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'a03bda078490e8ee991a1f86b53f27df7cf93a14', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', '7ffdbc358b63378f07311e883dddacc9faeeaf4b', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'ee1d50a0c6448253eaf8d1f7f6b00d893419589d', '52bf7ad1ce8f301684edb1376e39680e45b16332', 'c17519cec26cef6ec3edf6b30c5168c7ebb87792', '417eba8614feacc77212bf46552a0af153a968b2', '17fa1c2a24ba8f731c8b21f1244463bc4b465681', 'ca9c83ce1f11653bc656236937a7b21767cb28ea', 'b20e564edbef25009fa1baa2c369437c89147e61', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '792250ae660b7c25f85eeea7dcae623e4301d97c', '00d4410a4bb83b8d739e30be463939358c89f7de', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '3dab77815d36acfda913e48738ce1f63dde4b336', '44d2abe2175df8153f465f6c39b68b76a0d40ab9', '527cc8cd2af06a9ac2e5cded806bab5c3faad9cf', '29d1b9a6e6ff0a4216d10dd31376467d55e788a3', 'f1eb925b9a33e7ed70f8b713198d02e3372e83d7', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '731a2844c5af6b072d3b404ecabbb488cdad9d46', '025299a6b4e9dc907f53e042358a5fbe201ee44e', 'db20d81d40243d66ff90f11b5c6f058d43d3701f', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'ae37774ff871575b7799411bf87f42eb52634390', '84f7f9e121c1285e15cefbfc44bcb3322f73b6aa', 'c84462f6cea04ee6301e306e2a2b2a70aeaa7dd3', 'e5366a704ffa3b41aacd385f3c087ec3fd566934', 'f36f8d32252679f4221c3d2afc2407a9f56b29a7', '598fe25743f9492c5c1ba30274ea446f65426d85'}",46,set(),0,"['Zhiwen Fang', 'Zhou Yue', 'Weiyuan Liu', 'Feng Yang']",Zhiwen Fang,"Zhiwen Fang, Zhou Yue, Weiyuan Liu, Feng Yang",0.0
2f67d6ce99602549cb8736f56857488c6e4ea4d5,Transformer-Based Anomaly Segmentation,2020-05-05,"The recent improvement in anomaly detection methods has prompted research into anomaly segmentation i.e. finding the pixels of the image that contain anomalies. In this paper, we investigate novel methods for unleashing the full power of pretrained features for anomaly segmentation. We first present a simple baseline that uses a pyramid of deep convolutional features and show that it significantly improves over the state-of-the-art methods, which are much more complex. One issue with the baseline approach is that it is unable to use the global context of the image effectively. We show that global attention-based methods are better able to utilize the global context. Specifically, we present an approach based on a multi-scale transformer architecture and show that it further improves performance. By analysing the attention maps, we find that they often detect anomalous image regions in a zero-shot fashion, providing some insight into the result. A qualitative evaluation of our method shows significant gains.",https://www.semanticscholar.org/paper/2f67d6ce99602549cb8736f56857488c6e4ea4d5,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2cbb8de53759e75411bc528518947a3094fbce3a', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'aef2050fe0fa48136cff50ec38bb5af2c6992bce', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '6b85b63579a916f705a8e10a49bd8d849d91b1fc', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '04513c7c0b3a63fde81a996dae064a28d453c17a', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', '1f528877c4d8d5df3b3abbfa64379677d451956b', '6af440915b8a0718c93be1cf61905e41e620484a', '90902e16f4e8ff5e3c4bf0f971380af5753aacdd', 'bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '41747cbdbed84762dfbfc305254c97021279dc6e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'a8f3dc53e321fbb2565f5925def4365b9f68d1af', '4d39ee7cca8fedf792570724255a4357aa41dbf8', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'e99603b5b524485bcf1afb2f01acadc34dfb033c', '0495d9df8eb84dcdab4e5536179823cd26279949'}",28,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '1f528877c4d8d5df3b3abbfa64379677d451956b'}",2,"['Niv Cohen', 'Yedid Hoshen']",Niv Cohen,"Niv Cohen, Yedid Hoshen",7.142857142857143
32aab0c5468d9692877c53efc5612957e48205b2,Data refinement for fully unsupervised visual inspection using pre-trained networks,2022-02-25,"Anomaly detection has recently seen great progress in the field of visual inspection. More specifically, the use of classical outlier detection techniques on features extracted by deep pre-trained neural networks have been shown to deliver remarkable performances on the MVTec Anomaly Detection (MVTec AD) dataset. However, like most other anomaly detection strategies, these pre-trained methods assume all training data to be normal. As a consequence, they cannot be considered as fully unsupervised. There exists to our knowledge no work studying these pre-trained methods under fully unsupervised setting. In this work, we first assess the robustness of these pre-trained methods to fully unsupervised context, using polluted training sets (i.e. containing defective samples), and show that these methods are more robust to pollution compared to methods such as CutPaste. We then propose SROC, a Simple Refinement strategy for One Class classification. SROC enables to remove most of the polluted images from the training set, and to recover some of the lost AUC. We further show that our simple heuristic competes with, and even outperforms much more complex strategies from the existing literature.",https://www.semanticscholar.org/paper/32aab0c5468d9692877c53efc5612957e48205b2,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '2cbb8de53759e75411bc528518947a3094fbce3a', '732c21998e251d64cd58b6a86886ee5907efeaa5', '4748d22348e72e6e06c2476486afddbc76e5eca7', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '19862af96b6af51e879e6e3f1d3d421af5427005', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', 'b40890f3d917379ac4bd2e0933a134d45b4dc251', 'f533e50758dfdfe18d52d9cc2287cf9b8d98f233', '00a1077d298f2917d764eb729ab1bc86af3bd241', '0407b605b8f55db72e2545586bfe8e946b691b70', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '502169d1ba1c25abd99c7f5f454474cfaa420a8b', '9d713f1f79554a28b9788c0299cb07d34d782022', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', 'd82800c79dd335297336fe10b1a60d47706e4296', '64529523bb7af0cf258e6f5b0c5f0b3013ecdc6f', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '1d2105616d122389efbd1b0ac7c04c0c2f8ac996', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'cb3d43139c682518b1e05e64df6239b7c26527ff', '41747cbdbed84762dfbfc305254c97021279dc6e', 'd52ff4da17d41ea239de10dd2a68ae18f6a85d28', 'a7c828184693a453a6c2867dee233ed054b2012e', '85a6c053f27fc60d1b92a2f96848c383210ff9f5', '2e8d62277e40d465343e8dfb32ecc246f320540e', '206c2e79b5f1b4541b85f47517666961ed49500e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '72564a69bf339ff1d16a639c86a764db2321caab', '25761fd27d2ffad21329e85987dffa57a13de39f', 'a7d75aa3a0a9faa310fb524c350fba2093b0ec97', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",51,"{'931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '19862af96b6af51e879e6e3f1d3d421af5427005', 'f533e50758dfdfe18d52d9cc2287cf9b8d98f233', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0eb80e81580568ce9d70ad1c2495aef188a9587f', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'd52ff4da17d41ea239de10dd2a68ae18f6a85d28', '41747cbdbed84762dfbfc305254c97021279dc6e', '206c2e79b5f1b4541b85f47517666961ed49500e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'a7d75aa3a0a9faa310fb524c350fba2093b0ec97', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",21,"['Antoine Cordier', 'Benjamin Missaoui', 'Pierre Gutierrez']",Antoine Cordier,"Antoine Cordier, Benjamin Missaoui, Pierre Gutierrez",41.1764705882353
840530ea3d2008d301b49c9d25dbcc76f91b4ab6,HaloAE: An HaloNet based Local Transformer Auto-Encoder for Anomaly Detection and Localization,2022-08-06,". Unsupervised anomaly detection and localization is a crucial task as it is impossible to collect and label all possible anomalies. Many studies have emphasized the importance of integrating local and global information to achieve accurate segmentation of anomalies. To this end, there has been a growing interest in Transformer, which allows modeling long-range content interactions. However, global interactions through self attention are generally too expensive for most image scales. In this study, we introduce HaloAE, the first auto-encoder based on a local 2D version of Transformer with HaloNet. With HaloAE, we have created a hybrid model that combines convolution and local 2D block-wise self-attention layers and jointly performs anomaly detection and segmentation through a single model. We achieved competitive results on the MVTec dataset, suggesting that vision models incorporating Transformer could benefit from a local computation of the self-attention operation, and pave the way for other applications 4 .",https://www.semanticscholar.org/paper/840530ea3d2008d301b49c9d25dbcc76f91b4ab6,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '0eff37167876356da2163b2e396df2719adf7de9', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'f98788f32b0d33d200c9bc7d900d0ef39519c927', 'db787640c9b42416ff8d7015546e667e58267177', '2affb92fa5ec0ecb4b4a22864ed126f30a55ac8d', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '5db790198b9acf4e5efe350acdd814238fcacaa7', '19862af96b6af51e879e6e3f1d3d421af5427005', 'c8b25fab5608c3e033d34b4483ec47e68ba109b7', '3a906b77fa218adc171fecb28bb81c24c14dcc7b', '62ab13e536778b6b264af436af79584fdcf0d0a6', '5132500b23d2da47129b3f4f68dd30947a29e502', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '5435a9ab36a308cef10bc725104e8f778ed3a328', '04513c7c0b3a63fde81a996dae064a28d453c17a', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'b1464ca857593c049873421db2f37bf2d0ff676d', '575e4b980654773c40101659fe8d63ba325a2431', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', 'd6dccb5d71fbb6f5765f89633ba3a8e6809a720d', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '91e8117e7ebc966bc76de2cb52ec717d2acdb1a4', '1db9bd18681b96473f3c82b21edc9240b44dc329', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', '45f490710b4dd6697dba4c9b385a49554501711a', 'bc022dbb37b1bbf3905a7404d19c03ccbf6b81a8', None, '58a1a06d505526b08163ca36c3a130c043fee54c', '5366919840236059252c7f8f510dfb36df9e3206', 'f8d9c72770401c27f986da8cb7b10f61f60a7891', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '962dc29fdc3fbdc5930a10aba114050b82fe5a3e', '0ae67202f0584afccefa770865d14a46655d2975', '8a916608e81eea5d7494e577c8563cae44a1b8c6', '6869ab1f42e30b415829de9928f7e4a606113601', 'dbcf2a89553ecb52cbb3e489d313e764a5926bc4', '39ca8f8ff28cc640e3b41a6bd7814ab85c586504', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'ad7ddcc14984caae308c397f1a589aae75d4ab71', '598fe25743f9492c5c1ba30274ea446f65426d85', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",57,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '9277dc70c74bcadf80dab11c28ead83fd085deec', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '2e8d62277e40d465343e8dfb32ecc246f320540e', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'f8d9c72770401c27f986da8cb7b10f61f60a7891', 'b1464ca857593c049873421db2f37bf2d0ff676d', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '19862af96b6af51e879e6e3f1d3d421af5427005', '41747cbdbed84762dfbfc305254c97021279dc6e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '4dd78b8d466b4cfe55a1bbdc694291197ce62541'}",15,"['E. Mathian', 'H. Liu', 'L. Fernandez-Cuesta', 'D. Samaras', 'M. Foll', 'L. Chen']",E. Mathian,"E. Mathian, H. Liu, L. Fernandez-Cuesta, D. Samaras, M. Foll, L. Chen",26.31578947368421
0795b7462b6d186d4ccd63d185a25f54d56aaf5f,Explicit Boundary Guided Semi-Push-Pull Contrastive Learning for Better Anomaly Detection,2022-07-04,"Most of anomaly detection algorithms are mainly focused on modeling the distribution of normal samples and treating anomalies as outliers. However, the discriminative performance of the model may be insufficient due to the lack of knowledge about anomalies. Thus, anomalies should be exploited as possible. However, utilizing a few known anomalies during training may cause another issue that model may be biased by those known anomalies and fail to generalize to unseen anomalies. In this paper, we aim to exploit a few existing anomalies with a carefully designed explicit boundary guided semi-push-pull learning strategy, which can enhance discriminability while mitigating bias problem caused by insufficient known anomalies. Our model is based on two core designs: First, finding one explicit separating boundary as the guidance for further contrastive learning. Specifically, we employ normalizing flow to learn normal feature distribution, then find an explicit separating boundary close to the distribution edge. The obtained explicit and compact separating boundary only relies on the normal feature distribution, thus the bias problem caused by a few known anomalies can be mitigated. Second, learning more discriminative features under the guidance of the explicit separating boundary. A boundary guided semi-push-pull loss is developed to only pull the normal features together while pushing the abnormal features apart from the separating boundary beyond a certain margin region. In this way, our model can form a more explicit and discriminative decision boundary to achieve better results for known and also unseen anomalies, while also maintaining high training efficiency. Furthermore, to make the feature learning more efficient, we propose RandAugmented CutPaste which can simulate anomalies by creating local irregularities in normal samples to mitigate the insufficient of anomaly samples. Extensive experiments on the widely-used MVTecAD benchmark show that the proposed method achieves new state-of-the-art results, with the performance of 98.8% image-level AUROC and 99.4% pixel-level AUROC.",https://www.semanticscholar.org/paper/0795b7462b6d186d4ccd63d185a25f54d56aaf5f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '6a4f7514cf25a36b746b09eab4a2576a12961cb0', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', '3c3698ce314a77271b566713edb2911f921299e3', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'c48def9076e58095c4aea49a8daa931af1990701', '70f9968a356d840040a1c9207906f60376dc6bd4', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '5f61089d3d548a515f01b473f0119137d1f340d4', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '10ae15147d0bc0d6d06ceaae28165bf8646ae478', '6bbd51697c25493ea15f4cac830e28eeac143898', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '72564a69bf339ff1d16a639c86a764db2321caab', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '8381157eae4fbf8908d0312a9642f8e69e944449', '11e7c4182a7813d5acf1be198c8c96d164fb95a2', '180300ff8282220c76c7c41ded4d9d8c1be4d3fc', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'dc8301b67f98accbb331190dd7bd987952a692af', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '491b149544eff61778c216a4eb869ec0b008f346', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",47,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '6a4f7514cf25a36b746b09eab4a2576a12961cb0', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '180300ff8282220c76c7c41ded4d9d8c1be4d3fc', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",16,"['Xincheng Yao', 'Chongyang Zhang', 'Ruoqing Li']",Xincheng Yao,"Xincheng Yao, Chongyang Zhang, Ruoqing Li",34.04255319148936
d78f2e0d5e3040ad62d5bcd0abca8a8507bff209,Transfer Learning Gaussian Anomaly Detection by Fine-Tuning Representations,2021-08-09,": Current state-of-the-art anomaly detection (AD) methods exploit the powerful representations yielded by large-scale ImageNet training. However, catastrophic forgetting prevents the successful ﬁne-tuning of pretrained representations on new datasets in the semi-supervised setting, and representations are therefore commonly ﬁxed. In our work, we propose a new method to overcome catastrophic forgetting and thus successfully ﬁne-tune pre-trained representations for AD in the transfer learning setting. Speciﬁcally, we induce a multivariate Gaussian distribution for the normal class based on the linkage between generative and discriminative modeling, and use the Mahalanobis distance of normal images to the estimated distribution as training objective. We additionally propose to use augmentations commonly employed for vicinal risk minimization in a validation scheme to detect onset of catastrophic forgetting. Extensive evaluations on the public MVTec dataset reveal that a new state of the art is achieved by our method in the AD task while simultaneously achieving anomaly segmentation performance comparable to prior state of the art. Further, ablation studies demonstrate the importance of the induced Gaussian distribution as well as the robustness of the proposed ﬁne-tuning scheme with respect to the choice of augmentations.",https://www.semanticscholar.org/paper/d78f2e0d5e3040ad62d5bcd0abca8a8507bff209,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '02470bed70e38f6a3e69031784e802007a3a1cd3', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '34adc3101810bc4d5ef84b4136455a89b9c86c27', '5151d6cb3a4eaec14a56944d58338251fca344ab', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '732c21998e251d64cd58b6a86886ee5907efeaa5', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '4d376d6978dad0374edfa6709c9556b42d3594d3', '9acc51b06f54b07836fad4cc24633187dc21317f', 'b40890f3d917379ac4bd2e0933a134d45b4dc251', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '2ed2415c39d4023f9af410947b96970803d9f192', 'c17e0119e909e7fb6ce737a2b6496c7133633551', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'c53352a4239568cc915ad968aff51c49924a3072', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0f366de3ea595932dad06389f6e61fe0dd8cbe74', '35d894043b67cd11285dcf08fa28affaa1d50746', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '8a8cfa45b4c0d071fbffa091c02670b19c94b693', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'ae4a73e4fd69b284739fde6eef2608d271fcb51f', 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', '5647fab83543536ea8424317630e6056dc94076d', '48f9a48aa5b1230b05a443d2d531e6441a541686', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', None, '9af970dd5c03f112260254da1f9a1130e24bc1bf', 'db8c381cbaf80c4323959eccee07c85a76b54839', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', '01a4f33da8ad94ced3cf58548b28dbbb44148571', 'eb35fdc11a325f21a8ce0ca65058f7480a2fc91f', '2004b9864fcc04ce5919afa7d1ebfe894b36c0e0', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '153a99ad39e85eb09f6ae56b1eb72795265cb8a0', '39664b871e5b90aa0f82d89469a230d9ecd02498', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",59,"{'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '48f9a48aa5b1230b05a443d2d531e6441a541686', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'db8c381cbaf80c4323959eccee07c85a76b54839', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",16,"['Oliver Rippel', 'Arnav Chavan', 'Chucai Lei', 'D. Merhof']",Oliver Rippel,"Oliver Rippel, Arnav Chavan, Chucai Lei, D. Merhof",27.11864406779661
1ed9eaf526786704d81462c7f9960d9d3ef0cb84,Semi-orthogonal Embedding for Efficient Unsupervised Anomaly Segmentation,2021-05-31,"We present the efficiency of semi-orthogonal embedding for unsupervised anomaly segmentation. The multi-scale features from pre-trained CNNs are recently used for the localized Mahalanobis distances with significant performance. However, the increased feature size is problematic to scale up to the bigger CNNs, since it requires the batch-inverse of multi-dimensional covariance tensor. Here, we generalize an ad-hoc method, random feature selection, into semi-orthogonal embedding for robust approximation, cubically reducing the computational cost for the inverse of multi-dimensional covariance tensor. With the scrutiny of ablation studies, the proposed method achieves a new state-of-the-art with significant margins for the MVTec AD, KolektorSDD, KolektorSDD2, and mSTC datasets. The theoretical and empirical analyses offer insights and verification of our straightforward yet cost-effective approach.",https://www.semanticscholar.org/paper/1ed9eaf526786704d81462c7f9960d9d3ef0cb84,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '8388f1be26329fa45e5807e968a641ce170ea078', '5394da74498e00597295d18cd0557bd47e3fc341', '4d376d6978dad0374edfa6709c9556b42d3594d3', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '0c908739fbff75f03469d13d4a1a07de3414ee19', '9acc51b06f54b07836fad4cc24633187dc21317f', 'bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6', '1d0635cda34b8af995313848a0c42bac6efe79ec', 'd66d93fafe61e878b8da5a8d0ecee442d44b5be0', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', '8112c4305b88d85199267e9e03d3a0aca4432059', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '4c9e2d100dd2104a916bdd979cb42527320d09e8', 'ae227bac49a5615fba2d0116578715418a831aa7', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a0e8f4348968195c80494b7a4245edb91a252c93', '7eb24c2109f75c614cc7aa4c1cac8b643c05e70c', 'f3ec7e149b9832365f369d7191642bcb9373df2c', None, 'ae4ed4e5e6a6fb3bd544ef95b69e1bc244045a0f', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",31,"{'6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '62b77e5cb85fc61b84edd532f6d65714be152596', '7eb24c2109f75c614cc7aa4c1cac8b643c05e70c', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', 'bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",10,"['Jin-Hwa Kim', 'Do-Hyeong Kim', 'Saehoon Yi', 'Taehoon Lee']",Jin-Hwa Kim,"Jin-Hwa Kim, Do-Hyeong Kim, Saehoon Yi, Taehoon Lee",32.25806451612903
4758baad6b22c61682e7f7182bb93723046f36f5,Glancing at the Patch: Anomaly Localization with Global and Local Feature Comparison,2021-06-01,"Anomaly localization, with the purpose to segment the anomalous regions within images, is challenging due to the large variety of anomaly types. Existing methods typically train deep models by treating the entire image as a whole yet put little effort into learning the local distribution, which is vital for this pixel-precise task. In this work, we propose an unsupervised patch-based approach that gives due consideration to both the global and local information. More concretely, we employ a Local-Net and Global-Net to extract features from any individual patch and its surrounding respectively. Global-Net is trained with the purpose to mimic the local feature such that we can easily detect an abnormal patch when its feature mismatches that from the context. We further introduce an Inconsistency Anomaly Detection (IAD) head and a Distortion Anomaly Detection (DAD) head to sufficiently spot the discrepancy between global and local features. A scoring function derived from the multi-head design facilitates high-precision anomaly localization. Extensive experiments on a couple of real-world datasets suggest that our approach outperforms state-of-the-art competitors by a sufficiently large margin.",https://www.semanticscholar.org/paper/4758baad6b22c61682e7f7182bb93723046f36f5,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '790eceaa2cb59fef2634dad40f628346eb07cd3d', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'b5e6726faf0bcb623e776df2e32f4b13356609eb', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'c613d44a4e21ec7c1c23bce6d78a512ba35394d5', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9a6ee80121518fadeb21227f9bd9a0f31dfe49b0', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '3bb5a439a0d610a7eac68f73068cdd278b8c9775', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', '1c46943103bd7b7a2c7be86859995a4144d1938b', '7dcd4ac966093dc332e29811020b6a6cc3a53d75', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '38f93092ece8eee9771e61c1edaf11b1293cae1b', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'd3b614f11969127a08447c41257b3a7b58766d18', None, '9241ea3d8cb85633d314ecb74b31567b8e73f6af', 'c707517507873bc2cdc489b6fd9af74770468c48', '41747cbdbed84762dfbfc305254c97021279dc6e', '3b7c49dae915988b3cd8f8d10febf36b0518f988', '206c2e79b5f1b4541b85f47517666961ed49500e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', '6f0b0e3c88d062d6c6d1c1d6ec9f5ec4fe4ffdc4', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '2a417a16473e2bcb1c98cd7814bc106760925e60', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'add2f205338d70e10ce5e686df4a690e2851bdfc', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '0936352b78a52bc5d2b5e3f04233efc56664af51', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",55,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'd3b614f11969127a08447c41257b3a7b58766d18', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '3b7c49dae915988b3cd8f8d10febf36b0518f988', '206c2e79b5f1b4541b85f47517666961ed49500e'}",10,"['S. Wang', 'Liwei Wu', 'Lei Cui', 'Yujun Shen']",S. Wang,"S. Wang, Liwei Wu, Lei Cui, Yujun Shen",18.181818181818183
716cad55b33e2cd28129c8a13af45daa46095853,Towards Visually Plausible Explanations,,Introduction 2 The goal of this assignment is to firstly reimplement the work from the paper Liu et al. (2020) and secondly extend 3 their work. Liu et al. develops a new technique which visually explains VAE by generating attention maps from the 4 learned latent space. Then the paper applies the VAE into two applications: anomaly localisation and latent space 5 disentanglement. This paper reimplements Liu’s experiments and compares our results with the results from the paper 6 under restricted computational resources. The acquired results will be analyzed and compared to the original paper. 7,https://www.semanticscholar.org/paper/716cad55b33e2cd28129c8a13af45daa46095853,"{'515a21e90117941150923e559729c59f5fdade1c', '162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'bfa05c294f24f889de622a3fa6377b7aac7049fb', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'aae932cf9c2434f52b03991fcab050a61a960d48', None, '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'b7b37f61acedbae95b5476b8e9f3992085e864a3', 'f16b23e8e0788e3298e533e71bafef7135300a5e', '2ec3d4da1e035f95488f3587ec5c9ec7354711ab', 'a90226c41b79f8b06007609f39f82757073641e2', '04541599accc47d8174f63345ce9c987ef21685b'}",14,{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b'},1,[],NOT FOUND,,7.142857142857143
1ff64cee66e66cf9c402ad754a63175e8e578c7a,Consistency Ensured Bi-directional GAN for Anomaly Detection,2020-02-20,,https://www.semanticscholar.org/paper/1ff64cee66e66cf9c402ad754a63175e8e578c7a,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '571b0750085ae3d939525e62af510ee2cee9d5ea', '05355e895988589f19d67ed5de7c727a7de706c7', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '84de7d27e2f6160f634a483e8548c499a2cda7fa', '8388f1be26329fa45e5807e968a641ce170ea078', '4d376d6978dad0374edfa6709c9556b42d3594d3', 'b86ce2873e22d6f8fa6f68ff5f050cf36fa9306d', '0bdd74925d662a78efdf130d953dff97a131d12a', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '61d3dccb4eca3acf43a46d5c294061ea8069e1e4', 'c43d954cf8133e6254499f3d68e45218067e4941', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', 'ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'ab559473a01836e72b9fb9393d6e07c5745528f3', '353ecf7b66b3e9ff5e9f41145a147e899a2eea5c', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '1db6e3078597386ac4222ba6c3f4f61b61f53539', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",22,{'e021d59638966a6fbb36854cc2cf1045de7a62d2'},1,"['Kyosuke Komoto', 'Hiroaki Aizawa', 'Kunihito Kato']",Kyosuke Komoto,"Kyosuke Komoto, Hiroaki Aizawa, Kunihito Kato",4.545454545454546
81d863860eb73eaa5b858e65d3a95f39015a49fd,AutoOD: Automated Outlier Detection via Curiosity-guided Search and Self-imitation Learning,2020-06-19,"Outlier detection is an important data mining task with numerous practical applications such as intrusion detection, credit card fraud detection, and video surveillance. However, given a specific complicated task with big data, the process of building a powerful deep learning based system for outlier detection still highly relies on human expertise and laboring trials. Although Neural Architecture Search (NAS) has shown its promise in discovering effective deep architectures in various domains, such as image classification, object detection, and semantic segmentation, contemporary NAS methods are not suitable for outlier detection due to the lack of intrinsic search space, unstable search process, and low sample efficiency. To bridge the gap, in this paper, we propose AutoOD, an automated outlier detection framework, which aims to search for an optimal neural network model within a predefined search space. Specifically, we firstly design a curiosity-guided search strategy to overcome the curse of local optimality. A controller, which acts as a search agent, is encouraged to take actions to maximize the information gain about the controller's internal belief. We further introduce an experience replay mechanism based on self-imitation learning to improve the sample efficiency. Experimental results on various real-world benchmark datasets demonstrate that the deep model identified by AutoOD achieves the best performance, comparing with existing handcrafted models and traditional search methods.",https://www.semanticscholar.org/paper/81d863860eb73eaa5b858e65d3a95f39015a49fd,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0858fb6efb0e7ef549db94813b9d6f896073d60a', '317d21ce93fb36b97df84055eee260733b6c1b83', 'ee4a012a4b12d11d7ab8c0e79c61e807927a163c', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '4eb1f213f5e55946503d88d1f79861907a36a531', '084c55d6432265785e3ff86a2e900a49d501c00a', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '497e1979d8587fa28c7dd349568f2703030cd000', 'a7ce95c6f674b7b5b19a532491d160d142f8b2d6', '863efef58318bdc21986470200f6d4f2d206e039', '431ba9fae8fccad1665979d455c6307786e47318', '904627c2d5a91ab8cb1b682e42f06f1ca192aea6', '27dd9201022d8a60ff18206fe524cc6611a06f2a', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'd40ee5dd758c525dfb9932d726bb4e844b7b8478', 'c3b8353964ca585af16b62493cd978521640ed25', '41285e207f2bfb861d3aee7c1557a9b8525745af', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'ca57e4709625211b6e436dddf34435d9487b1fbc', '5f79398057bf0bbda9ff50067bc1f2950c2a2266', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '6ad11e44d7b85b1a01efe28319b4cc9de1154c88', 'f4838839719cf96951ade45a221700341f57c4d7', '1003462fd2d360542ea712430b13cf0c43fc7f9d', '21de3a36cb51adc205fad8a1d3d69118891dc3dd', '5005998975f91eabd5cfefefe02eb58a71147599', '6a2ed19ac684022aa3186887cd4893484ab8f80c', '6af440915b8a0718c93be1cf61905e41e620484a', '0ee649ccde98988ad05ef88266e432c07afe9d5a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'fe9b8aac9fa3bfd9724db5a881a578e471e612d7', '188e247506ad992b8bc62d6c74789e89891a984f', '73f76a40ed20aa3c6a8e27e4db4a8c102e7b4c6d', '114a32bc872f160b58f503aca13f887556b5006e', '6ff2a434578ff2746b9283e45abf296887f48a2d', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'd3810f2c401874651afce74fb0a54b309491cc29', 'd397f4cf400f6ffcb1b8e3db27bb75966a0513cf', None, 'a7c828184693a453a6c2867dee233ed054b2012e', '49d6382f6695d3285a01d4b4aca695adc6217088', '5df39cc393907ea78fddf461b494b4c5b1b5a2e4', 'e56b10f7cd4bf037beac84da5925dc4544fab974', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'eb42cf88027de515750f230b23b1a057dc782108', 'f3d7555e37d8616123f6986a18837ae69391c532', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '4c915c1eecb217c123a36dc6d3ce52d12c742614', '62adfea3cc1cd9eb6b53e0e8a40be5dfda2adf8d', '5d87d55f8bf58f574324f42f4a3a8826f59383e8', '67d968c7450878190e45ac7886746de867bf673d', 'dc8b789446416383bfafe9b1c504c4a2b17e68d1', 'da6057368920585bcf2443295b98418840f1fc80', '61a697e0ca3a000b0067ccc2b4b400c3cf2575a6', 'be11958c7d62c80d0505d249b0b8fdc1536b9b77', 'c1f457e31b611da727f9aef76c283a18157dfa83', '746cf281d8198310b1242048bf4fd90e0486f1a9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '5b7e86f59bc6e355b25046a4352051d73fad4d46', '35a59bd09974c7fc78cf681f77f7301e180fd23c', '516a3b2554894e527b9f0bcecfbeae172635bab6'}",66,set(),0,"['Yuening Li', 'Zhengzhang Chen', 'D. Zha', 'Kaixiong Zhou', 'Haifeng Jin', 'Haifeng Chen', 'Xia Hu']",Yuening Li,"Yuening Li, Zhengzhang Chen, D. Zha, Kaixiong Zhou, Haifeng Jin, Haifeng Chen, Xia Hu",0.0
d49e07bfaf60423e8d0731fb16e5dbd13504f62e,ECOLE POLYTECHNIQUE FEDERAL DE LAUSSANE SCHOOL OF LIFE SCIENCES Master project in Life Sciences Engineering Label-Efficient Volumetric Deep Semantic Segmentation of Intracranial Hemorrhages,,,https://www.semanticscholar.org/paper/d49e07bfaf60423e8d0731fb16e5dbd13504f62e,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '84de7d27e2f6160f634a483e8548c499a2cda7fa', 'f6d98770c7f9132d3b16c96e6b4f309eabb4f7d2', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', 'fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec', '03254edc77c0459ad9fd9ea458c3ae171c0a4247', '197be27fa6affc400c987c39589692ba5c38cee6', '50004c086ffd6a201a4b782281aaa930fbfe6ecf', '5631085e9f42814f887d18acd2e40948763bd127', 'f0e54c9a679cf40b79da747519f2da710ec4daed', '0ae980a489da2f310ee9ebb66fd6cfa4eff1d01c', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539', 'c0d7decaccfa8ba2599c944ef83caf4ae8b80db8', '39705e4a749981d0f88dc830cb2f23034af63d65', '504766c557004da5778dcfce26ddfe77acced470', 'd6e78069dbbb35592f013187ef3432286def8f18', 'b94a3bfe8ca48855e4b4c6bcab5b051197052d9e', '456f3918f9e1e1745a157058e9aa7e876ed441a9', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', '4b60c51e0d035accad72193b8e1b29540218a2b2', '0ea7c9f03edb596a5ab32cf3c0d4c7567da9c8b0', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', 'a997f1ecd85e1467d11252741d188fac8db22722', 'fe8cbe79ac0b68868b0d6eafc11fa91f7fa75acc', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'b3852f0113fcf8a3913c55ae92393ae6ccde347e', '1c46943103bd7b7a2c7be86859995a4144d1938b', 'a1e37e17015efc88bf72e7e858523b9dd65ed35c', '355d44f53428b1ac4fb2ab468d593c720640e5bd', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '8113d91be7cb771278f57fb121b4aa5b29e7c629', '94bee9b16c75753cfd3bae224c33fe1b219643ee', 'c10cc993f54cd0e77adaf051725cd111f31cc944', '4a5315532e4df6128cb4ab4a86bbfd757511c6f7', None, '12471dd4b3642c3f895859c8c7f0009575556ff8', '96a042468a1b445c6f8ebc48b3d7c99305fa84cf', 'a1b8a8df281bbaec148a897927a49ea47ea31515', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'a6dab7277fe9d7c062ca2ea8558e303fb1c3a59a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'a8f3dc53e321fbb2565f5925def4365b9f68d1af', '6541eba27e35e43c009cf775df96b679eaf49692', 'a102c28829b79cc25476fa435735e8849116b88a', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '441ff323c92331e655ce9ff896773fc00b55089a', 'ea2f0c49c9e725ad76ea28c66778e21c1bde5d82', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '038b582cccb00c54589c5563d9a00ee28dad83b0', '4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c'}",54,"{'16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7'}",2,"['Chunliang Wang', 'A. Spahr']",Chunliang Wang,"Chunliang Wang, A. Spahr",3.7037037037037037
2fe348f8be60fd9bb6e4c8cf9945b8ebc159f8fb,Automatic Unsupervised Fabric Defect Detection Based on Self-Feature Comparison,2021-10-29,"Due to the huge demand for textile production in China, fabric defect detection is particularly attractive. At present, an increasing number of supervised deep-learning methods are being applied in surface defect detection. However, the annotation of datasets in industrial settings often depends on professional inspectors. Moreover, the methods based on supervised learning require a lot of annotation, which consumes a great deal of time and costs. In this paper, an approach based on self-feature comparison (SFC) was employed that accurately located and segmented fabric texture images to find anomalies with unsupervised learning. The SFC architecture contained the self-feature reconstruction module and the self-feature distillation. Accurate fiber anomaly location and segmentation were generated based on these two modules. Compared with the traditional methods that operate in image space, the comparison of feature space can better locate the anomalies of fiber texture surfaces. Evaluations were performed on the three publicly available databases. The results indicated that our method performed well compared with other methods, and had excellent defect detection ability in the collected textile images. In addition, the visual results showed that our results can be used as a pixel-level candidate label.",https://www.semanticscholar.org/paper/2fe348f8be60fd9bb6e4c8cf9945b8ebc159f8fb,"{'f2d62b1921b63e4e77e2ad137abf0d9281941662', '4661ba3bdfe7901eb0aa5c012866c94117277a64', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '91068209eb1b1763babb9a7dbeed8c425cd32bae', '2af5133ad5075551090c2749b025e857347eb8eb', '2c69e6498e2a708774b25c64d07389e9074f0db6', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'e257f53541794182dfb73ad98d0074b974643a6f', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '9775d372bfaf889a395dc714e283b6a179e62537', 'c09a4d90754628015c311e9c51f4b3ab888c796e', 'cb6c24b034f5d9cbe561f378951a1a764d5ae99e', 'f7b41cc0e1972d914e3f2cea29372555fb228453', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",17,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '9277dc70c74bcadf80dab11c28ead83fd085deec', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '9775d372bfaf889a395dc714e283b6a179e62537'}",6,"['Z. Peng', 'Xinyi Gong', 'Bengang Wei', 'Xiangyi Xu', 'Shixiong Meng']",Z. Peng,"Z. Peng, Xinyi Gong, Bengang Wei, Xiangyi Xu, Shixiong Meng",35.294117647058826
7dbeb92e7c234b3887cc484ce406ad86b5743add,Detecting Persuasive Atypicality by Modeling Contextual Compatibility,2021-10-01,"We propose a new approach to detect atypicality in persuasive imagery. Unlike atypicality which has been studied in prior work, persuasive atypicality has a particular purpose to convey meaning, and relies on understanding the common-sense spatial relations of objects. We propose a self-supervised attention-based technique which captures contextual compatibility, and models spatial relations in a precise manner. We further experiment with capturing common sense through the semantics of co-occurring object classes. We verify our approach on a dataset of atypicality in visual advertisements, as well as a second dataset capturing atypicality that has no persuasive intent.",https://www.semanticscholar.org/paper/7dbeb92e7c234b3887cc484ce406ad86b5743add,"{'e7a4e1a5d933ca482ef215784085eaf19b8d5e16', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '1b7bd7052bfb8ca50485a9236f2e0d2e9be1398d', '2527626c11a84f15709e943fbfa2356e19930e3b', '6551a4ea38312b9cc8d9c88fdade5768090a0b35', '79c93274429d6355959f1e4374c2147bb81ea649', 'eeb33ad2ede9944918724978bcbfb08b4c8c50a8', '6648b4db5f12c30941ea78c695e77aded19672bb', '8388f1be26329fa45e5807e968a641ce170ea078', '8230a99a581b4d1da1134cbe896e8cd2f4a9882a', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '8201e6e687f2de477258e9be53ba7b73ee30d7de', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '28aa465c3af7e5ccf1b10ae9cf76e83aab3ee34f', 'a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8', '744196b6cb5091c0760d05ef068a92a6cd531587', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '1b25b4a35f1060332ddca95ff180a4825277f844', '86df22f8dbec3489432063ef569a4793dc232c70', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '2f4b4464bcb755a4566445493e32b3a3337226d1', '24472a31618bbc260e2bf45bd72427097875142b', '27ac832ee83d8b5386917998a171a0257e2151e2', '18d41e3bd94cf38736e37580912c3b4ba56f08d5', 'd6dccb5d71fbb6f5765f89633ba3a8e6809a720d', '65a9c7b0800c86a196bc14e7621ff895cc6ab287', '1db9bd18681b96473f3c82b21edc9240b44dc329', 'a9fd5511b42206a27748f373e0fdb7eb76a23055', '43f2ad297941db230c089ba353efc3f281ab678c', None, 'c41a11c0e9b8b92b4faaf97749841170b760760a', '8e63784bd5a24d5e3035e2a11753e65e6e56625d', '82635fb63640ae95f90ee9bdc07832eb461ca881', '0170bb0b524df2c81b5adc3062c6001a2eb34c96', '360ef12906a531733b66e7e15c3d51771e7126d3', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '155b7782dbd713982a4133df3aee7adfd0b6b304', '5aec474c31a2f4b74703c6f786c0a8ff85c450da', '9405cc0d6169988371b2755e573cc28650d14dfe', 'afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d', 'c8efcc854d97dfc2a42b83316a2109f9d166e43f', 'fb507ada871d1e8c29e376dbf7b7879689aa89f9', '962dc29fdc3fbdc5930a10aba114050b82fe5a3e', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '2bc1c8bd00bbf7401afcb5460277840fd8bab029', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', 'd8a305b9366608d54452ac30459ee57b4f5cf1c9', '2e2488d20bbcb0779ed8e9449023e94a9a7e3512'}",51,set(),0,"['M. Guo', 'R. Hwa', 'Adriana Kovashka']",M. Guo,"M. Guo, R. Hwa, Adriana Kovashka",0.0
e556942e2933feaf2137c376f0a9e9df1214e78c,Demystifying data and AI for manufacturing: case studies from a major computer maker,2021-03-08,"In this article, we discuss the backgrounds and technical details about several smart manufacturing projects in a tier-one electronics manufacturing facility. We devise a process to manage logistic forecast and inventory preparation for electronic parts using historical data and a recurrent neural network to achieve significant improvement over current methods. We present a system for automatically qualifying laptop software for mass production through computer vision and automation technology. The result is a reliable system that can save hundreds of man-years in the qualification process. Finally, we create a deep learning-based algorithm for visual inspection of product appearances, which requires significantly less defect training data compared to traditional approaches. For production needs, we design an automatic optical inspection machine suitable for our algorithm and process. We also discuss the issues for data collection and enabling smart manufacturing projects in a factory setting, where the projects operate on a delicate balance between process innovations and cost-saving measures.",https://www.semanticscholar.org/paper/e556942e2933feaf2137c376f0a9e9df1214e78c,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'f6ce06d59301c474a593ac16ee090049dc1947ba', 'fb9b768cb12c66615f054bcbcab8041660e84222', '035d232d4292bccb1ec0e94aaea44eb4ac2cdf85', '9ab7319dbe80549ba80e3320d0546d741a7a5791', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', 'fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5', '89d9aae7e0c8b6edd56d0d79b277c07b7ab66fda', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '6be44364db3a46ab5fcf8172910650b210cc5c39', '71b7178df5d2b112d07e45038cb5637208659ff7', '052b1d8ce63b07fec3de9dbb583772d860b7c769', 'e9f39f0aced4299df5bad08ca96b6fc963aaf64b', 'bffca73dad7a288d6cd1176a967e4ae3a3c9916e', 'dfdcf7770885e3ee5f31182e91e602aabe5abdbd', '58303ac8a136f0da05b4ebd53cb2bdad009ef38b', 'b3a8a169674d599714805e0359244ab9a9bc9be2', 'fcf0caeaaf2e2302551ba22777b511dc801eb7e4', None, 'cfea224977f062a1f279a48e310018f396f0746a', '7095f5a5b996785a131233bb4009b563586bc339', 'fbbcf0546ffe7f6b804db00650f9ab896191c1d3', '34ca8871bb79244b9a852359cb7bf850ed67335c', '219f7706e28c91dcff3d6c4273ac71868714cac2', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', '8d4594b4d4827f44b57863376d54536112b7aaca', '3d9813300c90dd2c7e4090b72f24569fa5530e65', '9a5105896d452c61ccf95bee5a6fad593aa0cb36', 'd0be39ee052d246ae99c082a565aba25b811be2d', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270'}",32,set(),0,"['Yi-Chun Chen', 'Bo-Huei He', 'Shih-Sung Lin', 'Jonathan Hans Soeseno', 'Daniel Stanley Tan', 'T. Chen', 'Wei-Chao Chen']",Yi-Chun Chen,"Yi-Chun Chen, Bo-Huei He, Shih-Sung Lin, Jonathan Hans Soeseno, Daniel Stanley Tan, T. Chen, Wei-Chao Chen",0.0
5d0f6636987dda636bb6bed61140507f8c560f20,MAL DATA MANIFOLD FOR ANOMALY LOCALIZATION,,"Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. Indeed, an autoencoder trained on normal data is expected to only be able to reconstruct normal features of the data, allowing the segmentation of anomalous pixels in an image via a simple comparison between the image and its autoencoder reconstruction. In practice however, local defects added to a normal image can deteriorate the whole reconstruction, making this segmentation challenging. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoencoder’s loss function. This energy can be augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. By iteratively updating the input of the autoencoder, we bypass the loss of high-frequency information caused by the autoencoder bottleneck. This allows to produce images of higher quality than classic reconstructions. Our method achieves state-of-the-art results on various anomaly localization datasets. It also shows promising results at an inpainting task on the CelebA dataset.",https://www.semanticscholar.org/paper/5d0f6636987dda636bb6bed61140507f8c560f20,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd891dc72cbd40ffaeefdc79f2e7afe1e530a23ad', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'c61b43acd00d73e58fade68b8eb7c3ae875fc60c', 'd3dd00e24f96bae7ad780ac5fdb0c14194d5cb74', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d', 'ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa', 'e858bcc487cea96695102db9bdafe3c5d4269d04', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '67a3276174a209812a04c539fad8b764168e4047', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'e763e059cead07d1c03646bfb8cb4a0a75ffc3ef', '622107e35327a8759b967ae6a6c654bdab738f91', '4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",22,set(),0,"['David Dehaene', 'Oriel Frigo', 'Sébastien Combrexelle', 'P. Eline']",David Dehaene,"David Dehaene, Oriel Frigo, Sébastien Combrexelle, P. Eline",0.0
a5d4801cd23986fab691fa6a5d35bb73450b381b,On Combining Convolutional Autoencoders and Support Vector Machines for Fault Detection in Industrial Textures,2021-05-01,"Defects in textured materials present a great variability, usually requiring ad-hoc solutions for each specific case. This research work proposes a solution that combines two machine learning-based approaches, convolutional autoencoders, CA; one class support vector machines, SVM. Both methods are trained using only defect free textured images for each type of analyzed texture, labeling the samples for the SVMs in an automatic way. This work is based on two image processing streams using image sensors: (1) the CA first processes the incoming image from the input to the output, producing a reconstructed image, from which a measurement of correct or defective image is obtained; (2) the second process uses the latent layer information as input to the SVM to produce a measurement of classification. Both measurements are effectively combined, making an additional research contribution. The results obtained achieve a percentage of success of 92% on average, outperforming results of previous works.",https://www.semanticscholar.org/paper/a5d4801cd23986fab691fa6a5d35bb73450b381b,"{'2cb61c8cbe8bce564cbc2460fcca8a7429911caf', '162d958ff885f1462aeda91cd72582323fd6a1f4', 'cbe00a99b47b49e9ef473a5c166972dcb2ec2b4f', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '616b246e332573af1f4859aa91440280774c183a', '30d1c4fa60ce1fd5b05c79631b1c0e54a26206bf', '4932b0b4be311f36cfa1d254d70b03715a6c72db', '7d39d69b23424446f0400ef603b2e3e22d0309d6', '52536a08a73d915c5c4cd6e66abb36b1336cf86c', '98df4dd94f6d5fb5527984c8067d869744ff9ad7', 'a0804116c017dac97acacc50d933d8dd24a26f75', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '26d9214ecf6a738095362738512f4cc9b44f15fe', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '02387355b74e216cc32cef35ab0453af0de0eda3', 'f1d2664f096dc6443b84d40f05f75b2925237030', '6373cb25e29f7be72f27bde092e7efd77a7f48e9', '23ef7a704466248ae7e51bd9fd8e731763f2620e', '0b1c14ccf1aad87f215bfa5c6678d975d44ffb3a', '769ef3d5021cd71c37d2c403f231a53d1accf786', 'f076e4355c0facf111716dcab2837803367dd2d8', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', 'ce1e3528047cd01937f6a8aa760640f6b3c8d531', 'b7c86bc1cd0579576d995fd9ad5986dee7a65c7e', 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', '8c3ae83da4542257971c4033087bcd7eb33465a6', 'db65b7d124292733a4bfae2586e8013988747e70', '71b7178df5d2b112d07e45038cb5637208659ff7', 'fcc92911d9f262af7e92782deb2f034200e87386', '7abeda3a20c13bfee416d94efa313ff870656fec', '25757e7819eeb8829d3524474f973b79befd7b59', '6af440915b8a0718c93be1cf61905e41e620484a', '3f651d12508715ba0331cfa62efe296c034278e6', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, '732750bec3b4d8c0108d6daed642500765d5c0ca', '43992f62332fc9d745fc119b829273e536c810ef', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e4845fb1e624965d4f036d7fd32e8dcdd2408148', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '7f575e099af94faca1fe9c9f04ab0ee4081c77f0', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '92a552175e992afd0b9fe943a02ec5580b4aa6df', '184ac0766262312ba76bbdece4e7ffad0aa8180b', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '7a77790650dd2a90aa4bcfc0ac064f5bfd598166', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c'}",50,set(),0,"['A. Tellaeche', 'Miguel Ángel Campos Anaya', 'G. Pajares', 'I. Pastor-López']",A. Tellaeche,"A. Tellaeche, Miguel Ángel Campos Anaya, G. Pajares, I. Pastor-López",0.0
0dafe4bb5dfb566471e4b0cb02ddb624aaba93d5,Instance-Aware Plant Disease Detection by Utilizing Saliency Map and Self-Supervised Pre-Training,2022-07-22,"Plant disease detection is essential for optimizing agricultural productivity and crop quality. With the recent advent of deep learning and large-scale plant disease datasets, many studies have shown high performance of supervised learning-based plant disease detectors. However, these studies still have limitations due to two aspects. First, labeling cost and class imbalance problems remain challenging in supervised learning-based methods. Second, plant disease datasets are either unstructured or weakly-unstructured and the shapes of leaves and diseased areas on them are variable, rendering plant disease detection even more challenging. To overcome these limitations, we propose an instance-aware unsupervised plant disease detector, which leverages normalizing flows, a visual saliency map and positional encodings. A novel way to explicitly combine these methods is the proposed model, in which the focus is on reducing background noise. In addition, to better fit the model to the plant disease detection domain and to enhance feature representation, a feature extractor is pre-trained in a self-supervised learning manner using only unlabeled data. In our extensive experiments, it is shown that the proposed approach achieves state-of-the-art performance on widely-used datasets, such as BRACOL (Weakly-unstructured) and PlantVillage (Unstructured), regardless of whether the dataset is weakly-structured or unstructured.",https://www.semanticscholar.org/paper/0dafe4bb5dfb566471e4b0cb02ddb624aaba93d5,"{'9757ef31095227cb289af22b0a4010eda754d100', '2d00dc606e9dcfe172de9f5d1c1398aabb88e4e9', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '534368a8ccd43cbea78779b7d9625363518bdecd', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '8763535d7b6f123827953a73f05e8587063b65e0', '9cd70ca81b4653aa2048002273c5ac9c36641390', 'b4f3fc2e2214af26d149e8033f767d28da74ee21', 'cebd4ab4ab52be88b26d976aa7d4fb35cc19c2a2', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', 'f9163156eeba67762a7441db48fe6720106137cd', '0ecfd6f87688a1bbbcec754284bb512fcb2c8768', 'c91f1cd7470c10f31f69a018bc336e76913725a1', '5ffe9b1d8219438f0343995ad3ea1a888e3d9f8e', 'ce61a2bbc0bafcc674423167cb2587027fe08a12', 'fded9477201ac8c951878af588521c7909216ae6', '34df928e08241405d2f7c454da6a0beb57fe2539', '9d556f1e8437b2a31d89067a0c577c2d054c7adb', '1c4e9156ca07705531e45960b7a919dc473abb51', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'b2f1c465d27194cac129369c9597c897217744e3', '84c9d17200d15c03eff764ec109ebcbb12295c88', 'f81b035f345c425f38f9273dc7178483400a34d2', 'b1464ca857593c049873421db2f37bf2d0ff676d', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '3a34bc8949d42f6088fb4e668660c7031fbca23f', 'd82b55c35c8673774a708353838918346f6c006f', None, '0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d', '818a94624754bdbc0b7b6d770237e17b3635ef52', '283743048be918a1a4144d78ea65f45398c37e2d', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '3b383b68d498e82a5f34ef1fae9be3f7cf58f249', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '34b4134bf598b0f0c0daf7749a36547163a55b09', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '5dbc4a131e731210b0da7219e07f6af3434c1b00', '6a97d2668187965743d1b825b306defccbabbb4c', '8bafbfff7c3181656498b7298731015f0abd56a4', 'f739c8c2c36c284296642980fb874fb85e0ac816', '31b38a19d87711489786ad54a5a00d5f0b2ead43', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",45,"{'3a34bc8949d42f6088fb4e668660c7031fbca23f', '3b383b68d498e82a5f34ef1fae9be3f7cf58f249', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '9cd70ca81b4653aa2048002273c5ac9c36641390', '8ee35ed698527d9695c872e3b76715fec4ef69ad', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'b1464ca857593c049873421db2f37bf2d0ff676d', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",10,"['Taejoo Kim', 'Hyeongju Kim', 'K. Baik', 'Yukyung Choi']",Taejoo Kim,"Taejoo Kim, Hyeongju Kim, K. Baik, Yukyung Choi",22.22222222222222
93040f8a5d10e8fde279e18d353aa3dca2873900,Divide-and-Assemble: Learning Block-wise Memory for Unsupervised Anomaly Detection,2021-07-28,"Reconstruction-based methods play an important role in unsupervised anomaly detection in images. Ideally, we expect a perfect reconstruction for normal samples and poor reconstruction for abnormal samples. Since the generalizability of deep neural networks is difficult to control, existing models such as autoencoder do not work well. In this work, we interpret the reconstruction of an image as a divide-and-assemble procedure. Surprisingly, by varying the granularity of division on feature maps, we are able to modulate the reconstruction capability of the model for both normal and abnormal samples. That is, finer granularity leads to better reconstruction, while coarser granularity leads to poorer reconstruction. With proper granularity, the gap between the reconstruction error of normal and abnormal samples can be maximized. The divide-and-assemble framework is implemented by embedding a novel multi-scale block-wise memory module into an autoencoder network. Besides, we introduce adversarial learning and explore the semantic latent representation of the discriminator, which improves the detection of subtle anomaly. We achieve state-of-the-art performance on the challenging MVTec AD dataset. Remarkably, we improve the vanilla autoencoder model by 10.1% in terms of the AUROC score.",https://www.semanticscholar.org/paper/93040f8a5d10e8fde279e18d353aa3dca2873900,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'be8c6c69f3e357bfad2987e45b62cff7e7474378', 'd100f625580dd6df123c69abff1d094e2d745613', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '8388f1be26329fa45e5807e968a641ce170ea078', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'd796ff29f8798c418d5374a6632231f02233dbba', '26c50d272883fc8f72656526f915bb283f772b27', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'bba5f2852b1db8a18004eb7328efa5e1d57cc62a', '4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '5993fb65a6e38b242fc1b259cf1f3d49f5dafcc2', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', '9d5290fadb7625862a966e0330bd0f9e111fc99d', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', '5435a9ab36a308cef10bc725104e8f778ed3a328', '37595f7a51982d776e57c7280b9445474d90f0be', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '2edf3a49bdbbb630666c51be9b856d613c9782b3', '5c5d99eff1377e141be293336a14ffddb323c364', '6af440915b8a0718c93be1cf61905e41e620484a', '38f93092ece8eee9771e61c1edaf11b1293cae1b', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'b36a5bb1707bb9c70025294b3a310138aae8327a', '17d9185640e46a49b260a1e1e533c36a71bffdc8', 'aae932cf9c2434f52b03991fcab050a61a960d48', 'e3fc2a67967b1355609094175f19b2412dd4851d', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', 'bf741643d5958773d605f011808cb3e83537748d', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', None, '0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d', '44d2abe2175df8153f465f6c39b68b76a0d40ab9', '2f7af18b35d155064243c21d0818b1570a3a696e', '206c2e79b5f1b4541b85f47517666961ed49500e', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '8381157eae4fbf8908d0312a9642f8e69e944449', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '9775d372bfaf889a395dc714e283b6a179e62537', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '746cf281d8198310b1242048bf4fd90e0486f1a9'}",55,"{'e021d59638966a6fbb36854cc2cf1045de7a62d2', '9277dc70c74bcadf80dab11c28ead83fd085deec', '9775d372bfaf889a395dc714e283b6a179e62537', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '206c2e79b5f1b4541b85f47517666961ed49500e'}",6,"['Jinlei Hou', 'Yingying Zhang', 'Qiaoyong Zhong', 'Di Xie', 'Shiliang Pu', 'Hong Zhou']",Jinlei Hou,"Jinlei Hou, Yingying Zhang, Qiaoyong Zhong, Di Xie, Shiliang Pu, Hong Zhou",10.909090909090908
ed4472cb96d82cb2a8e51b92a6f079b14ec2a040,TrustMAE: A Noise-Resilient Defect Classification Framework using Memory-Augmented Auto-Encoders with Trust Regions,2020-12-29,"In this paper, we propose a framework called Trust-MAE to address the problem of product defect classification. Instead of relying on defective images that are difficult to collect and laborious to label, our framework can accept datasets with unlabeled images. Moreover, unlike most anomaly detection methods, our approach is robust against noises, or defective images, in the training dataset. Our framework uses a memory-augmented auto-encoder with a sparse memory addressing scheme to avoid over-generalizing the auto-encoder, and a novel trust-region memory updating scheme to keep the noises away from the memory slots. The result is a framework that can reconstruct defect-free images and identify the defective regions using a perceptual distance network. When compared against various state-of-the-art baselines, our approach performs competitively under noise-free MVTec datasets. More importantly, it remains effective at a noise level up to 40% while significantly outperforming other baselines.",https://www.semanticscholar.org/paper/ed4472cb96d82cb2a8e51b92a6f079b14ec2a040,"{'a1a19aaddf57c0546357d890d9269092ba0afb26', 'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', 'be8c6c69f3e357bfad2987e45b62cff7e7474378', 'e257f53541794182dfb73ad98d0074b974643a6f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'd3dd00e24f96bae7ad780ac5fdb0c14194d5cb74', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '156b0af3dc5b6a223790c141b6031d1fa0ca56da', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', '75f4a545d0f392168039a68c022ec5f90c74e882', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', 'c3823aacea60bc1f2cabb9283144690a3d015db5', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '31630d1aa44ef8fcac8e127ed9d7ac57e3c11269', 'fab590052981189094edb167dd08e6d21e44672e', '5a98c143dabd1f163078e4c720f25b5f1d255597', '25757e7819eeb8829d3524474f973b79befd7b59', 'f0a0c0f0d6a7ff53abea40a8c0c678ed570bf851', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'c468bbde6a22d961829e1970e6ad5795e05418d1', 'fcf43325529c8b1cc26aeb52fd5d7e532abb0a40', None, '17d3f90cb63fbac50a5e49b8a46e633ec1f526fd', '8eb1bd8ecbd90e620dd2a3f3dcbf2b234cd6c52e', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0', 'eef29a4fef85c7ed8acde9ca42f8f09d944f361d', '9fa3720371e78d04973ce9752781bc337480b68f', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'a8f3dc53e321fbb2565f5925def4365b9f68d1af', 'ca53debc89167a6a48dc0f0016ba4ec86fd9cc17', '20764b1b54813f8e8dbfe82b10feb5ebebf72a7f', '9aa0a4c01a0fd0df84d80ad8c2580d3c6cc39efa', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', 'b39e3e767401ac2055c78676498721ec830e6be3', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",48,"{'363c81a08858df8dd7d1bde79c6e002e3b19f900', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070'}",3,"['Daniel Stanley Tan', 'Yi-Chun Chen', 'T. Chen', 'Wei-Chao Chen']",Daniel Stanley Tan,"Daniel Stanley Tan, Yi-Chun Chen, T. Chen, Wei-Chao Chen",6.25
eca095d05fc101970acda095e33acdcd4b643e3d,Unsupervised Learning of Multi-level Structures for Anomaly Detection,2021-04-25,"The main difficulty in high-dimensional anomaly detection tasks is the lack of anomalous data for training. And simply collecting anomalous data from the real world, common distributions, or the boundary of normal data manifold may face the problem of missing anomaly modes. This paper first introduces a novel method to generate anomalous data by breaking up global structures while preserving local structures of normal data at multiple levels. It can efficiently expose local abnormal structures of various levels. To fully exploit the exposed multi-level abnormal structures, we propose to train multiple level-specific patch-based detectors with contrastive losses. Each detector learns to detect local abnormal structures of corresponding level at all locations and outputs patchwise anomaly scores. By aggregating the outputs of all level-specific detectors, we obtain a model that can detect all potential anomalies. The effectiveness is evaluated on MNIST, CIFAR10, and ImageNet10 dataset, where the results surpass the accuracy of state-of-the-art methods. Qualitative experiments demonstrate our model is robust that it unbiasedly detects all anomaly modes.",https://www.semanticscholar.org/paper/eca095d05fc101970acda095e33acdcd4b643e3d,"{'c4bc3d8703ced63750a5b9ac3ddd4514fada596c', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'c3955d74f2a084a8ddcbd7e73952c326e81804b2', 'd532a73e7d1e3bde23f862a0b3105d6613f9fd89', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '84de7d27e2f6160f634a483e8548c499a2cda7fa', '14fdc18d9c164e5b0d6d946b3238c04e81921358', 'db787640c9b42416ff8d7015546e667e58267177', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '1322719978980a831e1aee78aa80a141379c44dd', '5db790198b9acf4e5efe350acdd814238fcacaa7', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'b110ba174df21a23a9521731d4181261ca5860ed', '62b77e5cb85fc61b84edd532f6d65714be152596', 'fd7789de401811fd8692466b8d49230e7184655f', '04513c7c0b3a63fde81a996dae064a28d453c17a', '36653f8705b56e39642bcd123494eb680cd1636b', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '8acbe90d5b852dadea7810345451a99608ee54c7', '317aee7fc081f2b137a85c4f20129007fd8e717e', 'b959d5655a3b2f92c2c1a8a7896fecafafea979d', 'ccaf15d4ad006171061508ca0a99c73814671501', '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'd961f1ec47bc2894d4b01cce7b918b303029fe48', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '51cdeeef710d1c84e10beadc8480c137ffe8d328', '26bf9f0e39fc020633c95cbe18d1076c19714bec', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '70f9968a356d840040a1c9207906f60376dc6bd4', 'e3ce36b9deb47aa6bb2aa19c4bfa71283b505025', '6ff2a434578ff2746b9283e45abf296887f48a2d', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d', 'bb5018951e0d869769af9336052acad0fe4b36bb', '229e225621e833133150310489cb5ee86c6c0146', '4543670c4b2d88a9b67525e0084044adef94ae76', '33fc67c7425c669bac36b4dba7fd427e55d309fe', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'a25b63a6a0071d7d88ff4671c1fd40f320a08533', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '8381157eae4fbf8908d0312a9642f8e69e944449', 'ba37a893c8d4c1d0bf152da07a565998296308cf', '810ae452a3a1f673ea241bd540f9551b2996ed5b', '2d4f96a46cbdd9b044b431078121e29464d834d6', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",57,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596'}",2,"['Songmin Dai', 'Jide Li', 'Lu Wang', 'Congcong Zhu', 'Yifan Wu', 'Xiaoqiang Li']",Songmin Dai,"Songmin Dai, Jide Li, Lu Wang, Congcong Zhu, Yifan Wu, Xiaoqiang Li",3.508771929824561
16a67491ed4bdb6293d1c2be35b0e8bae962cdeb,Explainable Deep One-Class Classification,2020-07-03,"Deep one-class classification variants for anomaly detection learn a mapping that concentrates nominal samples in feature space causing anomalies to be mapped away. Because this transformation is highly non-linear, finding interpretations poses a significant challenge. In this paper we present an explainable deep one-class classification method, Fully Convolutional Data Description (FCDD), where the mapped samples are themselves also an explanation heatmap. FCDD yields competitive detection performance and provides reasonable explanations on common anomaly detection benchmarks with CIFAR-10 and ImageNet. On MVTec-AD, a recent manufacturing dataset offering ground-truth anomaly maps, FCDD meets the state of the art in an unsupervised setting, and outperforms its competitors in a semi-supervised setting. Finally, using FCDD's explanations we demonstrate the vulnerability of deep one-class classification models to spurious image features such as image watermarks.",https://www.semanticscholar.org/paper/16a67491ed4bdb6293d1c2be35b0e8bae962cdeb,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', 'dc00e2c47411d6d257c979963e4dd2f7d97d5d03', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'fbc6562814e08e416e28a268ce7beeaa3d0708c8', '67b9052fdace3ed74297baaae14578246576ec0a', '49c076bbc21ab76720b610ab3840c15ce3dc4e6c', '7ff3f12f27ef8e9e7d754c23b1eeb09b664223bd', 'aa7bfd2304201afbb19971ebde87b17e40242e91', '8bdfc8d09bfb4e7ff63faeb25d0e3514ebdc2d18', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '88880d88073a99107bbc009c9f4a4197562e1e44', 'ac0a59165ee2ac666b1880316eefe349b87f6ba0', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '16a365950dcb89a4b4232ce1634784a0bc8f7b86', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'db787640c9b42416ff8d7015546e667e58267177', 'c87d57da3b1f2b467ef4995d30df832ee2281107', '5db790198b9acf4e5efe350acdd814238fcacaa7', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', '1d8f4f76ac6534627ef8a1c24b9937d8ab2a5c5f', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'b110ba174df21a23a9521731d4181261ca5860ed', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', 'e716698a6d28e7a47bea9b25dbc5df0da2d07158', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '2ac9995a47f9753041e8e760fb083dfb83998267', '4b07c418a40fdedbefeca7e78afe2b8a1c473537', '04513c7c0b3a63fde81a996dae064a28d453c17a', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '317aee7fc081f2b137a85c4f20129007fd8e717e', '4f51a64793d3b2a60e9e5846c31dae023cf5c69a', '1f528877c4d8d5df3b3abbfa64379677d451956b', '20f69cc41c87b8abdf36761c623d65713daeab3b', '6af440915b8a0718c93be1cf61905e41e620484a', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '90902e16f4e8ff5e3c4bf0f971380af5753aacdd', 'd3b614f11969127a08447c41257b3a7b58766d18', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '5091316bb1c6db6c6a813f4391911a5c311fdfe0', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'cf986bfe13a24d4739f95df3a856a3c6e4ed4c1c', 'a002e71561c90767240672f357b7d9e6d4d95186', None, 'b0dc598adda48acab590f95a5985fcc7abf2aca9', '82635fb63640ae95f90ee9bdc07832eb461ca881', 'e6573ee468b73641d66ef84496eb317b59304a00', '5d90f06bb70a0a3dced62413346235c02b1aa086', '92584dac09356c3c2e915932956bdc06f91d453f', 'eb42cf88027de515750f230b23b1a057dc782108', '01a4f33da8ad94ced3cf58548b28dbbb44148571', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'f302e136c41db5de1d624412f68c9174cf7ae8be', '54d2b5c64a67f65c5dd812b89e07973f97699552', 'c9e88f51dfcf15ff9677fcde5bff59bee1f2ca94', 'dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '90d91bad87a53d82f45a0153dc0f82c3e6036741', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '43dc45dca9c1e641c7855a033a91a71746ca8832', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",68,"{'1f528877c4d8d5df3b3abbfa64379677d451956b', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', 'd3b614f11969127a08447c41257b3a7b58766d18', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a'}",8,"['Philipp Liznerski', 'Lukas Ruff', 'Robert A. Vandermeulen', 'Billy Joe Franks', 'M. Kloft', 'K. Muller']",Philipp Liznerski,"Philipp Liznerski, Lukas Ruff, Robert A. Vandermeulen, Billy Joe Franks, M. Kloft, K. Muller",11.764705882352942
0eb80e81580568ce9d70ad1c2495aef188a9587f,Self-Supervised Out-of-Distribution Detection and Localization with Natural Synthetic Anomalies (NSA),,"We introduce a new self-supervised task, NSA, for training an end-to-end model for anomaly detection and localization using only normal data. NSA uses Poisson image editing to seamlessly blend scaled patches of various sizes from separate images. This creates a wide range of synthetic anomalies which are more similar to natural sub-image irregularities than previous data-augmentation strategies for self-supervised anomaly detection. We evaluate the proposed method using natural and medical images. Our experiments with the MVTec AD dataset show that a model trained to localize NSA anomalies generalizes well to detecting real-world a priori unknown types of manufacturing defects. Our method achieves an overall detection AUROC of 97.2 outperforming all previous methods that learn from scratch without pre-training datasets.",https://www.semanticscholar.org/paper/0eb80e81580568ce9d70ad1c2495aef188a9587f,"{'05e882679d61f4c64a68ebe21826251a39f87e98', '67bd5b3a67a6dedd26b6c4e6b279158433069a7d', '5db790198b9acf4e5efe350acdd814238fcacaa7', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '94c951bb90d0b86e056668aaadd2d5459ace5bc3', 'b022f2a277a4bf5f42382e86e4380b96340b9e86', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '6af440915b8a0718c93be1cf61905e41e620484a', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '4bec59a9940f2a111594c5b7ea1ccf2419ada04b', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', '6dbc8145124d338a96ee59bc745f0bbce1f00c76', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '0b93901e11e0277e04fe4f0133846250d0be7f89', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",27,"{'62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '48f9a48aa5b1230b05a443d2d531e6441a541686', '37595f7a51982d776e57c7280b9445474d90f0be', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",7,"['Hannah M. Schlüter', 'Jeremy Tan', 'Benjamin Hou', 'Bernhard Kainz']",Hannah M. Schlüter,"Hannah M. Schlüter, Jeremy Tan, Benjamin Hou, Bernhard Kainz",25.925925925925927
caa3706a21f97404368fa10a5fe80d5929770618,Anomaly Clustering: Grouping Images into Coherent Clusters of Anomaly Types,2021-12-21,"We introduce anomaly clustering, whose goal is to group data into semantically coherent clusters of anomaly types. This is different from anomaly detection, whose goal is to divide anomalies from normal data. Unlike object-centered image clustering applications, anomaly clustering is particularly challenging as anomalous patterns are subtle and local. We present a simple yet effective clustering framework using a patch-based pretrained deep embeddings and offthe-shelf clustering methods. We define a distance function between images, each of which is represented as a bag of embeddings, by the Euclidean distance between weighted averaged embeddings. The weight defines the importance of instances (i.e., patch embeddings) in the bag, which may highlight defective regions. We compute weights in an unsupervised way or in a semi-supervised way if labeled normal data is available. Extensive experimental studies show the effectiveness of the proposed clustering framework along with a novel distance function upon existing multiple instance or deep clustering frameworks. Overall, our framework achieves 0.451 and 0.674 normalized mutual information scores on MVTec object and texture categories and further improve with a few labeled normal data (0.577, 0.669), far exceeding the baselines (0.244, 0.273) or state-of-theart deep clustering methods (0.176, 0.277).",https://www.semanticscholar.org/paper/caa3706a21f97404368fa10a5fe80d5929770618,"{'8999355e47248bc60f5768fc2168fd28295b5f27', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '4bfcce73148d485eb2290475bbc42080a78b03d7', '4fcf637197abc8022c5c301f755a26f91c06b78b', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', 'b91180d8853d00e8f2df7ee3532e07d3d0cce2af', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'ac8ab51a86f1a9ae74dd0e4576d1a019f5e654ed', 'f708482e99ed40a2fb9e363577479e1fd15afc9f', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'c342c71cb23199f112d0bc644fcce56a7306bf94', '00a1077d298f2917d764eb729ab1bc86af3bd241', '7417d7dcf6152736612e3f04ccc72731dc8d9505', 'aec822f56ff1794c32f5826cfb266f9b477f4df8', '0430b241bdd0b67d37e1143370f8d24fc46d83e9', '90d6e7f2202f754d8588f9536e3f5b4a24701f24', 'f44ff4fc0ed0142cb18472a5ba421bb538aa837e', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '0c9ae806059196007938f24d0327a4237ed6adf5', 'ba64121fc3b4b9afc10543cff25d9ec84a9d8860', '954937ece00fd465f6a639fa739a04af8d5d7efb', '04513c7c0b3a63fde81a996dae064a28d453c17a', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '37595f7a51982d776e57c7280b9445474d90f0be', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '498e003901f8287e89e5064477cd22dd47e49d61', '3d539147a3f4b286455f4c33b35fce866d7b0b6d', '72bf4b2ce534b95bc24118491dbc4f8d550734a2', '3dc1e5fbf7842c214554aac02343cfd1b44ea435', '6af440915b8a0718c93be1cf61905e41e620484a', 'd06d778c97827dfd0dc3244e01a96236d35a34c2', '85efeeb25d8e363606d94c8fadaa922ba9b93a37', '7c5bae29a266a7a67228c0a9b051961bc48ed4db', '6dbaff29d3898cf60f63f5a34cb9610ebb75220c', 'b6a0f30260302a2001da9999096cfdd89bc1f7fb', 'b8de958fead0d8a9619b55c7299df3257c624a96', '008abebf4a9404db9050c9d2fbca769f4faf3ca6', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '3094456890fb14340ed26c254e776e39f9533f75', '45a7c4dbc76778127eec187aa2c24672e0c55551', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '8c04f169203f9e55056a6f7f956695babe622a38', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', None, '41747cbdbed84762dfbfc305254c97021279dc6e', '461d2c494d0353834c54f13e74cc80cd56dbe365', '63e15a936effd5aa76707e254e616f02a1f3f361', 'a7c828184693a453a6c2867dee233ed054b2012e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '5f3b50c6c826ad105163b09d53e1eb498a4b3994', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', 'c02dfd94b11933093c797c362e2f8f6a3b9b8012', 'c4c0ba0f41d8d51ad896f673cc26f2a9c0810763', 'a7d75aa3a0a9faa310fb524c350fba2093b0ec97', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', '2c37826357c18148f6f0773d22f7a4488831c1c4', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '1d033b30f38642e4b6dd146bb8b464bfb58aad96', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",68,"{'62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'a7d75aa3a0a9faa310fb524c350fba2093b0ec97', '37595f7a51982d776e57c7280b9445474d90f0be', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '498e003901f8287e89e5064477cd22dd47e49d61', '41747cbdbed84762dfbfc305254c97021279dc6e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['Kihyuk Sohn', 'Jinsung Yoon', 'Chun-Liang Li', 'Chen-Yu Lee', 'Tomas Pfister']",Kihyuk Sohn,"Kihyuk Sohn, Jinsung Yoon, Chun-Liang Li, Chen-Yu Lee, Tomas Pfister",13.235294117647058
4dd78b8d466b4cfe55a1bbdc694291197ce62541,Unsupervised anomaly segmentation via deep feature reconstruction,2020-11-26,,https://www.semanticscholar.org/paper/4dd78b8d466b4cfe55a1bbdc694291197ce62541,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '732c21998e251d64cd58b6a86886ee5907efeaa5', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '85384a8871030bbd1681adee9e9956dce4d751ba', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '3bbcb7fbebde8b15794fc54db16cfcbc059bacb5', '317aee7fc081f2b137a85c4f20129007fd8e717e', '8631f070ee635f0ec52f522834668a7c417eae94', 'a0e8f4348968195c80494b7a4245edb91a252c93', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', '41747cbdbed84762dfbfc305254c97021279dc6e', '4100414ad0763bdc91bd15bb6e0424a44d7a35fe', '17d7b57dcc5c50e3bf2dada669a7905a8f5b13ef', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'ba1f6ef20824aba161c4b3666e29e99486f20390', '2910bec6d4de87e22be5119cef3c488d2ae50e2a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '8381157eae4fbf8908d0312a9642f8e69e944449', '23364d3dfab309ef3af5bcfda9a222029ad22b23', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'fe09f7a379944444201552e952b910188c0aeaca', '66ccd943eebb652af13b6096c6edc3407eb510e5', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",30,{'41747cbdbed84762dfbfc305254c97021279dc6e'},1,"['Yong Shi', 'Jie Yang', 'Zhiquan Qi']",Yong Shi,"Yong Shi, Jie Yang, Zhiquan Qi",3.3333333333333335
df81f97a51cdedeaa7580a9c2da9581a634b3466,NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds,2022-06-23,"In order for artiﬁcial agents to perform useful tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classiﬁcation. This practice restricts novelties to well-framed images of distinct object types. We suggest that new benchmarks are needed to represent the challenges of navigating an open world. Our new NovelCraft 1 dataset contains multi-modal episodic data of the images and symbolic world-states seen by an agent completing a pogo-stick assembly task within a video game world. In some episodes, we insert novel objects that can impact gameplay. Novelty can vary in size, position, and occlusion within complex scenes. We benchmark state-of-the-art novelty detection and generalized category discovery models with a focus on comprehensive evaluation. Results suggest an opportunity for future research: models aware of task-speciﬁc costs of different types of mistakes could more effectively detect and adapt to novelty in open worlds. Description Scene-focused, multi-modal, episodic data of the images and symbolic world-states seen by an agent completing a pogo-stick assembly task within a video game world. Classes consist of episodes with novel objects inserted. A subset of these novel objects can impact gameplay and agent behavior. Novelty objects can vary in size, position, and occlusion within the images. Hyperparameter Tuning. Supervised loss weights of 0 and 1 were tested to verify that the combi-nation of losses was increasing performance. Initial learning rates 1 , 0 . 1 , 0 . 01 , and 0 . 001 were tested with 0 . 1 found to perform best on the validation set.",https://www.semanticscholar.org/paper/df81f97a51cdedeaa7580a9c2da9581a634b3466,"{'97c943bda664004e6aded753abec22a0f4d20eef', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '802168a81571dde28f5ddb94d84677bc007afa7b', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'ef34818ad7562698e102f8ecc41c6f6a8b4a519a', '149f5a50eef5b115fc67c21693c4e701a6161c43', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '5b8013f4425b6b889a514e95fe6355a83c64d1ea', '904627c2d5a91ab8cb1b682e42f06f1ca192aea6', '9acc51b06f54b07836fad4cc24633187dc21317f', '59bb8d6c3eec8f925710db4d2488e2a23167d3e8', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'e2bc01813d6ef50194588086e2adea42bdf2323b', '8f7ed8686fc97c4e624c8ea4f52fc48d3b03d6b7', '73c07e0a998576bb9d9409e5eed713788c0be037', 'f1d454f3bfb8f73702bbeb3bf38f8e7d829bb690', '712e279ecea207968717d8401000e7ca0b7bb74d', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '71b7178df5d2b112d07e45038cb5637208659ff7', 'e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d', '429173b6033ce240e0b5930379417f703d0e38fe', '378927c2709643934e7ee48e812e410223a73ae3', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '02d0ef096d3b39bb83a344393522360aaf69d694', 'aae932cf9c2434f52b03991fcab050a61a960d48', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'ec86014544ad1a1d8363feaf89ce88098d5b98f0', None, '5712edce918859a9b22471dd0ed78ef4ea1fc724', 'ad4a0938c48e61b7827869e4ac3baffd0aefab35', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', '22909dd19a0ec3b6065334cb5be5392cb24d839d', '7fc00d1b8f7d73f9d5f468352059643e1ba47ca8', '5d90f06bb70a0a3dced62413346235c02b1aa086', '723ad3204e614a2f8076ed4a9cee8c9a06abcf98', 'eb42cf88027de515750f230b23b1a057dc782108', 'f986968735459e789890f24b6b277b0920a9725d', 'f9717d29840f4d8f1cc19d1b1e80c5d12ec40608', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', 'e6936c5da35d1de228c427704f97eb93ff5382cd', '58820d25393909b5bb6e4088c97615060ff0c739', '5a5effa909cdeafaddbbb7855037e02f8e25d632', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '629ae83d63f558e16b530441d765dc822d2949e1'}",47,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '149f5a50eef5b115fc67c21693c4e701a6161c43'}",2,"['Patrick Feeney', 'Sarah Schneider', 'Panagiotis Lymperopoulos', 'Liping Liu', 'matthias. scheutz', 'Michael C. Hughes Dept. of Computer Science', 'T. University', 'Center for Vision', 'Automation', 'Control', 'Austrian Institute of Technology']",Patrick Feeney,"Patrick Feeney, Sarah Schneider, Panagiotis Lymperopoulos, Liping Liu, matthias. scheutz, Michael C. Hughes Dept. of Computer Science, T. University, Center for Vision, Automation, Control, Austrian Institute of Technology",4.25531914893617
c20a429ede0cb84dcece92c2346cffc906505256,[Reproducibility Report] Explainable Deep One-Class Classification,2022-06-06,"Fashion-MNIST and CIFAR-10 and exceeds the state-of-the-art on the pixel-wise task on MVTec-AD. They give evidence to show a clear improvement by using few (1 up to 8) real anomalous images in MVTec-AD for supervision at the pixel level. Finally, a qualitative study with horse images on PASCAL-VOC shows that FCDD can intrinsically reveal spurious model decisions by providing built-in anomaly score heatmaps.",https://www.semanticscholar.org/paper/c20a429ede0cb84dcece92c2346cffc906505256,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '0c6e8912fe8ed3c8cf9008a7d59edcf469522a45', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '43dc45dca9c1e641c7855a033a91a71746ca8832', '7edbd1ee743632893de81d117c05120774dc36f4', '6af440915b8a0718c93be1cf61905e41e620484a', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd3b614f11969127a08447c41257b3a7b58766d18', '48f9a48aa5b1230b05a443d2d531e6441a541686', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', None, '82635fb63640ae95f90ee9bdc07832eb461ca881', 'e6573ee468b73641d66ef84496eb317b59304a00', '1c2efb418f79b5d29913e014a1dfd78865221c39', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '01a4f33da8ad94ced3cf58548b28dbbb44148571', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'c9e88f51dfcf15ff9677fcde5bff59bee1f2ca94', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '032db195efd97fe2bcd20c4ad04628c70ff4e79c', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",28,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'd3b614f11969127a08447c41257b3a7b58766d18', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",11,"['João P. C. Bertoldo', 'Etienne Decencière']",João P. C. Bertoldo,"João P. C. Bertoldo, Etienne Decencière",39.285714285714285
b2e730e05c19144d7e93a43c24ebcc5d425fa05c,Detection of surface defects on pharmaceutical solid oral dosage forms with convolutional neural networks,2021-08-17,,https://www.semanticscholar.org/paper/b2e730e05c19144d7e93a43c24ebcc5d425fa05c,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '4675b6b4075ddf91df71cc0677c3b36df0ac46bc', '22b5886c054a8427118ce14ae39cca9f7767dab1', '31f1c4cf34ce0bb35382c35b2f468cf72bffae0b', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '455d9a4ff96561d543acbcb2aa81d6cd8fcd20df', '4915febbe5295aed7944c7f53ba3c9ae141375ae', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', 'ee4a012a4b12d11d7ab8c0e79c61e807927a163c', '65b864858f73b99fe56eebb1e3a28a9fe156e4b1', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '971e2f8d95617f263e1bfa7081db06f1eb6211dc', 'efdbd7af97c0fb0dbf0e302c616eda750e1772e9', '5aea896df0724208ea9631099207ec7a437f55e5', '70a0893a77f90ca07732d89b91cb32c13d69e7f6', '2f76f1dac9a5c89ffa0f0b6eab2910c1073a24bf', '6615f7838b9ff5194921ca05189e51c32cfbbcb2', '6f9f143ec602aac743e07d092165b708fa8f1473', '46331b0880dff17b39ea247d23ddb23820b25e42', 'f7ba124930c369e39146af1c4af2d033a09be880', 'dd2612a5b720001354713be5f9a57a34013d4867', 'a4cec122a08216fe8a3bc19b22e78fbaea096256', '1cd95faea6372805527314776e245d85cca22cc0', '047efd37f34a916d50dbacf4c52afd968389e5e1', '5f86851ccdcbdb0d5a939e216ad8425d8a0887b4', '895e770ae8bd559898c50e7c59776d1b572f8f73', '71b7178df5d2b112d07e45038cb5637208659ff7', 'c0f17f99c44807762f2a386ac6579c364330e082', '01b9afe0ddeb6a2b6dadf56821a7bdbdd17319d9', '9217e28b2273eb3b26e4e9b7b498b4661e6e09f5', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '26c1e598d80e9839380b51b75b9ff79b735979b1', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '6dbaff29d3898cf60f63f5a34cb9610ebb75220c', '358b9707c2d45c06e23a264d21390c2ed5a1d7ee', '17d3f90cb63fbac50a5e49b8a46e633ec1f526fd', '3850c4b24c82a48f057b6cd9f5b83a3200c7c13d', '27a6425224141d77241aec38234e173d41452a83', 'ab7af7023418c77edfae7d2ee25fa796c926d5ea', '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', 'd6172e8df57726ef9934b255ecc702a12d7ba683', 'd6f2f611da110b5b5061731be3fc4c7f45d8ee23', '4712c173431c3672ccb5e3d6e4709923cf8be4b9', '8c4be5f5ff36bb326ae4325d2ed79a18a0296107', '63bc06753e0d38b511ddc07482822c24785e8c9a', 'dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4', 'eb42cf88027de515750f230b23b1a057dc782108', 'b2b8ab163fb0183325dd3458e3cbaad2f8bf265e', '0efb841403aa6252b39ae6975c1cc5410554ef7b', '45e1fd010aee9d7b7e68c15a7951b22508ac014f', 'b390fcf2316d60ca4f26309af859b57f7f1386cd', '0cd3f5a9830da4ff84eff3a050e5a90cba77bc57', '1031a69923b80ad01cf3fbb703d10757a80e699b', '21d29cad997d8c5ed0ad309d23ac3f819c6feebb', 'ffba4d38e1c3fe2802c0df595a5c669e7d434b3f', '273f42950468dafb689f33e337c7f6ae43e8b3af', '761c4289b6eaf95b3f626e78ed6950b29637afc7', 'aeda0531681764381b4c8b9c139ade3200e7f5cf', 'd7a1d5e6b2da522cb17581cb2016dc7ad24fc030', '31534751dbd254fb7bf6ba2f43db5dfb6b54c6a7', '42232e12695cf2e4e8a19c50b0830b8e8290fde4'}",61,set(),0,"['Domen Rački', 'D. Tomazevic', 'D. Skočaj']",Domen Rački,"Domen Rački, D. Tomazevic, D. Skočaj",0.0
be792b7ca13f9ead9ac220830d0989482810313f,Image Synthesis as a Pretext for Unsupervised Histopathological Diagnosis,2020-10-04,,https://www.semanticscholar.org/paper/be792b7ca13f9ead9ac220830d0989482810313f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '8388f1be26329fa45e5807e968a641ce170ea078', '14fdc18d9c164e5b0d6d946b3238c04e81921358', 'addae423490bbe82da4fb2fc265237178686b4e8', '744fe47157477235032f7bb3777800f9f2f45e52', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'c468bbde6a22d961829e1970e6ad5795e05418d1', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', '231af7dc01a166cac3b5b01ca05778238f796e41', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba', 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'be0ef77fb0345c5851bb5d297f3ed84ae3c581ee', '23ffaa0fe06eae05817f527a47ac3291077f9e58', '34008f26cec7fae1f60b8da38abb6b012bf83e13', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",22,set(),0,"['Dejan Štepec', 'D. Skočaj']",Dejan Štepec,"Dejan Štepec, D. Skočaj",0.0
7b7087b7452adc2fe8a874678049f591c1342c0f,Deep Morphological Anomaly Detection Based on Angular Margin Loss,2021-07-16,"Deep anomaly detection aims to identify “abnormal” data by utilizing a deep neural network trained on a normal training dataset. In general, industrial visual anomaly detection systems distinguish between normal and “abnormal” data through small morphological differences such as cracks and stains. Nevertheless, most existing algorithms emphasize capturing the semantic features of normal data rather than the morphological features. Therefore, they yield poor performance on real-world visual inspection, although they show their superiority in simulations with representative image classification datasets. To address this limitation, we propose a novel deep anomaly detection algorithm based on the salient morphological features of normal data. The main idea behind the proposed algorithm is to train a multiclass model to classify hundreds of morphological transformation cases applied to all the given data. To this end, the proposed algorithm utilizes a self-supervised learning strategy, making unsupervised learning straightforward. Additionally, to enhance the performance of the proposed algorithm, we replaced the cross-entropy-based loss function with the angular margin loss function. It is experimentally demonstrated that the proposed algorithm outperforms several recent anomaly detection methodologies in various datasets.",https://www.semanticscholar.org/paper/7b7087b7452adc2fe8a874678049f591c1342c0f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '21063765fc3dc7884dc2a28c68e6c7174ab70af2', '599fd051c9438011ec5b581983c89e8922b4a5e6', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5db790198b9acf4e5efe350acdd814238fcacaa7', '57a807f65e61bbba0ea3ba02572cc5843ecef2b6', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '0dccbb7902ddda1d32599b65f8b34d90c44dc718', '4c94ee7df6bc2bfcac76703be4f059a79010f7e5', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'be012ed29fc4fc366d6b39514679d838eec1f056', 'f7174c5c29c3904cc2d23f26be2b896a5bc715b4', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', '0849b5c9a0a184068fd3d498e09aa2ae18673add', '6fd9e3cb0cf23c8ef4aa7065d9be407c45250bff', 'd4f100ca5edfe53b562f1d170b2c48939bab0e27', '9dc915697768dd1f7c7b97e2c25c90b02241958b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', None, 'c2b733a79db700b971327a58ef42699fe8a416aa', 'bd8f77b7d3b9d272f7a68defc1412f73e5ac3135', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '8381157eae4fbf8908d0312a9642f8e69e944449', 'df9ce6851c57a2b10ad91be7a2aa3a1f10107582', '9fc17fa5708584fa848164461f82a69e97f6ed69'}",35,"{'363c81a08858df8dd7d1bde79c6e002e3b19f900', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'f7174c5c29c3904cc2d23f26be2b896a5bc715b4'}",4,"['Taehyeon Kim', 'E. Hong', 'Y. Choe']",Taehyeon Kim,"Taehyeon Kim, E. Hong, Y. Choe",11.428571428571429
0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b,Towards Visually Explaining Variational Autoencoders,2019-11-18,"Recent advances in Convolutional Neural Network (CNN) model interpretability have led to impressive progress in visualizing and understanding model predictions. In particular, gradient-based visual attention methods have driven much recent effort in using visual attention maps as a means for visual explanations. A key problem, however, is these methods are designed for classification and categorization tasks, and their extension to explaining generative models, e.g., variational autoencoders (VAE) is not trivial. In this work, we take a step towards bridging this crucial gap, proposing the first technique to visually explain VAEs by means of gradient-based attention. We present methods to generate visual attention from the learned latent space, and also demonstrate such attention explanations serve more than just explaining VAE predictions. We show how these attention maps can be used to localize anomalies in images, demonstrating state-of-the-art performance on the MVTec-AD dataset. We also show how they can be infused into model training, helping bootstrap the VAE into learning improved latent space disentanglement, demonstrated on the Dsprites dataset.",https://www.semanticscholar.org/paper/0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2b40fcc5e0019e31d599f167be0b73fbae41face', '675d381653da0d2825ae37ab06069a1525fafb79', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '0d0a810f622a0d753ef41f32cf963254ba9926b8', '7361e42c5eb0d5438c4294cc7ea3f9a53d326309', 'e3b5c2fecec38ab3a7139fcc45814073f1369248', '46f74231b9afeb0c290d6d550043c55045284e5f', 'd19356ce442d9c04625b3a253f370feaf00ea6a0', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '35da0a2001eea88486a5de677ab97868c93d0824', '4d790c8fae40357d24813d085fa74a436847fb49', '63cbac5a39cd926a806f60116b845f9bd70f5544', '6fe99c4969c2f2d3dde8ada84e7388d74eaf0528', 'e8874d7d585ae1c355e186efdcc9f704b3d43b49', '1a2a770d23b4a171fa81de62a78a3deb0588f238', '3f32b0b933e4b08e735240d95e099837bb05f679', 'be012ed29fc4fc366d6b39514679d838eec1f056', '8acbe90d5b852dadea7810345451a99608ee54c7', '33469aa1130c6bfb838fbb6216f5c42c483a2799', '89583143a04d7f02a45e0831a4fc55eaf090573c', '208ebe27e70640de8a94f0638fb13bfda71cd943', 'fc9d85cdbe303a41a6224f63527af47cda9d4bb0', '6af440915b8a0718c93be1cf61905e41e620484a', 'b4397fb367c3d0db46cee0e250706f9317494809', 'aae932cf9c2434f52b03991fcab050a61a960d48', '0ca6cccbfcf3df972a470c7fe18f7eaed9420cd6', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '5694e46284460a648fe29117cbc55f6c9be3fa3c', '11211bb7f7528a4d718d7abbe4981cc28eda13d2', '2d20253a2c87c8c6a30441051a373d6ce269fb83', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'a8f3dc53e321fbb2565f5925def4365b9f68d1af', '441a95b80875c7fe0ae98c5d301e2c92feb4c191', '731a2844c5af6b072d3b404ecabbb488cdad9d46', 'fd7c12e1eac960a4b4e7d72499c94b8eb747eefe', '32e277b85802685105254430c4170ad2b1a16c04', 'a90226c41b79f8b06007609f39f82757073641e2', '04541599accc47d8174f63345ce9c987ef21685b'}",48,set(),0,"['WenQian Liu', 'Runze Li', 'Meng Zheng', 'S. Karanam', 'Ziyan Wu', 'B. Bhanu', 'R. Radke', 'O. Camps']",WenQian Liu,"WenQian Liu, Runze Li, Meng Zheng, S. Karanam, Ziyan Wu, B. Bhanu, R. Radke, O. Camps",0.0
3c74c79813441c3cd9926b92b8ff2418f1b95ff0,Anomaly Segmentation Network Using Self-Supervised Learning,,"Anomaly segmentation, which localizes defective areas, is an important component in large-scale industrial manufacturing. However, most recent researches have focused on anomaly detection. This paper proposes a novel anomaly segmentation network (AnoSeg) that can directly generate an accurate anomaly map using self-supervised learning. For highly accurate anomaly segmentation, the proposed AnoSeg considers three novel techniques: Anomaly data generation based on hard augmentation, self-supervised learning with pixelwise and adversarial losses, and coordinate channel concatenation. First, to generate synthetic anomaly images and reference masks for normal data, the proposed method uses hard augmentation to change the normal sample distribution. Then, the proposed AnoSeg is trained in a self-supervised learning manner from the synthetic anomaly data and normal data. Finally, the coordinate channel, which represents the pixel location information, is concatenated to an input of AnoSeg to consider the positional relationship of each pixel in the image. The estimated anomaly map can also be utilized to improve the performance of anomaly detection. Our experiments show that the proposed method outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for the MVTec AD dataset. In addition, we compared the proposed method with the existing methods through the intersection over union (IoU) metric commonly used in segmentation tasks and demonstrated the superiority of our method for anomaly segmentation.",https://www.semanticscholar.org/paper/3c74c79813441c3cd9926b92b8ff2418f1b95ff0,"{'2c03df8b48bf3fa39054345bafabfeff15bfd11d', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '1a00dc525da31292e3734cbae2de681f114e30b1', '8381157eae4fbf8908d0312a9642f8e69e944449', '51cdeeef710d1c84e10beadc8480c137ffe8d328', '571b0750085ae3d939525e62af510ee2cee9d5ea', '62b77e5cb85fc61b84edd532f6d65714be152596', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', None, '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a'}",17,"{'62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '41747cbdbed84762dfbfc305254c97021279dc6e'}",5,"['J. Song', 'Kyeongbo Kong', 'Ye In Park', 'Seonggyun Kim', 'Suk-Ju Kang']",J. Song,"J. Song, Kyeongbo Kong, Ye In Park, Seonggyun Kim, Suk-Ju Kang",29.41176470588235
30b99ae0682d42a2010be401dd1d8f7baca9bb5f,A Unifying Review of Deep and Shallow Anomaly Detection,2020-09-24,"Deep learning approaches to anomaly detection (AD) have recently improved the state of the art in detection performance on complex data sets, such as large collections of images or text. These results have sparked a renewed interest in the AD problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review, we aim to identify the common underlying principles and the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic “shallow” and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that are enriched by the use of recent explainability techniques and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in AD.",https://www.semanticscholar.org/paper/30b99ae0682d42a2010be401dd1d8f7baca9bb5f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '99382657c0afc9e8946c45e5d799281e0e9adc7d', '659728df482951c392562ecf8efaa1ac24a468e4', '3c052b0dfea5b654dd5ba6a9a7bb2f348a6b9deb', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', 'db787640c9b42416ff8d7015546e667e58267177', '1322719978980a831e1aee78aa80a141379c44dd', '195d0a8233a7a46329c742eaff56c276f847fadc', 'cac33f91e59f0a137b46176d74cee55c7010c3f8', 'f13981668a98173bf6b49310f171a2093167a027', '2ea785d090f88f54473806eb20670d79d62fa5f7', '8976e91ccae57a20c29f3c9d88bf45b19973c952', 'fb09c30909f2e5e0665edccca28b031df591eb48', 'a4cec122a08216fe8a3bc19b22e78fbaea096256', 'ebde1dd5ece38b9e5654c5a39e41694b1552a82f', '04513c7c0b3a63fde81a996dae064a28d453c17a', '63e8beb91117be84709811ca1a4ac9407e4245c7', 'f56faf5b807cbb0aaa6a22ee25a4eb6e431a46c1', '10a498003e9204f5fc1328e706510a37e514d8c7', '2eb2320ff1e1a109d9c8bf0d53b3edc370d4cea6', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', '964465406626125ce235faaccf25e265c56f501b', '5379a4f29127452e67e07411ac0ef91fd6a19fad', 'ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba', 'a7c828184693a453a6c2867dee233ed054b2012e', '3440f10464a5017cd21133ec60090ff80ad2abdd', '9552ac39a57daacf3d75865a268935b5a0df9bbb', 'ea36358e4363fa452b55de2325ceae9802a51d81', 'a1f947eb629f3dd9cb734fadd1cda31187424c9b', 'a790f659df2c286a63793f8f2e12aaf56247169e', '90d91bad87a53d82f45a0153dc0f82c3e6036741', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', 'c564aa7639a08c280423489e52b6e32055c9aa7f', '1d033b30f38642e4b6dd146bb8b464bfb58aad96', '71df4b737c35fb3d05f44036419e78b5330b580f', 'ae74522002f9093fbf63a20efb57d80ee2f4f564', '275aaca7621b2ee4ff81cd37162f6c9a90f306e4', '3d3eec2b29f705c7b044b44497302d39596b5554', '3a98ae164076c60ff63a1281b8c323a4f5ed33d7', '9acc51b06f54b07836fad4cc24633187dc21317f', 'bcbfd96098803f3530779fbb9b7eba772d1fc24d', '355b4e74774798c177c82943eef925d66a2bb2ce', '1fcbefeb0beae4470cf40df74cd116b1d4bdcae4', 'ca04f6fb87815426e1bec8f7fc0dcbbaf9f35814', '5dce96b15fed603fc191bfbce912a33d21143c8d', '3bb5a439a0d610a7eac68f73068cdd278b8c9775', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '595aed9aa694565348794782a3ebf8344ced529a', '1d9c8cec327ab41aa2e87c6888c51a76071650ce', '39361b3507c9f8b0a97780568b645f80a208d78a', 'e86f71ca2948d17b003a5f068db1ecb2b77827f7', None, 'e264c151d5929642970e8d41b1d0946e4182c4a2', '56ba633b3d7979f8ee2119372db9a9b05913c24d', '7d16801e9e9346edcb444589d201b041854ccebf', 'a9f7e6743220a3d3f1a86921cc61bceb4ece0918', '261e81cba749f70271fa4b7e230328fc1a4a6c96', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '4c729c317045bcf2a85cfc3157225e61c3cb6c1a', '45d731944e809b86e7e0b0f1092c38563a94a11b', '29c9f747ee075b839a6a2c43c0c6d825b787755f', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', 'd2b62f77cb2864e465aa60bca6c26bb1d2f84963', '086015aa2c44bd2ebd95ab6a1a562e57177c7fa8', '843959ffdccf31c6694d135fad07425924f785b1', '853a0ee6f891ba8217600e19c68f60ad39ed9524', 'd837267b364b4dc97bb35facda235a19be5ed374', '5f48fa873b5a9cfa32952f885db2f6ea91dce18b', '3adcfd254b271bcc2fb7e2a62d750db17e6c2c08', '0469f92dbce67ec4444d094e818eeebaaed3d8d5', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', '6d61a7503c7eb0730f70865a08090b210a078127', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '66a541054ae33714db8c6341ff5d97d8436ac425', '7568d13a82f7afa4be79f09c295940e48ec6db89', '0f810d38b26a7d1c5c7fddd7879b4ffa5fdc81d4', '31868290adf1c000c611dfc966b514d5a34e8d23', 'a8ad5657a52f549523fb5608c7a78801e8b7a950', '20ba55ee3229db5cb190a00e788c59f08d2a767d', '5f3767b64261b0150b554d8c2e70441d512f63ce', 'e1d7afefd8f1d107bce9cc5f9a4faa5d4f207264', '495fb0eba265eeabe1f6fbc3f7f934b3f9903b90', 'f076e4355c0facf111716dcab2837803367dd2d8', '384bb3944abe9441dcd2cede5e7cd7353e9ee5f7', '3e5069a058a11a9a4ed77cb9ee65cd681c6d8356', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'c844c679babcd5c399397eb3f2600007943aace6', '359dfdfea38f645d5fa49efc846a3b5ebce317fe', '2abde28f75a9135c8ed7c50ea16b7b9e49da0c09', '154df96b95e8b9635771442244fe48b125933bb1', '45557cc70cd6989ab6b03e5aeb787e34299099f7', 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', '1ed33896e82cc3810b349cdffc2039f0b8edd82e', '54c35ae24a4d6a48ef691baf17f1441a17909181', '6af440915b8a0718c93be1cf61905e41e620484a', '378927c2709643934e7ee48e812e410223a73ae3', '42ae24e5c7561f3b38084743377d5b5d6b8a8b61', 'f30b10bb58e49138cbf33e625746c87b662a9e7d', 'e3ce36b9deb47aa6bb2aa19c4bfa71283b505025', '6ff2a434578ff2746b9283e45abf296887f48a2d', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', 'cc384cff27d8a609f89f9e915c26bf31c39749a1', 'b94043a133e3d07ed0b1cfc036829e619ea0ba22', 'd65ce2b8300541414bfe51d03906fca72e93523c', '32d8a10c47096fefe17a68f3166059f172ad094e', '8ff840a40d3f1557c55c19d4d636da77103168ce', '41554fb139c9eee976d43600168e38eb5305d532', 'a4f44dec593425345b95ff3ad3b6c02b03e5b791', 'f753af1e0709a700bc7f7aa3ebdc7d49a06d8ef1', 'aa6d323bd08aea5d61a3c68466e863cce1db0a02', '70d3bf78ca2d9f4582c9d3e5aafb539de05ce13d', '87f40e6f3022adbc1f1905e3e506abad05a9964f', '388645c44061f6e88fff0ecdad2f622936207d67', 'eae906e4375b70900192233c376ba014ec32cdf3', '1c9932feb06a3b873361a3318183396214fba4b5', 'b110ba174df21a23a9521731d4181261ca5860ed', 'b07ce649d6f6eb636872527104b0209d3edc8188', 'e2f5999b5898f8674a6fd04eb0420e305641d8c1', '1d4ec24a6da3be62dc5d7efbae2a101c63f187e8', '93724b0c210401d8e93aa93cca2ea2993efc0845', 'b83a6c77e61a38ada308992cc579c8cd49ee16f4', '2d09a9dca14b4f24d82cac9d76d81967432f36fc', 'f466157848d1a7772fb6d02cdac9a7a5e7ef982e', '3a83d8595e6727269c876fcebd23ee9ddd524b76', '2f85b7376769473d2bed56f855f115e23d727094', 'd9f0e1c7e240597992232840f7cb96ceeefa1940', 'df40ce107a71b770c9d0354b78fdd8989da80d2f', 'aeed631d6a84100b5e9a021ec1914095c66de415', '9896835f050121358372254a9bce57ca117672c8', '948c81cb849299b099c97b3220e4f680e1f1e4da', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972', 'd46155be59bed4d7d2082b02bcb6734a6d66c428', '92584dac09356c3c2e915932956bdc06f91d453f', '62adfea3cc1cd9eb6b53e0e8a40be5dfda2adf8d', '1cb7d8ede56d077eb5dcbc25bbe1d95999341060', '97c651d906ab8a9068d0d3583e50bb45ffd55ae5', '25761fd27d2ffad21329e85987dffa57a13de39f', 'd2fe8bdc0d638ce6f082b4a0cd08d999f4e9e8d3', 'd783c15c5468ac47d6e52f722742459ae800043b', 'd4254d9a938d238182ae55eabd79367404d6ea2b', '1d011918890db7c5fac80c152488a4792661f434', '967d532a66dab7edcb818b0f9dc59fe8da7dc171', 'dc8301b67f98accbb331190dd7bd987952a692af', 'e4a85af3f5dc41e13dc2cae9ee851953709b764e', 'e15cf50aa89fee8535703b9f9512fca5bfc43327', '0e1f153576c7f9f2628cdd34a1067c4d26bdc096', 'ef550f9939bc0b866c16ee2b92dfb6db043483b2', '790eceaa2cb59fef2634dad40f628346eb07cd3d', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '62f43b69f719842a9b6871b8fb3ad2f8bb38d169', '9360e5ce9c98166bb179ad479a9d2919ff13d022', '3621fff4a1c791901ea4a1359c10575193ec712d', '4bd4387e35ffe7d3738589db987cb32c16b30b48', '0fc425a8004830fdd7f207efd4fa7a2331d56d3f', 'da1fa5958aac40af3991eb4bda2ebe4a221be897', 'acdb866055fc097a07cde1fa74e991f2d1397479', '2ae06ae7126debdff634aab69a133d4c808c1f78', '45efdc94fc601610907322dbfda3777e44dce8b4', '4f51a64793d3b2a60e9e5846c31dae023cf5c69a', '9aaa6f6234c39253103744e90b117a28713b3882', '575a0e97702edcb0621a47b574949bac50e34200', 'c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d', '03b3f0b58e14d7840303e52b17e023fb54667fdc', '353ecf7b66b3e9ff5e9f41145a147e899a2eea5c', 'e0fd47d54bdbcc2a0fc4755d873245cf8d4d7814', '7aa38b85fa8cba64d6a4010543f6695dbf5f1386', '79f618ec9ea278efb3381375d41f83ddf964edf2', '7920674d9c9bbdf9893194ff4fc9c3b28f4cc1ef', '98b4d4e24aab57ab4e1124ff8106909050645cfa', '5ad2476610312f380dd4e6475ee706199560b21a', 'b1cd46e5e559cc6513cd3977cfeb066f6d893174', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '3538c520244b508945476f0814d2ba1e8f22307e', 'd891dc72cbd40ffaeefdc79f2e7afe1e530a23ad', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '7dd86508438657ac7a704a5d952a2a4422808975', '197be27fa6affc400c987c39589692ba5c38cee6', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '793fa365083be47b0e92e35cf19400347acd7cbd', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '4ed2257c125ef90346ca6132ffd958d585c70e51', '484ad17c926292fbe0d5211540832a8c8a8e958b', 'f7e72483714da394612298d5855185f13fe21ae9', '34db624a496cb92717e911ca6986d977aa541fc3', '15d1838111f327af5d7c7c56fb887e3cc6d95fd3', '35b0f627a040705c8e0feddb53743cfda68a44a2', 'e7c883497fd3e9838ead70ce97b1f53331cebc70', '4b76b63c25869d87228f3838b6e53dc78be8eed8', '83fcb78e3b58c230a051914daac3bfb00482b34c', '24741d280869ad9c60321f5ab6e5f01b7852507d', '4177ec52d1b80ed57f2e72b0f9a42365f1a8598d', 'b6f7439fe287dbd5a58e27476e1053d393d81adc', 'dd97aae76c7d210ff6a88607996ecd8ddcf22b60', '70f9968a356d840040a1c9207906f60376dc6bd4', 'f37e1b62a767a307c046404ca96bc140b3e68cb5', '271f03dd2ad25328832732efc8d8724b1f56574a', '44e1dd74f0446ec91221189ad3a65edb1a0208fe', '4cfd8f903506865e7ccf28b0a07ee3c551487e92', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', 'f302e136c41db5de1d624412f68c9174cf7ae8be', '23f9220e0ca8f2cb522c36d158ca88f043007c68', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '5f4e09abac0f83e19a21f9987bd4d81ca5f2eb1f', '81e4cd1855c9f068f5de593d878dad95cb214546', 'd98ec42c5bc64b06b5d6e259467528e0121ae69b', '1f4294d8e0b0c8559479fac569fc0ea91b4dc0bd', '599fd051c9438011ec5b581983c89e8922b4a5e6', '906ed11d6431ff32e90476c0acade160ab1c9a70', '4f5844c9e7db68af7c2c5b918082636c3307cef9', 'b6e9a37ea173b363693688a1f6d6fa0ecc9d1e97', 'e24c0387fa0ec3c32ebc97c050c94b8b01eeadd2', '9b97401527af0ebcf23b11bf57094c49553101de', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '4b07c418a40fdedbefeca7e78afe2b8a1c473537', '0da52a5651004a7fe0411b036cf898914b672e79', 'bf38dfb13352449b965c08282b66d3ffc5a0539f', 'de86c61defbb8c259583074f3cf63afe13571ce1', '17fa1c2a24ba8f731c8b21f1244463bc4b465681', '355692eb86b06a0a23af45c106cfb02c95bf380e', '1d7d0e8c4791700defd4b0df82a26b50055346e0', '45aa47293d70bbed4d93725ed9858bf6dfcd81a1', '53df899e1a18082b8654677b4c0aa95dbd96f0e0', '75c73d6e4b1cbc2aa906889f2a5c99705b6a411f', '2bb4de055c148568660573e82505501d9773c650', '60ffad108980bd0931839eeb4393880d605a60b5', '46918f499b2c5dbd177eb9da124da6806060d6e4', '2309f7c5dad934f2adc2c5a066eba8fc2d8071ec', '803d421305e07f471f0d0fd278d6043d26763767', '10f8d1106e49fa07c1dab8bd200e76896ee9dd13', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '888dbb50bd63a94e349081b27b78c671607452f4', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'e192324faad5885d2a409ac1c1b4b20aa4ca717f', '0aaa5f51faa9a5c03f788009cbf2288988880278', '32425327592e082bc2e1b6f3df019dce1d4944b6', '9e66b328144102f57f14b5b47620d3bc19c684b8', 'fc36d50be4352afada233f55a59f0dca0a7a826b', '058bec13449f05cece18c3e32040bb388b049a7e', '69e460953d9b13aded4d906b974c0d80c1ceaef7', '82a3fd4b689f386b3f4158fc767c1848d09abd7d', '2ed7cc027367295b1a7d7cd49406acfa5c580138', 'aa109a5c8440332a05ac538d98c4f93d25500c81', '31b38a19d87711489786ad54a5a00d5f0b2ead43', '22c0bf46726ad1c90b5fac7f16638c813e86c829', '9cc912ae25797e5f7c0d73300d3968ad8339b411', 'dcd5b17b26c028b574cfcadd0d4e47b8d169ce5c', '43d75d3a22db904d052d4c435e2d1f22be3887e0', '732dfd5dd20af6c5d78878c841e49322e1c4d607', '136dee73f203df2f4831994bf4f0c0a4ad2e764e', '8201e6e687f2de477258e9be53ba7b73ee30d7de', 'f9c5cd2d6ee66c0133ca8ca415b3b38a914614c6', 'e58d9e4117fb905d241fddf7c93e6a9f5f00e5fc', '863efef58318bdc21986470200f6d4f2d206e039', '0e20a8346ee9181ba7ee27e857bd7c09ba34f8ba', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', '4bf95e8a116734cff3f5ba5c146df1770dc9cfa3', 'a4c52c6c4c852341304305afe909ab466551d0dc', 'd40ee5dd758c525dfb9932d726bb4e844b7b8478', '79aec905ae2bc04df612325e89a1a24bada52052', '730966f44d4e7eda143f3cb4dcb8e4a01581aae8', 'e3116ebb52c152deae918a04c34441ac0d956b8a', '2c20e7220269b28fb1935a83d0e7f2db330aa691', 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', '36653f8705b56e39642bcd123494eb680cd1636b', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'ac84f464aa17bfabe676646ffe33941ef01d2402', 'e2dba792360873aef125572812f3673b1a85d850', 'ecb365ef9b67cd5540cc4c53035a6a7bd88678f9', '82d5af4167948027efb3177d1fe00322cbee3bc1', '0e5f3a914302e777ffaa9306e8cb0c857b21fb9d', '9cd4bb5e3f78da1d0d27a97bfd7dca80ac0b77c5', '6c405d4b5dc41a86be05acd59c06ed19daf01d14', '8012c4a1e2ca663f1a04e80cbb19631a00cbab27', '5f4c2600317338978041af2aa9101f62d9f6790e', 'a1e33c9f79f993cc2f7d917d8cb6baee095c570d', '7fc604e1a3e45cd2d2742f96d62741930a363efa', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '7c46799502bebfe6a9ae0f457b7b8b92248ec260', '759d9a6c9206c366a8d94a06f4eb05659c2bb7f2', '4ca507758234dcf754a7adc458dd574b70a285d7', '50fd3df75cdb9de03ebb2cfd2f24fd61a8681f48', 'bc9293bcee13cae5cff8a088f4038c4236decd42', 'b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b', 'bdb527bc3005fd18e20bbd8877d7bc246461a783', '802168a81571dde28f5ddb94d84677bc007afa7b', 'e64a9960734215e2b1866ea3cb723ffa5585ac14', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', 'd5051890e501117097eeffbd8ded87694f0d8063', 'c2e95dcf4445735c060d05262dd2ac0738e4e73d', 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '333e80cb1be31236c6b20ab7813cb264604d5d9f', '5b59992ca6b77aaec066a0d3142336d2cb1028f1', '2a28b9e66d1b65805f90e101fcba71c1af813be8', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', 'e1715a0f3ba06e34f0745ce114ce0f375648639d', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '36e4eafe4af6cfdc66e45c51f2309a14aa3b78d7', '3dd9ddf2594d7d63af5d361154992ef2abf6d593', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', 'fc70fa3bedc32c0f49c42f0822788638c5847c79', '8765f22fbcdcf610a08b01db01edc4b8cc67d082', '97eebd000dff5a370f3e42b8d0fa89063371087e', 'bbbe62e768b626706727c5fd2eeaa7a78c032ece', 'bee570503aaa0ed5bc5dd4cf6aa742df0b5cef87', 'beb7348757e0fdd2c2134886434031c8b6f2963a', '1ffcb27536ab5436e6d753919ab27ac1a44b4b69', '0b544dfe355a5070b60986319a3f51fb45d1348e', 'd9665992ee36699b8ae4a2e2294552cd4be9003a', 'eae7d5b15423a148e6bb32d24bbabedfacd0e2df', '6c2b28f9354f667cd5bd07afc0471d8334430da7', '2805537bec87a6177037b18f9a3a9d3f1038867b', 'eb42cf88027de515750f230b23b1a057dc782108', '9d26f0ba02ee5efe9b9c7bdcb5f528c8b8253cf7', '69115684eb15614b1219366ef93ddc23682b1cac', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'd1aaf33e8ff0824d80bc6346693d2600003aabc7', 'fbf26e1085ac3b038f47d4d1945ebda45d5e57fb', '85021c84383d18a7a4434d76dc8135fc6bdc0aa6', 'c4fbd107e50156b9cf54de651db7e34abaa183c7', '21c627d8dcd976f48ff513c9c8b8e10e1fa1469b', 'f02218771a8faa4b2d59588a46d0c40bfec95176', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '7cf5dddc831dacdbb9a1ab5553c0a6e99ef64623', 'ca9f84c3922004ec6133aa9c2048ceeb17702fee', 'a724bb040771307571f3ae1233a115cd62bb52be', '2c6593059a852eb234fc3d118afe438a110de7ed', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', 'a1b5a7548b14153daa11468f0390b7c30111362e', '6b99cfaff4b0be4e07c4a2353619d47b04d6ae05', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '431ba9fae8fccad1665979d455c6307786e47318', '098d6a714c772f7fc099157fc8bd9037f9bade65', '9a7e0641b0d47145e1ea3742b6bafca7a786128e', '996a8247c9f6710e07e978fc83dc828fb2fe222c', 'aaa76e15235d937d093a7063c0be86ed84494dee', '03ce834859d360b030829249c068fdda9939fb90', '64f260cac1a9b2240b748b8106d2339f25b98565', 'e716698a6d28e7a47bea9b25dbc5df0da2d07158', '317aee7fc081f2b137a85c4f20129007fd8e717e', 'ff4b3bbb455c9cc561ddec097a869140b3c1303d', '00695a31a80221c7125e49885a4767896ec2c4f7', 'd82b55c35c8673774a708353838918346f6c006f', '329b84a919bfd1771be5bd14fa81e7b3f74cc961', 'f07d6814c33cd3384354a29d1d413b10540b10b3', '5712edce918859a9b22471dd0ed78ef4ea1fc724', '5f61089d3d548a515f01b473f0119137d1f340d4', 'dd8eb6662c515381ad78059d59c85a1e70fa35ab', 'e98236e37049b46453c7d78f77c8cfaeefc0bfe9', '966c4df32a99dae7cec240e71e96ccdb5e3806c4', '6fa36fc00ce2587b5f702bcdcc945fce8a3253a0', 'da6057368920585bcf2443295b98418840f1fc80', '9a679663be4981d99b79f28dc946ac24344935d6', '429f020e5af8d3c12d5a7a4f3198ddb32a8c2419', 'b6a3e0028d99439ce2741d0e147b6e9a34bc4267', 'a90226c41b79f8b06007609f39f82757073641e2', 'bac43b8b79b69edeb7cefe9e6f57c6ec70c889cf', '27222787908c3a1c6fb6c4b5cb5ef8b2542f1b3c', '22e8bfe5dc2f29668f5aa9769d7df68bc1d23838', '075c541203ffdfc29d48abc06bde2a0f6a97be16', '6e4e75c88a0801c87f47a171aa69a9914f9129bf', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '16d70e8af45ca0ae2c1bb73f3be6628518d40b8f', '96257114fe4c5f7a4b682958dcf55c72cafe2a09', '3febb2bed8865945e7fddc99efd791887bb7e14f', '846e4e85bf83656077d6c5be7e31cd823dc24291', 'a9471eb5de84eb5648e794ced25ed29526cb24c5', '3e8ccf9d3d843c9855c5d76ab66d3e775384da72', '20f69cc41c87b8abdf36761c623d65713daeab3b', 'b68c34c55925a75804f97491b745de66b1ffc4be', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'dcb207ce848b358aeb2e4698c9ea1ad273ce98db', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '8978cf7574ceb35f4c3096be768c7547b28a35d0', '94f7f1ccd7e25c4d5f997d66365b00231478e987', 'ba3fff783b5e6d0ed4bc4fda2735de02ea870e3c', 'ebb5eb554b887c0ffa8fceea76a1d63cc2b81898', '94192bcdf3507e3543910c03b16bd06c5338fd47', '67628543f7ae51979acadfbb8860568b25f263da', 'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '6be216d93421bf19c1659e7721241ae73d483baf', '69c784da3839474fc7274f53609e0e3049cff5ef', '571b0750085ae3d939525e62af510ee2cee9d5ea', '9c5c794094fbf5da8c48df5c3242615dc0b1d245', '9e85c7a651663039c557749edf260e7b30c55e00', '43b329f879b16c17d8699c755f4ecc5d40408904', '89d239cd19542b72818c8973b64dc5d578191ac9', '5b8013f4425b6b889a514e95fe6355a83c64d1ea', 'a57c6d627ffc667ae3547073876c35d6420accff', '1eb7f46b1a0a7df823194d86543e5554aa21021a', '97cd86d8d8c0f27cd3e64c6ca5cfdeb957ee39f4', 'da32b5d34ce3710efcbf7f1008db2050c000ec56', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '0d64856887512b728e24a762086e8a97ea6eeb59', 'f134f7976191ae4616342878dfbfc2ebe0c0c5c1', '2edf3a49bdbbb630666c51be9b856d613c9782b3', '48ddd9101a90fe65e3061de69626741b843ff5e4', '62d43f751659e7bd1f869768e7f392da68d7ee15', '424c3ab98f1ae2d9e9ecf892e15a12c09f4e9ffe', 'd094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c', 'a0f0a94927c0013fa924ee43c8ddbace1d71e3fb', '1ce38ff6a6801a0a7e0ec1fbd24503d7a2142fbf', '86275934c44eec65ccead5a52a1c48c198de34ab', '651adaa058f821a890f2c5d1053d69eb481a8352', '2a71fb5e47141d86458a5a034a3d152c8e0bffb6', '5e665a933a408d39ba3a432ac537e6673f3b0cd1', '8faad7901db9a73cacaf92ecdedbaece87d95f92', '5276b44dfa828959096e887969f2721d11f5cf2e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'aa4bddbd10eafd8e1b54338517eedfee408f03ae', '111fd833a4ae576cfdbb27d87d2f8fc0640af355', '3185fd6ca0664a06ad0db58ea92142f0e97cb89e', 'cf552964a6f7eb63fa012e55308c6612defb65cb', '87c280d0dc204ca5db0d325991a21c211aeec866', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '96bd1cd9b37cc9eea6ecc1b46afc29f95a10d424', '2c455f0da2bd86a9b9ea432d1485049073d7c63d', '5db790198b9acf4e5efe350acdd814238fcacaa7', '4b67b6a9b2b2f625fe6d69d1e522d779ef878eef', '7d3e76a1f129b49ff88a84d0eb1c32b0f83f74ad', '4ecc1703dfa8cf20767321746a10524ab733493b', '5b55d69c4b5f9a371f04944453283ed36ddb90ce', 'c6a1c78a64227dc353ecbda8a5552c814db178f8', 'bee2aeac46f73e14105a3205502de9879692d3fe', '6507909a8f77c88144c3a67b9336bd1c85e84cac', 'cb030975a3dbcdf52a01cbd1c140711332313e13', 'b638657cf00bcd705d968c616e50d36f9c6738e2', '1b84b0b323c4572b065e41d8dc282fda03f2338b', 'ff7bcaa4556cb13fc7bf03e477172493546172cd', '79f85457eb8e03fce11d2cd9a79a91aedb9d565f', 'a8a28239577cefc801a817975ea4f1607aa4d9c9', 'fa5853fdef7d2f6bb68203d187ddacbbddc63a8b', '435c170edd031b65cf9087cf3c8473f071477df5', '2d3ce845bd2ad9014fbfa3f00a3284a4048bbdf4', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', '4e6238c8613b5b81f81552939bce33296aedfbfe', '3f600e6c6cf93e78c9e6e690443d6d22c4bf18b9', 'ca4edb65a0664804e4819c5c809d0dfba9bdb2df', '09c4ba8dd3cc88289caf18d71e8985bdd11ad21c', 'a4bb027dd9f9ef23244b5e0918ef427c1cbdbf1d', '0d98fd878be87f810d73d0f415d36debad87d860', 'd7b968f3c9356e0a8d6d295d5eb37cdc748e64b9', '05e882679d61f4c64a68ebe21826251a39f87e98', '675d381653da0d2825ae37ab06069a1525fafb79', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '314cb3091043a47d8d10ec08313a2131d3ef3238', '549e8e5eea04b301cbb805f5502afffef492d344', 'ae3f31c841c460b15a81bf51655f4c0e39cacc79', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '71a0d7f73b2d2477ae3dfa4abf9df4dcb6d03117', '08f886674d0a0a9d8eb87d3c4f57a31c4f5d132e', '3ed8624298e7c8947cf0a4ac987e412170aed4d0', 'c62043a7d2537bbf40a84b9913957452a47fdb83', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '2095f4042679f211ebbb35fb7a6a55166abb3334', '7c3870e4c6f75aefeb7801c75026cefb512304f6', '5d1596adeac9a058462aa70016204b3dc1f19d93', '6b85b63579a916f705a8e10a49bd8d849d91b1fc', '17a273bbd4448083b01b5a9389b3c37f5425aac0', '5096d5817c4ed89635d9f065c79a44a2601e939f', 'e5243a084492250f1d662897a65016df56c72f51', '193edd20cae92c6759c18ce93eeea96afd9528eb', '42d906c733f273109c0ed716a5ef6e2a379beb26', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '892e53fe5cd39f037cb2a961499f42f3002595dd', 'b959164d1efca4b73986ba5d21e664aadbbc0457', '1134a0e4d079ea1a6d32a75022956491a561e601', '1813ef743e31864e0a02dd5b8ede628ab508141e', '2c44f73d6a0f99cba0b387064cabb710a6bb1daa', '74fae15b0aa3c67d700254d3bb806b935dd410cd', '4f180e8a1a2ea4b182719318bd6fe4380aa4f52c', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', 'f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6', 'e010584f68816b306fa038ca812d0c8b4ba011a9', '450e2decdba98cbaaa403d433df53be775389b9e', '62d5807dd20f99fabe41b088a5225a6d0fe9ee46', '14c277610ce63372fb44163140d6457be84663e8', '18bc1d4271abe8dd6e16179cdb06524a4f396e16', 'a41efad7ff629b8db586dbd140fe1464532dc406', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '732c21998e251d64cd58b6a86886ee5907efeaa5', 'e1211e7c0a9637418fca12eaaab9ac9a1bbdbea6', '696938f50404661092c3cad68ef8efa25d76f647', '38e20b356f12392e8165feb5ce50be56b77c03ba', 'fd17bd9a5dc24a081ad9743570f50dd6750f54b2', 'bc8725797fd8c7532b6c32524fdb84a334c64716', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', '0af9abdafc0b287e0e03c3af06d48d0da17522ef', '7f5fc9db054e5bf6da0cec0da3bb0a47766623b7', '9eb1b16fbd4786eaac91f308d75609b9321868ce', 'cc5afe344cc7ed7acd68a28b9774ea8023a162dc', '25badc676197a70aaf9911865eb03469e402ba57', 'cda0324c7f815d53d75149ea97b122f15e5b2f1c', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '780235e404923ef3466024462cb0704c70de8e9f', '8381157eae4fbf8908d0312a9642f8e69e944449', '03fffbaca597aaa740ec910acae727976f9bc19c', '4db2f23a5ad2259b90aa9b0545d27cd44337515a', 'a8db789522b9375396bd91de631342740ba19a12', '184ac0766262312ba76bbdece4e7ffad0aa8180b', '66773ecea49a061fd5dd6561e0e36afa8cae54ba', 'a3d1937f3416ac7281adf22bc3d9c5cb3e007b0a', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '153a99ad39e85eb09f6ae56b1eb72795265cb8a0', '3056add22b20e3361c38c0472d294a79d4031cb4', '06671547fd94c44688b10c8cd550242557e55154', '3e00dd12caea7c4dab1633a35d1da3cb2e76b420', '78f9c5fdf3e7ff3b0163abd50e4838ffdeaf67ce', 'ac0a59165ee2ac666b1880316eefe349b87f6ba0', 'aa5741c74b7fac10680c1cfbdd49d9ffb5751a68', '105c373f17248112d68dc9bd2fa7342aaf7f83c1', '50c13e845ce77ec46416ca163d90865f9195d40f', '6d12a1d23b21a9b170118a56386552bc5d4727de', 'd53d9f84acfd9958084784f890df3e7f666298b4', '5187df17503f78c7e063c2ea0a707e3e59c48235', '9ebb5c0d6d54707a4d6181a693b6f755ec8a45a9', 'be94fe9f2414639cd3f6cef0fdeafd4a10d1b2e5', '59bb8d6c3eec8f925710db4d2488e2a23167d3e8', '00a1077d298f2917d764eb729ab1bc86af3bd241', '547c854985629cfa9404a5ba8ca29367b5f8c25f', '62ef7585de2a94ac18e51ac1c6396496a9a94498', '411837ee33b53a44db20f60427960b6001d8711c', 'b87274e6d9aa4e6ba5148898aa92941617d2b6ed', 'f44ff4fc0ed0142cb18472a5ba421bb538aa837e', '199ee1e5705ab5cc6041f7fb91ea83f348515c03', '0bdd74925d662a78efdf130d953dff97a131d12a', '211c9c65b2cc31f7f2b0a0b6d805846b437da15a', 'd8384f7ef288d2d5cb267128471c5427fc98b54b', '3af2d34cca85244ead2d4be994ea074a05d43656', 'ab08f2a0b98fe7938d08875eb6125fa518620222', 'd612d7c21d4130a457968273d79c2c2f6946953d', '8c25071e5b2045843c4cab3fb9f51b7258347236', '7a8187efe5b42fca7d5b04149e0c140dabf770ed', 'ba10c37a6a24276f5e67a22a71d0d511c01cf5e1', '1b88e9567c05701a4d7023c86b4e36685db88372', '25c61beda55be5a1f665190384971980afef5386', '6b6360c6d2bdc55360925445b77d21126b477e9a', '6658bbf68995731b2083195054ff45b4eca38b3a', 'd8566c59824db615bece24944e0aba09eda303f3', '4bdf6ec7229d307d172e6cce48052b11524b8789', 'e9672150c4f39ab64876e798a94212a93d1770fe', 'e791c35e79d2e61a9760d841e8a1aa860c072de3', '73f76a40ed20aa3c6a8e27e4db4a8c102e7b4c6d', '5091316bb1c6db6c6a813f4391911a5c311fdfe0', 'bfb428ef50370deb193a7775c0ec8068c8f8c8b7', '281d048689bad12d8dce8316a61c31b15c6f50de', 'a002e71561c90767240672f357b7d9e6d4d95186', '28f7cc049f3f4a4db81f0d0a608a4f57636cc35b', '919c38984f3122973cc7de28e510508e65f9d692', 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', '021fa253ebd9c5d78ee52b545a1ee915f0dafe27', '0e7af8e91b8cb2cea1164be5ac5d280b0d12c153', '501c02c7caa7fc2c7077405299b4cbe7d294b170', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '5c6eea437f24b9fac9487f16a9166ea9ef491e27', 'ecade8c741e29b89143450f6b098cd618bc5237d', '385197d4c02593e2823c71e4f90a0993b703620e'}",566,"{'e021d59638966a6fbb36854cc2cf1045de7a62d2', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972'}",5,"['Lukas Ruff', 'Jacob R. Kauffmann', 'Robert A. Vandermeulen', 'G. Montavon', 'W. Samek', 'Marius Kloft', 'Thomas G. Dietterich', 'K. Muller']",Lukas Ruff,"Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, G. Montavon, W. Samek, Marius Kloft, Thomas G. Dietterich, K. Muller",0.8833922261484098
7eb24c2109f75c614cc7aa4c1cac8b643c05e70c,Mixed supervision for surface-defect detection: from weakly to fully supervised learning,2021-04-13,,https://www.semanticscholar.org/paper/7eb24c2109f75c614cc7aa4c1cac8b643c05e70c,"{'425fc8829ff30c4795776a92076b6d6ba8714f51', '1c9d2244346972d582560b5dbfd10ad7a0784a38', '4675b6b4075ddf91df71cc0677c3b36df0ac46bc', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', 'ee4a012a4b12d11d7ab8c0e79c61e807927a163c', '349a5c6a114226131c8db14b799fb70bf45b2f08', '0ebbc37e8c1e9766dc0ccf3780a824a30ad9d62e', '65b864858f73b99fe56eebb1e3a28a9fe156e4b1', 'efdbd7af97c0fb0dbf0e302c616eda750e1772e9', 'f8599ad5332cdf2c9919988ba300bb4b438b5834', 'c52902d07bf0ec989a10e74d0ba404f0f9b8339b', '94f6c36ceff963dd9a6a2b45fb3754b071bceb17', '6c7bdab6e39a6045f4700efb5b09a8c5e646e7c9', '53599f3748b73f5d3bbddab646905b5b8e7d3210', 'd7da9bddc31fd6e851f6b06a894d613c3529d09c', '895e770ae8bd559898c50e7c59776d1b572f8f73', 'e5014a547281b5d64c89cb14825757c565f02639', '25757e7819eeb8829d3524474f973b79befd7b59', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '62f3d3015cee122bd147d7d878c85f70cc15680d', '590c9a1ff422b03477f7830b20609f212c85aa13', '66ad2fbc8b73242a889699868611fcf239e3435d', 'd1de3e98901b27054b8f87b535699e33dd9259d8', 'f341bfc9284972bd7e470082caf3c805a94662b4', '358b9707c2d45c06e23a264d21390c2ed5a1d7ee', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', '17d3f90cb63fbac50a5e49b8a46e633ec1f526fd', None, '27a6425224141d77241aec38234e173d41452a83', 'ab7af7023418c77edfae7d2ee25fa796c926d5ea', '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', '41747cbdbed84762dfbfc305254c97021279dc6e', '288aea9479e7e76bfd6dee01c0f8e5c6ed76a18c', 'fa62b0a1ef618ee2595f06f1af9744ad63938a63', '4712c173431c3672ccb5e3d6e4709923cf8be4b9', '63bc06753e0d38b511ddc07482822c24785e8c9a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '804eecda772857604566935070b6d3d8644b628e', '7f33e88328dcd2f3aa4859cba96e14725e21d43c', '0cd3f5a9830da4ff84eff3a050e5a90cba77bc57', '74baf0185659ef0e1f8d412d3e906f6e73a6a873', 'd7a1d5e6b2da522cb17581cb2016dc7ad24fc030', '31534751dbd254fb7bf6ba2f43db5dfb6b54c6a7', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",46,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '2c89b183df320c3ef698989bdc5d1d4731c4d65d'}",2,"['Jakob Bozic', 'Domen Tabernik', 'D. Skočaj']",Jakob Bozic,"Jakob Bozic, Domen Tabernik, D. Skočaj",4.3478260869565215
4c4a6a0e8c57e282dc96a100d1db8d9410c3bd67,Improving unsupervised anomaly localization by applying multi-scale memories to autoencoders,2020-12-21,"Autoencoder and its variants have been widely applicated in anomaly detection.The previous work memory-augmented deep autoencoder proposed memorizing normality to detect anomaly, however it neglects the feature discrepancy between different resolution scales, therefore we introduce multiscale memories to record scale-specific features and multi-scale attention fuser between the encoding and decoding module of the autoencoder for anomaly detection, namely MMAE.MMAE updates slots at corresponding resolution scale as prototype features during unsupervised learning. For anomaly detection, we accomplish anomaly removal by replacing the original encoded image features at each scale with most relevant prototype features,and fuse these features before feeding to the decoding module to reconstruct image. Experimental results on various datasets testify that our MMAE successfully removes anomalies at different scales and performs favorably on several datasets compared to similar reconstruction-based methods.",https://www.semanticscholar.org/paper/4c4a6a0e8c57e282dc96a100d1db8d9410c3bd67,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '4d8f2d14af5991d4f0d050d22216825cac3157bd', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e', 'a01fb557abc65ec5c37c28ca18298f27aa0dba72', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'e5000713fa1dec7ba73162f516048b65110d96c0', '8a756d4d25511d92a45d0f4545fa819de993851d', '03a5b2aac53443e6078f0f63b35d4f95d6d54c5d', '4f8d648c52edf74e41b0996128aa536e13cc7e82', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '59f119cc17823bc3f0629cd7b8b9abf5f222cfab', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', None, '5f61089d3d548a515f01b473f0119137d1f340d4', '91d7a634288acf07a5d2cef021e1f1ba5ea1662e', '41747cbdbed84762dfbfc305254c97021279dc6e', '9fcadebc4fe00f033ea213a1fa974d46c2852eec', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '452059171226626718eb677358836328f884298e', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3'}",31,{'41747cbdbed84762dfbfc305254c97021279dc6e'},1,"['Yifei Yang', 'Shibing Xiang', 'Ruixiang Zhang']",Yifei Yang,"Yifei Yang, Shibing Xiang, Ruixiang Zhang",3.225806451612903
d3b614f11969127a08447c41257b3a7b58766d18,Encoding Structure-Texture Relation with P-Net for Anomaly Detection in Retinal Images,2020-08-09,,https://www.semanticscholar.org/paper/d3b614f11969127a08447c41257b3a7b58766d18,"{'798432c9f33de4c497f534cc574dedc89a58d3f2', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '193b518bc3025804c6d587c74cbc154d91478417', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '193532f7dab6481d4feaef9350e4fd6c434920e7', '93516fb0ecbc8bee22669cd6b0ad7e1f7dc082b0', '195dae7a72c64f19b0984337db7125a66ed237c4', '44885e8f48a653f4e8fca4d28e5661823d91da7a', 'ae97c81b45780dc91e18eb84236d8a40a290b329', '33e7e4d7ad01d921544c3bc7097add01e3b65083', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '919f595bf4235a37f6caef315b8a05b02ec0b6df', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '08dc94471605308669c8d3d8284ba94fcc93e345', 'b60f795c6f512ff3ebf6ee09f487aec21edbfec0', '2abde28f75a9135c8ed7c50ea16b7b9e49da0c09', '5d5c0f15fdfd2743ccf0923b26a657e69cdb6ef6', 'c43d954cf8133e6254499f3d68e45218067e4941', 'ca9c83ce1f11653bc656236937a7b21767cb28ea', '8acbe90d5b852dadea7810345451a99608ee54c7', '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'e1e2eed17278e189f3774aed52d2e249435fde97', '617a52776f261924f24615e2cdebf4d2172e7d9e', '27beafdc3153a4bf41332849a5911b8f830d5b8f', '1532750abbb9eac71592ff8f81f1a1a3f7ed9a54', '6af440915b8a0718c93be1cf61905e41e620484a', 'd003a82747ab2276133bc182230a3b70f14d2e85', 'dc0b1a938919ce42a7da41fac00791e84ab15028', None, 'ac9748ea3945eb970cc32a37db7cfdfd0f22e74c', '9fcadebc4fe00f033ea213a1fa974d46c2852eec', '3a3eeceba9dd6dc4fcc7971eeae2d39af5e51215', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'a3fce9324329581d484dfc8c3f018bc31751ca82', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', '61ab4147ec745498df468f46eecaf28d8265c053', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '83e1eb609e4267251a3bcb7ec47cc0754ae5f54b'}",45,set(),0,"['Kang Zhou', 'Yuting Xiao', 'Jianlong Yang', 'Jun Cheng', 'Wen Liu', 'Weixin Luo', 'Zaiwang Gu', 'Jiang Liu', 'Shenghua Gao']",Kang Zhou,"Kang Zhou, Yuting Xiao, Jianlong Yang, Jun Cheng, Wen Liu, Weixin Luo, Zaiwang Gu, Jiang Liu, Shenghua Gao",0.0
0a19abb5b8284fb9479587b8ebab19fda61c6876,Unsupervised anomaly localization using VAE and beta-VAE,2020-05-19,"Variational Auto-Encoders (VAEs) have shown great potential in the unsupervised learning of data distributions. An VAE trained on normal images is expected to only be able to reconstruct normal images, allowing the localization of anomalous pixels in an image via manipulating information within the VAE ELBO loss. The ELBO consists of KL divergence loss (image-wise) and reconstruction loss (pixel-wise). It is natural and straightforward to use the later as the predictor. However, usually local anomaly added to a normal image can deteriorate the whole reconstructed image, causing segmentation using only naive pixel errors not accurate. Energy based projection was proposed to increase the reconstruction accuracy of normal regions/pixels, which achieved the state-of-the-art localization accuracy on simple natural images. Another possible predictors are ELBO and its components gradients with respect to each pixels. Previous work claimed that KL gradient is a robust predictor. In this paper, we argue that the energy based projection in medical imaging is not as useful as on natural images. Moreover, we observe that the robustness of KL gradient predictor totally depends on the setting of the VAE and dataset. We also explored the effect of the weight of KL loss within beta-VAE and predictor ensemble in anomaly localization.",https://www.semanticscholar.org/paper/0a19abb5b8284fb9479587b8ebab19fda61c6876,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6be216d93421bf19c1659e7721241ae73d483baf', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d', 'ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa', 'e858bcc487cea96695102db9bdafe3c5d4269d04', 'b72771c316d60190aff053ef8a216ba57d62f541', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', 'e0783f34937794275e35a254acd04c16c924be12', '67a3276174a209812a04c539fad8b764168e4047', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '2cebf0212380f83b7171fb5660f842c8d7043f60', None, 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '2c740e574eea66fdcf473e15ed2c228baef2eccd', 'fc937d5bf0958457f158bd915bd378a0da51216e', '580062407427236ced45253a2ff7df2e147a81e2', 'b508b1a9bd9350fd6063453cc2e522dfc2e3510e', 'a90226c41b79f8b06007609f39f82757073641e2'}",23,{'d9d7ab13ce305ccee309c989a2341d72b1252070'},1,"['Leixin Zhou', 'Wenxiang Deng', 'Xiaodong Wu']",Leixin Zhou,"Leixin Zhou, Wenxiang Deng, Xiaodong Wu",4.3478260869565215
04a03d6e5205795f89324737dfb5ea88c42735d8,Weakly-Supervised Defect Segmentation Within Visual Inspection Images of Liquid Crystal Displays in Array Process,2020-10-01,"This paper proposes a novel weakly-supervised defect segmentation approach for the visual inspection of LCD array images by a joint application of known weakly-supervised segmentation and unsupervised anomaly segmentation technique. Potential defect regions are firstly identified via active heatmap and masked out. Generative CAE trained via a GAN framework is further applied to create defect-free contents within the masked regions. A comparison between the generated image and the original image leads to precise defect segmentation. Our experiment over LCD inspection images showed that the proposed approach achieved comparable segmentation performance to the fully supervised FCN model, justifying its applicability for serious industry scenarios. Although the approach was motivated by and validated for the visual inspection in the LCD panel industry, it is conceptually a general method and has the potential to be applied in wide areas.",https://www.semanticscholar.org/paper/04a03d6e5205795f89324737dfb5ea88c42735d8,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '9626ea6825b434ee934f7a2e6844838aad6c3c1d', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '3b9bfdeeb9ac6ada5a5833b1f179cb97f3e6804b', '317aee7fc081f2b137a85c4f20129007fd8e717e', '2b507f659b341ed0f23106446de8e4322f4a3f7e', '98a702211e52622a50691972e4aec51f996edcd5', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', '35e93be1c4ea5d3740680d4397c050116c117667', 'd21ebaab3f715dc7178966ff146711882e6a6fee', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '97484a4f67958433ecd73653918ee1b8a16b5b2d', '23ffaa0fe06eae05817f527a47ac3291077f9e58', 'c1e714a9ec329629798a88ebff8657c349fec739', 'f4e0e970a52742ba9c9f8f8d978f0f95fd56249f', '1a0912bb76777469295bb2c059faee907e7f3258', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539', 'affe7e93c31abf7a28088e5b3a83ddf24bf07a3f'}",21,set(),0,"['Fan Li', 'G. Hu', 'Shengnan Zhu']",Fan Li,"Fan Li, G. Hu, Shengnan Zhu",0.0
fb52b5d8c07326cc8f618d525ae162e1a89f1009,Unsupervised Anomaly Detection Using Style Distillation,,"Autoencoders (AEs) have been widely used for unsupervised anomaly detection. They learn from normal samples such that they produce high reconstruction errors for anomalous samples. However, AEs can exhibit the over-detection issue because they imperfectly reconstruct not only anomalous samples but also normal ones. To address this issue, we introduce an outlier-exposed style distillation network (OE-SDN) that mimics the mild distortions caused by an AE, which are termed as style translation. We use the difference between the outputs of the OE-SDN and AE as an alternative anomaly score. Experiments on anomaly classification and segmentation tasks show that the performance of our method is superior to existing methods.",https://www.semanticscholar.org/paper/fb52b5d8c07326cc8f618d525ae162e1a89f1009,"{'86dc692fc0b6ee97077ae4132517cb8538802bcc', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '16161051ee13dd3d836a39a280df822bf6442c84', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '0c908739fbff75f03469d13d4a1a07de3414ee19', '00a1077d298f2917d764eb729ab1bc86af3bd241', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '36653f8705b56e39642bcd123494eb680cd1636b', '34439db81b482cd562e1cdba974c70a2b89cd6d4', 'bdc7b63cb38609c5902efaee8eb588c196cbac77', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '6ff2a434578ff2746b9283e45abf296887f48a2d', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '25761fd27d2ffad21329e85987dffa57a13de39f', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",27,set(),0,"['Hwehee Chung', 'Jongho Park', 'J. Keum', 'Hongdo Ki', 'Seokho Kang']",Hwehee Chung,"Hwehee Chung, Jongho Park, J. Keum, Hongdo Ki, Seokho Kang",0.0
f0839ca18e069bec36f97a4671b7b3baeb6c1912,Energy-Based Anomaly Detection and Localization,2021-05-07,"This brief sketches initial progress towards a unified energy-based solution for the semi-supervised visual anomaly detection and localization problem. In this setup, we have access to only anomaly-free training data and want to detect and identify anomalies of an arbitrary nature on test data. We employ the density estimates from the energy-based model (EBM) as normalcy scores that can be used to discriminate normal images from anomalous ones. Further, we back-propagate the gradients of the energy score with respect to the image in order to generate a gradient map that provides pixel-level spatial localization of the anomalies in the image. In addition to the spatial localization, we show that simple processing of the gradient map can also provide alternative normalcy scores that either match or surpass the detection performance obtained with the energy value. To quantitatively validate the performance of the proposed method, we conduct experiments on the MVTec industrial dataset. Though still preliminary, our results are very promising and reveal the potential of EBMs for simultaneously detecting and localizing unforeseen anomalies in images.",https://www.semanticscholar.org/paper/f0839ca18e069bec36f97a4671b7b3baeb6c1912,"{'d03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c948ab13b9ecfa35374913710f849e806297e18', '27222787908c3a1c6fb6c4b5cb5ef8b2542f1b3c', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '9360e5ce9c98166bb179ad479a9d2919ff13d022', 'f63e917638553414526a0cc8550de4ad2d83fe7a', '97cd86d8d8c0f27cd3e64c6ca5cfdeb957ee39f4', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '154df96b95e8b9635771442244fe48b125933bb1', '355692eb86b06a0a23af45c106cfb02c95bf380e', '10a498003e9204f5fc1328e706510a37e514d8c7', 'aeed631d6a84100b5e9a021ec1914095c66de415', '8f33ff90dd7d8ca5d6863efe532efb9f699b8086', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '35b966347dae2f0d496ea713edf03a68211838a5', '9dd6e0d34a98fe2e2a9d2ae875c551ca4377e40d', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', None, '2e8d62277e40d465343e8dfb32ecc246f320540e', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '73d6a26f407db77506959fdf3f7b853e44f3844a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '6b66d111d2d6bcb35c546f6cffd4404990227d07', 'd8021847ed0e3f26b53416c2a254a85451ee5f1e'}",28,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",4,"['Ergin Utku Genc', 'Nilesh A. Ahuja', 'I. Ndiour', 'Omesh Tickoo']",Ergin Utku Genc,"Ergin Utku Genc, Nilesh A. Ahuja, I. Ndiour, Omesh Tickoo",14.285714285714286
f8d9c72770401c27f986da8cb7b10f61f60a7891,Self-Attention Autoencoder for Anomaly Segmentation,2021-08-31,"Anomaly detection and segmentation aim at distinguishing abnormal images from normal images and further localizing the anomalous regions. Feature reconstruction based method has become one of the mainstream methods for this task. This kind of method has two assumptions: (1) The features extracted by neural network is a good representation of the image. (2) The autoencoder solely trained on the features of normal images cannot reconstruct the features of anomalous regions well. But these two assumptions are hard to meet. In this paper, we propose a new anomaly segmentation method based on feature reconstruction. Our approach mainly consists of two parts: (1) We use a pretrained vision transformer (ViT) to extract the features of the input image. (2) We design a self-attention autoencoder to reconstruct the features. We regard that the self-attention operation which has a global receptive field is beneficial to the methods based on feature reconstruction both in feature extraction and reconstruction. The experiments show that our method outperforms the state-of-the-art approaches for anomaly segmentation on the MVTec dataset. It is both effective and time-efficient.",https://www.semanticscholar.org/paper/f8d9c72770401c27f986da8cb7b10f61f60a7891,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '4d376d6978dad0374edfa6709c9556b42d3594d3', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'a538b05ebb01a40323997629e171c91aa28b8e2f', 'a8e8f3c8d4418c8d62e306538c9c1292635e9d27', '49e17ad5bf10eb17f4c35a93a1588a6f0f8760db', '62b77e5cb85fc61b84edd532f6d65714be152596', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, '5366919840236059252c7f8f510dfb36df9e3206', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'cd18800a0fe0b668a1cc19f2ec95b5003d0a5035', 'eb42cf88027de515750f230b23b1a057dc782108', '962dc29fdc3fbdc5930a10aba114050b82fe5a3e', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '43cb4886a8056d5005702edbc51be327542b2124'}",25,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '62b77e5cb85fc61b84edd532f6d65714be152596', '2e8d62277e40d465343e8dfb32ecc246f320540e', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e', '4dd78b8d466b4cfe55a1bbdc694291197ce62541'}",6,['Yang Yang'],Yang Yang,Yang Yang,24.0
d52ff4da17d41ea239de10dd2a68ae18f6a85d28,Synthetic training data generation for deep learning based quality inspection,2021-04-07,"Deep learning is now the gold standard in computer vision-based quality inspection systems. In order to detect defects, supervised learning is often utilized, but necessitates a large amount of annotated images, which can be costly: collecting, cleaning, and annotating the data is tedious and limits the speed at which a system can be deployed as everything the system must detect needs to be observed first. This can impede the inspection of rare defects, since very few samples can be collected by the manufacturer. In this work, we focus on simulations to solve this issue. We first present a generic simulation pipeline to render images of defective or healthy (non defective) parts. As metallic parts can be highly textured with small defects like holes, we design a texture scanning and generation method. We assess the quality of the generated images by training deep learning networks and by testing them on real data from a manufacturer. We demonstrate that we can achieve encouraging results on real defect detection using purely simulated data. Additionally, we are able to improve global performances by concatenating simulated and real data, showing that simulations can complement real images to boost performances. Lastly, using domain adaptation techniques helps improving slightly our final results.",https://www.semanticscholar.org/paper/d52ff4da17d41ea239de10dd2a68ae18f6a85d28,"{'63c98a8d300db1d54b06b0c6712011693aac2fa3', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '907a90967f68da4311802247408e0515e363f930', '1d5972b32a9b5a455a6eef389de5b7fca25771ad', '762a75cc06ff35ce026182d1907300e75f9d24c6', 'c9030bab89325427f0fc7d639a0e0b735dd4c3bd', '92e4bccf9ab17244dcefc50a547e87a23e1fd3bb', '7705d1e2aa1cf19367613c14159cfaed47a8b74a', 'a5694a6fc3963af6cc1e6ce9afddf4ee96d8f738', 'b4255c0bc1ae0eef07b2d38c3271646f9b3bff60', '429aea828954ba77da9cb3a1a8dfd4d9ea4d7101', '08ea8c08d3b3d79db3d1d43088c629ebdbb3e6f0', '10951c1d6e3e8d7cc98593bec2ec8723733ba9dd', '502169d1ba1c25abd99c7f5f454474cfaa420a8b', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', '12a91c9d4a55fc93f15f4acef078c8908af3c9b9', '185c5278c741c98bea3201866b6c68265a6e1af4', '1e8f366c93f07e93445da2b4e821612afabaf8c6', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '1d2fe1f395467549a1986490762808b16121bf0e', 'd81421695d5d429a47eefe266986d197d7b313f2', None, '9b6e4cbf1f8d6fbf09017769ae65ff90234e0aa0', '500e54f274f5f228a6ed83e45e68ae7c7f4bee88', 'e632f0c2e5e0b91588b3874889fa2d535ed1d3ca', '320b227027030fc291de2896fc3c6da49d7614be', '72564a69bf339ff1d16a639c86a764db2321caab', 'e763e059cead07d1c03646bfb8cb4a0a75ffc3ef', '1365b4a286e607a4902ef11c84a1f309719d946c', '7802e7e3fcb7bd0a0c44762b53470416e7d290a9', '83fb6d2721cd26be4964882ce929ff8c98ebb688', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', '5d1864d759d272c5dc928b641d113527a3e81f99', '43718091a83025135aada68e6c02dd81f23e6039', 'f15aecec2a5672beaae77853ea0eea560505df8e', '12d0cf8ae5ffe1b89345e1dcead22be592d844b2', 'ed3cb211816c30188f61c2cdda0bd55c81eefa13', 'b41df3236875d0df0620be7a420914adf8a9ee5b'}",38,set(),0,"['Pierre Gutierrez', 'Maria Luschkova', 'Antoine Cordier', 'Mustafa Shukor', 'Mona Schappert', 'T. Dahmen']",Pierre Gutierrez,"Pierre Gutierrez, Maria Luschkova, Antoine Cordier, Mustafa Shukor, Mona Schappert, T. Dahmen",0.0
41747cbdbed84762dfbfc305254c97021279dc6e,Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings,2019-11-06,"We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.",https://www.semanticscholar.org/paper/41747cbdbed84762dfbfc305254c97021279dc6e,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '802168a81571dde28f5ddb94d84677bc007afa7b', 'c613d44a4e21ec7c1c23bce6d78a512ba35394d5', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9acc51b06f54b07836fad4cc24633187dc21317f', 'e81c70bc8b81797645332e5db726add973a5633a', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'c7fd979f0f690783b4f98236ba0b8d5483a5563a', 'c53352a4239568cc915ad968aff51c49924a3072', '3bbcb7fbebde8b15794fc54db16cfcbc059bacb5', '8a8cfa45b4c0d071fbffa091c02670b19c94b693', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a0e8f4348968195c80494b7a4245edb91a252c93', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'e854885e41b6754177d0892129a8215b7e467c23', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '10f8d1106e49fa07c1dab8bd200e76896ee9dd13', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, 'ff7bcaa4556cb13fc7bf03e477172493546172cd', '5d90f06bb70a0a3dced62413346235c02b1aa086', '2910bec6d4de87e22be5119cef3c488d2ae50e2a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', '23364d3dfab309ef3af5bcfda9a222029ad22b23', '563143c5f4fed0184c1f3e661917da94cfed1d46', '1ca64f740193b8a6d76fe39716873737a85eab9e', '317c172f314f8cb634f7569ed5bf3ae7dd25c313', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",37,set(),0,"['Paul Bergmann', 'Michael Fauser', 'David Sattlegger', 'C. Steger']",Paul Bergmann,"Paul Bergmann, Michael Fauser, David Sattlegger, C. Steger",0.0
6299ea2e8eae21669b18f8cc02682eca4cd0676d,A Feature Memory Rearrangement Network for Visual Inspection of Textured Surface Defects Toward Edge Intelligent Manufacturing,2022-06-22,"Recent advances in the industrial inspection of textured surfaces—in the form of visual inspection—have made such inspections possible for efficient, flexible manufacturing systems. However, establishing a unified manual-feature-based inspection model for homogeneous and nonregularly textured surfaces presents an enormous challenge. Furthermore, in real industrial scenarios, collecting and labeling sufficient defective samples is impracticable due to the scarcity of defects and the endless variety of defect types, thus limiting the performance of supervised deep learning methods. To address these challenges, we propose an unsupervised feature memory rearrangement network (FMR-Net) to accurately detect various textural defects simultaneously. Consistent with mainstream methods, we adopt the idea of background reconstruction; however, we innovatively utilize artificial synthetic defects to enable the model to recognize anomalies, while traditional wisdom relies only on defect-free samples. First, we employ an encoding module to obtain multiscale features of the textured surface. Subsequently, a contrastivelearning-based memory feature module (CMFM) is proposed to obtain discriminative representations and construct a normal feature memory bank in the latent space, which can be employed as a substitute for defects and fast anomaly scores at the patch level. Next, a novel global feature rearrangement module (GFRM) is proposed to further suppress the reconstruction of residual defects. Finally, a decoding module utilizes the restored features to reconstruct the normal texture background. In addition, to improve inspection performance, a two-phase training strategy is utilized for accurate defect restoration refinement, and we exploit a multimodal inspection method to achieve noise-robust defect localization. We verify our method through extensive experiments and test its practical deployment in collaborative edge–cloud intelligent manufacturing scenarios by means of a multilevel detection method, demonstrating that FMR-Net exhibits stateof-the-art inspection accuracy and shows great potential for use in edge-computing-enabled smart industries. Note to Practitioners—Most conventional visual inspection methods rely on supervised training and consequently require a large amount of labeled data and can detect only specific types of texture defects. In contrast, the proposed FMR-Net is a robust model for the simultaneous and accurate inspection of textured surfaces for various defects that does not require any real labeled defect samples. Furthermore, this model can also support a different fine-grained detection method that is very suitable in the edge computing paradigm. These two characteristics are both extremely important for practical industrial applications. Manuscript received XX XX, 20XX; revised XX XX, 20XX. This study was financially supported by the National Natural Science Foundation of China (Grant No. 51775214) (Corresponding author: Wenyong Yu.) Haiming Yao and Wenyong Yu are with the School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan 430074, China (e-mail: ywy@hust.edu.cn; u201812016@hust.edu.cn). Xue Wang is with the State Key Laboratory of Precision Measurement Technology and Instruments, Department of Precision Instrument, Tsinghua University, Beijing 100084, China (e-mail: wangxue@mail.tsinghua.edu.cn). To the best of our knowledge, this is the first unsupervised edge intelligent vision inspection framework. As such, it can provide inspiration and serve as a reference for intelligent industry.",https://www.semanticscholar.org/paper/6299ea2e8eae21669b18f8cc02682eca4cd0676d,"{'2f787621e9f5a09da03056c7c82d08d035715420', '2895770450e9cdfa4bfa42ea035b0a2397205e95', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd67b9dafcf94017784c266e021fe29baf2ffd572', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '723fa2b1ba138154c58e42d7152bd7264c27a555', '987156a80c8c054ec81335dec1c642ff071e20f2', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', 'f5ada173e628caf97c25b20c16a219ed384a006e', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '896de8418884f4aab1ae4a60027500c9e8baffc3', '3d2218b17e7898a222e5fc2079a3f1531990708f', '062a0d008b697b2523ddda510733925ffd35af42', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'e8180ad45ed5ca732e492db32aa85e769836132e', 'fb8e2adf906990107791b49489ede76ea33f21aa', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '510a24375b5166842cae47f2e54052846704e8f4', '5435a9ab36a308cef10bc725104e8f778ed3a328', '31bc0d4ec9a5bfc2152c4928ac2c3864959c0342', 'e3a442aa24e5df7e6b2a25e21e75c4c325f9eedf', '21275eb2a8cf85d193f36d6639784016b1a8ceda', '484d1e02b5c47c0245a41acb97d32bf7a70d0737', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'dca73526dcb51428af31c950414a34b1754ba260', '928cd808aba140ec298508df87c5579811ff2f41', '70f9968a356d840040a1c9207906f60376dc6bd4', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', '91a73e9c6cbba422ee50e287f1bfa9ba30f6922b', 'd81421695d5d429a47eefe266986d197d7b313f2', None, '85aefb7a0c0e0f7a60b7c453d1767c9dd6b7964a', '41747cbdbed84762dfbfc305254c97021279dc6e', '728d6ebfab4c843b603fb5628d18ac12aad46ad4', 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', 'f66db9695292665591a7f1142a5d5151d632ca60', '5a554c8d22d47ac499aeb7fb0532ca9be65e5a2e', '5db1b742cd18678ed08a813970bfaba3527df037', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '51871d01c26acb651c81adaf073c32c3d9ec0f0b', '3e0e337b477e0c226da00eae03fd29882275a469', '46d4a2b7ccf38b80b09574cf17544ff2297a8fbf', '46786ce31ff75adc402cabd0df489bba43b5643b', '032db195efd97fe2bcd20c4ad04628c70ff4e79c', '66ccd943eebb652af13b6096c6edc3407eb510e5', '1bbe9c0526e4627a8708d103629bfb4662c925fb', 'f2b818fad7ef6c8a82ee4d6fb2568202ac97b874', 'cb52e0abac9b0236ab288e5564df9e051e65a9b4', '5b19f91f119bb624a27e2003ee675fdddee11ea3', '9a7228ce42d5cc0f2dfb676155ec0cf570f83f9b', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",55,"{'2895770450e9cdfa4bfa42ea035b0a2397205e95', 'd67b9dafcf94017784c266e021fe29baf2ffd572', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '41747cbdbed84762dfbfc305254c97021279dc6e', '62b77e5cb85fc61b84edd532f6d65714be152596', '46786ce31ff75adc402cabd0df489bba43b5643b', '21275eb2a8cf85d193f36d6639784016b1a8ceda'}",7,"['Haiming Yao', 'Wenyong Yu', 'Xue Wang']",Haiming Yao,"Haiming Yao, Wenyong Yu, Xue Wang",12.727272727272727
5cbfdaacac1f6648bc2b3e129f3afe0572882e2a,Defect Detection in Atomic Resolution Transmission Electron Microscopy Images Using Machine Learning,2021-05-27,"Point defects play a fundamental role in the discovery of new materials due to their strong influence on material properties and behavior. At present, imaging techniques based on transmission electron microscopy (TEM) are widely employed for characterizing point defects in materials. However, current methods for defect detection predominantly involve visual inspection of TEM images, which is laborious and poses difficulties in materials where defect related contrast is weak or ambiguous. Recent efforts to develop machine learning methods for the detection of point defects in TEM images have focused on supervised methods that require labeled training data that is generated via simulation. Motivated by a desire for machine learning methods that can be trained on experimental data, we propose two self-supervised machine learning algorithms that are trained solely on images that are defect-free. Our proposed methods use principal components analysis (PCA) and convolutional neural networks (CNN) to analyze a TEM image and predict the location of a defect. Using simulated TEM images, we show that PCA can be used to accurately locate point defects in the case where there is no imaging noise. In the case where there is imaging noise, we show that incorporating a CNN dramatically improves model performance. Our models rely on a novel approach that uses the residual between a TEM image and its PCA reconstruction.",https://www.semanticscholar.org/paper/5cbfdaacac1f6648bc2b3e129f3afe0572882e2a,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'a1b5a7548b14153daa11468f0390b7c30111362e', '5d89617fee5d916a0ac389c73ef8311b7f713fd9', 'de891e097b4e656a72e99bd60fb2374c17c0bf1e', '8eb453d79c172c4bca3dd184679a7796ade1ff01', 'd6f240222746b5741a7a14bbbf4d648e0fc1855c', '9acc51b06f54b07836fad4cc24633187dc21317f', '053e5c1f175cf385fb8ab551e68446e24b3475a5', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', '7d55fca31cdf6c05458898a85ded2a934d1c7976', 'ab3508a7053c3dad3ba8d41d3ed3145d4966a5a3', 'd00ca89ff28d6f3293155eb657961c462fa41054', '62b77e5cb85fc61b84edd532f6d65714be152596', '1533a3079cc4b92cec8d8a6d93224666a7ba5b42', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'e23ab0eda804714481f7573d41d5e15eaa093452', '01c00b89f6c5eede78a28880987bbf7764b7ba58', '83d990e4051ae9940449b803e94deab7a113a8cd', '4f8d648c52edf74e41b0996128aa536e13cc7e82', '9552e625973a8c67a7e709cc4aa75c4fc71ce261', '9557cef6c7ec4179a7fa0a079c05a333b37b00a6', '6af440915b8a0718c93be1cf61905e41e620484a', None, '13df0f1045c6b010d81a754103b9cad78c2beb47', '3dc53735347ff10084222f4d151519bbe1a00e96', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '95467a31ee53eba30e9f2554283bec6f28ccbf1c', '9c21441e384c32bea9680648417e91884b7aaff4', 'eb42cf88027de515750f230b23b1a057dc782108', '79e18890b81fd8a9a7230a41fb14c04fcf712644', '09986807ddfb438dd827e45e7e39cd9609c5ce7c', 'f02218771a8faa4b2d59588a46d0c40bfec95176', '2d211d160e6701a80ed442a36d3a4de7382529c9'}",34,"{'62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f'}",2,"['Philip Cho', 'A. Wood', 'K. Mahalingam', 'K. Eyink']",Philip Cho,"Philip Cho, A. Wood, K. Mahalingam, K. Eyink",5.882352941176471
fc086bf5f6d1627153b68abdd5a4450e141b4ca3,CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows,2021-07-27,"Unsupervised anomaly detection with localization has many practical applications when labeling is infeasible and, moreover, when anomaly examples are completely missing in the train data. While recently proposed models for such data setup achieve high accuracy metrics, their complexity is a limiting factor for real-time processing. In this paper, we propose a real-time model and analytically derive its relationship to prior methods. Our CFLOW-AD model is based on a conditional normalizing flow frame- work adopted for anomaly detection with localization. In particular, CFLOW-AD consists of a discriminatively pretrained encoder followed by a multi-scale generative de- coders where the latter explicitly estimate likelihood of the encoded features. Our approach results in a computationally and memory-efficient model: CFLOW-AD is faster and smaller by a factor of 10× than prior state-of-the-art with the same input setting. Our experiments on the MVTec dataset show that CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by 1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source our code with fully reproducible experiments1.",https://www.semanticscholar.org/paper/fc086bf5f6d1627153b68abdd5a4450e141b4ca3,"{'06671547fd94c44688b10c8cd550242557e55154', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '47638197d83a8f8174cdddc44a2c7101fa8301b7', '1c4e9156ca07705531e45960b7a919dc473abb51', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', '4f8d648c52edf74e41b0996128aa536e13cc7e82', '83d074cc5051ade0c08d66180e4a04d2c112fa97', 'b1464ca857593c049873421db2f37bf2d0ff676d', '355692eb86b06a0a23af45c106cfb02c95bf380e', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '3c3698ce314a77271b566713edb2911f921299e3', '48e1de7d085808004d5f0493d486669a3d2930b5', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', 'b36a5bb1707bb9c70025294b3a310138aae8327a', 'd3b614f11969127a08447c41257b3a7b58766d18', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', None, 'c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d', 'd6f2f611da110b5b5061731be3fc4c7f45d8ee23', '41747cbdbed84762dfbfc305254c97021279dc6e', '25e433197844c239742f67fbb4171e913e0b9fe2', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '01a4f33da8ad94ced3cf58548b28dbbb44148571', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '501c02c7caa7fc2c7077405299b4cbe7d294b170', 'a08cf46861c057fbab685d486218c3829b221e3d', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",44,"{'931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd3b614f11969127a08447c41257b3a7b58766d18', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '2e8d62277e40d465343e8dfb32ecc246f320540e', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', '41747cbdbed84762dfbfc305254c97021279dc6e', '4dd78b8d466b4cfe55a1bbdc694291197ce62541'}",13,"['Denis A. Gudovskiy', 'Shun Ishizaka', 'K. Kozuka']",Denis A. Gudovskiy,"Denis A. Gudovskiy, Shun Ishizaka, K. Kozuka",29.545454545454547
c3ce677da645368f908879b313234f85628ace43,Triplet-Graph Reasoning Network for Few-Shot Metal Generic Surface Defect Segmentation,,"Metal surface defect segmentation can play an important role in dealing with the issue of quality control during the production and manufacturing stages. There are still two major challenges in industrial applications. One is the case that the number of metal surface defect samples is severely insufficient, and the other is that the most existing algorithms can only be used for specific surface defects and it is difficult to generalize to other metal surfaces. In this work, a theory of few-shot metal generic surface defect segmentation is introduced to solve these challenges. Simultaneously, the Triplet-Graph Reasoning Network (TGRNet) and a novel dataset Surface Defects- $4^{i}$ are proposed to achieve this theory. In our TGRNet, the surface defect triplet (including triplet encoder and trip loss) is proposed and is used to segment background and defect area, respectively. Through triplet, the few-shot metal surface defect segmentation problem is transformed into few-shot semantic segmentation problem of defect area and background area. For few-shot semantic segmentation, we propose a method of multi-graph reasoning to explore the similarity relationship between different images. And to improve segmentation performance in the industrial scene, an adaptive auxiliary prediction module is proposed. For Surface Defects- $4^{i}$ , it includes multiple categories of metal surface defect images to verify the generalization performance of our TGRNet and adds the nonmetal categories (leather and tile) as extensions. Through extensive comparative experiments and ablation experiments, it is proved that our architecture can achieve state-of-the-art results.",https://www.semanticscholar.org/paper/c3ce677da645368f908879b313234f85628ace43,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '0229285fa6c46871391c40a433c3cf777dba33a7', 'f503d7f11ed437d498805cb4906ca69aad6f7f73', 'ee4a012a4b12d11d7ab8c0e79c61e807927a163c', '0f15d8bdccc8b9a6d50287922126a07d9406ec85', '05c4eb154ad9512a69569c18d68bc4428ee8bb83', '798eccf088004ac2bcfcf452d42c1d7daeaaaa03', '1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6', '459b2454799635a7520cd4a5ec14bb5cd826c571', '3f0214808397b0adbc14a5139bc8d811019a23e1', 'f681389d9f8090a8525f0078a53cc62f0a637d8b', 'afec16fd5c4859d25ad805d5e15702cd24ee85fa', 'f5b9b024b3e3d7207225365bd52a4a0666e0f9a6', '41cc24f3e6b5c10cf67df1b583c05ae07f11d818', '614d808f4115ff738c44168cb8e7784f33c8bf8a', '73cb9d4a01f9d7d821674b1943209b4852fe2bba', '91b33e7a08fa030abf7ba550972b6f4944d9b7cc', '8436a4cdaa80edb2e7f2e44217670e6c09bedb36', '163ea468518070f6dcdc07dd6d73bcbac5c640eb', '7e50deaa917178c6469898ae37142ba531f130c9', '2c3754b7e4e770edafae70a35ab4ab2f1cd8e6e5', '1f3a7b3b6a05a6392dc4f2ccaa49f93444c021a7', 'e30847c0ccf34c88cf080bf9a4bea0fbec8ed8d8', 'ccf4b380a482f2bff42bba243198c798cc149136', '5e925a9f1e20df61d1e860a7aa71894b35a1c186', '8a8cfa45b4c0d071fbffa091c02670b19c94b693', 'bf3ec4aa9c8238b1d67eb7579176ac67444d640a', '0cb53a5ef780f037c1f2fd7de1f748b3f81726bc', 'd81421695d5d429a47eefe266986d197d7b313f2', '8b7ae1b97d7822908f1c6597d7c4df88c5aceb62', '8e7666c21ae8be01ec4a3d794ff3d24f7992d731', '0d3b2db9af4a72f2e0ec6f15a7f0bc6fe6e97cdb', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '46d4a2b7ccf38b80b09574cf17544ff2297a8fbf', '52c03e632bb0cc7807efd0b87504ec18d044af74', 'c1898f9b88e92c05fe42b48c960bdb95898963fd', '8330d141c4f999cb15458bd7cea0fd75cf1d74ba', '6cdd8852c1324ebc36d20a453d5eb95a3df8c6f7'}",39,set(),0,"['Yanqi Bao', 'Kechen Song', 'Jie Liu', 'Yanyan Wang', 'Yunhui Yan', 'Han Yu', 'Xingjie Li']",Yanqi Bao,"Yanqi Bao, Kechen Song, Jie Liu, Yanyan Wang, Yunhui Yan, Han Yu, Xingjie Li",0.0
cf122c84af8c85e15c3dffaca4069dd455b56a1e,Visual Anomaly Detection for Images: A Survey,2021-09-27,"Visual anomaly detection is an important and challenging problem in the field of machine learning and computer vision. This problem has attracted a considerable amount of attention in relevant research communities. Especially in recent years, the development of deep learning has sparked an increasing interest in the visual anomaly detection problem and brought a great variety of novel methods. In this paper, we provide a comprehensive survey of the classical and deep learning-based approaches for visual anomaly detection in the literature. We group the relevant approaches in view of their underlying principles and discuss their assumptions, advantages, and disadvantages carefully. We aim to help the researchers to understand the common principles of visual anomaly detection approaches and identify promising research directions in this field.",https://www.semanticscholar.org/paper/cf122c84af8c85e15c3dffaca4069dd455b56a1e,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '932a106c21a1db1e1876459c1521d27fd152caac', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '732c21998e251d64cd58b6a86886ee5907efeaa5', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '2decefd147bca93f40aebb2b693374893a84f37f', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'a57c6d627ffc667ae3547073876c35d6420accff', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '85384a8871030bbd1681adee9e9956dce4d751ba', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', '5435a9ab36a308cef10bc725104e8f778ed3a328', '998818d9249a395aa44518259762aab44f8f4ac8', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '152b59d1022489a207bbe3cff3e42579fe7ad86b', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '6af440915b8a0718c93be1cf61905e41e620484a', '00695a31a80221c7125e49885a4767896ec2c4f7', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a0e8f4348968195c80494b7a4245edb91a252c93', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', None, 'c2b733a79db700b971327a58ef42699fe8a416aa', '7d8c1561870ebcbb833cccf2d802f1097df28f39', 'c0c07935977e70e71d296535729fc718636d76c4', '4100414ad0763bdc91bd15bb6e0424a44d7a35fe', '41747cbdbed84762dfbfc305254c97021279dc6e', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', '2910bec6d4de87e22be5119cef3c488d2ae50e2a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', '1db6e3078597386ac4222ba6c3f4f61b61f53539', '8ee35ed698527d9695c872e3b76715fec4ef69ad', 'f9f836d28f52ad260213d32224a6d227f8e8849a', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '23364d3dfab309ef3af5bcfda9a222029ad22b23', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '66ccd943eebb652af13b6096c6edc3407eb510e5', '0fe615dc0a422100e85cfb7e26c9306c481f6c75', 'fe09f7a379944444201552e952b910188c0aeaca', '9a058fd787914ffbf90f607a5c62b271a8a87ea7', '22c0bf46726ad1c90b5fac7f16638c813e86c829', '75a838cbc1541858b9c484001cade327640dc280'}",72,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '9277dc70c74bcadf80dab11c28ead83fd085deec', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '4dd78b8d466b4cfe55a1bbdc694291197ce62541'}",11,"['Jie Yang', 'Rui Xu', 'Zhiquan Qi', 'Yong Shi']",Jie Yang,"Jie Yang, Rui Xu, Zhiquan Qi, Yong Shi",15.277777777777779
29fd9e0f7d81af7bb57e0f21d4e46ae9ec8a6b35,Self-Supervised Training with Autoencoders for Visual Anomaly Detection,2022-06-23,"—Deep convolutional autoencoders provide an effective tool for learning non-linear dimensionality reduction in an unsupervised way. Recently, they have been used for the task of anomaly detection in the visual domain. By optimising for the reconstruction error using anomaly-free examples, the common belief is that a trained network will have difﬁculties to reconstruct anomalous parts during the test phase. This is usually done by controlling the capacity of the network by either reducing the size of the bottleneck layer or enforcing sparsity constraints on its activations. However, neither of these techniques does explicitly penalise reconstruction of anomalous signals often resulting in a poor detection. We tackle this problem by adapting a self-supervised learning regime which allows to use discriminative information during training while regularising the model to focus on the data manifold by means of a modiﬁed reconstruction error resulting in an accurate detection. Unlike related approaches, the inference of the proposed method during training and prediction is very efﬁcient processing the whole input image in one single step. Our experiments on the MVTec Anomaly Detection dataset demonstrate high recognition and localisation performance of the proposed method. On the texture-subset, in particular, our approach consistently outperforms a bunch of recent anomaly detection methods by a big margin.",https://www.semanticscholar.org/paper/29fd9e0f7d81af7bb57e0f21d4e46ae9ec8a6b35,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '19862af96b6af51e879e6e3f1d3d421af5427005', '2bed351a6eb9966e510b893a90fb87fc43731c85', '3e5069a058a11a9a4ed77cb9ee65cd681c6d8356', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '0179d2cac957ab0e4729d399facbbeccbce00da9', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'a997f1ecd85e1467d11252741d188fac8db22722', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '48f9a48aa5b1230b05a443d2d531e6441a541686', '41747cbdbed84762dfbfc305254c97021279dc6e', 'd21ebaab3f715dc7178966ff146711882e6a6fee', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '2a417a16473e2bcb1c98cd7814bc106760925e60', '843959ffdccf31c6694d135fad07425924f785b1', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",27,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '48f9a48aa5b1230b05a443d2d531e6441a541686', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '19862af96b6af51e879e6e3f1d3d421af5427005', '41747cbdbed84762dfbfc305254c97021279dc6e'}",8,['Alexander Bauer'],Alexander Bauer,Alexander Bauer,29.62962962962963
66d2554c2d976e912f063fd58c31936772949417,"Simulation and Synthesis in Medical Imaging: 5th International Workshop, SASHIMI 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Proceedings",,,https://www.semanticscholar.org/paper/66d2554c2d976e912f063fd58c31936772949417,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '332b58cd218c7d2d022d51e1fe1a63469f5c5c89', '65b16da51891a6b98140d425804c8a0fd0299219', 'cf0bcf6cd3de4cae726d02decb07a87d613ca5a4', 'e0ea008f23921d5d25dd150352b64e0c0c8cdd97', '2f0852dcba69b4dcfc7306d3d1b0c594428d2f93', '194cf02f568470439eb9d27a64dcc99ef9799ab2', '7058f9b5e86fe98d5014ff74400cb4e7cc1e5af8', '39db2a0d018e872e29826534eba9dd2b77080e84', '7abd0194a83fafff6a3d14fff06bacd3aad1a431', '573ed082ed92a602e4f86771a47f5b088708c38c', 'baa1ae74fbf7ed6204f2f6364d51375ff81aabc1', '141b8315d3bcdbb73a280380906ea981992938e7', '6ecc91743aea2d9f747c670065c3eff0b1b0e689', '7b6464d814f5358328c771a7112f26afe916dcc4', '3aaf49dc0ff97f96809be5c83ab4dd7d9ca3ebcf', '744fe47157477235032f7bb3777800f9f2f45e52', '54cd51f4ce28b3c35fbbfd47331dc313584a7004', 'c2fb5b39428818d7ec8cc78e152e19c21b7db568', '77a1ca2df0871df21f85c2c2ca110946e350cfa5', 'f5d73c953c64e089e4ed86a92f4431f1afa8e55d', 'd0aab674e8ac28696601d3b216569bcdc831d6f9', '11a8dcaec7a7751a9e240440267c5773fc7faefa', '3a46ef8a2f949023fefcba71bd195d0868a58768', 'd772de4f8c22e13345689d185d8e6e64b9501c50', 'de885aa4b9306b5ce4f11f0b9a1780e7d7bd11ba', '77094ddcdd01658f2237f0c696c61fa5ad4c0d4e', '979e9db08ebadbb6b5df8282373203a33c528fc9', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '4cdcf2ae5e1fafebd9b3613247a7b1962584da34', '80b2dbefdef33858dc6c78b0df1f8179e6c6d77a', '03f1b685f40176784838827283de7ae32b6eee59', 'd35b1cfb76b29e03bdef563fce3fa72174ff5d73', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', 'fa56122bf5e9c66cd4418513d0b8d914024e4e9b', 'bcb044b968916a2ab846d74cc1ce966f562e91d0', 'dc5bef5a597260483ca3b8b0cde594d3aa597449', 'ff7bcaa4556cb13fc7bf03e477172493546172cd', 'e79566139295286ed11f52e1e0e71585e8768f4c', 'ba913e2c03ece1c75f0af4d16dd11c7ffbc6e3ba', '57df0cd79104dbd1cf2bea32b3e5098e5aa5f994', 'd23edb16cdab35d38b606b08f9b84fb013454b47', 'e97ec9836b3630de98cc02bfc1eab1dd5d3b8f76', 'ef43ecfc72bf0cbfee340a85ce8fbb25ea353fae', '0a70555ec88e53173942384072c4e6d204d59b00', '58aeff8d5cdee26da7e2909b5ec99eee6048cf95', '8b3931990711a0963469b8fa16311814aaa8b3ab', 'eb42cf88027de515750f230b23b1a057dc782108', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '80d25e1f2e529b70a376bfe952c440e4510e0a95', 'be0ef77fb0345c5851bb5d297f3ed84ae3c581ee', '6c8a56ae495e5c8871061d1cd0f863d174f5e2ce', 'a8a742c5bc8eb1f64de7e6b37b146f71317a691f', 'f1c88a53d1109117d1332c425e8af52bf21ce1d7', '34008f26cec7fae1f60b8da38abb6b012bf83e13', '37c971257466feebf1e788681a2955d76ca57dee', '8b7625b12c38087743733ae5902243544ce9ca10', 'bdabdeab5f92029c136f1e36ab79b4f06bac0ef7', 'd65399b4e6f3184155ab4af10e6d7c6e71451bb9', 'e981430f7f237084bdc48cff7d23c85d25471744', '82b46dd7c67b17dfc34b10b4e7db6f8391cd4886', '8464ef5f79e6e10127405e2795a64372ed312d50', '4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c', '9e5be29ff2d6bf97607c31ab298590e75812143c', 'f37644654bd02fec0ef10bd8387e71b87bb02374', '05db8e3a342f8f239203c24d496e809a65ca7f73', 'ad84720c06cc958a5c26461c1e30f05a4bf053a9', 'ab48847b65380babc5af2fc25215fc5e9c6d0688', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '502dd3f72a41bc81d42ae76b1ffce404c9ec864d', 'd7ec319d24ba07c065b39cecea1f9a0baf2c7c08', '06a748879ea5d198067c0e573eccccd6442ba375', '8388f1be26329fa45e5807e968a641ce170ea078', 'e4b17209bfffb5809810c87fbb2079cb9263f7d0', '1952e3ce9816c3689d665c83d5d44e4df6f05719', '841bda24e8a9e9782802be0220ddf536056a9d7d', '91bf9dca5d10430f0cf3b138153d316540e9c89c', '96150ecc66dc45bb16262b2790d122b5756fd707', '0c0292cc64a2e0bc50e9f7aa22bf10ce9b361212', 'f7e4c270b5c73b9f811426e02b5d3849db81eb43', '80a0bf3ac3064ba6d8186f7447b42aaa7bf3bfcf', '34d6e3da80ee25840f6dadf36b27717da0bb609b', 'c6bebbea24bfeafec4251b6ab41d1f2244ea6490', '8acbe90d5b852dadea7810345451a99608ee54c7', '14d9be7962a4ec5a6e55755f4c7588ea00793652', 'f3e4b8c61102ad84f4edc9f59224ac280478677f', 'c7c2319440bbba2a423b0d4a0693fb746fc6592e', '69e8473a600c8b5689e3ffde486b1fa77facb461', '8c5233c3614f834b194925b4ae9944778def09d0', 'af5f88ceb30fd2e677d9d46fe9768906d7389986', 'd92f735b0773b4e697e7e72798eccae2f647acd6', 'd997beefc0922d97202789d2ac307c55c2c52fba', '97c9b2e53eab7210cc660598bd1290df65e93364', 'f5975baa6c0d6d35dabffe7c6d190f589602c62a', '16fcccab73ff7c172bc9b3d401127a3e0ae16178', '2f071c5e1688de8534c7776c31fe4ad6af91527e', 'fef52e5d52434e10f65ea73a0ffae1910f6c7284', None, 'f19108c55b7c1831566ce3250322e0f5637d44c9', '083093a2baa2c7b1773980584473d9a58a64dd39', '384ed183aa4dcde3bfaadeeb990ec9212eaca39a', 'c703618d1f97a2d2184a09bbd73520034a19ef56', '87b83fefb82216aad1c14cd1898d195722bcee42', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '531a2c789de66118bfaf37feb30b21a8b83faf2b', '6605814a6a0abac781bd8c15549f19a1aa958a52', 'a4defec5e169db9d2cad1680b2dce163490c472f', '56a66ca3e1fe8a984ab6a85386cf7efdd201f0b6', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', '23ffaa0fe06eae05817f527a47ac3291077f9e58', '94be567c32ae76bdaadabd4975807a94181e39b3', 'd27e3c0284b261d251c881155e780f1c939302c8', 'aac10422cdcc69ffa43ea423d10e808d5631d175', '07eb34ac6be81ef658e2c3199a80aee1b523f205', 'b31192d40ef06eafc80fef13698ef765bf8e0e68', '0ce2db95b183f99c945394ff6e773c54beebb477', 'd0a49fbf8334976a643e9e9d04b7bb147e095204', '855cc266dc53cbae96b9c46c76b3d06e665faee0', 'cfc3c1c4c2524af10419a2d0b1a4bae2692b7ae3', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'f6eb86d738cc3672adb24554d154a792e8e5eaf9', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'fb0240a074d81043f067df96a2d90c6cff9efb9c', '2dd32ff6608812d9b5d3877340df1cf9fceda08f', 'b5cc267e35707b0a6ae0701fd1bd505d90ece30a', '5ddb12cd3678de9bd533c738bb7fce27330d67e0', '11d5dbc084b045a59532906f5e02f8382d37a59e', '6bd4169a457f498520613ae4e2382c1a1271f94a', '55c5bfdafc17e17c1e51b5e0e20cab70412e05ae', '6c2c8bbf0fb53cb0b5b3d45add4f4ab3c1f582b1', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6e3510886f4b84a08a06abc954647a29f981639d', 'ba5d7defc50e82de5479c6550c07b0748fd92188', 'd45af6bc0c29f777d2d633c37c5f74821c0cfd3d', '2ead06344c34f758b16ab6ef32a7fb1be2d4beb2', 'cf343676b57dd016212320544e1b813f8c196a7b', 'c42faad6f2ab45bb3a1cf27408cae32f575632b6', '4aec89a3d2ae290a6194dc638879c60a77aa9c99', '1732eb67fb9425bc6f546bca9f88d2144bcbe7da', 'cc49f4818c0aa856f3579d0478b68595249658df', 'dc169f30f62d57f3785090e33ef1875df5124ec5', '4b709e0cac11f67d079fbe72d2fefd09d2e29f30', '5ddb1e671d8bfca1483fe002742dc0e77dd92594', '7c3c49517ed397879720479308bd206ef5dd2393', 'c1cc356ae6303b254ce88919ade3907221a5b58d', '947c86d5134b9efc3ec332f3b0141e05db343665', 'bce496a9b3378bc1fd6528870b5e892efa5ef98b', 'fa6118dcade9b14799df5a1e198cc4603e64c6cb', '2abde28f75a9135c8ed7c50ea16b7b9e49da0c09', 'c73ad76698d323191f994de40ef118c1e67f745d', '49252c023bf47bb6f6b0b8baebb11f489750262d', '7c2bcf6f32b05a04cd3444c030db743e5666af88', 'c38a1dae6fa68ffbb66bee39651a293d98e19bfa', '23623a90d79c76804d785f9c2f9e6f13927a3569', '21de3a36cb51adc205fad8a1d3d69118891dc3dd', '21d692c7dec2b2c4c584750cce7ff8cbe329d2a4', '2b90eae0267f3c9efb5f276919c87b93e7f34ab1', '5986547c7380f5a8fb6028093f827b3662f838a2', '072d892aad32538fd634bf8c46819e4ff04b5fbe', '64a952c947058cd0f6b4a5bb344632adaa585a6a', '186deea6be76314e04e20121dd703d4d53777030', '757993ad8c3574857a01906d2b46a5909882a4fa', 'c468bbde6a22d961829e1970e6ad5795e05418d1', '601106659dc89cb329e8a045ef6ef288fe37b0dd', '17e5f8c0946f60c75c11d819670ae4ff6a48fa4c', '6fe3bdbcefd15a1de12c7781b504f3c63f05ac63', 'e046019d1f0568097496a79c89fdcbfecc052a43', 'e16890a7bb34aa9eab1d47e88a928cd5ec256d25', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '6303bac53abd725c3b458190a6abe389a4a1e72d', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '6c3c1419cb6aedf28ec9608c0a1f169e7fe7ee03', 'b16dd8cc3de743bb6e506b331c338d1879b10b41', 'b2e08a26bb660953d39f54f0d04ce66ef9e8d9b2', 'd6f2f611da110b5b5061731be3fc4c7f45d8ee23', 'a3d7efa24dd2a87a9de14de8729edd1d52ae4dc4', '432a09d95694b6dcbce4ffef19313002ee4bcd07', 'ea9b50ce2f18a6474a2f38355868a62a22782efb', 'c9bf946d8ee2b4ebc4a708b8048cc3c311b7abd7', 'e8a5f27e7805f8de84ea008d59452ff864271696', '01c3f607bde7943fad4ce6a92301b4194dda1ec3', '79d6f055833647011788c411d7c15c01c93d694a', 'a26d43492b5888e185ad8dd2f76934d241129227', 'd0eeab8fcf819261d1b95c60fd48ee9c7d242d7f', '9e825c9f1c306ea3536391feac7e67f56a896416', '995b94cb4246172843153414c1e6dc4cb004dbf4', '5ff3534d3d3d4462578ca5c168084555c16e04ee', 'f7b3a85144b36bfe60b971ab91e0b832a127a326', '6817d90ba883f2f834cea22006c85465e498d02a', '06feba1ffd596b41884cea6e8ef0da89b6dd2233', 'e15cf50aa89fee8535703b9f9512fca5bfc43327', 'eb35c5cd2a4641ac1c8c4869846fec3da95478b1', 'cdb48a96036b8cd2367eea596cff2db828305150', '5e08f63ad267527945205f339f14540fcea19490', '3bda8b8dd09117f7d5abc12cf4581ac50b6412ee', '571f4226cb7fbaf2f771fe32c0e4f02b010a223a', 'e43d70ee93e79095590d9430759234ab80e5b055', '70201e0cd05d37cb362acd72435ae0249071cbf5', '4cf0f73ce7a157f218494088f4dc0feaf33ba0db', '2ca2eea1177cff0bf09dc3dc924ec5837e20c841', '6bd307e719255073e9ed4e8ea647c80b7755067a', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '7194f1c34cebfedd8b26f04f80c91af7ba735f3c', '9d5995faba6bc44f357da9c78af26df47fd29990', '14fdc18d9c164e5b0d6d946b3238c04e81921358', '0a2956d2aaf44039b87bcda372288c5fc6da934f', '28b3833743ab00904da1f4a30cd6c771cc164c0d', 'ce1ee33d280fea92689fbdfdb0cb0c264b535ed3', '13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986', 'a810adaab7f36ca8d8daf3f074fb6fc7ee7110d5', '88869ea17c3d31fbfd190087ddfc2093cb28b66b', 'e91dc8887841c51debfee1efa23cf9b1d8e4bbd4', 'cb364352258d6fcecef6b3d93ca1cd1d67e7d3cb', 'a8d385038b34b8eb366bd986b276f0cec81a2856', '04ab1454381d05c763e3d6642c089ad833a56c6d', '843a1f76a0c82dd0f883fb1bdafae6ad2c8feb5b', 'addae423490bbe82da4fb2fc265237178686b4e8', '1dddfba077f5396ffc3d1da44f7426109fd55d99', '0d3b365fc10690e45b7aca392e561269888255e3', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'b0637bb5cfe847f1dd8da7bf4af2f83ccbded0fa', 'dd6d044696df5e4353ff7c92b8009e1201c85129', 'c3cfd78c3b96c464122bcddf50033fdcd2429249', '0f571d5af8c85f78d22b64e9581347dba9c37a3d', '37a052144b510b8827634c38146b190d8b2c8d0b', '21b5e050525ecbec2119e47409a296eb29edc115', 'acbeebdfd9dd3456628604eefcd53f50f974b132', 'ea6726091bf63e18940a5280b7b92929f0d1a029', '1af44da4f2b4fd8abb9f2f1061ad1503cb016491', '364ac687b6b8abf738a529d285d6587b42bee1a3', '6a85d4c8d553bcd29b07b882913fd83d6cd5aaac', '879b8667453838e2e835b2114a634c4cfaa2dad6', '95a8c9d4c055fb3195b46e4d9f8d8d40673b4245', 'cec1f19832cff206edac4e18edabce7ae83ca9ce', 'eb6edf5b260825cb9fa1ee7d6ef4ba167102ed7a', '7fc464470b441c691d10e7331b14a525bc79b8bb', '231af7dc01a166cac3b5b01ca05778238f796e41', '9406246f6972c03e5bfaac4df4676648dc4ac935', 'b1a5d33011a657e0177572609048aa9e7a04dbc9', '8970e9caed1fca960ead644e6453a1a7321a7e6d', '53fe3dacfa638864d85e56031f8def97da2ad35a', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', '26c8e3f3f127f254039a7a69cbb905a3730e75cc', '2b37777583372237e63405f258a1c40a3eda8bc9', '45fb5c20ef5844a1798f567be93300652e7214f2', '9fa3720371e78d04973ce9752781bc337480b68f', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '554cb0e8a604701ca78f2d782f2a26119eadaa81', 'a6876ea89e677a7cc42dd43f27165ff6fd414de5', '0691767046c609a14aeabbb691cb26748cb2bb41', '83ecd8c4007fa6b8bb97169ca7b83e905bcba0e8', '01bb390bfec9ebaea8d9e3be8ef9c8d05b268aa5', '73a54f9d2c9ca04537ab9ef678e39fd49f459ef6', '47843a76d8b59c0a2a9c31034d7185bc248c677a', '43b7f2450681e5ebcbcf772c8224ae9a2d8fe618', '5f2213f1a5caf360d9c7cb29163f7a127135066c', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '0d66b34c339b51eb5c05eef517ce319e0883ac27', '80de6f973aa211197e219c66988f583bdba4bc6f', '0c826127c8280a15d234867b41113b18ec9a35f0', '8882b1a1c507e07df8bd3ec0c857e80f5c7f90a1', '36814dfafaf5ca7871eb5b5f3838db3cc1099389', '4f1c38d90e7d701c3fdca6ea1547c57cd237c366'}",264,set(),0,"['Ninon Burgos', 'D. Svoboda', 'J. Wolterink', 'Can Zhao']",Ninon Burgos,"Ninon Burgos, D. Svoboda, J. Wolterink, Can Zhao",0.0
08b66b00a9ce6ab8090668f9f848c5659617bae9,Surface Defect Detection Methods for Industrial Products: A Review,2021-08-20,"The comprehensive intelligent development of the manufacturing industry puts forward new requirements for the quality inspection of industrial products. This paper summarizes the current research status of machine learning methods in surface defect detection, a key part in the quality inspection of industrial products. First, according to the use of surface features, the application of traditional machine vision surface defect detection methods in industrial product surface defect detection is summarized from three aspects: texture features, color features, and shape features. Secondly, the research status of industrial product surface defect detection based on deep learning technology in recent years is discussed from three aspects: supervised method, unsupervised method, and weak supervised method. Then, the common key problems and their solutions in industrial surface defect detection are systematically summarized; the key problems include real-time problem, small sample problem, small target problem, unbalanced sample problem. Lastly, the commonly used datasets of industrial surface defects in recent years are more comprehensively summarized, and the latest research methods on the MVTec AD dataset are compared, so as to provide some reference for the further research and development of industrial surface defect detection technology.",https://www.semanticscholar.org/paper/08b66b00a9ce6ab8090668f9f848c5659617bae9,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', 'e85e7458b8b38ae0b77743885856ce870912329c', 'fb0e6b7786d4e5cf40b664fe6fe2498bc53edb72', 'd36d77cf28346d5fa526ccee2f7f0d756ba5a15a', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'a0dd32cc9d53d43dd068e40239f0aec4b2ee7344', '5d1401e87c31e4ebe9ed585a223e569b93b578cd', '1830d05de03a84147d3a4c45e1e759b21c3bfd97', 'e3cec47277c2133b6bc43aff70b77d3bee44709a', '89558937d45149780f88bb2264437068511b0699', '666d86914279a374fd41cc26bb45a6ff90623991', '49da709d51fe306da3297374afa5a35af3162e69', '9277dc70c74bcadf80dab11c28ead83fd085deec', '8d6384463645f5222b9aff2b990e2d881a86aa56', 'f20d4d60cfb02475043be9fe632b1497671dc25a', '1fdc51f4f4969709b735f395dd13b656b53a2653', '37595f7a51982d776e57c7280b9445474d90f0be', '6e5231bc928e304a9532698e727c6acedb543908', '5d017a9382a2fdd9edba02c520f0be56739cae47', '62fa28f297ccb3b3a2667490499c48d97ce05886', 'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '63eb7986f726c7a8cf14b720fa6eba3ab168c4a4', '735aa2d3eb0da5dc2e126144eec7030f245defb7', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', '04957e40d47ca89d38653e97f728883c0ad26e5d', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'ce711e917b9f6a4abd2d3555714a90a280c9fa44', '2e8d62277e40d465343e8dfb32ecc246f320540e', '34a0a27cd78f9ba82581c27c72d62f1c484b336e', '0085a44834f1987c288aa5bda544dd853e9ec4f9', '3ae930c4272b1b6d93754e1f8fa79f494d7bb867', '988112900cdcab56ebfc5f6af44476beb5094e42', '46d4a2b7ccf38b80b09574cf17544ff2297a8fbf', '5b5933c26b7c6ccadf1464397c8af38c9cffc19b', '03745b54ddb7ce72759524ee44b5dc77efe5940d', 'e26b8dff3aafd3bd5e4c789e3fd438da2f6aa0e9', '9fcc1189d5b83258ed2c78b0447c96eb527fb63c', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', 'dbb351b38417671246d8d51885333195cc9a1130', 'a70bc416b1124525499b0ac3d5b009637dc6c187', 'a71383362e299a44e8852a2772fd2767721e6fe6', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '57fe938dd4fa5b3e30a00ae856094fb654f9ffe7', 'b4c04e7101bc94ecaefe71f2b02f2e36a35c5586', 'dd8502990c6a7c40e95237be1f22c0fc3ac64e39', '1bd2c33cbf509aceeb0b5b04b2ad743b305e9a75', '3fac778364d0a67ed6214b0cedeff33e2873e197', 'b0e5ec93c2648ec25a5afd51dc6ba9f171615abd', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '19862af96b6af51e879e6e3f1d3d421af5427005', '4e1ad4504b65425e8d5ac4235c4e43cc59821bbb', '030076e9405028bfaf48932faea31467a54c86f9', '82bb2aa6bb721107df65f0cbcbb14ccb2de12f76', 'b595b1f5f740f4b51d550f3a111b3ff865da030a', 'e95cf80f757bf25c14e7767d70d400fff19b04dc', '61aceb1ad60b3d17387ebdbd55fbafe5b061f09a', 'a228ce656599fe1413ed0671c260b5dad1190e3e', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', 'febda9d873d87cdc5d80a89c23e8676c487771a7', '8dcdef2f6f7b3e62414286e9e930bcdecfc6b4c8', '7cc7b5e5633afc85dc25ff8b5e26ae9203c23789', '523a3a25b5da622985b82cb9c1a1a04c4e2130bc', '12174778a1adbc467cc55ca04295c055e276df5b', '8075381161ef78909817102e8a38fbf4c6920b45', 'f155262f653484db72f32fb2d748e82c6db38dce', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', None, 'fb52b5d8c07326cc8f618d525ae162e1a89f1009', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '64683ae006c740d10f65a17fa7f8e8f8d5b71a7c', '41747cbdbed84762dfbfc305254c97021279dc6e', '97ec22e0c2f7eee796cecec6374a0b284c4d0cb9', '5db1b742cd18678ed08a813970bfaba3527df037', 'c3ce677da645368f908879b313234f85628ace43', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '12f196ad4cd0fa2fe714e6ec240af2fa82825b9d', '0761888c1238ee48be34150fade7f6ae83b5e774', '0614e38aec4e676f138fc0f7e07304359bdc78b5', '5e747c230ca9323c67a27448efc9654d460def96', '1d11c334e3d9547e6989aba2838de33264b1052e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '6f97d14d92ccce0e884248d125df112921c6c552', 'f9d1ca07a38bbcac53da259fcaf77773270c5e9c', 'ee802c050c3e4d9b5ee51404e043d36992472387', 'd3744325106b2c15b17786b3447bd55d874b54f8', '0bbd56a5fbe39b03fcba1abf55320785be6fb3c1', 'd84c62734eb07141495421da1fdf9ed211ea4f93', '262e44bfa7920e4cbb6f5d71afafd77ebf6156c3', 'eebac817dc9a967eba6c70b29f6db36df8e1c00d', '3471e9ccb56e206563b6375b25a665861059901f', '8cc156003c0adb94beaaa7ff307e5258b6f22173', '6c9e5539c96022af666d0ea5b0a9b1e1bec0a29a', '0c5274ab2f2ca11e2bf5ac1faed219e180c3bef7', '9ba7cb21073685cb2104db1b7e1f801bb7142e0a', 'f4e8549edc9114f9f8cc432a522b2a8197393c4a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'd3b94b38a58c9e7c229064e6a4ae5cc3f1c77964', 'fa8e0bf401bd716c73a686d5451868638945ce3f', '21c8d0baf01c6b2207e4748cac54321b8fc1f456', '99436caa4a0ad48889316e2484ff9f8c3c2f8c76', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '09f3518409e82cc859db8582ec4e054545588eeb', '5dbd7c2ba7bc494e94e840241d7d5468b230e78f', 'b1eba6bce41e86a1302936899017829e99eff3f0', '5e85e7e190d6ffd9f1cc12e638b6755121fe18cf', '57af4710e5ee8f6304e3a4195405f2bc593454ca', 'be0f370c2acae5bd2ec7d0bd46f0a538b0f5b998', '452317d13263afd962ae3237066cd0a2e2a93edb', '491b149544eff61778c216a4eb869ec0b008f346', 'c7e6f85aa4fabb6756cdb00efe472ae5730c283c', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '97c58b63f80fa08d825ac0aaa31bf3432e2d4fd2', 'dfd5c2d199d830272eb7cfb4049ac5ff885a25d5', '36f175bf48f6c4766f7bb2d8c671747ed923cd4e', '1cf28f60d90d2dc2454596e48a61f8a2ff36d8ff', '8950c711df55516df9183a2650c9475d87a4249e', '08e15f8b48be499081294d39dc9e7be86b6fc7ed', '91cfca85d27a640b1d15aede96db2d3084700ffd', '11a87066589678b625047ea7e19e99c05e30cdbe', 'facb5c0ce8690ae77fe98a6b73d148b6e907abed', 'a087a1705d4eb046070d07784282b533682f4f6a', '9d3485077fc3f7c9c0f94473208d1d5e16f2c49f', '3cdbefc533ffb8f506a798bac6fd7501f78473c7', 'e663e20b30a2fdb87af2a31938f99d0cdfb1c417', '42533b0e6af0f00a753c2ab527fa8e0015f3335e', 'b6a1cd6bb9bf2befb5da322b2efc5781abed37a7', '9c131f92bea583c33daa94fc5e647de67ef9a96d', '10ae15147d0bc0d6d06ceaae28165bf8646ae478', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'fa98e294fa52c1bd59b77aeeb8d2cce698c0efed', '09017726c2c427756b6c08c7ecff613252a4f17b', '9fdea0884a98a490698bdd4c91e1dd2b83f51828', 'c992f74eb6ceddd73eb29a5113d04140484fb8fd', '5401005e8ae0f3e566b950ed184d009d8d1f2166', 'c35cc864c4eab4217aaa01a8b093712285db2c6c', '66e56a96a8faf14c12c5526d0b4a29fb03b42181', 'eb99009d7c264b8e46bde1fc614ac1e1b6050a3d'}",139,"{'ea68899e52526ce59c1f0b0cbc7cd992a0700383', 'c3ce677da645368f908879b313234f85628ace43', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '9277dc70c74bcadf80dab11c28ead83fd085deec', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'fb52b5d8c07326cc8f618d525ae162e1a89f1009', '37595f7a51982d776e57c7280b9445474d90f0be', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'd84c62734eb07141495421da1fdf9ed211ea4f93', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '19862af96b6af51e879e6e3f1d3d421af5427005', '41747cbdbed84762dfbfc305254c97021279dc6e', 'b6a1cd6bb9bf2befb5da322b2efc5781abed37a7', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",17,"['Yajun Chen', 'Yuanyuan Ding', 'Fan Zhao', 'E. Zhang', 'Zhangnan Wu', 'Linhao Shao']",Yajun Chen,"Yajun Chen, Yuanyuan Ding, Fan Zhao, E. Zhang, Zhangnan Wu, Linhao Shao",12.23021582733813
13508fc5268937ebf7eb80e58ebfb7e01eed3caa,On the nature and types of anomalies: a review of deviations in data,2020-07-30,,https://www.semanticscholar.org/paper/13508fc5268937ebf7eb80e58ebfb7e01eed3caa,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '4063ecd68b0908287ce74c1385afcc07026bb2ae', '5e5cc9b83ea55da2aa579199cfe2133cfe834a46', '88c2c3772201d4ee244e80b05f577cf79b454531', '497e1979d8587fa28c7dd349568f2703030cd000', '6cf98b123feac6504b0dc3a8b46e1462dd69121e', 'a5875d64958a53e59f9005bc74c0f212f3074f8d', '1eb131a34fbb508a9dd8b646950c65901d6f1a5b', 'd96d01357fef177caefc8cb0d35212d65d9236c5', '28b746a538ee25055bf79df7ba70cdfc37c8e308', '2eb2320ff1e1a109d9c8bf0d53b3edc370d4cea6', 'fd08484d50f4bfafd8078bf5fdee57e3e948f471', '160a2034868aa44ce005fbe16d76aee65873bc92', 'f5f18ca0dab2258985c9db56913a7d9adfe763d8', 'f2a944c139038253e5a637bba6df2a1cc8985490', '02bf073e9f6700340a20d7bd8e7e14ae70322726', 'a7c828184693a453a6c2867dee233ed054b2012e', 'c36991759325bedd19f69264f72d1cbf59a6158c', 'a790f659df2c286a63793f8f2e12aaf56247169e', '21daf03a7707ae1fa7d91d04999b487cb21cdb65', '36445111c9f9eb6763fedab5294aca792519f925', '6c90b2f5136229217f1b696d460c9a1dc4aab50b', 'ae74522002f9093fbf63a20efb57d80ee2f4f564', '3f53299e9075459f26fff3af2ba6787ae8f65fce', 'fec7a634daf4c82b2a0e4eaa9f021f951aaaa87c', 'b1f60bfe874748f8494e2ab9cade49e21af3c5fd', '7293d7440d89fc038d7e9ee8d1460cc9b3759478', '9acc51b06f54b07836fad4cc24633187dc21317f', '2dccec3c1a8a17883cece784e8f0fc0af413eb83', '52b9752a47000546a6461e1b4059d232e547c082', '3725f014d2c51f112db51c25449e9e4dadb860e8', '587e7f2bd2b2d4d43e1eb47f4742c2f71ae32d71', '582095d38f04f55665edd0adab421edbf6b3dda2', None, '814090a6a70e70877d86c1b61de3b44adce0a001', 'ca70967ad4a85370cfdcac09deb3462b60f197b4', '31c7004afa43c587302ad5c7d0c9cab2f6485483', '50f73229265928835e81cff5f9077317f150a2c8', 'fa0df59dfccadeb28ae454754b5b640a78831f0c', '85bdb955125949b296b623557903cb8fd5b9ede5', 'd24239179ef08fc10a4a0a63d96222b1438d90be', '249a3b1cdd977fc66a39bd1dd6e29ecb5214bad3', 'c27b5b13da3a1b53f251dbfe2a90900a95fafaaa', '9609204ffa71611461378c33f5a680df130571b1', '09c93eccdf26b5804754fd7430d3e5ec55349292', 'd798cb0ef57f71958e900c2a95723b7ef1ff2a34', 'aa7d69294351a5c39f2395478f66d802a8404875', '49adcd233d23ebb8059c72fd0f259a862a6e4898', '5d45e2cbe8cff587ea9ca4d6d8584757b8b6c311', '9b8ca5fcde6faa654124803b2813e5590ba689a7', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '6f7ef8ed60553b37bdf335876ac4e0adf400d1a8', '0b4b0ad43462dd2e26acdc0ef7ce4e3ceacf670b', 'ab99c1f8981f65cb3d5d43511cda2450fef6bb99', 'dc3f9764b82dcd2c2afa9614e2020ff31471f9d3', '4f94202c9300db57bae73af076f8711b286ec3b2', '1e8df9c69edbca7edbbb470fda9764e660fb0160', '9be428c9383d47b86570b1b9fc20faf006346c5d', '8c304155f25c08f0b24926955d2b92026dd186ab', '4f0ac26777d457225a5b12c3329687aba06e27dc', '50a16a83dd7750fdc3df3e8396c56a962feb5a1e', '386d61c0776c64bc4311214508616b6e5758bb5f', '96abcdded2985bd44b9514e28f5b8da4fa1e4371', '526bfbdb0affeafd3a91a5b9aec84aef130d0c6c', '5560712f77c88e3316b1cfb19279205cef35988c', '72e3c7607d84d34ad2a41ae3e8612acd474a0b0d', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972', '400198c40e1131047b8408fe9921e310a3f5bb6d', 'cf851cf44e6ba60c8fef4ae747dbedaa92981e69', 'f0dbec615985d4cc6be2b1f55b84dd614fc9d980', '5e2bb96c47ccaa16a4e7192e8fadb3b3e1c3acdc', '3ef92372004424c15826ad89f9e15f665c440668', '0c67f0ea34a9fcc7d18117d14164b91f336372dc', '0d83def5e8da5ec7dd3098f742da9767f3c5d408', 'dea1e981ee8e03c21decc3f8891e50457d265a5a', '9c8e0922089f99efea26824052c7b096c1360de1', 'e7e3138353ecdbea825c43175b1dad81100197e3', '8edafe88aaf59d145cb5e881d5b2afba8942fb14', '0fc425a8004830fdd7f207efd4fa7a2331d56d3f', '74e72c8bae6d30a232da08f744dbb7b8b03b76dd', '14bb7043bf6b9f551638a1f4102cee4f149190ad', '20b7637f600c542f1efeaf5c29e289efd344b14b', '5935f52caf1df059ed9e301ad1fbfbd8d01bfa18', '4c8cdb489df782fef106835c8739a37498879d04', 'd5aa9c9067d329bc2eb2ee5f4f584e46a67476c0', '8d5fdb0662281a111fec595ebceb74eb690a0146', 'e8c9df6860678a00f808138961e319447f544ac2', '9f09561af59a8e7ae127443b6134c86dbebdfef4', '979da1d26b1717adb739e0917d6fed97a9697573', '83684a662282c747738faaf67f2b7782e8cabbbe', 'd17b91a170a79f6ace701e82a88ef287f070fd65', '8bc9868fe6c936614f7f94b01757723e9ffaaa43', '4c2d7cd9ab2ecf93d6ea271695fa8cc8731eb5fc', 'c83671aeb9233d05d1413a1cce04f5014762fcc7', 'd2494a68038108c8f2c03a673b0ae8fb55c9cb74', '16a3608ddd0ee149a87e2be4b23908496e36f9b2', '9aa2ea302c1fb1d49ad19991cb04e40d2190816a', 'bd2e048c676ad778351bd7d7660240a978422117', 'beef6a2992535baf8c871a8b60b9f4a6e0066959', '863960d717fbdd1db861034a845a0a23013d7e4d', '8af955a9e8e3230cf896d2ee3bca2a2c32cdc9f9', '3a8e86f21b5bd71ced6be80227af3b5e8f5d6484', 'adf8f5b9c20e2778d2a9cc6fe5950a0fe1f1e4c2', '694e91e6ab9b1492cd5347cbb2411dae8a0e51c8', '4e176662ce0510315b41d70c8e181a1c45e052b7', '4cfd8f903506865e7ccf28b0a07ee3c551487e92', '0fde2428befa677b3b90f2655a0f1c2574c41ab3', 'fa62b0a1ef618ee2595f06f1af9744ad63938a63', 'b5e5a7eee59dd740897c0c3d1ada96c2e2a7e0a7', '585bf445ec84c1d9621b2726bdcce9f544b515c8', 'e12145a8defaa461beedc82df6c8deabc79ff957', '23f9220e0ca8f2cb522c36d158ca88f043007c68', '897455c3cf24c9ed427b5fe081466447677ecd0e', '4a02b1fc5577a6e496831a0ceab5c9f14e34e306', '633a51104cab0c5903fb4d54e7e7ae1384de3dcc', 'fab510d074fd48ce08c0e12b36cbe24819898c01', '5fcf39017264b90a7e2ccccd1e6ab34361edfcb1', 'dc0975ae518a5b30e60fde23a41c74bafd7c6f8c', '45b28e364e48a425a8ce6e2681ed9d8daaf18d3c', '906ed11d6431ff32e90476c0acade160ab1c9a70', '8467534990215ef80b005bc9e4df5a1a2b2e7745', 'bed15bd9e19149c6e28cf68a55961b31abc16d6e', '46638e4246b08b403a7d761a91378dafa782ecbc', '4b07c418a40fdedbefeca7e78afe2b8a1c473537', '0da52a5651004a7fe0411b036cf898914b672e79', 'b45187ed536410bcabc83bcccf93b854df3334e8', 'ca34071945a3983f2cdbbeab0b9ea19555c3c3be', 'f5c184e80fdff676f7ba0293b923a8cafd57ef9a', 'e1b678090b555c441f3fe18bbb5e3e0c3518f7ba', '355692eb86b06a0a23af45c106cfb02c95bf380e', '53df899e1a18082b8654677b4c0aa95dbd96f0e0', '0371c0b072a96ff60b792d97c44a3fe27d69ff5c', '14ffbd877e43007128ce98dde80abf63cab8e8a4', '2309f7c5dad934f2adc2c5a066eba8fc2d8071ec', '6b70a0df2d90f9cc38297e5558442e1276dfbafb', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '77192cac2e6c575a1f11b5fcc90bd1375595b586', '81922c0f27ce2a1d36caa13d8389e6dce2c2ca07', '14b6c61bd9ffc8bd0e8f64783983be71b76a1fce', '7f1ffbdcb2192b036ef9ab1c5cc969558bc597b0', 'd57a543573b9543612a17ffab007a6603d6826fe', '35a3997adca1f1ab09b776a05a9cb8e8ccf01d56', '43d75d3a22db904d052d4c435e2d1f22be3887e0', 'c2dfd94737eec5835ccfed6592f59e47b21879ed', 'd2a440c64efa63c41592171c2b9b35a92cbfdbde', '00d681cfff7f0224ace607e515f4ed510e792df9', '863efef58318bdc21986470200f6d4f2d206e039', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', 'b2acef429ed5ef6acb50fbb11863887e86a82fb3', 'b755d941ebdbcd608f08230c68920dd18c892f9f', '6106e589a3fd60fa891728c0fc522f818723c1de', 'e3116ebb52c152deae918a04c34441ac0d956b8a', '1d40f1415a89e01cfa1a36ed8bac9b8319ac7854', '6d77a03fbf6341674a52d9bf95c9e49f02ef1a74', '053a1b6cf645f2e5727fb7d1479a9df0ef9f45bd', '5c08ccba51c040a48907d3d9ab997c43bf17c43d', '01bdc155677c0643285f451c57f82118a7296410', 'ddf549240e9013400a328efd5492f1f880037569', 'cb868f0b242b9623b7544a58b6a21647dfa138a5', '031fd2ac327447cccfc301476654890a2e62b6ca', '213757112fa7ddef49cbfdf89886ec5604747e4b', '18e83e547cf1c5a220b9b49d3d87c4c82ffaace1', '6bef49c93a57d258469c4b2b14aaf7676b0eb480', '764896ad374224e53d3cafe9575ca58487724802', 'd09cab5ef546b967a5d8d7e8786177ede73a501a', 'ca5dcb06d66743c461e6146bdc8800d58ec64377', 'b4d0a7af3e30ce14ddc388cbb15585239ceb523e', 'caacf440c3660084a6503cb1d0574da96ebd0fb7', '2ce8d1dfda5145f1881e63c7837c30f59244c8e0', '7c1bb3f136310d95e4732da60d6130d7eb4a7fc5', '6e0530ddd9a8c0c93408140ad08b074f02b45520', '329c04e501f0c39ad270aa3f9a46ccfe0f4a56ed', '99ca397de7385e3987836de7928cb0ebe64e1897', '1ffcb27536ab5436e6d753919ab27ac1a44b4b69', '8af4dab6c1bf208743966bebe2d88692649d70dc', '14cc1b130f63df6bd061c402d78bb773e158742d', 'd0b53064da3c2d6726eaec1ac9906f4f5e78b62a', 'fbf26e1085ac3b038f47d4d1945ebda45d5e57fb', '4ec07dd3fbd9b0cc5459b8f19ab0599cfe000ddf', '26b8fb9e8730fe4b753b185d97c77c8acab3cdac', '6852ff4b312c0ab3fc11728f6d868a5bac8e83be', '19dd0fa50047a80532506eeb7273ad292ec440fd', '79157c479db7cbf0cba2c6e197644b38aa0e80df', '909790121c92e19e03688c0eb34ba2787e27238d', '2fc546a340101eb20d834da96c827d7e83090129', '9b3bd556982dab9aa1d529c696f783556fb77f3a', '0074db523f835f0e9727ceeaede9e14346e41b51', '0772e7a5e0ce50ab5e0fb6c662c617b75d728562', '996a8247c9f6710e07e978fc83dc828fb2fe222c', 'b25663fa149be5286de193c13324098aedd7e2cc', '48197abfa8afc790e8f9d89f27aef6da2b7b2d4b', 'e716698a6d28e7a47bea9b25dbc5df0da2d07158', '9460aa334bc0edca33b88da2a2a6f0d6a1b27f92', 'fde93161a53a7122591bce4a9a9a7381a2a4b71e', 'c9c9443b41c54a2413740502d12ab43cdccd0767', 'e44e0ccd11fb5bc6c747f09b401cbbd597386d28', '34229d94fb3b4c6d2fa85f074421d604ec60f571', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '7cc2ca92b9e542abb6d39f36603c67e2c415cc8b', 'ffc7433ef398ced5f13464ac9952607b308b6d80', '27cbe8f134065d3fc61234d822cdd86742471001', 'e98236e37049b46453c7d78f77c8cfaeefc0bfe9', '0a99f1de7dc80bbb22b5b38c00b199f864d3aa5b', '6c8feef5555301e16818a851563caf4b8199e712', '91620155be40a417174a98c42ef6bdcc9b93db4a', 'f818d90524a6ff81804b0d7441a21a4fffd837b9', '98a19a7bcc0608fcd83e7623a23a47a28db99d14', '5b6a8cacc844d75b9fb397a18739521d947a755e', 'dc51b452894dc2c4f7f7dce4ff2c8a1463369ebb', 'de24704601484dec0fa0a35f139464f9f658bee8', 'ce472e00131ea52f96a960fadcb8e4a60766d483', '5d6a27089ee7325174059b774683cf8db6c3c469', '89b730484470a29f7a4b06cf2743a183f927977c', '880180a21398022fef16560004f9a38c271d8f28', 'e4461eb4aca202067a4c95dcbc1055ee73687247', 'a96e508a94c37ef847b172e7d31b5bbe25629cbb', '77cf5bbd7663c1f7dc6fb103ec753ab12f85ca3c', '364c93a5a4f1f8bfcf087c26be6f4945d1240c4d', '23253676fa190baaf5979fae3ff5472763431d46', 'b9a217389e65fbf74da5fda223c7141fcde70055', 'd25686e1314a23d23d5f1b46b6f6e4f42218a85c', 'd153bea3d3cd121cb8b4328ecf6d10e450324da7', '953ea66f83c54169aefb028cc3ba87f132f99f18', 'd0329d8cdd95a7091c983b36b4e65b98d22182b2', '707843728eff81a509f6c66ee3324a542e4e7ba9', 'd448a33c77562dd0bc001da91336a0160a141272', '32ca430411682888f8615ed4ccbba78f166f30d7', 'dcb207ce848b358aeb2e4698c9ea1ad273ce98db', 'a3d67fea3a7ea85e3c857114ecf55f70104b8edc', '30793b5d0ab959f02ce0f187624ed94dd490a6e4', 'df121bfd1154665b673788f11a30edf8702f44fc', 'e4681fbd08a59d5498b7cc301d6f2372c559cd58', '453b19a046c889d46ddacc2c0c716c32affad868', '101384b4871fd2450dfc0ab100ea6142a6894a0d', 'aed55b04672111734ab8f8a527378e48d37675f9', 'c2d6bb53d7a9a17774e5b3393c724fb6fe0d671e', '9c5c794094fbf5da8c48df5c3242615dc0b1d245', '5122d216c4626a27171a653fe7efad67940b1a36', 'f703bbe0b3eeafbc0e1ec89bcf6495483828a752', 'c0d6fde348605475f4a5bf1633c3ddadd17d662c', 'e83e2b314192304583162e2de5c4e8299f31a1d3', 'c11c88dc851bddad3f0ad9907662df0a29cb0375', '2edf3a49bdbbb630666c51be9b856d613c9782b3', '69497049c77d8c49b1bf0a704d332fcc4a9b7a01', '8e3e53fc1f4e09a4a62667e3d2a29ad48f565a53', '346709bd2195ab2be8d1c99657fab3faec4691d5', 'e028820ff569c59338fb7df22484d2435e194d0b', 'f6e4d7f44410daa6f59713ac15be2bdb5cbf1d34', 'c15b569503b999dab65fa69df011aec057d70a1b', 'cf552964a6f7eb63fa012e55308c6612defb65cb', '36306a48c0098f6aafb3a20504e650b448689961', '1e72868404119952b593e496f910ea166896c4dc', '93a7f5b7f51622430a4a4d4002152b277e4be470', '1b32b77718be22ca31c2a0dba709c815e19d4672', '8855c6fd6652c089958e56eee538937a54edfcea', '5e80a3ceb4b2e1e1d4f64c138aecfaa8b944a966', '762fc1f41a23f7a474897cc9f46c0181361e6c08', 'f2704fd016fb0436f94cd7c7cb85c9684e8cc817', 'c63fca2af19e74cf6d4bb52606678c93fcdb8b0b', '738407e209b1c5ac0f555546597dacf8684a5463', 'aef8caeacc5a59eb04bef6b2984a2042b0132f54', 'a72ccbf4ccfa39388abd233344321679cc91d90a', '2d3d5a4b3ab1eb3190cf6c9f9540a1a341c03b89', 'ba70444c600b33da1a58b0efb0786a2ad626d038', '91d7a634288acf07a5d2cef021e1f1ba5ea1662e', 'e353a1ea6f1eefbe34666c188016f2aa36d809c0', '3d4f526199fd2af34a36a3499f7958a8b2581d9f', 'c8a073a51895b4fa325bb3564571029104c3585b', 'db9490fc390b546391280fc1d0a851aa0882e9f8', '0b50a4378be9bf313398a845325b0ecef39d0e9c', '7edadeea92fe1dfc1b8e399419e948b6b4ff7a45', '07e714617d4bf98b7ab408bf7ebaee1c9275a0da', '5f1562ed253ba3db7ca31ccf8065d0c26c6c7187', '07cfc436fab92d74ee5e3a89e21e4d0e2ba587b5', 'bd55a149cd2bb1644a93eb85cebb5fb1c24db763', 'e9ac27fd47eb6d4c6baadf8c6515dd6d90e55085', '5092eb222e7baa8d9394f9c8cb5d0e814bdb381b', '69a2152c95fb4b9ef53359fc49201b74819587f9', '1ffd9b39a7330c5442244e1ed7c66f153fef7fe9', '763584f3f4f59ad57ffaceb7df9f16317822f3a3', 'ae3f31c841c460b15a81bf51655f4c0e39cacc79', '3470847133adad25a35ebc4651e8ca791fa63322', '3cb54f04765c19e7e0580196c29c64e49f63a744', '053ce0824a6ffa8f2adf228f67087bc321b64227', '5d1596adeac9a058462aa70016204b3dc1f19d93', '6ab5d1795a7e9ea3f07b38a8045478a65a98a594', 'f56e535b3d336c670c1f7464c3b58f03dededdfc', '07b8ce0a13684c46e81e564a1aa4271891d86275', 'b61efdf872ae58f160457b0c1555394cb8fbb048', 'd2f18cbcbd7c33996a613434561a12dc557ae2b1', '424e3a0aaa7d9a987a9957f71a63b882f8f63484', 'd5220db4909513567bfcefff098e1f61acb4ca36', '48c013f733cbd9b5052691aee73ef088164d6992', 'cc0a5068f0eb59906697fc19e5525eb191f4c5c2', 'ce8e39166e566b596e3ec599ce985986aab836f6', 'd0a54d807d702144508f6419f614326b22d60ecf', '2642976f5337650cdc55c8a843d4f0d94c19321e', 'af25d3d884d9ee38bc46e98c824fadedd8b23a8a', 'a4e0bdd3fc6d92d03b10c0e75844333bfc9df8a8', '686b8d68bbbd6a84efaf41f30ff56c9bc0f5279d', 'c7c47e3052007230218edfdc1f46c8c8f8dd4d29', 'bc36143f51eb1a23b28eabb30af040f9f00a36b7', 'a50cc74da2125ed17277e28c28a0c3083e9eac94', '79a32d9229942897b4c833995a4ef0918b5b7e67', '06b7b73bb7de6fca598a8487d8302ffa7eface3e', 'e0b16bb5d747d61a0f689a73354a5736a909378d', 'fe8d91583cf2638f9ff066c99ec75afb407da87f', '7bd05d7130b3cb64d3f8c8481810e4a2e8b935f6', 'ad017461f25fa2534539b7c62ab5c6abb912d872', '0e9755850178ba7a27bea39fc586ad3042c6d629', 'efee5e554716d3f3cd5ecf163506fb01c24ce263', '4a36fe2ba575504c7114f735a18ad16fa97b353d', 'cb2c03629eb532f8f150a9fd8e45588dd2663ead', 'd8e0b6b225b36cac23608b41a51e13ddb2746cbd', 'd0d7539ef99330da99befa76863c0be209594884', '690b953238fb97f9c8e8927571671d45dc78dcfa', 'a8db789522b9375396bd91de631342740ba19a12', 'a77d85dce4754658fe0e46ef656e5d5fc683f875', '153a99ad39e85eb09f6ae56b1eb72795265cb8a0', 'd53d9f84acfd9958084784f890df3e7f666298b4', '1022317b065ce94cdfa710f3700821480b5ffd1e', 'b770ffc7f906124969cf05c451cc0ed5948acc43', '266438fa4056ec9de3990787034121d97fbb699d', '52cea870acf9d0dc33abcccfc599129e6094088d', '182f2c5ed91d1615cae67cea73d02f32200bb3f0', '03ccde55ec10a09713c52a0463d189e1623a91cd', '4c425ad261268e680f62aa5b3aa67fc5ef1d7950', 'cf45bce52cca1f6e450ddaa1d19fe6e30661dffb', '66827d727c869ce1be766dd14885f5a6870d2c6b', '5d85302f76005a1f28525d28228447b369d08428', 'b7eb411a67aae3483fa5bfa073efac89784c9105', '8c71bbed92e47a85a5214d8306c5ece2bd6390ab', '2ba7b69ec332e233e8661c016c2620dd0e3961bb', 'd51e5171bbb03ae4b984e6c7704b93c385618484'}",334,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972'}",2,['Ralph Foorthuis'],Ralph Foorthuis,Ralph Foorthuis,0.5988023952095808
8ee35ed698527d9695c872e3b76715fec4ef69ad,Learning Semantic Context from Normal Samples for Unsupervised Anomaly Detection,,"Unsupervised anomaly detection aims to identify data sam- ples that have low probability density from a set of input samples, and only the normal samples are provided for model training. The inference of abnormal regions on the input image requires an understanding of the surround- ing semantic context.This work presents a Semantic Context based Anomaly Detection Network , SCADN, for unsupervised anomaly detection by learning the semantic context from the normal samples. To achieve this, we ﬁrst generate multi-scale striped masks to remove a part of regions from the normal samples, and then train a generative adversarial network to reconstruct the unseen regions. Note that the masks are designed in multiple scales and stripe directions, and various training examples are generated to obtain the rich seman- tic context. In testing, we obtain an error map by computing the difference between the reconstructed image and the in- put image for all samples, and infer the abnormal samples based on the error maps. Finally, we perform various experi- ments on three public benchmark datasets and a new dataset LaceAD collected by us, and show that our method clearly outperforms the current state-of-the-art methods.",https://www.semanticscholar.org/paper/8ee35ed698527d9695c872e3b76715fec4ef69ad,"{'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '732c21998e251d64cd58b6a86886ee5907efeaa5', '84de7d27e2f6160f634a483e8548c499a2cda7fa', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'c4a1f79d62bafabc6447ed885525796786f21e22', '5db790198b9acf4e5efe350acdd814238fcacaa7', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '64f260cac1a9b2240b748b8106d2339f25b98565', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'f6284d750cf12669ca3bc12a1b485545af776239', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', '722ff8967633d0806298c22d25a845da222615f3', 'a997f1ecd85e1467d11252741d188fac8db22722', '8acbe90d5b852dadea7810345451a99608ee54c7', '10a498003e9204f5fc1328e706510a37e514d8c7', '6af440915b8a0718c93be1cf61905e41e620484a', 'f5a3598028cd375071a38f90f1b2122308e3a100', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '70f9968a356d840040a1c9207906f60376dc6bd4', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '4cfd8f903506865e7ccf28b0a07ee3c551487e92', '41747cbdbed84762dfbfc305254c97021279dc6e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '18e9e01f6cff97b9ac35c4300761cfc61a04ad8a', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '8381157eae4fbf8908d0312a9642f8e69e944449', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '2a417a16473e2bcb1c98cd7814bc106760925e60', '731a2844c5af6b072d3b404ecabbb488cdad9d46', '843959ffdccf31c6694d135fad07425924f785b1', 'ae37774ff871575b7799411bf87f42eb52634390', '746cf281d8198310b1242048bf4fd90e0486f1a9', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '3262e77099cefe24cff1308f204e673cac832451'}",46,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '41747cbdbed84762dfbfc305254c97021279dc6e'}",2,"['Xudong Yan', 'Huaidong Zhang', 'Xuemiao Xu', 'Xiaowei Hu', 'P. Heng']",Xudong Yan,"Xudong Yan, Huaidong Zhang, Xuemiao Xu, Xiaowei Hu, P. Heng",4.3478260869565215
d08775cf2bebcffa05c6fa506f687ef56953f128,AnoSeg: Anomaly Segmentation Network Using Self-Supervised Learning,2021-10-07,"Anomaly segmentation, which localizes defective areas, is an important component in large-scale industrial manufacturing. However, most recent researches have focused on anomaly detection. This paper proposes a novel anomaly segmentation network (AnoSeg) that can directly generate an accurate anomaly map using self-supervised learning. For highly accurate anomaly segmentation, the proposed AnoSeg considers three novel techniques: Anomaly data generation based on hard augmentation, self-supervised learning with pixel-wise and adversarial losses, and coordinate channel concatenation. First, to generate synthetic anomaly images and reference masks for normal data, the proposed method uses hard augmentation to change the normal sample distribution. Then, the proposed AnoSeg is trained in a self-supervised learning manner from the synthetic anomaly data and normal data. Finally, the coordinate channel, which represents the pixel location information, is concatenated to an input of AnoSeg to consider the positional relationship of each pixel in the image. The estimated anomaly map can also be utilized to improve the performance of anomaly detection. Our experiments show that the proposed method outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for the MVTec AD dataset. In addition, we compared the proposed method with the existing methods through the intersection over union (IoU) metric commonly used in segmentation tasks and demonstrated the superiority of our method for anomaly segmentation.",https://www.semanticscholar.org/paper/d08775cf2bebcffa05c6fa506f687ef56953f128,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '571b0750085ae3d939525e62af510ee2cee9d5ea', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '1a00dc525da31292e3734cbae2de681f114e30b1', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '51cdeeef710d1c84e10beadc8480c137ffe8d328', None, '41747cbdbed84762dfbfc305254c97021279dc6e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'a9d83b30c3e615286d3e24b6a2e2228872b39bc8'}",26,"{'62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e'}",7,"['J. Song', 'Kyeongbo Kong', 'Ye In Park', 'Seonggyun Kim', 'Suk-Ju Kang']",J. Song,"J. Song, Kyeongbo Kong, Ye In Park, Seonggyun Kim, Suk-Ju Kang",26.923076923076923
43bcef4084dbf90a849a48f9d0ee6a5f9e798b06,A reweighting offset bin classification network for surface defect detection and location of metal components,2022-01-01,,https://www.semanticscholar.org/paper/43bcef4084dbf90a849a48f9d0ee6a5f9e798b06,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd278d70a495d7699b1af85e9966b04a02644d052', '8e3f9c297bb2df253c505df20c5b2045e5dc67c7', '7ffdbc358b63378f07311e883dddacc9faeeaf4b', '019615181a80b6dca5d79a8e72e5eec21eb5cfde', '31db339dfe02a42923cfab7d103a0372c5aa7ddb', 'ea99a5535388196d0d44be5b4d7dd02029a43bb2', 'be7e167bef0103586990ab9fe388e6d0b79871ad', '71b7178df5d2b112d07e45038cb5637208659ff7', '3af65fa7b6cfff74dc8eae063f9456cd3337cf05', '10450ebd0266d22a9a067dacf98e7a7d2573467a', 'f61a2a2a2ef4266c2299d80e23dc591fb4fb0d17', '32a69681c103807704f71b838454c7924ceec5ce', '912bf95ee3ba3ad8cab403b97583caa2d9283746', '7da75ad0abf809b3da55909643215ab1d00e8b08', '04957e40d47ca89d38653e97f728883c0ad26e5d', '2e53867e8349c015ad46964809de47252f65e07d', 'a19a1d3dabeddf923b678a51994c652480272bbb', 'fef5a33e67a320e8ffd241142d6f60b3ff3a6d75', 'bc626a52664e948a0ffb2b95d0e1e6377a01171a', None, '4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0', 'de9949331c81cc8697d48dfd1b9f54d604a7d85a', '85aefb7a0c0e0f7a60b7c453d1767c9dd6b7964a', '2cfc634f7ed2c323da9fae27ce2d9cc437ac6c90', 'e3cb347d9c39ed237e4837c6b40b35a970355491', 'e4845fb1e624965d4f036d7fd32e8dcdd2408148', '72564a69bf339ff1d16a639c86a764db2321caab', 'd5851ecc786b643ed203fce98276bf67270e3add', '20f01423f6544338b0b67890ae63b0090235361a', 'aecba64d2a661b720b24724a1ef5f0eb8a853461', 'da60e046aac895b5775ed34bde45beb86aad0fe8', 'd3e09080f662f155a7f4c44597d963a2e97976a5', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', '9fcc1189d5b83258ed2c78b0447c96eb527fb63c', '658db1cce4192b0f76c5143653c4c6a5c61f1684'}",36,set(),0,"['Gu Caohan', 'Yi Lu', 'Chen Mingzhi', 'Gui-fang Sun', 'Z. Ni']",Gu Caohan,"Gu Caohan, Yi Lu, Chen Mingzhi, Gui-fang Sun, Z. Ni",0.0
4588b87fcec20e40761feb0c4bfce2cb96667d0a,A Comparison of Supervised and Unsupervised Deep Learning Methods for Anomaly Detection in Images,2021-07-20,"Anomaly detection in images plays a significant role for many applications across all industries, such as disease diagnosis in healthcare or quality assurance in manufacturing. Manual inspection of images, when extended over a monotonously repetitive period of time is very time consuming and can lead to anomalies being overlooked.Artificial neural networks have proven themselves very successful on simple, repetitive tasks, in some cases even outperforming humans. Therefore, in this paper we investigate different methods of deep learning, including supervised and unsupervised learning, for anomaly detection applied to a quality assurance use case. We utilize the MVTec anomaly dataset and develop three different models, a CNN for supervised anomaly detection, KD-CAE for autoencoder anomaly detection, NI-CAE for noise induced anomaly detection and a DCGAN for generating reconstructed images. By experiments, we found that KD-CAE performs better on the anomaly datasets compared to CNN and NI-CAE, with NI-CAE performing the best on the Transistor dataset. We also implemented a DCGAN for the creation of new training data but due to computational limitation and lack of extrapolating the mechanics of AnoGAN, we restricted ourselves just to the generation of GAN based images. We conclude that unsupervised methods are more powerful for anomaly detection in images, especially in a setting where only a small amount of anomalous data is available, or the data is unlabeled.",https://www.semanticscholar.org/paper/4588b87fcec20e40761feb0c4bfce2cb96667d0a,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '5cbca39eb8a7a97f998b62fa1b3cd061f0a79849', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '369f43ced18846e0818607e5d4a35c1803db8fb3', '34a51fe1bbfbc2c347e706e139ffb2a49f9ba70a', None, '5aebfbdd2b3b2e7ea1e75f4473c6b1dc50377de4', '5f61089d3d548a515f01b473f0119137d1f340d4', '732750bec3b4d8c0108d6daed642500765d5c0ca', '8267d5baf76e6d8e9956df19c560e27718a602bf', 'e0c8cd2ca2cf38afaf73b0265b6b5370a4066016', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '5fc7af3f77cd81af4947da742ff6dc063714a3db'}",15,set(),0,"['Vincent Wilmet', 'Sauraj Verma', 'Tabea Redl', 'Haakon Sandaker', 'Zhenning Li']",Vincent Wilmet,"Vincent Wilmet, Sauraj Verma, Tabea Redl, Haakon Sandaker, Zhenning Li",0.0
1e78fb6e1c95e0831f6e9f20186534f3bf20db4e,A Unified Model for Multi-class Anomaly Detection,2022-06-08,"Despite the rapid advance of unsupervised anomaly detection, existing methods require to train separate models for different objects. In this work, we present UniAD that accomplishes anomaly detection for multiple classes with a uniﬁed framework. Under such a challenging setting, popular reconstruction networks may fall into an “identical shortcut”, where both normal and anomalous samples can be well recovered, and hence fail to spot outliers. To tackle this obstacle, we make three improvements. First, we revisit the formulations of fully-connected layer, convolutional layer, as well as attention layer, and conﬁrm the important role of query embedding ( i.e. , within attention layer) in preventing the network from learning the shortcut. We therefore come up with a layer-wise query decoder to help model the multi-class distribution. Second, we employ a neighbor masked attention module to further avoid the information leak from the input feature to the reconstructed output feature. Third, we propose a feature jittering strategy that urges the model to recover the correct message even with noisy inputs. We evaluate our algorithm on MVTec-AD and CIFAR-10",https://www.semanticscholar.org/paper/1e78fb6e1c95e0831f6e9f20186534f3bf20db4e,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '790eceaa2cb59fef2634dad40f628346eb07cd3d', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '599fd051c9438011ec5b581983c89e8922b4a5e6', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '9cbbce7fc7fd38abf568e005606ea35e02da6cfa', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '19862af96b6af51e879e6e3f1d3d421af5427005', '3b3aefbbdb64e5812f133f220b3f129a36a30065', '4758baad6b22c61682e7f7182bb93723046f36f5', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd07284a6811f1b2745d91bdb06b040b57f226882', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '93040f8a5d10e8fde279e18d353aa3dca2873900', '4ed4dc4df5dbde2677852c33080e3c893bf0a5ba', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '37595f7a51982d776e57c7280b9445474d90f0be', 'd9704f8119d6ba748230b4f2ad59f0e8c64fdfb0', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd3b614f11969127a08447c41257b3a7b58766d18', None, 'c707517507873bc2cdc489b6fd9af74770468c48', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '206c2e79b5f1b4541b85f47517666961ed49500e', '5d90f06bb70a0a3dced62413346235c02b1aa086', '8381157eae4fbf8908d0312a9642f8e69e944449', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '02805f18989b7e77f30ee13defd6fecfcd0f499f', '962dc29fdc3fbdc5930a10aba114050b82fe5a3e', '843959ffdccf31c6694d135fad07425924f785b1', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '30895c61bb836f2cae7ef5ba6516886f746a7153'}",50,"{'6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '9cbbce7fc7fd38abf568e005606ea35e02da6cfa', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '19862af96b6af51e879e6e3f1d3d421af5427005', '3b3aefbbdb64e5812f133f220b3f129a36a30065', '4758baad6b22c61682e7f7182bb93723046f36f5', '62b77e5cb85fc61b84edd532f6d65714be152596', '93040f8a5d10e8fde279e18d353aa3dca2873900', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '37595f7a51982d776e57c7280b9445474d90f0be', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd3b614f11969127a08447c41257b3a7b58766d18', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '206c2e79b5f1b4541b85f47517666961ed49500e', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '02805f18989b7e77f30ee13defd6fecfcd0f499f'}",21,"['Zhiyuan You', 'Lei Cui', 'Yujun Shen', 'K. Yang', 'Xin Lu', 'Yu Zheng', 'Xinyi Le']",Zhiyuan You,"Zhiyuan You, Lei Cui, Yujun Shen, K. Yang, Xin Lu, Yu Zheng, Xinyi Le",42.0
854d0f20fdfecf383bbc7c4e163fadc3355a76fe,Towards a Plug-and-Play Fully Automated Unsupervised 360-Degree Deep Learning Visual Defect Detection System,,"Visual defect detection is critical to ensure the quality of most products. However, majority of small medium manufactures still rely on tedious and error-prune human manual inspection. The main reasons include: 1) the existing automated visual defect detection systems require altering production assembly lines, which is time consuming and expensive 2) the existing systems require manually collecting defective samples and labeling them for a comparison-based algorithm or training a machine learning model. This introduces heavy burden for Small and Medium-sized Enterprise (SME) manufactures as defects do not happen often and are difficult and time-consuming to collect. Furthermore, we cannot exhaustively collect or define all defect types as any new deviation from acceptable products are defects. In this paper, we overcome these challenges and design a three-stage plug-and-play fully automated unsupervised 360degree defect detection system. In our system, products are freely placed on an unaltered assembly line and receive 360 degree visual inspection with multiple cameras from different angles. As such, the images collected from real-world product assembly lines contain lots of background noise. The products face different angles. The product sizes vary due to the distance to cameras. All these make defect detection much more difficult. Our system use object detection, background subtraction and unsupervised normalizing flow-based defect detection techniques to tackle these difficulty. Experiments show our system can achieve 0.90 AUROC in a real-world non-altered drink ware production assembly line.",https://www.semanticscholar.org/paper/854d0f20fdfecf383bbc7c4e163fadc3355a76fe,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '82c7313ecc711537e9ce1e3c6abd678c9409448a', '98269ed00775c50c64b94f492da2e3e3952bf7ba', 'a381e58d8e28ab0fb61492463d8ea5f569c5eba6', '1f476738e6d2950ab2ca08ac852764640c8e9d93', '7ffdbc358b63378f07311e883dddacc9faeeaf4b', '00ce9aa4fc7d688af71fd3a0a467ea99c9b8017b', 'b1464ca857593c049873421db2f37bf2d0ff676d', '6b6360c6d2bdc55360925445b77d21126b477e9a', '2506cf222f0e05f2b9360fe1950dcc8033a1cd2b', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '5a987c003262da601ab0356219c36951112dd015', '9c24454b071bc8e96ea46c5064a7bddf07cca464', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '9ef18f83f7c355d0892e45772b9a6fa0c2616fd1', 'e79272fe3d65197100eae8be9fec6469107969ae', '689757a2c0443f2f98c1c99c9e71683a49b1b757', 'fd550b29c0efee17be5eb1447fddc3c8ce66e838', 'e53a42b0eb3b1085c1c58de9194457417e7aa24a'}",21,{'b1464ca857593c049873421db2f37bf2d0ff676d'},1,"['Zijian Kuang', 'Xinran Tie', 'Lihang Ying', 'Shih-Chun Jin']",Zijian Kuang,"Zijian Kuang, Xinran Tie, Lihang Ying, Shih-Chun Jin",4.761904761904762
f182ec2b3567284f0e01cfaec0169e3605252710,Anomaly Detection for Industrial Inspection using Convolutional Autoencoder and Deep Feature-based One-class Classification,,"Part-to-part and image-to-image variability pose a great challenge to automatic anomaly detection systems; an additional challenge is applying deep learning methods on high-resolution images. Motivated by these challenges together with the promising results of transfer learning for anomaly detection, this paper presents a new approach combing the autoencoder-based method with one class deep feature classification. Specifically, after training an autoencoder using only normal images, we compute error images or anomaly maps between input and reconstructed images from the autoencoder. Then, we embed these anomaly maps using a pre-trained convolutional neural network feature extractor. Having the embeddings from the anomaly maps of training samples, we train a one-class classifier, k nearest neighbor, to compute an anomaly score for an unseen sample. Finally, a simple threshold-based criterion is used to determine if the unseen sample is anomalous or not. We compare the proposed algorithm with state-of-the-art methods on multiple challenging datasets: one representing zipper cursors, acquired specifically for this work; and eight belonging to the recently introduced MVTec dataset collection, representing various industrial anomaly detection tasks. We find that the proposed approach outperforms alternatives in all cases, and we achieve the average precision score of 94.77% and 96.35% for zipper cursors and MVTec datasets on average, respectively.",https://www.semanticscholar.org/paper/f182ec2b3567284f0e01cfaec0169e3605252710,"{'01625cba9f8a783994377d4f35aa765242faab4f', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'e0f73e991514450bb0f14f799878d84adc8601f9', '4b8678a4ec60947dcc53530e6a198088ff90af30', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '732c21998e251d64cd58b6a86886ee5907efeaa5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '7ca09256a4d2743164ac8116da831946b1b8d2d4', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '84bdd4897a924bf4863dc34576995f952532320e', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '7b2c82e9c7491760f7b132ae719a007e5c51b098', 'b0c065cd43aa7280e766b5dcbcc7e26abce59330', 'c53352a4239568cc915ad968aff51c49924a3072', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'eb4e68345cf4fb953245f34653553959523f7e4c', '8a8cfa45b4c0d071fbffa091c02670b19c94b693', '3b9cfe673dc2f651ab71a38af304daaa60a8206b', '67529adb196e5b5e003c07dc8e54a1b71247f6d5', '00695a31a80221c7125e49885a4767896ec2c4f7', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a0e8f4348968195c80494b7a4245edb91a252c93', '73f76a40ed20aa3c6a8e27e4db4a8c102e7b4c6d', 'c367d10860cc88be75e5561a36ba8e1e44cb8933', '190181ca2e04db44b2536c5f9d0e2367538ccdb0', None, '580396c680951b7ff93defcac7cfe085dfe1814e', '41747cbdbed84762dfbfc305254c97021279dc6e', '219f7706e28c91dcff3d6c4273ac71868714cac2', 'a7c828184693a453a6c2867dee233ed054b2012e', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '23ffaa0fe06eae05817f527a47ac3291077f9e58', '5b6ec746d309b165f9f9def873a2375b6fb40f3d', 'a2a1a84bc6be32d981d8fac5da813a0f179a3f75', 'db6a64ac194188e46ddceee7954a902dca008c25', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '3d76e4a420ee27ca5101648e7ea7d717e73207c6', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",47,"{'41747cbdbed84762dfbfc305254c97021279dc6e', 'e021d59638966a6fbb36854cc2cf1045de7a62d2'}",2,"['Jamal Saeedi', 'A. Giusti']",Jamal Saeedi,"Jamal Saeedi, A. Giusti",4.25531914893617
a046f52e8057958acb6cf179638b8d24535ee506,FL-MGVN: Federated learning for anomaly detection using mixed gaussian variational self-encoding network,2022-03-01,,https://www.semanticscholar.org/paper/a046f52e8057958acb6cf179638b8d24535ee506,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '36db3efac28debf164ed83363a9b7a5ecc9fd17b', '7a59dd34a23832b7046b90dd296ddbd53b701b35', 'b1c7d765e878dd6f9c01a222152ab5091aab1101', 'a7b44a3196320484c34acfe2204fa163a2a5c528', '27b078cd2b6906ede921da844c2cbabfb1d0ebb3', '165064cde473c4dfe3e6d375fc44857fc849dab3', 'fbe6553641ce3c6a1914ef5d9f8797fa762c8bad', '63576b10727bc550cea2163198bbaa9722a1c916', 'f3f589921f53d1ba5f84a7f774732c319570fcab', '91815e24a770de7091aa21523cf67143741ad499', '60f43e763b370af0028317d7f6d94885cdfe390a', '6b6360c6d2bdc55360925445b77d21126b477e9a', '03538806e21be89bfddf72195a1e0e84b404b06d', '6c4e9fef6f71f9cb54ab802a2302201565cd0ed5', 'dd748369db6e9d78d5617bd3304179a9f9c79f5a', '64553f320cb3e9ea5285e14315380f04d4168ff4', '8dff7c4c92df5a0f96ad3f19e989648fbdb6d7d7', '3166a41b9f73fdd3112e4c75e7ac2e210673ca2f', 'ec5d66ad274faf2b8e3d6a3ba9519e1faac5275e', '2a56bd89fd1a9457f0705142540ffc4396fad4f7', 'df55232cd62ec57788ca23ef284abe9ee9d5453b', 'fdd0682d2a44fc5b24baeb2cd007e5bd2f49340f', '775247047d0b56950ba5ea77d4a29772eca95c1b', '8ed98bd58c799718d6fd389e2218bb89b1ecb9d7', 'a5a685092ddee74867e79d81668aef018b3e00f3', '2324d25fcbeb11d04dd2956026a5c4d68eac54dd', '12e4da113ad5db979b139280c1789b469389476d', '74c1fea115395e10746e4ef3c7f8c970913f9028', '383061c39d9835d24d9bddb6bf11f2cdd11a23f2', 'a91c259bd3df8b2763f59ac583fb912c30e9dc40', '49bdeb07b045dd77f0bfe2b44436608770235a23'}",32,{'775247047d0b56950ba5ea77d4a29772eca95c1b'},1,"['Dongmin Wu', 'Yi Deng', 'Mingyong Li']",Dongmin Wu,"Dongmin Wu, Yi Deng, Mingyong Li",3.125
9c1eed367424c573ff495961fb0f4a76eb75db79,An unsupervised defect detection model for a dry carbon fiber textile,2022-06-06,,https://www.semanticscholar.org/paper/9c1eed367424c573ff495961fb0f4a76eb75db79,"{'9ac46875f929e552aebf4ad1b585f5e23849149b', '775247047d0b56950ba5ea77d4a29772eca95c1b', '1b0bdf467e29693925a570b63615e6be8446439b', '0984fcdeef834ec29e37ff710444c196a3f96f0d', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a66eafd9512b5ee67f7af58af10c48cf8170d948', '7304b5ae51dc9d91bd988141d6d7b1f02aa3f86f', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '76a9f336481b39515d6cea2920696f11fb686451', '0f366de3ea595932dad06389f6e61fe0dd8cbe74', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",14,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', '775247047d0b56950ba5ea77d4a29772eca95c1b'}",2,"['Martin Szarski', 'S. Chauhan']",Martin Szarski,"Martin Szarski, S. Chauhan",14.285714285714286
37257b1e003d97f617f41a5ccf982566ce0a208b,AnomalyHop: An SSL-based Image Anomaly Localization Method,2021-05-08,"An image anomaly localization method based on the successive subspace learning (SSL) framework, called Anomaly-Hop, is proposed in this work. AnomalyHop consists of three modules: 1) feature extraction via successive subspace learning (SSL), 2) normality feature distributions modeling via Gaussian models, and 3) anomaly map generation and fusion. Comparing with state-of-the-art image anomaly localization methods based on deep neural networks (DNNs), AnomalyHop is mathematically transparent, easy to train, and fast in its inference speed. Besides, its area under the ROC curve (ROC-AUC) performance on the MVTec AD dataset is 95.9%, which is among the best of several benchmarking methods.",https://www.semanticscholar.org/paper/37257b1e003d97f617f41a5ccf982566ce0a208b,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '52d7ae292f285ab24b050b8d229ac98cd674523c', '5c2148a698c0f9cb1364f1936431bcf97b04e2ef', '8a4f46417e1239f562fb7ecd7addb3631edcb871', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '4b579a64556d157926d1fd08191b812a638d37de', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'e1820e33e0347c4e9e625b640c7156faefe74159', '38ff1be1f6b6f53b82ba4527721820dedeb59afc', '0b29e2b329411a375573ca5014eec4a09031c3fb', '72afa0fd1263d4ec60be39ed31be6755fdbaafa1', 'ffd743cdef874446ea3bae04cad34d1ec309fa6e', '1c4e9156ca07705531e45960b7a919dc473abb51', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', 'eebd8bfdb2929dfdb1110cf9fbf8d0d008c8edca', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'd2f5b81ebf06d43f9579d233e687323eb99c9aa6', '24d48ebc062f05f9883f1b9c36f81b91be6f3221', 'd5f324c13644f753f0634b3d2bd02ee9c7899ae4', '785a7e01267683deb54a94f6a8b4019806e3f085', '17c153285e983ce75098d7224f7abdb932229ab9', None, '475d637203b01d1df739792d6168d7c24fbeb981', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'cf4ee08b8f571cc40f5c0e07906c49caf0ac023d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'd0b011880a2ae0f5fd4cc2a098bcaace04aee214', '503b713d3f19909cb759aedfcaf6e86706adf7d4', '962b56cf0a99243e577ec75b8c55191af80e6b0b', 'c64fd1e19b1d20f35ee110a6259f5d5dd964dfae', 'cae76e39bc6b8d49b101539db446e40a92d70bd4', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",38,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",8,"['Kaitai Zhang', 'Bin Wang', 'Wen Wang', 'Fahad Sohrab', 'M. Gabbouj', 'C. Kuo']",Kaitai Zhang,"Kaitai Zhang, Bin Wang, Wen Wang, Fahad Sohrab, M. Gabbouj, C. Kuo",21.05263157894737
a090711c5e17f0d9907f243c05251350215c088f,Transformaly - Two (Feature Spaces) Are Better Than One,2021-12-08,"Anomaly detection is a well-established research area that seeks to identify samples outside of a predetermined distribution. An anomaly detection pipeline is comprised of two main stages: (1) feature extraction and (2) normality score assignment. Recent papers used pre-trained networks for feature extraction achieving state-of-the-art results. However, the use of pre-trained networks does not fully-utilize the normal samples that are available at train time. This paper suggests taking advantage of this information by using teacher-student training. In our setting, a pretrained teacher network is used to train a student network on the normal training samples. Since the student network is trained only on normal samples, it is expected to deviate from the teacher network in abnormal cases. This difference can serve as a complementary representation to the pre-trained feature vector. Our method - Transformaly - exploits a pre-trained Vision Transformer (ViT) to extract both feature vectors: the pre-trained (agnostic) features and the teacher-student (fine-tuned) features. We report state-of-the-art AUROC results in both the common unimodal setting, where one class is considered normal and the rest are considered abnormal, and the multimodal setting, where all classes but one are considered normal, and just one class is considered abnormal 1 .",https://www.semanticscholar.org/paper/a090711c5e17f0d9907f243c05251350215c088f,"{'02227c94dd41fe0b439e050d377b0beb5d427cda', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '1c06870e1ecc63e120e45a2283ca4b72c153e867', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '6e0121548ae114b8ed70b5189cbc4800d8b4290d', '70472c97e0460cbc04bc0148b0fc59392edb3c50', 'db787640c9b42416ff8d7015546e667e58267177', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '19862af96b6af51e879e6e3f1d3d421af5427005', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '2528a82dd2266600d4ee2b54165556a984de94d4', 'e31fa9510047c0df23fb4dd37ee7c70783a3fa60', '547c854985629cfa9404a5ba8ca29367b5f8c25f', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'c85a9d25147b0eaf765855df475dc5cd95e4d2f5', '04513c7c0b3a63fde81a996dae064a28d453c17a', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '498e003901f8287e89e5064477cd22dd47e49d61', '0d5406775fab3e71848908327fb5504df5f60f92', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '6af440915b8a0718c93be1cf61905e41e620484a', '38f93092ece8eee9771e61c1edaf11b1293cae1b', 'cdd553c54d5769ec218a8ea921e27144a6b1aadb', '6ff2a434578ff2746b9283e45abf296887f48a2d', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '4cfd8f903506865e7ccf28b0a07ee3c551487e92', 'db8c381cbaf80c4323959eccee07c85a76b54839', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '175373c715aa28b50c3242c82ab27c10729f83be', '5d90f06bb70a0a3dced62413346235c02b1aa086', '97f08c1ae8ca5ddf5948c66bfbbc0546ac154807', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '4d39ee7cca8fedf792570724255a4357aa41dbf8', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'add2f205338d70e10ce5e686df4a690e2851bdfc', 'c92ee6ff32fa4833fa1c2bdf29284e2a58ddb640', 'd2c733e34d48784a37d717fe43d9e93277a8c53e'}",45,"{'78d80c343d36baaf89f18e12d325cf6309fb6c8f', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'db8c381cbaf80c4323959eccee07c85a76b54839', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '498e003901f8287e89e5064477cd22dd47e49d61', '19862af96b6af51e879e6e3f1d3d421af5427005', '41747cbdbed84762dfbfc305254c97021279dc6e', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f'}",10,"['M. J. Cohen', 'S. Avidan']",M. J. Cohen,"M. J. Cohen, S. Avidan",22.22222222222222
d60a828c4f76162bd167326c52de70dcf73d9530,Reproducing Visual Explanations of Variational Autoencoders,,"In this work we perform a replication study of the paper “Towards Visually Explaining Variational Autoencoders"". 3 This paper claims to have found a method to provide visual explanations of Variational Autoencoders (VAEs). The 4 paper’s primary claim is that their proposed method can generate gradient-based attention maps from the latent space of 5 a VAEs. This is visually demonstrated on the MNIST dataset. Moreover, these attention maps are claimed to be useful 6 for anomaly detection, which is demonstrated on the UCSD Ped1 and MVTec-AD datasets. Finally, this method is 7 integrated into a loss function to obtain the attention disentanglement loss. This loss is shown to improve latent space 8 disentanglement when integrated into a FactorVAE model, which is demonstrated on the dSprites dataset. This paper 9 aims to reproduce all of the claims stated above. 10",https://www.semanticscholar.org/paper/d60a828c4f76162bd167326c52de70dcf73d9530,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'e1041d0c162de1889d5b97846b4a187044a4124a', 'fd7c12e1eac960a4b4e7d72499c94b8eb747eefe', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', '9163a1161848ec55f9de3c771821c70181d2a496', '5091316bb1c6db6c6a813f4391911a5c311fdfe0', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', None, 'e3b5c2fecec38ab3a7139fcc45814073f1369248', '46f74231b9afeb0c290d6d550043c55045284e5f', 'd19356ce442d9c04625b3a253f370feaf00ea6a0', '04541599accc47d8174f63345ce9c987ef21685b'}",14,{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b'},1,[],NOT FOUND,,7.142857142857143
f33de7b2fa5425391f5afa81b85818d03325cb0e,Image Anomaly Detection by Aggregating Deep Pyramidal Representations,2020-11-12,,https://www.semanticscholar.org/paper/f33de7b2fa5425391f5afa81b85818d03325cb0e,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'ce9edb785f28c81bd7c2864940ed001429178e1e', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '88ecd1aa9148c59782cb35ffd6c9b08084087ad8', '357e32e0769a05b831a993c68631f9ff8ff62111', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '67bdefa8dc2cb991beb4b421e14271155de781a5', '7e889ff5d94f2efb2df34089d8f2cca5e314792b', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'df8294254b229e1751de70db5988273f97e218a0', 'b37b3086add419e4679255366d61d4e70896651e', '2eb2320ff1e1a109d9c8bf0d53b3edc370d4cea6', '118fbb38b521b9b70f66359f57fee1f96a70cc9a', '6bb61321d45960f18098568f54eeb1ce413b7abe', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '70f9968a356d840040a1c9207906f60376dc6bd4', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '4fd62d384b792511441c2f358b25726012e13a48', 'fb6cf1fcb62937ea8c16759a7b64191d5abdbcee', '4ad090484636e926285abb2dfe3b449c56692528', '05b986c308c34af35ecbc8631f9742a9a2d8647f', '9fa3720371e78d04973ce9752781bc337480b68f', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '84af0bbe339c1adbc9d075dee99b9d4f86a186c5', '78e41d3eb2acd47083a4ec4765ad443617a109ef', 'd4ca18249446328c86d9da295a21c679aea1ed77', 'f9cc7e2c400b4ab509e47d158017cd1cbf526792', '0936352b78a52bc5d2b5e3f04233efc56664af51'}",36,set(),0,"['P. Mishra', 'C. Piciarelli', 'G. Foresti']",P. Mishra,"P. Mishra, C. Piciarelli, G. Foresti",0.0
d413b9954cbfc613baa75f185eb2c32bb2ce9a5d,Joint Use of Skip Connections and Synthetic Corruption for Anomaly Detection with Autoencoders,2021-08-30,,https://www.semanticscholar.org/paper/d413b9954cbfc613baa75f185eb2c32bb2ce9a5d,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '2788a2461ed0067e2f7aaa63c449a24a237ec341', '64c72496e8dde82de4e1294d56d2a5a3ae2495b8', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '8388f1be26329fa45e5807e968a641ce170ea078', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9acc51b06f54b07836fad4cc24633187dc21317f', 'ab96c776f96e10f10d88ac5abbe9335afe935c81', 'a9e438c1e66917379509165fc40f335514870b56', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'f466157848d1a7772fb6d02cdac9a7a5e7ef982e', '510a24375b5166842cae47f2e54052846704e8f4', '5435a9ab36a308cef10bc725104e8f778ed3a328', '3328f64fe21404f64c85966c28f6c9f1101e0cb8', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '90e4f12fa8fb126d0f416c8b61bfb5f73f8b7b74', '25757e7819eeb8829d3524474f973b79befd7b59', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '10f8d1106e49fa07c1dab8bd200e76896ee9dd13', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'c09a4d90754628015c311e9c51f4b3ab888c796e', '206c2e79b5f1b4541b85f47517666961ed49500e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', '2a417a16473e2bcb1c98cd7814bc106760925e60', '572bdf59c34df16c1ade08590001f1b106cdf6b3', '5954f7aee33d7334cfa0516b0b81b41bdaf7c238', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '75a838cbc1541858b9c484001cade327640dc280'}",38,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', 'ab96c776f96e10f10d88ac5abbe9335afe935c81', '206c2e79b5f1b4541b85f47517666961ed49500e'}",5,"['Anne Collin', 'C. De Vleeschouwer']",Anne Collin,"Anne Collin, C. De Vleeschouwer",13.157894736842104
2c89b183df320c3ef698989bdc5d1d4731c4d65d,Reconstruction by inpainting for visual anomaly detection,2020-10-17,,https://www.semanticscholar.org/paper/2c89b183df320c3ef698989bdc5d1d4731c4d65d,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', '1cae417456711c4da184f5efcd1b7464a7a0661a', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '8388f1be26329fa45e5807e968a641ce170ea078', '8201e6e687f2de477258e9be53ba7b73ee30d7de', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '0c9ae806059196007938f24d0327a4237ed6adf5', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', '5435a9ab36a308cef10bc725104e8f778ed3a328', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '91a73e9c6cbba422ee50e287f1bfa9ba30f6922b', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', '37c59035e9985cda2321b2bdcb4849335210ac85', '5f61089d3d548a515f01b473f0119137d1f340d4', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '094ac7510d1723cb9c2da01db47291322aa29025', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '1d033b30f38642e4b6dd146bb8b464bfb58aad96', 'f36f8d32252679f4221c3d2afc2407a9f56b29a7', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",37,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e021d59638966a6fbb36854cc2cf1045de7a62d2'}",3,"['Vitjan Zavrtanik', 'M. Kristan', 'D. Skočaj']",Vitjan Zavrtanik,"Vitjan Zavrtanik, M. Kristan, D. Skočaj",8.108108108108109
3b0284d501e9b1b6c199d8b07c6826a165c4b4f2,ViM: Out-Of-Distribution with Virtual-logit Matching,2022-03-21,"Most of the existing Out-Of-Distribution (OOD) detection algorithms depend on single input source: the feature, the logit, or the softmax probability. However, the immense diversity of the OOD examples makes such methods frag-ile. There are OOD samples that are easy to identify in the feature space while hard to distinguish in the logit space and vice versa. Motivated by this observation, we propose a novel OOD scoring method named Virtual-logit Matching (ViM), which combines the class-agnostic score from feature space and the In-Distribution (ID) class-dependent logits. Speciﬁcally, an additional logit representing the virtual OOD class is generated from the residual of the feature against the principal space, and then matched with the original logits by a constant scaling. The probability of this virtual logit after softmax is the indicator of OOD-ness. To facilitate the evaluation of large-scale OOD detection in academia, we create a new OOD dataset for ImageNet-1K, which is human-annotated and is 8 . 8 × the size of existing datasets. We conducted extensive experiments, including CNNs and vision transformers, to demonstrate the effectiveness of the proposed ViM score. In particular, using the BiT-S model, our method gets an average AUROC 90.91% on four difﬁcult OOD benchmarks, which is 4% ahead of the best baseline. Code and dataset are available at https://github.com/haoqiwang/vim .",https://www.semanticscholar.org/paper/3b0284d501e9b1b6c199d8b07c6826a165c4b4f2,"{'d03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0e4b0d177e550d365f456375781cd0e4f7a04979', 'd98ec42c5bc64b06b5d6e259467528e0121ae69b', 'c8b25fab5608c3e033d34b4483ec47e68ba109b7', '3b316377f1d7cbcf3c907c4d8b08c05f4521b541', '431ba9fae8fccad1665979d455c6307786e47318', '547c854985629cfa9404a5ba8ca29367b5f8c25f', '820f81f4263ad84b581e2b0feec563db0c64ff9b', '2b8088253e2378fce001a090fe923b81e8dedf25', 'f19092561296244e1dafe7d799e7906e96a63773', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '36653f8705b56e39642bcd123494eb680cd1636b', 'c3ddd90b53dc797029c4576af01b9c35bb846a44', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '45557cc70cd6989ab6b03e5aeb787e34299099f7', 'ae9bf201f128cabaa4350b54ff6607525c736cd5', 'b9bd435b65d8214f1bcab9268ac2fce509cfffe6', 'a43f7d6a751a6ad8667272f1176d2f15dbd8feb6', '652529542d33d1687b89c0af0f66a1a4ab2efc55', '29309743870c825f9645a4803af727402462e513', '35b966347dae2f0d496ea713edf03a68211838a5', '39b492db00faead70bc3f4fb4b0364d94398ffdb', '6ff2a434578ff2746b9283e45abf296887f48a2d', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', None, 'bb5018951e0d869769af9336052acad0fe4b36bb', '7f9760a76e9cf424da0b72d42f75594cefc4a329', '714d78a452562adcacbb9f28f39dd64a8198e6ea', '18c125ce0f64e85577f7d30132cf0e92ec664bf4', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '2b62161cd182637acf711d34a50c8ee42c997226', '485037ec7cbee7c9460d341213ebf5d4d7474702', '05eb6eb4ea7d2b332295dfa5aeb64d5f47c1e628', '0a58924a54fbeec7e8fc2632e7dc1463c6f0091d', 'fee5c79243d99161f1128b3de322add6fe2b6987', '0495d9df8eb84dcdab4e5536179823cd26279949', 'ad7ddcc14984caae308c397f1a589aae75d4ab71'}",38,{'820f81f4263ad84b581e2b0feec563db0c64ff9b'},1,"['Haoqi Wang', 'Zhizhong Li', 'Litong Feng', 'Wayne Zhang']",Haoqi Wang,"Haoqi Wang, Zhizhong Li, Litong Feng, Wayne Zhang",2.6315789473684212
e173f1066fe0a7777c05eb036d28eda31b4f5cd8,Projected Sliced Wasserstein Autoencoder-based Hyperspectral Images Anomaly Detection,2021-12-20,"Anomaly detection refers to identifying the observation that deviates from the normal pattern, which has been an active research area in various domains. Recently, the increasing data scale, complexity, and dimension turns the traditional representation and statistical-based outlier detection method into challenging. In this paper, we leverage the generative model in hyperspectral images anomaly detection. The gist is to model the distribution of the normal data, while the outof-distribution sample can be viewed as the outlier. At first, the variational inference-based anomaly detection methods are investigated. We theoretically and empirically find that they are unstable due to the strong notion of distance (f -divergence) served as the regularization. Secondly, this paper introduces sliced Wasserstein distance, which is a weaker distribution measure compared with f -divergence. However, the number of randomly slicing poses a difficulty to estimate the true distance. In the end, we propose a projected sliced Wasserstein (PSW) autoencoder-based anomaly screening method. In particular, we leverage a computation-friendly eigen-decomposition method to find the principal component as slicing the high-dimensional data. Furthermore, our proposed distance can be calculated with the closed-form, even the prior distribution is not Gaussian. Comprehensive experiments conducted on various real-world hyperspectral anomaly detection benchmarks demonstrate the superior performance of our proposed method.",https://www.semanticscholar.org/paper/e173f1066fe0a7777c05eb036d28eda31b4f5cd8,"{'8679caeac5fc01ad40fcb1d7040623ff6ef68ce9', '5a7608d0ab7147bb91a0b90827d3635ea8a1ff6f', 'ca56df64a351f873c8c138874326a6f64eec011d', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '732c21998e251d64cd58b6a86886ee5907efeaa5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '9ca3af4440eb4aa4fd0a65dfa559685b2c39cd42', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '8d5e5b680c3206d85832203ebcbb0f8295b7bfe5', 'd2958dc046f74144f8f64913612c24bac3268f1b', '00a1077d298f2917d764eb729ab1bc86af3bd241', '355b4e74774798c177c82943eef925d66a2bb2ce', 'ffa46c6c0956204fbb59c576155ba7199cc49c96', '20fcf3d229ddfee812fdda2d2219c9cb92610af9', '306609a4abdae3c3f21fb11581d35911a4772012', '4aea3547974399a32d7aa7c007b10bd665e93fab', '0372728b9a2def008ef3240a62362f0afbfb5d43', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '6745c95b88ff9b12401a9ba6f4007f036be591a0', '4b07c418a40fdedbefeca7e78afe2b8a1c473537', '7042203472d1fa2923c1e9e0c29eeaefc33c14fe', '9a1c19b56e81fead0b8de7ad984f1f92cd8bc130', 'f4fcda45da5eab0752942867b68f9fbdfa59da4a', '1c46943103bd7b7a2c7be86859995a4144d1938b', 'e39f6313d374531a1b76441b091b897fb6b4272f', 'e7070b52403920d914d483285a42addb2de9ef2b', '00695a31a80221c7125e49885a4767896ec2c4f7', '4e97c55f4c228e0a9ae715c3ae8af44abc0dcbc4', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '902e76dfa8a36355eb27dec795fa66700527a8d9', '4751ee333ae0a74558dba9a1437858a2b721f81a', 'a90226c41b79f8b06007609f39f82757073641e2', 'a7c828184693a453a6c2867dee233ed054b2012e', 'df93cf5adc9d662605ea05579a323dd3fd69f887', '032d865e92d97613a3659ec4a0b3e3243535b8ff', '6f1d45549864dc5d539276df8e4382d5c0dc69c6', '5239f449210b089b75ab335fc74720dbf2e02b58', 'a8db789522b9375396bd91de631342740ba19a12', '21bb1ea15514e3d093638eb86bed49ebc05fa94a', '6f24d7a6e1c88828e18d16c6db20f5329f6a6827', '3c074de0fb42049e31de3e5ffe63fb3aae28c378', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",43,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Yurong Chen', 'Hui Zhang', 'Yaonan Wang', 'Q. M. Wu', 'Yimin Yang']",Yurong Chen,"Yurong Chen, Hui Zhang, Yaonan Wang, Q. M. Wu, Yimin Yang",2.3255813953488373
10771db928358e66ad76ebe1b46343787710fe59,SEMICONDUCTOR DEFECT CLASSIFICATION,2020-10-25,"Automated inspection has become a vital part of quality control during semiconductor wafer production. Current processes are focussed on finding defects via variation from a ‘golden’ image using pixel to pixel comparisons or utilization of opaque neural network-based approaches. We present a novel approach, which uses the Bag of Visual Words technique to determine local features that correspond to specific defects within a wafer image, known as a custom vocabulary, as a way to begin creation of a more transparent system for automated defect detection and classification. We demonstrate that the custom vocabularies, combined with machine learning algorithms, result in high performance accuracies with efficient computational run-",https://www.semanticscholar.org/paper/10771db928358e66ad76ebe1b46343787710fe59,"{'642e328cae81c5adb30069b680cf60ba6b475153', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '10da0ae02c614b574aad28809969c2e6b03702ab', '442a7613e992da09758482b035204ac2184ec7da', '852d0047d5d379d19127458054f65a007405be91', '6e28216ad6fd39e353f2f3be83e840932b24c2d4', 'b91180d8853d00e8f2df7ee3532e07d3d0cce2af', 'd8c35a70fc2ec1749323ea2827befc14c68028ff', '0c958860ac71d5deca6e452b8e34bf9658eff7fc', 'd9281df17aa89b4c67e617c9af618f9b71ef2ac1', '467a8ee5faec87607b710322d36364fb28a5981b', '4538e65545c25de7c9d5d6e250bf753adf86b757', '7a2252ccce2b65abc3759149b5c06587cc318e2f', '6c7cf406a47048730c1a08d46cb0166b16566524', 'd6cda0477d5b7892097604447c502f1845717185', '8c04f169203f9e55056a6f7f956695babe622a38', None, '1b8ff4ee827dae5b23e8702b02ac5c176dbbd9ef', '4543670c4b2d88a9b67525e0084044adef94ae76', 'deb7727169553e66c2d5bc8ddc6142cde592e1f5', 'e7d4a58cd59b25df6c7f176f7fd2ecbc4900307d', 'd7ea2cdcfbdb8fb5b5761f7e0a1753d647ebe913', '976e29fe6c9baeb39732bca0e35f66f84d5bdd90', '3dc86d60349a46f231565b9e1bf37319a30181d9', '21670fb228c09dfc059814afb93a837b61fdd985', '19334a3ba2c1b4e9a37bac9f498280da28be7f62', 'f0c5991dbb130fa6b5de011cf7a04f6ed815ef68', '1fc0be3a3382759bffecb8df220caf5ec063ee2d'}",28,set(),0,"['Terence Sweeney', 'D. Kerr', 'S. Coleman']",Terence Sweeney,"Terence Sweeney, D. Kerr, S. Coleman",0.0
14d4b3cf84382653ba6c58b7aa5798ecb7713664,Channel Randomisation with Domain Control for Effective Representation Learning of Visual Anomalies in Strawberries,,"Channel Randomisation (CH-Rand) has appeared as a key data augmentation technique for anomaly detection on fruit images because neural networks can learn useful representations of colour irregularity whilst classifying the samples from the augmented “domain”. Our previous study has re-vealed its success with signiﬁcantly more reliable perfor- mance than other state-of-the-art methods, largely specialised for identifying structural implausibility on non-agricultural objects (e.g., screws). In this paper, we further enhance CH-Rand with additional guidance to generate more informa- tive data for representation learning of anomalies in fruits as most of its fundamental designs are still maintained. To be speciﬁc, we ﬁrst control the “colour space” on which CH-Rand is executed to investigate whether a particular model — e.g., HSV , Y CbCr , or L ∗ a ∗ b ∗ — can better help synthesise realistic anomalies than the RGB , suggested in the original design. In addition, we develop a learning “curriculum” in which CH-Rand shifts its augmented domain to gradually in- crease the difﬁculty of the examples for neural networks to classify. To the best of our best knowledge, we are the ﬁrst to connect the concept of curriculum to self-supervised representation learning for anomaly detection. Lastly, we per- form evaluations with the Riseholme-2021 dataset, which contains > 3 . 5 K real strawberry images at various growth levels along with anomalous examples. Our experimental re- sults show that the trained models with the proposed strategies can achieve over 16% higher scores of AUC-PR with more than three times less variability than the na¨ıve CH-Rand whilst using the same deep networks and data.",https://www.semanticscholar.org/paper/14d4b3cf84382653ba6c58b7aa5798ecb7713664,"{'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'ba013acca784bfea74241c879e18b72984950493', '5bb4293f57bdc4bebda402bd4fe39ee3cf5d3e16', '8de174ab5419b9d3127695405efd079808e956e8', '62b77e5cb85fc61b84edd532f6d65714be152596', '73f76a40ed20aa3c6a8e27e4db4a8c102e7b4c6d', '732c21998e251d64cd58b6a86886ee5907efeaa5', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '48f9a48aa5b1230b05a443d2d531e6441a541686', '66d93532f450a36e01257ba9dddfdf878797a583', 'db787640c9b42416ff8d7015546e667e58267177', '4282a344671189e17c9c9e00e329fe2d0fa71769'}",12,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '5bb4293f57bdc4bebda402bd4fe39ee3cf5d3e16'}",4,"['Taeyeong Choi', 'Grzegorz Cielniak']",Taeyeong Choi,"Taeyeong Choi, Grzegorz Cielniak",33.333333333333336
d84c62734eb07141495421da1fdf9ed211ea4f93,Unsupervised Two-Stage Anomaly Detection,2021-03-22,"Anomaly detection from a single image is challenging since anomaly data is always rare and can be with highly unpredictable types. With only anomaly-free data available, most existing methods train an AutoEncoder to reconstruct the input image and find the difference between the input and output to identify the anomalous region. However, such methods face a potential problem – a coarse reconstruction generates extra image differences while a high-fidelity one may draw in the anomaly (Fig.1). In this paper, we solve this contradiction by proposing a two-stage approach, which generates high-fidelity yet anomaly-free reconstructions. Our Unsupervised Two-stage Anomaly Detection (UTAD) relies on two technical components, namely the Impression Extractor (IE-Net) and the Expert-Net. The IE-Net and Expert-Net accomplish the two-stage anomaly-free image reconstruction task while they also generate intuitive intermediate results, making the whole UTAD interpretable. Extensive experiments show that our method outperforms state-of-the-arts on four anomaly detection datasets with different types of real-world objects and textures.",https://www.semanticscholar.org/paper/d84c62734eb07141495421da1fdf9ed211ea4f93,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '14bc1322116b7288782dd0637c9fe2b361d22562', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '41fcef711faca9013fd0980a9f6ec1d23c9c76c8', '8201e6e687f2de477258e9be53ba7b73ee30d7de', '8388f1be26329fa45e5807e968a641ce170ea078', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9b09d296059909490096e34e9df2d95314787ad5', '35da0a2001eea88486a5de677ab97868c93d0824', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '744fe47157477235032f7bb3777800f9f2f45e52', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'c53352a4239568cc915ad968aff51c49924a3072', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '5435a9ab36a308cef10bc725104e8f778ed3a328', '6a25e474075e26ddd18a24cd80deeb1d2ab33b42', '9460aa334bc0edca33b88da2a2a6f0d6a1b27f92', '1c46943103bd7b7a2c7be86859995a4144d1938b', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '1f528877c4d8d5df3b3abbfa64379677d451956b', '60104351ac65115503c9e92e856bcab6a13b0ce8', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd3b614f11969127a08447c41257b3a7b58766d18', None, 'c2b733a79db700b971327a58ef42699fe8a416aa', '41747cbdbed84762dfbfc305254c97021279dc6e', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'ffdcad14d2f6a12f607b59f88da4a939f4821691', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', 'be0ef77fb0345c5851bb5d297f3ed84ae3c581ee', 'c661d1940518445f350aa5e49ed16f815d90bec2', '34008f26cec7fae1f60b8da38abb6b012bf83e13', 'f5b0d51ca54fd1b7268486393679dd612d482f64', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '0943ba71d5a4d839a4d2d88a8aee72025fb77982', 'add2f205338d70e10ce5e686df4a690e2851bdfc', 'e15cf50aa89fee8535703b9f9512fca5bfc43327', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",51,"{'1f528877c4d8d5df3b3abbfa64379677d451956b', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'd3b614f11969127a08447c41257b3a7b58766d18', '41747cbdbed84762dfbfc305254c97021279dc6e'}",5,"['Yunfei Liu', 'Chaoqun Zhuang', 'Feng Lu']",Yunfei Liu,"Yunfei Liu, Chaoqun Zhuang, Feng Lu",9.803921568627452
6517f92d519fc126cc18924231bafd8945a554d1,Reconstruction Student with Attention for Student-Teacher Pyramid Matching,2021-11-30,"Anomaly detection and localization are important problems in computer vision. Recently, Convolutional Neural Network (CNN) has been used for visual inspection. In particular, the scarcity of anomalous samples increases the difficulty of this task, and unsupervised leaning based methods are attracting attention. We focus on Student-Teacher Feature Pyramid Matching (STPM) which can be trained from only normal images with small number of epochs. Here we proposed a powerful method which compensates for the shortcomings of STPM. Proposed method consists of two students and two teachers that a pair of student-teacher network is the same as STPM. The other student-teacher network has a role to reconstruct the features of normal products. By reconstructing the features of normal products from an abnormal image, it is possible to detect abnormalities with higher accuracy by taking the difference between them. The new student-teacher network uses attention modules and different teacher network from the original STPM. Attention mechanism acts to successfully reconstruct the normal regions in an input image. Different teacher network prevents looking at the same regions as the original STPM. Six anomaly maps obtained from the two student-teacher networks are used to calculate the final anomaly map. Student-teacher network for reconstructing features improved AUC scores for pixel level and image level in comparison with the original STPM.",https://www.semanticscholar.org/paper/6517f92d519fc126cc18924231bafd8945a554d1,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', 'e8874d7d585ae1c355e186efdcc9f704b3d43b49', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'e399a626ba21fafb19b3661603ec9724058e951b', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'd6dccb5d71fbb6f5765f89633ba3a8e6809a720d', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'df67d46e78aae0d2fccfb6212d101a342259c01b', '82527ee075d2f7bf731da80edd8d4a92b01c2b8b', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, '41747cbdbed84762dfbfc305254c97021279dc6e', '93967329802185e3fe2f0946b66e3359943325fe', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '353ecf7b66b3e9ff5e9f41145a147e899a2eea5c', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'a8f3dc53e321fbb2565f5925def4365b9f68d1af', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', '8cb34cbdcf65c23ef98430441b14a648c4e8d992', '317c172f314f8cb634f7569ed5bf3ae7dd25c313', 'ad655c25e052fa4eeed53421344aca6f239c4c9d', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",32,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '9277dc70c74bcadf80dab11c28ead83fd085deec'}",3,"['Shinji Yamada', 'K. Hotta']",Shinji Yamada,"Shinji Yamada, K. Hotta",9.375
df972693ea52670a2dbbb21fd475c3c27890992e,A Comprehensive Review of Deep-Learning-Based Methods for Image Forensics,2021-04-01,"Seeing is not believing anymore. Different techniques have brought to our fingertips the ability to modify an image. As the difficulty of using such techniques decreases, lowering the necessity of specialized knowledge has been the focus for companies who create and sell these tools. Furthermore, image forgeries are presently so realistic that it becomes difficult for the naked eye to differentiate between fake and real media. This can bring different problems, from misleading public opinion to the usage of doctored proof in court. For these reasons, it is important to have tools that can help us discern the truth. This paper presents a comprehensive literature review of the image forensics techniques with a special focus on deep-learning-based methods. In this review, we cover a broad range of image forensics problems including the detection of routine image manipulations, detection of intentional image falsifications, camera identification, classification of computer graphics images and detection of emerging Deepfake images. With this review it can be observed that even if image forgeries are becoming easy to create, there are several options to detect each kind of them. A review of different image databases and an overview of anti-forensic methods are also presented. Finally, we suggest some future working directions that the research community could consider to tackle in a more effective way the spread of doctored images.",https://www.semanticscholar.org/paper/df972693ea52670a2dbbb21fd475c3c27890992e,"{'f4fe5c55ab658efcec9c3a44c2c9f969d5518767', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'a2a9983f60f732a70c2412b396930da188a112f4', '61d1146cc72c3ecf3f36486f718e11ce0472a7a1', '78a604b9ff7968a12b42d6421fbbb0fb9523320f', 'a6859f695e6b2bd967df7cdb8becf8c9465b472a', '25a2dbc55bcef77e81d2b961d60411a8c323f75c', '745d715623debdca4d1c719bc23c54ce11f7d96d', 'a31e45127aaaf0d2d1cbc0b13205880d116c09e9', 'c412d8269cbc408827cf61fd0f7dafb0877d7ef2', 'e9829021fefd5c4544883642f8f944e475eee0ef', 'f9c387a8cd16d6258b1c301058867569011d9a9b', 'afc11a384ed298f2980f6a1547ef0aa3cb5573c6', 'e4425f0b540acff10e0ecee1a8a362f584ff4d5c', '10e19c22877621990f64ec7190364e63c0dcda68', 'f429b695a0d24593400e2b73dace4908320fbf68', '5849d7f421d6e85cd2cc24ad8963793fa9e116c6', '854df6036a3a2e0a03ba8f089cd17cb82b02de80', 'd7299cb573b4e60cbe568c51a35f98aef182b11b', '2380cb3f2ed91fed3966560c2261ca0d46986b7d', '744fe47157477235032f7bb3777800f9f2f45e52', '2d066beb34469559e0fc5e5ab4d68dc736cfd46f', '5cd47df260e65b2650a1123a2136ee5bc918d4c6', 'aa2720bd32bffc142cb1b9ef53523df57f7218af', '77f1a5e3166b7fca66870fb61ddc8d6070d12cd0', '780f1beb184c19d65247314c34f18f1837971ea6', '70c8253c6954e3f02760dea1a6f701c0e18bde18', '23cc897d7e94957c3cf3e77639147ca75d0cb476', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '30d4c64b0c02b8220b23397092fce51eab5d7ee7', '38f07a1e267d6822b2ac1fce3c5c74f8442043e5', 'f585e4128a150ff31c0150056af2b74d49ca0322', '47364dceef11cb6f36af8b68b127b74da45a0978', '44d2abe2175df8153f465f6c39b68b76a0d40ab9', '846f9980d37a89c4390f5922a147fdaf5b61f1bb', 'c7b14989ee25750dd2749a900d39c61f36a111a3', 'c5222dfe915948750d43456dadd64d6cf44aca25', '046d09f510ef51a302b59eeb7045ec791f923ccd', '4543670c4b2d88a9b67525e0084044adef94ae76', 'eb42cf88027de515750f230b23b1a057dc782108', '02100a41e52fa1b3f0b0de5b5f7562a24d2b5a03', '566a1ad5afc0f5a080e041cd5174ff923d11e0f4', '35b64edbcc9c6889bc41c70003ae847f3ba666e5', '526c4a4a60592770460f017c22500afd0b31a3ac', '517543720ad632a13e3846d1f10e35d22fc4547a', '5b6ec746d309b165f9f9def873a2375b6fb40f3d', '66970c48758b65a36d77c0fa9add1198d36ecd59', '84f63d525bdc6a8e5d298972e07442121eb31567', '05d408a8b720f3b45a7e3a83fb14015554133582', 'a33fa56607c43e12cc4d7b2075ac9abf79e8e880', 'e7fde7daa9fe93ae172291a7a502edefd10f7529', 'afc4cc092f990644ff7a11dc7ab60519920cbc9d', '677fc4abdae996e0f2fab8f7d94d7bb4f2aa8b69', '4258fd74a8bbb03b0997e76ba8ab6684b161f9d3', '505a654f13b950445b428d7b20be24f850e4b4d0', 'b6e4d96e4adfaba9de89dda2696e75139ccb77e4', 'c02dfe65313ed9ba7b0912f1992d6a9c48dc5f8f', 'd891dc72cbd40ffaeefdc79f2e7afe1e530a23ad', '4445c6dae49074cdefda59f0c3c03886f04467bc', 'c92faa385c7e600a45430f9a374fc32435ede87e', 'e3a10973ee4e3be5fc53bee96e4d8e56469e432a', 'a29f2bd2305e11d8fe139444e733e9b50ea210d6', '02b28f3b71138a06e40dbd614abf8568420ae183', '01c9fd4c011a580e106dd4a8d4e86299acac8564', '6fe1439e40429c7cd7029ecf83ca6f36fd0c8040', '3d26fb6e819a79b6abd4964d8d96314e74f73423', '1663122ca7c8240305dad06e7ca987bd248b0305', '5d753a065ac6cabcce1cedf774f0cc81a7801ac6', '23a4da2d9a67361629a9e757035d509a1146a942', '33d6b2d9fc7cb152e3cc134a3fd5cbdc02405b3f', 'ee125fef53038c2b31b3c084844e34efd80785e7', 'f2669f87d93739ef977d2a47cee42d586d31a9e0', 'b89d881f0603248819808ac241a359cbf3014622', 'ebd55542967468debb78a78f120f001dc8129aac', 'e0ff0dc2574ce6d4bdca7bc41756b8e12d953cfd', '317aee7fc081f2b137a85c4f20129007fd8e717e', 'e26102cde5fc8f8b2872be32208b1beb51cb40c7', '41fdf7e43621c5b1e17eefe0a321e90039f76e57', '5103ff72b7d5700d8e32597d645cc37f21019379', '55467ff033b0f08aabc45dce26d42245ae6ef4a4', 'f4d38c99b8064efba89adddcfac91c85b9e687e9', None, '445def496333e92ac9d7beeb5168a905f7449c4c', 'bbe52eba4a23bb37b57be770bf82cb6bdb4e3cf7', '0b313436628a4f88627c34c373d9591b8d267f0d', '908091b4a8757c3b2f7d9cfa2c4f616ee12c5157', 'ce8431d4f3c1bc879fc839041516d9116442945a', '39b562b9679f0b789bb11acc4e08c7d798ca1b21', 'f6667bc5be13aa62b8ff03f1294a60ff2ea1a13e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'bdf81dcd76fa96e980e24cdd1d912b772b801f44', 'b4f8c1353aa2d88cacfaef1b3afba74dbf427d89', '96d8412c14d8756d0b5682ec39fad5063fee2d9d', '155dde0ea9609c7c68bbe9f498c854d6812afa32', 'b82058b4bf630d33e129ab097b8cacf6cc3d4556', 'bcf4f29b56ccbfdd775fd41ca837010a0c180ea7', 'd5cbb15a8354b6abc38da34ebdce3a2a9eeb8118', '8b443b98099f4d713dcdc6cd706a7010b457a586', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '6cfa0cd6c63c9d33b424eb7a9235428eb65e5e2c', '753bb416c4ec90031d3eaf238e4b6f53645defac', '4c95d65d0aaa530b6c4c628091c738bffba2b00e', '6f9be47ae591b37a20a940883359b113ec5f3609', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'd42b66341e68a8f932af47eae8204f4d55ab089e', 'd92ef81e39d65d89f2c35d63088d1950ed862e7d', '703dc51b138e49efa554e8dd5817e966b6a18c91', 'b71ac1e9fb49420d13e084ac67254a0bbd40f83f', '272100433b5bb66ecf86da59974f8eb950625d25', '043c62d35243e8aa7b8dfd98cf43367cfaf2482f', '65f96431077b7a4cfb999fbe8fc68db73ab80077', 'cbf3118faf6d00a2ed3adaba1f58598aef04230d', 'dfd48a719029050c6a19ddb7911d6dc840f01f77', 'fe0ced86e17be34f3267f58ed3560598285e62f8', '87c280d0dc204ca5db0d325991a21c211aeec866', '1e76597e331c37b283eb5ccd8a146a0b6fd37491', 'd0a41bf42ece9a2ff9140b0240d52a8248f2f928', '6e948f2d5634f1a1e43bfe6a0d0abca3140e7c0e', '9a6ee80121518fadeb21227f9bd9a0f31dfe49b0', '911acf1766c8d2e216b1efb5ebf0df251012f2e7', '3e81e7c5e6f4caa029b6918d23b8f19f9f1f9231', '5598872d32fd15e367584eb99c07ae79f794243e', 'd4e54ea33c097cc0a741200d45053e78f5d5ba9c', '27835ef64f2fa29e18cd23bf8a4a919987fc5ad1', '37033b779765b5ed3b3eaaf8e1d5c5a62ff02e85', '694cccc7205053af917d1d038d8fc4ba45777959', '7f37998a72b7475afad32e2e58e02d3eb721b5ac', 'eebf1a48b030104f64b487c6aff3d5f3c0fce9f7', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '87ecaf580e9c5af977368930fc453f318bdf5e0f', 'f3246658f050084390b862a249998611cc979664', '484f5a035b6b80e63943aa849a6c289f5a0db4ce', '0f08e2f70d4973183fbbd4a27d973069f333aa16', 'e8a5f27e7805f8de84ea008d59452ff864271696', '21bb9543695df9109353706b77926c6407b96c9e', '7c454683cb2bf20012fac6b3a5e51439be95e68e', '4cdc2235cb3ca02c8fd615520ae84b0813752e9d', '6164f5a183e1ce0ddc5aae1b140cff7c7f32df00', '004c7dbd5578865ac72cfa7b6ebc51c7fa7cda31', 'c12b8ba3830db4957563624afc6500a1c013d7cd', '78f0f6f55cdbb65ab63cd4178f6e035bddaf7fbb', '613c63818e03bbb56cbcef1d3f0061d0d37e5966', 'd44b403a81764457dce2ec098592e4981716bcb2', 'c4c06578f4870e4b126e6837907929f3c900b99f', 'f218e9988e30b0dea133b8fcda7033b6f1172af9', '9063b17ccfdf73fc789d01d3c44c451244638528', 'bf904f5fa08258d4eba1b80e6e6a14906bad27a6', '9667f8264745b626c6173b1310e2ff0298b09cfc', 'dafd046b1660ef4fb29c09912fb74642ac128f1c', '5e83ab70d0cbc003471e87ec306d27d9c80ecb16', 'ac1f84cc50f31b2ae7775820242d7c71f1c3f42a', '4501ab9a5d2d40e9f47c777d601131578fa969f6', '4f8d648c52edf74e41b0996128aa536e13cc7e82', '71b7178df5d2b112d07e45038cb5637208659ff7', '9aea99b194a3473829cef62d71ec466a09cb462e', 'e1aae1c92a8177da9ea481b41df4af59e44765ac', '9c284eccd0c319a4a933f4be04e0cc627a9cfd23', 'b4d1c1b9ec675638e1fb7fc1d6fc1fa820a52cc5', '1a7205588d9c4eb764ff893b8991e5044f2278b6', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'c0492f7b36b271d924c89506079593bccc3dc409', 'aa77f0064c1dcc628fcf0fd951c7d83181ceb1f9', 'b8ca108a81a859da4df68ff5a996da2e347e0f9c', 'ccd354af0b0f54cd202727edd1280f09f061d7f8', '2d45428866bc457cbb1e3dd86aa1942c32def25a', '04f45db0a9d02633a56f606baf88389ca0fbcdf3', '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', '2ea4e541e968fc2d363f15d2661f448a57cf1b3d', '1b3641d18c44143cdf1e23e6e6d0366b3da24bd7', '17498446b84b211105e3291a0ca4ce6228a10de9', 'ddf76e881da8d59ed0fd9237e8e40fe7b372e0c2', '4acad7303aa1a90a7e087937afc430e7ef9d15d7', '25e5170c178fe2578900fbb49890d98bbf51e46a'}",173,{'2c89b183df320c3ef698989bdc5d1d4731c4d65d'},1,"['Ivan Castillo Camacho', 'Kai Wang']",Ivan Castillo Camacho,"Ivan Castillo Camacho, Kai Wang",0.5780346820809249
9cbbce7fc7fd38abf568e005606ea35e02da6cfa,AnoViT: Unsupervised Anomaly Detection and Localization With Vision Transformer-Based Encoder-Decoder,2022-03-21,"Image anomaly detection problems aim to determine whether an image is abnormal, and to detect anomalous areas. These methods are actively used in various fields such as manufacturing, medical care, and intelligent information. Encoder-decoder structures have been widely used in the field of anomaly detection because they can easily learn normal patterns in an unsupervised learning environment and calculate a score to identify abnormalities through a reconstruction error indicating the difference between input and reconstructed images. Therefore, current image anomaly detection methods have commonly used convolutional encoder-decoders to extract normal information through the local features of images. However, they are limited in that only local features of the image can be utilized when constructing a normal representation owing to the characteristics of convolution operations using a filter of fixed size. Therefore, we propose a vision transformer-based encoder-decoder model, named AnoViT, designed to reflect normal information by additionally learning the global relationship between image patches, which is capable of both image anomaly detection and localization. While existing vision transformers perform image classification using only a class token, the proposed approach constructs a feature map that maintains the existing location information of individual patches by using the embeddings of all patches passed through multiple self-attention layers. Subsequently, the feature map, which has been transformed into three dimensions, is used to perform decoding. This design preserves the spatial information sufficiently by excluding the fully-connected layer, which extracts latent vectors in existing convolution-based encoder-decoders. The proposed AnoViT model performed better than the convolution-based model on three benchmark datasets. In MVTecAD, which is a representative benchmark dataset for anomaly localization, it showed improved results on 10 out of 15 classes compared with the baseline. Furthermore, the proposed method showed good performance regardless of the class and type of the anomalous area when localization results were evaluated qualitatively.",https://www.semanticscholar.org/paper/9cbbce7fc7fd38abf568e005606ea35e02da6cfa,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0eff37167876356da2163b2e396df2719adf7de9', 'd3dd00e24f96bae7ad780ac5fdb0c14194d5cb74', 'c8b25fab5608c3e033d34b4483ec47e68ba109b7', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', '4758baad6b22c61682e7f7182bb93723046f36f5', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '9221ae991591154a94b416fa4812e991d06ea5a5', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', '39b492db00faead70bc3f4fb4b0364d94398ffdb', None, '2e8d62277e40d465343e8dfb32ecc246f320540e', 'cf122c84af8c85e15c3dffaca4069dd455b56a1e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '24046c62be024695e9c73768ef6bcf870ca383c0', '24b8a0b02bcb7934967757fc59d273a71ba67e30', '962dc29fdc3fbdc5930a10aba114050b82fe5a3e', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', 'a6fd96a900d4130940b488863b71fd09ad41ccb9', '49ae00b9a8539ba1a2a7d77408daad850fd33095', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'ad7ddcc14984caae308c397f1a589aae75d4ab71', '7256dade1cb0e9676d304ade0ab57d3ce0e3a7c0', '598fe25743f9492c5c1ba30274ea446f65426d85', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",33,"{'4758baad6b22c61682e7f7182bb93723046f36f5', 'cf122c84af8c85e15c3dffaca4069dd455b56a1e', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '24046c62be024695e9c73768ef6bcf870ca383c0', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '49ae00b9a8539ba1a2a7d77408daad850fd33095', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['Yunseung Lee', 'Pilsung Kang']",Yunseung Lee,"Yunseung Lee, Pilsung Kang",27.272727272727273
8e180ffb0c4bfe4db41a245637042a28fc98d891,Learning Unsupervised Metaformer for Anomaly Detection,2021-10-01,"Anomaly detection (AD) aims to address the task of classification or localization of image anomalies. This paper addresses two pivotal issues of reconstruction-based approaches to AD in images, namely, model adaptation and reconstruction gap. The former generalizes an AD model to tackling a broad range of object categories, while the latter provides useful clues for localizing abnormal regions. At the core of our method is an unsupervised universal model, termed as Metaformer, which leverages both meta-learned model parameters to achieve high model adaptation capability and instance-aware attention to emphasize the focal regions for localizing abnormal regions, i.e., to explore the reconstruction gap at those regions of interest. We justify the effectiveness of our method with SOTA results on the MVTec AD dataset of industrial images and highlight the adaptation flexibility of the universal Metaformer with multi-class and few-shot scenarios.",https://www.semanticscholar.org/paper/8e180ffb0c4bfe4db41a245637042a28fc98d891,"{'c209d9c0d49b2377860acad2acbcc13523a40b7f', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '5151d6cb3a4eaec14a56944d58338251fca344ab', '9e1847a58978ae7040a6afb91d112076d8738592', '4041de0d24854e29f270c2233609f6e696528005', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'bd63fef46192e7dd3eec6ab5ed0c2afa19556b3a', '689c97982f0ef6d8b0df3ec33a3abe29b8f97c1f', '5db790198b9acf4e5efe350acdd814238fcacaa7', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'f1b9a9a2498a594b46dd840877d25dbe03420b82', 'b8d7bbe9e194579cf6598aa83ed7043e4c1181dc', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'd5caec8107da41ec71fc0bb36d60fc2d8834846e', 'b1464ca857593c049873421db2f37bf2d0ff676d', '42b3a039a666caab2881bfef244d3ce074b7f529', '10a498003e9204f5fc1328e706510a37e514d8c7', 'c889d6f98e6d79b89c3a6adf8a921f88fa6ba518', '2583797b4e5ee1a4bfc9da9d76e44ece4329170e', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '9f295c2dd41c9dec1c0e866c1701b4cf48ff807d', 'a0e8f4348968195c80494b7a4245edb91a252c93', 'd3b614f11969127a08447c41257b3a7b58766d18', '70f9968a356d840040a1c9207906f60376dc6bd4', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '41747cbdbed84762dfbfc305254c97021279dc6e', '7d277c97cf9d0c8a0ed671b3fb9b1e7c8e647cfc', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'e2820bffe5b42cb7d88b7f65c12171c62ab4aae2', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73'}",39,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'd3b614f11969127a08447c41257b3a7b58766d18', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', '41747cbdbed84762dfbfc305254c97021279dc6e'}",5,"['Jhih-Ciang Wu', 'Ding-Jie Chen', 'C. Fuh', 'Tyng-Luh Liu']",Jhih-Ciang Wu,"Jhih-Ciang Wu, Ding-Jie Chen, C. Fuh, Tyng-Luh Liu",12.820512820512821
72d8b9cf34289da6c7431496659d9a0e54243b7e,Weakly Supervised Temporal Anomaly Segmentation with Dynamic Time Warping,2021-08-15,"Most recent studies on detecting and localizing temporal anomalies have mainly employed deep neural networks to learn the normal patterns of temporal data in an unsupervised manner. Unlike them, the goal of our work is to fully utilize instance-level (or weak) anomaly labels, which only indicate whether any anomalous events occurred or not in each instance of temporal data. In this paper, we present WETAS, a novel framework that effectively identifies anomalous temporal segments (i.e., consecutive time points) in an input instance. WETAS learns discriminative features from the instance-level labels so that it infers the sequential order of normal and anomalous segments within each instance, which can be used as a rough segmentation mask. Based on the dynamic time warping (DTW) alignment between the input instance and its segmentation mask, WETAS obtains the result of temporal segmentation, and simultaneously, it further enhances itself by using the mask as additional supervision. Our experiments show that WETAS considerably outperforms other baselines in terms of the localization of temporal anomalies, and also it provides more informative results than point-level detection methods.",https://www.semanticscholar.org/paper/72d8b9cf34289da6c7431496659d9a0e54243b7e,"{'a7bfb9bbe2e3d6dfa980e5e40b1f447f007984a3', 'bc9293bcee13cae5cff8a088f4038c4236decd42', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'b89f8f74432f4caaa96d65bc242ca05932bc5004', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', 'ca0917853ea55c0ec4cded50914eb825fd45d00f', '5187df17503f78c7e063c2ea0a707e3e59c48235', '80184c6a88fc97a09393b7336bc2ddb12e9b1030', '904627c2d5a91ab8cb1b682e42f06f1ca192aea6', 'a4c94b221062d0737ee967affa80ce2110cc50c0', 'f37bc75aa1833e1330c39c4f04b131baca08d67b', 'df0402517a7338ae28bc54acaac400de6b456a46', '3dd9ddf2594d7d63af5d361154992ef2abf6d593', '440d248d148f7e36dad232e48f1c5c1cbc556d86', 'ca04f6fb87815426e1bec8f7fc0dcbbaf9f35814', 'ee1d50a0c6448253eaf8d1f7f6b00d893419589d', '00ccecc56ed83945fafb8e2dc48ffc1609618040', '06d4409e591be2affe151fbc471196d430ee1f09', '317aee7fc081f2b137a85c4f20129007fd8e717e', '0b771778298718f1656c332beb931a6c452988c4', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '792250ae660b7c25f85eeea7dcae623e4301d97c', '803a1fed191ad3eb79eb3c073900b31e7e5ad0a9', '18f355d7ef4aa9f82bf5c00f84e46714efa5fd77', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '08a426042c9926419198ee22c9bf80e6e4b5791b', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '7336c45f4049f7a7b91a2e57a4b526faa8eced30', '1855fc5254f6c40c49df7fc15409e8278cabad3c', '41747cbdbed84762dfbfc305254c97021279dc6e', '60ca4a90d751e315a2b143289a5c54488e324949', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '8a916608e81eea5d7494e577c8563cae44a1b8c6', 'de638f32e6e5762328357b855a9af3de8c20ea29', '6869ab1f42e30b415829de9928f7e4a606113601', '0017aeb0c049a383d962399d26100ec2bf5cc7c7', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', 'f780a8fe6eb184e34c03823fa1b2bcd4b5b4fb7c', '598fe25743f9492c5c1ba30274ea446f65426d85', '67628543f7ae51979acadfbb8860568b25f263da'}",44,"{'41747cbdbed84762dfbfc305254c97021279dc6e', 'c8c70d1a201f41af78b4e3f11810d0f8c6c452b3'}",2,"['Dongha Lee', 'Sehun Yu', 'Hyunjun Ju', 'Hwanjo Yu']",Dongha Lee,"Dongha Lee, Sehun Yu, Hyunjun Ju, Hwanjo Yu",4.545454545454546
149f5a50eef5b115fc67c21693c4e701a6161c43,SegmentMeIfYouCan: A Benchmark for Anomaly Segmentation,2021-04-30,"State-of-the-art semantic or instance segmentation deep neural networks (DNNs) are usually trained on a closed set of semantic classes. As such, they are ill-equipped to handle previously-unseen objects. However, detecting and localizing such objects is crucial for safety-critical applications such as perception for automated driving, especially if they appear on the road ahead. While some methods have tackled the tasks of anomalous or out-of-distribution object segmentation, progress remains slow, in large part due to the lack of solid benchmarks; existing datasets either consist of synthetic data, or suffer from label inconsistencies. In this paper, we bridge this gap by introducing the “SegmentMeIfYouCan” benchmark. Our benchmark addresses two tasks: Anomalous object segmentation, which considers any previously-unseen object category; and road obstacle segmentation, which focuses on any object on the road, may it be known or unknown. We provide two corresponding datasets together with a test suite performing an in-depth method analysis, considering both established pixel-wise performance metrics and recent component-wise ones, which are insensitive to object sizes. We empirically evaluate multiple state-of-the-art baseline methods, including several specifically designed for anomaly / obstacle segmentation, on our datasets as well as on public ones, using our benchmark suite. The anomaly and obstacle segmentation results show that our datasets contribute to the diversity and challengingness of both dataset landscapes.",https://www.semanticscholar.org/paper/149f5a50eef5b115fc67c21693c4e701a6161c43,"{'d03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0008bf4e851fe1be9696307ad24585127bec536a', '0e4b0d177e550d365f456375781cd0e4f7a04979', 'a176b0ad0916e11712174f0cc973ab9f8e0e59e7', 'a41efad7ff629b8db586dbd140fe1464532dc406', '802168a81571dde28f5ddb94d84677bc007afa7b', '927ee108115e03cc14c70e567b044e66423fb54b', 'd5add0ccc3f5a4c2586a55d84a9f74add8190452', '50ebb3f8f19154f6e129ca2f04af094cf17b9ad9', 'c8c494ee5488fe20e0aa01bddf3fc4632086d654', 'a9b4fc31e6c0253a8924d6fcd19c70c4ac6f3db2', 'c269ef171487144dd97ac82c29c211e384968b43', '985769b3e1f1b1e871c20253f6287716c5c6c6b1', '40709121423d2d332c72057fd2268382a98fb8e9', '431ba9fae8fccad1665979d455c6307786e47318', '97bb928a9db5c9546e7de8c38ba52da7695f7b65', 'c6e4516912e31ceca7151781b71e13e41dc50b84', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'd2452e8b0c4d44a0d954931b70b3151efd37d096', '98360611fdd34dd52bd9234abf306200cc40225a', 'b44313836f435c8c774f9123cc29a38ad8deb7bd', '36e4eafe4af6cfdc66e45c51f2309a14aa3b78d7', '815c84ab906e43f3e6322f2ca3fd5e1360c64285', '0df347f5e3118fac7c351917e3a497899b071d1e', '71b7178df5d2b112d07e45038cb5637208659ff7', 'd82800c79dd335297336fe10b1a60d47706e4296', '9217e28b2273eb3b26e4e9b7b498b4661e6e09f5', 'c0fb5023875e3ecb9560e70bc96f56b9dc34155b', '86bbf0def8c464f3b287c1a42465323915f2b419', '229e105fd4d34815e476702dd5ca4362943c475d', 'ef8d42105b06d2bb06b2177921a6415e44d5a90d', '10f8d1106e49fa07c1dab8bd200e76896ee9dd13', '6ff2a434578ff2746b9283e45abf296887f48a2d', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'b959164d1efca4b73986ba5d21e664aadbbc0457', 'ff7bcaa4556cb13fc7bf03e477172493546172cd', None, 'c707517507873bc2cdc489b6fd9af74770468c48', '4f0b8f730273e9f11b2bfad2415485414b96299f', 'ce05ebc31e7aa8e4152673bb240b9f8d27ebea21', '1330d1be226904d6421c378c138bb26fb08b00c3', 'a25b63a6a0071d7d88ff4671c1fd40f320a08533', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', 'f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', '1031a69923b80ad01cf3fbb703d10757a80e699b', '2daa90492b5509b33567eaf49360926f0e79f286', 'bff013da42d934d513ea186ba2e772a68d034586', '3af5222ec90044319588f337344ef453ac5cb0fd', 'e9a88a25b4d6332de95d829b5a892275dc3ffcfc', 'ebb5d9db9152ce81671143c35c5d6ce58b23255e'}",52,set(),0,"['Robin Chan', 'Krzysztof Lis', 'Svenja Uhlemeyer', 'Hermann Blum', 'Sina Honari', 'R. Siegwart', 'M. Salzmann', 'P. Fua', 'M. Rottmann']",Robin Chan,"Robin Chan, Krzysztof Lis, Svenja Uhlemeyer, Hermann Blum, Sina Honari, R. Siegwart, M. Salzmann, P. Fua, M. Rottmann",0.0
cd36a8ef4be917d0e1aa5c5e9cf545601cdee533,Artificial intelligence-empowered pipeline for image-based inspection of concrete structures,2020-12-01,,https://www.semanticscholar.org/paper/cd36a8ef4be917d0e1aa5c5e9cf545601cdee533,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '133981fcdec11dce6a3ceafa548cdadac9375054', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '2941488b503121f9e8e5b09b7bdf28568b6e39e0', '2621f385e02f682f522eb2886033e2482c71de37', 'dfd5c2d199d830272eb7cfb4049ac5ff885a25d5', '6f4472e311228397e319213ba3ee90bdaef66da3', 'aea2e91f1cd90c0fc9f63790c62600ad2d9a99a6', 'ff8d5fe3a7a75711549c6fa2c951e5b702d4636c', '1142ff65b9392c3d2f2c19196978a0dcb2ad45c1', '04e645fc3e5a578b8d5d662f0b0070eb1255a3e2', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '53226cb05116e39f8aefb0cab75e4e3b83004244', '59e2fb3e14be18f925985895e6df86320cbdba9f', '90398f81712bf9ff4e1b274cc9faf3c03b13d5e2', '14a74f38561e40f839fbac6c9fb06b085e39f282', 'e91fc6c5e5f083b28ef7b4f06163310cf07e8b0d', 'a4cec122a08216fe8a3bc19b22e78fbaea096256', 'a228ce656599fe1413ed0671c260b5dad1190e3e', '6344120752edb26d7c4d17c55ce4ca3f4adf446f', '62094816252357787791872dbb825e99e3f9fc7b', 'a4faeb68c39eda9fa87834a54d13b6b1e1d7d92b', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '6ea358c63de04be500d1ecfffb6f59617ae8bb2a', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '11c1926d89083a435aba89707a981a3515da490c', 'bab9e71e13da27c6caa87cd677814839e9809f2c', 'f4e8549edc9114f9f8cc432a522b2a8197393c4a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '358b9707c2d45c06e23a264d21390c2ed5a1d7ee', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '414170e0f6959ec452c6da866a61a2a557682f56', 'a78f8d0c1d6bf1b2a96ec2e50a8cc9cefbf6f8eb', '20d3c8710b03c31cc6cb86a6fd964478586c4e34', '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', 'ce24c24674af9c0c10cfc7a1a59fd850fc5f0ce1', '4c753f5ab22fe05777dbef32d706fa029e0be1af', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '6bb2951a790400e88e7eb3754f5af2daee245afb', 'b07a01e3d5989316cf9204622463dedffd7bc128', '52a57597f872c8aeb7131ae06afcbb8fc3325d87', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '24046c62be024695e9c73768ef6bcf870ca383c0', '2705c429a30f5a5c16ab68bd68c27ff54ebedd5d', 'b2b8ab163fb0183325dd3458e3cbaad2f8bf265e', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'c1f277de5326780c3a37eac4424338c7bb0551eb', '230e5d70718cb5007da065a9e3d66f30a4706001', '034462766dabc28bc8149204a1f30d9cbe062628', '34f25a8704614163c4095b3ee2fc969b60de4698', '6c700640b5516346fedf489c82ce5ccb290b710b'}",54,{'24046c62be024695e9c73768ef6bcf870ca383c0'},1,"['J. Chow', 'Zhaoyu Su', 'Jimmy Wu', 'Zhaofeng Li', 'P. S. Tan', 'Kuan-fu Liu', 'X. Mao', 'Yu-Hsing Wang']",J. Chow,"J. Chow, Zhaoyu Su, Jimmy Wu, Zhaofeng Li, P. S. Tan, Kuan-fu Liu, X. Mao, Yu-Hsing Wang",1.8518518518518519
c4e5c2f51770ac7389b0fe76659f5141c4f47f1b,Anatomy-aware Self-supervised Learning for Anomaly Detection in Chest Radiographs,2022-05-09,"—Large numbers of labeled medical images are essential for the accurate detection of anomalies, but manual annotation is labor-intensive and time-consuming. Self-supervised learning (SSL) is a training method to learn data-specific features without manual annotation. Several SSL-based models have been employed in medical image anomaly detection. These SSL methods effectively learn representations in several field-specific images, such as natural and industrial product images. However, owing to the requirement of medical expertise, typical SSL-based models are inefficient in medical image anomaly detection. We present an SSL-based model that enables anatomical structure-based unsupervised anomaly detection (UAD). The model employs the anatomy-aware pasting (AnatPaste) augmentation tool. AnatPaste employs a threshold-based lung segmentation pretext task to create anomalies in normal chest radiographs, which are used for model pretraining. These anomalies are similar to real anomalies and help the model recognize them. We evaluate our model on three opensource chest radiograph datasets. Our model exhibit area under curves (AUC) of 92.1%, 78.7%, and 81.9%, which are the highest among existing UAD models. This is the first SSL model to employ anatomical information as a pretext task. AnatPaste can be applied in various deep learning models and downstream tasks. It can be employed for other modalities by fixing appropriate segmentation. at:",https://www.semanticscholar.org/paper/c4e5c2f51770ac7389b0fe76659f5141c4f47f1b,"{'05e882679d61f4c64a68ebe21826251a39f87e98', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'f6a4b57eb5850b8457ab1aca799943d256f9c00d', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '91cb927cf0153b5d0820cff363883d339736b2da', '769149c0dc0ed308eca8bc916f4326b2e2f57a1f', '5985e77cce2a6a3720682c81dbeaef7b417e0459', '3574ef6eabf1bb1be0994290c471061c7ff1964b', '3a78adf9ec84c85a6414b7b31b2cb40e530ef256', '726c95fa3bd47401befc7513b6e52d1c806f26af', '63936fe9d0c6c7e87e1f939c926412349ced5716', '197ec03481b5e845fb4d34dd99a4b8e844fdabcc', '6ea88feb2e6d47dfef9f00bfbff4f11c82d38fc1', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '8554f73402cf0bf6afd33f915d727ae0bf225886', '364128bcce9836d60e685bb717b80f30e25092e0', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', 'a21de9f6408b333d917f7a8b2585230ed8b6c57a', 'b022f2a277a4bf5f42382e86e4380b96340b9e86', '37ca62abf1e8d9d15bdc26e83bfec37168788efa', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'c53352a4239568cc915ad968aff51c49924a3072', 'd6e78069dbbb35592f013187ef3432286def8f18', '342ce4663b1cbe2a1ca2f0e85bd362a3432635b8', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'd82800c79dd335297336fe10b1a60d47706e4296', '052b1d8ce63b07fec3de9dbb583772d860b7c769', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'c787e4bcfe9b217e5ee7464d34fee5084d48d866', '7bd431157c5c5af038df34b8c28cc793cecdbb77', '6af440915b8a0718c93be1cf61905e41e620484a', 'fa1aa090d09dc5d420d0cce37cea72c21e99d36b', '522b643c937573aa2b060bbcac28c63378b1d2d9', '4b5eb40e45110dffac9ad7be68a294ecedaec1d4', None, '0c5ed0c30375703306f36d341d31772f3bd5af47', '33a8d53849cb58badbbb083c4f2b9c93998df579', 'f51ac2bdcc2addfd2fe540ac483ae4d54016400e', '4edf00ac407cb2db9ed62ed69fe5d69984b7ca37', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '9ac074098d3c48234258b1a9ee8a0ad7e748a9e0', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '4c2e4726fd880d27617603775766801dee464be4', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'c89bfd998b0a6c656010b629814ab0cad3cff72e', '843959ffdccf31c6694d135fad07425924f785b1', '1d4816c612e38dac86f2149af667a5581686cdef', 'd4254d9a938d238182ae55eabd79367404d6ea2b', '6351ebb4a3287f5f3e1273464b3b91e5df5a16d7', '1d2cb20e87be1c8d6dff56d20001b006646b66fb', 'add2f205338d70e10ce5e686df4a690e2851bdfc', 'c88b753123211325a1b18ba426d3ccec312e6767', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '89a816719613e220a64ab2590c938c23bbfe187e', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",59,"{'fa1aa090d09dc5d420d0cce37cea72c21e99d36b', '78d80c343d36baaf89f18e12d325cf6309fb6c8f'}",2,"['Junya Sato', 'Yuki Suzuki', 'Tomohiro Wataya', 'Daiki Nishigaki', 'Kosuke Kita', 'Kazuki Yamagata', 'N. Tomiyama', 'S. Kido']",Junya Sato,"Junya Sato, Yuki Suzuki, Tomohiro Wataya, Daiki Nishigaki, Kosuke Kita, Kazuki Yamagata, N. Tomiyama, S. Kido",3.389830508474576
eb8eb355062ee4fbe3a8ad51f15f68b8f0c7d916,Autoencoders Without Reconstruction for Textural Anomaly Detection,2021-07-18,"Automatic anomaly detection in natural textures is a key component within quality control for a range of high-speed, high-yield manufacturing industries that rely on camera-based visual inspection techniques. Targeting anomaly detection through the use of autoencoder reconstruction error readily facilitates training on an often more plentiful set of non-anomalous samples, without the explicit need for a representative set of anomalous training samples that may be difficult to source. Unfortunately, autoencoders struggle to reconstruct high-frequency visual information and therefore, such approaches often fail to achieve a low enough reconstruction error for non-anomalous pixels. In this paper, we propose a new approach in which the autoencoder is trained to directly output the desired per-pixel measure of abnormality without first having to perform reconstruction. This is achieved by corrupting training samples with noise and then predicting how pixels need to be shifted so as to remove the noise. Our direct approach enables the model to compress anomaly scores for normal pixels into a tight bound close to zero, resulting in very clean anomaly segmentations that significantly improve performance. We also introduce the Reflected ReLU output activation function that better facilitates training under this direct regime by leaving values that fall within the image dynamic range unmodified. Overall, an average area under the ROC curve of 96% is achieved on the texture classes of the MVTecAD benchmark dataset, surpassing that achieved by all current state-of-the-art methods.",https://www.semanticscholar.org/paper/eb8eb355062ee4fbe3a8ad51f15f68b8f0c7d916,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '8388f1be26329fa45e5807e968a641ce170ea078', 'd468363414b9ec6507ff24cbeefecb4828f52f6b', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'd9704f8119d6ba748230b4f2ad59f0e8c64fdfb0', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '91e647bd24f76e56c11016c7a45e328c0ea6ae24', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'd3b614f11969127a08447c41257b3a7b58766d18', None, '9fa3720371e78d04973ce9752781bc337480b68f', 'eb42cf88027de515750f230b23b1a057dc782108', '3e2da7c1c7dfc7960d1515b61f32fdc55359eea7', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'e5366a704ffa3b41aacd385f3c087ec3fd566934', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'ca4edb65a0664804e4819c5c809d0dfba9bdb2df', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",28,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'd3b614f11969127a08447c41257b3a7b58766d18', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb'}",5,"['Philip A. Adey', 'S. Akçay', 'M. Bordewich', 'T. Breckon']",Philip A. Adey,"Philip A. Adey, S. Akçay, M. Bordewich, T. Breckon",17.857142857142858
6d6a1eaf6e3695d1bde5f80d19c40e50a4b8de0b,DMnet: A New Few-Shot Framework for Wind Turbine Surface Defect Detection,2022-06-16,"In the field of wind turbine surface defect detection, most existing defect detection algorithms have a single solution with poor generalization to the dilemma of insufficient defect samples and have unsatisfactory precision for small and concealed defects. Inspired by meta-learning ideology, we devised a cross-task training strategy. By exploring the common properties between tasks, the hypothesis space shrinks so that the needed sample size that satisfies a reliable empirical risk minimizer is reduced. To improve the training efficiency, a depth metric-based classification method is specially designed to find a sample-matching feature space with a good similarity measure by cosine distance. Additionally, a real-time feedback session is innovatively added to the model training loop, which performs information enhancement and filtering according to the task relevance. With dynamic activation mapping, it alleviates the information loss during traditional pooling operations, thus helping to avoid the missed detection of small-scale targets. Experimental results show that the proposed method has significantly improved the defect recognition ability under few-shot training conditions.",https://www.semanticscholar.org/paper/6d6a1eaf6e3695d1bde5f80d19c40e50a4b8de0b,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '368a8fbf6304a192a67f614d032510e5a4100552', '455d9a4ff96561d543acbcb2aa81d6cd8fcd20df', '795fd0df43ac5a139ed5bbe762d2ae94117c9bf8', '9d5ec23154fb278a765f47ba5ee5150bd441d0de', '6c759b2ca99833dea750480b0ee7caae965a0069', '07b32dd02477a023cf16a6dd3ff6ec51ee6ae1aa', 'bb913226ba283b84e8d102b719eaeb4948eced8d', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', '2ad5f836e1d9876fa3fc53cb2c0a704b45988f0f', '9fb7b636edeaf344394fdf37481d7b83eec75358', '22a5318d16aa50f705b510629ad3fa43e9592c1a', '33e8862d706fb746f8604bb47d1265d293d69c4e', '8c64e80412836bef698fd10762e0676ceac63818', '35172f0513d6a9fb9b1a40b7ad466da96a112d68', '2b619e6fd2266713a59abb8bb27fd146e4652695', 'cc7827a17a7759a04aa389290d1a874db56e85e5', 'bfe284e4338e62f0a61bb33398353efd687f206f', None, '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'cec05bf951a7278fd7bf21047b7812b52951a152', 'c14cab6880995166095e1b19a8a31bdacf08e229', '5936754b5762260bf102ac95d7b26cfc9d31956a', 'dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '2c2c593f4659b3c4731a5ec1f0c2752df848a910'}",28,set(),0,"['Jinyun Yu', 'Kaipei Liu', 'Liang Qin', 'Qiang Li', 'Fengli Zhao', 'Qiuli Wang', 'Haofeng Liu', 'Bo Li', 'Jing Wang', 'Kexin Li']",Jinyun Yu,"Jinyun Yu, Kaipei Liu, Liang Qin, Qiang Li, Fengli Zhao, Qiuli Wang, Haofeng Liu, Bo Li, Jing Wang, Kexin Li",0.0
f533e50758dfdfe18d52d9cc2287cf9b8d98f233,Data augmentation and pre-trained networks for extremely low data regimes unsupervised visual inspection,2021-06-02,"The use of deep features coming from pre-trained neural networks for unsupervised anomaly detection purposes has recently gathered momentum in the computer vision field. In particular, industrial inspection applications can take advantage of such features, as demonstrated by the multiple successes of related methods on the MVTec Anomaly Detection (MVTec AD) dataset. These methods make use of neural networks pre-trained on auxiliary classification tasks such as ImageNet. However, to our knowledge, no comparative study of robustness to the low data regimes between these approaches has been conducted yet. For quality inspection applications, the handling of limited sample sizes may be crucial as large quantities of images are not available for small series. In this work, we aim to compare three approaches based on deep pre-trained features when varying the quantity of available data in MVTec AD: KNN, Mahalanobis, and PaDiM. We show that although these methods are mostly robust to small sample sizes, they still can benefit greatly from using data augmentation in the original image space, which allows to deal with very small production runs.",https://www.semanticscholar.org/paper/f533e50758dfdfe18d52d9cc2287cf9b8d98f233,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '7d76a09aa363685bc0f04a502ed853dc09a574e2', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '732c21998e251d64cd58b6a86886ee5907efeaa5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '23c9defbedd488c5e4de4220c41d15d31dd8b759', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', 'b40890f3d917379ac4bd2e0933a134d45b4dc251', '0407b605b8f55db72e2545586bfe8e946b691b70', '502169d1ba1c25abd99c7f5f454474cfaa420a8b', '9277dc70c74bcadf80dab11c28ead83fd085deec', '04513c7c0b3a63fde81a996dae064a28d453c17a', '37595f7a51982d776e57c7280b9445474d90f0be', 'd82800c79dd335297336fe10b1a60d47706e4296', '64529523bb7af0cf258e6f5b0c5f0b3013ecdc6f', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '35d894043b67cd11285dcf08fa28affaa1d50746', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '1d2105616d122389efbd1b0ac7c04c0c2f8ac996', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'd52ff4da17d41ea239de10dd2a68ae18f6a85d28', '41747cbdbed84762dfbfc305254c97021279dc6e', '85a6c053f27fc60d1b92a2f96848c383210ff9f5', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '72564a69bf339ff1d16a639c86a764db2321caab', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', '25761fd27d2ffad21329e85987dffa57a13de39f', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a'}",40,"{'931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '37595f7a51982d776e57c7280b9445474d90f0be', 'd52ff4da17d41ea239de10dd2a68ae18f6a85d28', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '5a5906c4b87d3615a9dacbfa24708e4a90617b8a', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",11,"['Pierre Gutierrez', 'Antoine Cordier', 'Thais Caldeira', 'Theophile Sautory']",Pierre Gutierrez,"Pierre Gutierrez, Antoine Cordier, Thais Caldeira, Theophile Sautory",27.5
9eade303d33e8ac2cc7a431d1a6619c266a3072a,Evaluation of Point Pattern Features for Anomaly Detection of Defect within Random Finite Set Framework,2021-02-03,"Defect detection in the manufacturing industry is of utmost importance for product quality inspection. Recently, optical defect detection has been investigated as an anomaly detection using different deep learning methods. However, the recent works do not explore the use of point pattern features, such as SIFT for anomaly detection using the recently developed set-based methods. In this paper, we present an evaluation of different point pattern feature detectors and descriptors for defect detection application. The evaluation is performed within the random finite set framework. Handcrafted point pattern features, such as SIFT as well as deep features are used in this evaluation. Random finite set-based defect detection is compared with stateof-the-arts anomaly detection methods. The results show that using point pattern features, such as SIFT as data points for random finite set-based anomaly detection achieves the most consistent defect detection accuracy on the MVTec-AD dataset. Keywords—defect detection, anomaly detection, random finite set, keypoint detection.",https://www.semanticscholar.org/paper/9eade303d33e8ac2cc7a431d1a6619c266a3072a,"{'2b1a3d7e6045dc6b544a548b372c1f8492b85967', '642e328cae81c5adb30069b680cf60ba6b475153', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '526346a9aec1d39f34b51e4c85ae6cdf83b1f6ff', 'f3c98f0e454978e26ea9b73b6b332188862a6f87', '48d6c454f05cba426e9a0d5d0fad36f81919935d', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'a3ed2678133c328443d0a626bdd4db5adc0b946c', '5efa73676159b7d32de7cc8d1cd94bf8aec8345c', 'd36d77cf28346d5fa526ccee2f7f0d756ba5a15a', 'a62bdda9ae6f86fc06d7edf5d3b429eda3a6640e', '354923bc917ac774438a048b87db9fabed4d757e', '69401bfdafab7cde00bb8e5b2f6c28e9d72d8cfb', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', '15a4e2a15f20ed77609a70fb268cbcfafa21df54', 'facf56ab4cd06ac2970530a0c425df7a6a8a3d45', '07c44c676f9ed88c4c2cab2f257615d632c56ec7', 'a89f0a78f86077864e108a1bd2c4e670c85907f8', 'b8038c45fd3beae4ba06d588d7f35bff60494563', '5d990bedf3f8700c571ec5e83197d02d771e1c19', 'a228ce656599fe1413ed0671c260b5dad1190e3e', '162d660eaaa1eb2144d8030102f3e6be1e80ce50', '371322935e635ff56c10a74395b6b66a7487fa83', '19be6c969ad2d744321f538a66e7d8615145cbcf', '11c1926d89083a435aba89707a981a3515da490c', '911aa843612a8a47579e4d3da141fdee564965ba', '864e7db59f2ccfec1ee9f6eba79566ac7b0634df', '1d2105616d122389efbd1b0ac7c04c0c2f8ac996', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '358b9707c2d45c06e23a264d21390c2ed5a1d7ee', '4cab9c4b571761203ed4c3a4c5a07dd615f57a91', '1aa5a8ad5b7031ba39e1dc0537484694364a1312', '800296522d60e8aec816162a8255836818b860d2', '414170e0f6959ec452c6da866a61a2a557682f56', 'b962a558c7e334388135dd2be8cdccdce1336ebe', None, '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', '4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0', '219f7706e28c91dcff3d6c4273ac71868714cac2', '97ec22e0c2f7eee796cecec6374a0b284c4d0cb9', '70073a4d2ebbb7ce5f432075e60850855ef9d7f6', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '7b0dc177090c8836bc09b306b953059096939030', '514b8c50a5b427e2aae75f877454ec9ab3cb4e99', '2713e7a59105a832e20c01c3c202b9dcd2b5f889', '80499c3b9b6460048e94ab782b7ffff7b942d3fd', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'ff6b4d196274c395e86e7287430c08b21166d29a', '47cbebf6c7139b79db2ecb80d69b8effdc4cc276', 'f9cc7e2c400b4ab509e47d158017cd1cbf526792', '9a7228ce42d5cc0f2dfb676155ec0cf570f83f9b', 'b6427febbcc396a2a88ecccda59a23a6aece7149'}",52,set(),0,"['Ammar Mansoor Kamoona', 'A. Gostar', 'A. Bab-Hadiashar', 'R. Hoseinnezhad']",Ammar Mansoor Kamoona,"Ammar Mansoor Kamoona, A. Gostar, A. Bab-Hadiashar, R. Hoseinnezhad",0.0
3b3aefbbdb64e5812f133f220b3f129a36a30065,Anomaly Detection via Reverse Distillation from One-Class Embedding,2022-01-26,"Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consist-ing of a teacher encoder and a student decoder and introduce a simple yet effective ”reverse distillation” paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model’s one-class embedding as input and targets to restore the teacher’s multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively pre-serves essential information on normal patterns, but aban-dons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach’s effectiveness and generalizability.",https://www.semanticscholar.org/paper/3b3aefbbdb64e5812f133f220b3f129a36a30065,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '8e180ffb0c4bfe4db41a245637042a28fc98d891', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '83dfe3980b875c4e5fe6f2cb1df131cc46d175c8', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '0c908739fbff75f03469d13d4a1a07de3414ee19', '1c4e9156ca07705531e45960b7a919dc473abb51', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', '37595f7a51982d776e57c7280b9445474d90f0be', '18f207d8dab7357f4f674211ec4f150de1c93a0e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'c889d6f98e6d79b89c3a6adf8a921f88fa6ba518', 'fdc369b826bafb1eb0c4e1ff03dff3517896f80b', '292b78282340ccfa7cfd1b0dbd7c38c2b39a2230', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'd3b614f11969127a08447c41257b3a7b58766d18', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08', None, '7d3a0fca300423684d01d5ab767f8eacdaa45f51', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '02805f18989b7e77f30ee13defd6fecfcd0f499f', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '5a5effa909cdeafaddbbb7855037e02f8e25d632', '463c3e13c2d6fb3148bb2a1f0328b484d8a353f9', '30895c61bb836f2cae7ef5ba6516886f746a7153'}",49,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '02805f18989b7e77f30ee13defd6fecfcd0f499f', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd3b614f11969127a08447c41257b3a7b58766d18', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '93040f8a5d10e8fde279e18d353aa3dca2873900', '8e180ffb0c4bfe4db41a245637042a28fc98d891', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '37595f7a51982d776e57c7280b9445474d90f0be', '7d3a0fca300423684d01d5ab767f8eacdaa45f51', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",16,"['Hanqiu Deng', 'Xingyu Li']",Hanqiu Deng,"Hanqiu Deng, Xingyu Li",32.6530612244898
8fec178e2a9b8b626ad89d34cd7b5a4a2db9ef1d,Anomaly Detection of Defect using Energy of Point Pattern Features within Random Finite Set Framework,2021-08-27,"In this paper, we propose an efficient approach for industrial defect detection that is modeled based on anomaly detection using point pattern data. Most recent works use global features for feature extraction to summarize image content. However, global features are not robust against lighting and viewpoint changes and do not describe the image’s geometrical information to be fully utilized in the manufacturing industry. To the best of our knowledge, we are the first to propose using transfer learning of local/point pattern features to overcome these limitations and capture geometrical information of the image regions. We model these local/point pattern features as a random finite set (RFS). In addition we propose RFS energy, in contrast to RFS likelihood as anomaly score. The similarity distribution of point pattern features of the normal sample has been modeled as a multivariate Gaussian. Parameters learning of the proposed RFS energy does not require any heavy computation. We evaluate the proposed approach on the MVTec AD dataset, a multiobject defect detection dataset. Experimental results show the outstanding performance of our proposed approach compared to the state-of-the-art methods, and the proposed RFS energy outperforms the state-of-the-art in the few shot learning settings.",https://www.semanticscholar.org/paper/8fec178e2a9b8b626ad89d34cd7b5a4a2db9ef1d,"{'1d327de48c02f886303c1b7627724d4ed795ad91', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'e7d0c37f4f3589a3b787f39e8307704da5ed8d6c', 'e85e7458b8b38ae0b77743885856ce870912329c', '48d6c454f05cba426e9a0d5d0fad36f81919935d', 'f7eceb72c0e1d432b0f96b985a5305a669b55119', 'd36d77cf28346d5fa526ccee2f7f0d756ba5a15a', '5db790198b9acf4e5efe350acdd814238fcacaa7', '8f1379c4f8901098a191e35c5543b312e569d68f', '5d990bedf3f8700c571ec5e83197d02d771e1c19', '04513c7c0b3a63fde81a996dae064a28d453c17a', '162d660eaaa1eb2144d8030102f3e6be1e80ce50', '37595f7a51982d776e57c7280b9445474d90f0be', '86d27422aac2398cfe132ae8e312a6f2d190f754', '3e20e571cb1ee0d29f34386002739d3ae0c050c7', '0f366de3ea595932dad06389f6e61fe0dd8cbe74', '10a498003e9204f5fc1328e706510a37e514d8c7', '37f274b5f7cd94ade75d9c4b9dea18273d484e5c', 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'eb42cf88027de515750f230b23b1a057dc782108', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'f3c98f0e454978e26ea9b73b6b332188862a6f87', 'a3ed2678133c328443d0a626bdd4db5adc0b946c', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '46bca62def0666a400eb6b1610e384f403085567', '9d5ec23154fb278a765f47ba5ee5150bd441d0de', 'b40890f3d917379ac4bd2e0933a134d45b4dc251', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '8b440596b28dc6683caa2b5f6fbca70963e5909e', '614d808f4115ff738c44168cb8e7784f33c8bf8a', '267502d21b44884570fcd95a855821cc3e86e6eb', 'f5c26e45334aa347d7c6bf22b700e96d03539139', '19be6c969ad2d744321f538a66e7d8615145cbcf', '11c1926d89083a435aba89707a981a3515da490c', '0a0d53ed428b5c28e7f2712e2d6b4e3123cfc668', '6818668fb895d95861a2eb9673ddc3a41e27b3b3', '911aa843612a8a47579e4d3da141fdee564965ba', 'b8de958fead0d8a9619b55c7299df3257c624a96', '4936c8c03c7d9720530ce29b47b5266a7d79efd9', '4cab9c4b571761203ed4c3a4c5a07dd615f57a91', '5150454f20ebb8314d00223ad23347d5fa0d1eb8', None, 'ed767a9d01f04a764e9146c0542216cc48624ec6', '976e29fe6c9baeb39732bca0e35f66f84d5bdd90', 'd7724bf9687e442b50252f959ed9842418f9aea7', 'b05568c6467d716b93fc98fdf345dafdcb1ef617', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', 'b20fcdf082da73ffc3a5ceaff617810e1922d06d', 'bd38762b29adb53c762ce323938a380053c078f9', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '2b1a3d7e6045dc6b544a548b372c1f8492b85967', 'a227b85127ba56a6ba633a6f0172082098546d12', '526346a9aec1d39f34b51e4c85ae6cdf83b1f6ff', '9e1847a58978ae7040a6afb91d112076d8738592', '354923bc917ac774438a048b87db9fabed4d757e', '9d5ea177c7fcaf88ec6f56cbeb3e9b74c08e98a3', 'e8180ad45ed5ca732e492db32aa85e769836132e', '182d11020bf2842f135f1ec1dcac20237e0dc8b7', '676043564bb46dcbe1c94c7ea668cf596bb9b95a', 'c53352a4239568cc915ad968aff51c49924a3072', 'e0408181bccb7e3754dd5e6785ec47d8beb8b6bd', '6af440915b8a0718c93be1cf61905e41e620484a', '35b966347dae2f0d496ea713edf03a68211838a5', '6cf61e7e30e1646f5dcbbf1351e8d27b29342b11', '01b6affe3ea4eae1978aec54e87087feb76d9215', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'cdbb606ae47c64049262dfbd3bb147d3f4ba8420', '70073a4d2ebbb7ce5f432075e60850855ef9d7f6', '7b0dc177090c8836bc09b306b953059096939030', 'ff6b4d196274c395e86e7287430c08b21166d29a', '7cb2bedc49377b3cab3ddfbd3aff13e57af49880', '3c90ed3445589907ccdb9d783528993ba7b35e40', 'b6427febbcc396a2a88ecccda59a23a6aece7149', '5efa73676159b7d32de7cc8d1cd94bf8aec8345c', 'a62bdda9ae6f86fc06d7edf5d3b429eda3a6640e', 'b110ba174df21a23a9521731d4181261ca5860ed', 'b80deba9cce6ad3bc8f5624c4a151a64ee226f14', '97cd86d8d8c0f27cd3e64c6ca5cfdeb957ee39f4', 'd23826a25de6ec30b86fe507261cc11b9c18a5fb', 'c8e4d8ded0624f13cd7763b8e7a62fe7e36da6d3', 'a89f0a78f86077864e108a1bd2c4e670c85907f8', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'b1464ca857593c049873421db2f37bf2d0ff676d', '2faef2d5cd56aec03c66315d36b0ec791312f308', '800296522d60e8aec816162a8255836818b860d2', '47cbebf6c7139b79db2ecb80d69b8effdc4cc276', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73'}",91,"{'37595f7a51982d776e57c7280b9445474d90f0be', '182d11020bf2842f135f1ec1dcac20237e0dc8b7', 'b1464ca857593c049873421db2f37bf2d0ff676d', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",4,"['Ammar Mansoor Kamoona', 'A. Gostar', 'A. Bab-Hadiashar', 'R. Hoseinnezhad']",Ammar Mansoor Kamoona,"Ammar Mansoor Kamoona, A. Gostar, A. Bab-Hadiashar, R. Hoseinnezhad",4.395604395604396
8fa04c148b1db419a106837328877d46345b61cd,Real-Time Anomaly Detection in Packaged Food X-Ray Images Using Supervised Learning,,": Physical contamination of food occurs when it comes into contact with foreign objects. Foreign objects can be introduced to food at any time during food delivery and packaging and can cause serious concerns such as broken teeth or choking. Therefore, a preventive method that can detect and remove foreign objects in advance is required. Several studies have attempted to detect defective products using deep learning networks. Because it is difficult to obtain foreign object-containing food data from industry, most studies on industrial anomaly detection have used unsupervised learning methods. This paper proposes a new method for real-time anomaly detection in packaged food products using a supervised learning network. In this study, a realistic X-ray image training dataset was constructed by augmenting foreign objects with normal product images in a cut-paste manner. Based on the augmented training dataset, we trained YOLOv4, a real-time object detection network, and detected foreign objects in the test data. We evaluated this method on images of pasta, snacks, pistachios, and red beans under the same conditions. The results show that the normal and defective products were classified with an accuracy of at least 94% for all packaged foods. For detecting foreign objects that are typically difficult to detect using the unsupervised learning and traditional methods, the proposed method achieved high-performance real-time anomaly detection. In addition, to eliminate the loss in high-resolution images, the false positive rate and accuracy could be lowered to 5% with patch-based training and a new post-processing algorithm.",https://www.semanticscholar.org/paper/8fa04c148b1db419a106837328877d46345b61cd,"{'043d1f7b26d0aa723bf2d63eb277d2b8be19bec0', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'a03c62d4206d4dd0ef4bf8312bfdb0d4971a1123', '2576cae4e65d8b4853fd371289e2916417c74587', '2788a2461ed0067e2f7aaa63c449a24a237ec341', '7d39d69b23424446f0400ef603b2e3e22d0309d6', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'c158d7c2200f7482292a82322a96c03fec5c1d19', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'c18663fea10c8a303d045fd2c1f33cacf9b73ca3', 'ae97c81b45780dc91e18eb84236d8a40a290b329', 'e15cf50aa89fee8535703b9f9512fca5bfc43327', '388645c44061f6e88fff0ecdad2f622936207d67', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '1527f687d691aee0b3be8c8721d491bf772aed93', 'a17542bfb13074d8a48e1ce2ff6b3ba744433422', '41c67d04be2d1632c0d3b0880c21c9fe797cdab8', 'f43f8b9f8e6eaf6197cdb4b28da5a503347918fb', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', '12a91c9d4a55fc93f15f4acef078c8908af3c9b9', 'b724c3f7ff395235b62537203ddeb710f0eb27bb', '62b77e5cb85fc61b84edd532f6d65714be152596', '0098c071deea5c6723e00053eeb58d52594ca596', '38d7920f0e8a3a672ea37c8612b2b2947b9ba9d1', '71b7178df5d2b112d07e45038cb5637208659ff7', '317aee7fc081f2b137a85c4f20129007fd8e717e', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '19f3299deda9f33003a6378788806acdb089669f', 'a47f8794d88c5c27123153c4eb9e08046e2b0c9d', '6af440915b8a0718c93be1cf61905e41e620484a', '0d38129a3281fe3447457895ed057b1d537c3b27', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '70f9968a356d840040a1c9207906f60376dc6bd4', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, '42211726950e5a968441c594e88bbfc00ac1fe7f', '400b3d5b70aa709db9e83d84995e8b959c8bdad2', '281d048689bad12d8dce8316a61c31b15c6f50de', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0', '38adcd9e51cb28cfaacb306a8e88158bdac41115', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'e4845fb1e624965d4f036d7fd32e8dcdd2408148', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '72564a69bf339ff1d16a639c86a764db2321caab', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '447974e494c8228340420c5b09e375adf1fd5f7a', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', '1a0912bb76777469295bb2c059faee907e7f3258', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', '0c0d4e2e701b411cc7fc348a2acef1ebdbcbc556', '2a6f7f0d659c5f7dcd665064b71e7b751592c80e'}",57,{'62b77e5cb85fc61b84edd532f6d65714be152596'},1,"['Kang-jik Kim', 'Hyun-Bin Kim', 'J. Chun', 'Min-Goo Kang', 'M. Hong', 'Byung-Bin Min']",Kang-jik Kim,"Kang-jik Kim, Hyun-Bin Kim, J. Chun, Min-Goo Kang, M. Hong, Byung-Bin Min",1.7543859649122806
c75acecad5c137f050a58c546fd61ae46ece4ebf,Anomaly Detection Via Self-Organizing Map,2021-07-21,"Anomaly detection plays a key role in industrial manufacturing for product quality control. Traditional methods for anomaly detection are rule-based with limited generalization ability. Recent methods based on supervised deep learning are more powerful but require large-scale annotated datasets for training. In practice, abnormal products are rare thus it is very difficult to train a deep model in a fully supervised way. In this paper, we propose a novel unsupervised anomaly detection approach based on Self-organizing Map (SOM). Our method, Self-organizing Map for Anomaly Detection (SOMAD) maintains normal characteristics by using topological memory based on multi-scale features. SOMAD achieves state-of-the-art performance on unsupervised anomaly detection and localization on the MVTec dataset.",https://www.semanticscholar.org/paper/c75acecad5c137f050a58c546fd61ae46ece4ebf,"{'f33de7b2fa5425391f5afa81b85818d03325cb0e', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '599fd051c9438011ec5b581983c89e8922b4a5e6', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '1c4e9156ca07705531e45960b7a919dc473abb51', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '67529adb196e5b5e003c07dc8e54a1b71247f6d5', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', '70f9968a356d840040a1c9207906f60376dc6bd4', '9dd6e0d34a98fe2e2a9d2ae875c551ca4377e40d', 'db8c381cbaf80c4323959eccee07c85a76b54839', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '4e9b467deb651f1333f4a99331c50760286f452e', '401ec2881b20ce7d6dc07c274a1d8f821d4c3841', '9775d372bfaf889a395dc714e283b6a179e62537', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'e7bd06dd41a271e7e6ff2734fe0da466f18f3750', '4b83e9a048e677ff9fab226e8f7fbaa33fd32024'}",29,"{'f33de7b2fa5425391f5afa81b85818d03325cb0e', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '37595f7a51982d776e57c7280b9445474d90f0be', '9775d372bfaf889a395dc714e283b6a179e62537', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'db8c381cbaf80c4323959eccee07c85a76b54839', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",12,"['Ning Li', 'Kaitao Jiang', 'Zhiheng Ma', 'Xing Wei', 'Xiaopeng Hong', 'Yihong Gong']",Ning Li,"Ning Li, Kaitao Jiang, Zhiheng Ma, Xing Wei, Xiaopeng Hong, Yihong Gong",41.37931034482759
09e5f6c9ec13ebd67fa80ab106685f71b2594108,Applying Center Loss to Multidimensional Feature Space in Deep Neural Networks for Open-set Recognition,,"With the advent of deep learning, significant improvements in image recognition performance have been achieved. In image recognition, it is generally assumed that all the test data are composed of known classes. This approach is termed as closed-set recognition. In closed-set recognition, when an untrained, unknown class is input, it is recognized as one of the trained classes. The method whereby an unknown image is recognized as unknown when it is input is termed as open-set recognition. Although several open-set recognition methods have been proposed, none of these previous methods excel in terms of all three evaluation items: learning cost, recognition performance, and scalability from closed-set recognition models. To address this, we propose an open-set recognition method using the distance between features in the multidimensional feature space of neural networks. By applying center loss to the feature space, we aim to maintain the classification accuracy of closed-set recognition and improve the unknown detection performance. In our experiments, we achieved state-of-the-art performance on the MNIST, SVHN, and CIFAR-10 datasets. In addition, the proposed approach shows excellent performance in terms of the three evaluation items.",https://www.semanticscholar.org/paper/09e5f6c9ec13ebd67fa80ab106685f71b2594108,"{'02227c94dd41fe0b439e050d377b0beb5d427cda', '468c3476b93e5e5ffa38e7fb2494bc7fd5901ae8', 'cfaae9b6857b834043606df3342d8dc97524aa9d', '37595f7a51982d776e57c7280b9445474d90f0be', '42a047ca1bc1e5c8fecafb9d1ea2cbd03aae05fb', 'd4f100ca5edfe53b562f1d170b2c48939bab0e27', '9dc915697768dd1f7c7b97e2c25c90b02241958b', 'd094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c', '6ff2a434578ff2746b9283e45abf296887f48a2d', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, 'bd8f77b7d3b9d272f7a68defc1412f73e5ac3135', '7437fb168cea92e1df8332ac618f7f07b071aca8', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '2750dbc60d5ccc8fbe5e4babae6cfab543940f1a', '21117380118ddce47b3c515c5228372c513e61ba', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e6df192c9b654bc5cc371c55012cf99d85cb61df', '759d9a6c9206c366a8d94a06f4eb05659c2bb7f2', '4b04b42dc57b99060a3b9a870012659dca44054f', '4cfd770ccecae1c0b4248bc800d7fd35c817bbbd', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', '0ceb0778ecc49ab17f711d0a006714f5063e44ef', 'd2c733e34d48784a37d717fe43d9e93277a8c53e'}",24,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', '37595f7a51982d776e57c7280b9445474d90f0be'}",2,"['Daiju Kanaoka', 'Yuichiro Tanaka', 'H. Tamukoh']",Daiju Kanaoka,"Daiju Kanaoka, Yuichiro Tanaka, H. Tamukoh",8.333333333333334
4f72fee7da492a5cf332209422c9e30411cc112f,Decomposing Textures using Exponential Analysis,2021-06-06,"Decomposition is integral to most image processing algorithms and often required in texture analysis. We present a new approach using a recent 2-dimensional exponential analysis technique. Exponential analysis offers the advantage of sparsity in the model and continuity in the parameters. This results in a much more compact representation of textures when compared to traditional Fourier or wavelet transform techniques. Our experiments include synthetic as well as real texture images from standard benchmark datasets. The results outperform FFT in representing texture patterns with significantly fewer terms while retaining RMSE values after reconstruction. The underlying periodic complex exponential model works best for texture patterns that are homogeneous. We demonstrate the usefulness of the method in two common vision processing application examples, namely texture classification and defect detection.",https://www.semanticscholar.org/paper/4f72fee7da492a5cf332209422c9e30411cc112f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '831ed2a5f40861866b4ebfe60257b997701e38e2', 'c5c2351d72fa9914f3266cf271c2cc2c53964e2b', '3803d42330506aff3a5cc5eaf69cf589c9c8929b', 'da8b511af044d12ea06e87b7f9db443e240fc9d1', '847aebda115d8d64f3b6c4f2c5960c4202f34e36', 'f6b135d1b02bcd5f933e3256fee8a47df247c3cf', '8c472db88c536d8e7102d0e1da0903e83f9d1e79', 'a201332dd06ae485de3a3de06a6ddfe23a5d224f', 'd13d8dfe7bcb841959273909bbc363000bb5517a', '6c7cf406a47048730c1a08d46cb0166b16566524', 'beab29428dbc5e5195cb42850eefae471cf0f910', 'edeea32645724a4d7591b2530ed54d1af4d3aeac', '9175e4f461aaaddc87072e2b1451c8da7fdff7bb', None, '995b4e884977af598db9ad44c89392850c304c00', '18c125ce0f64e85577f7d30132cf0e92ec664bf4', '694c7c58b1abdebe7a0b9894698e71e63880da46', '26e7763159518a9cc3baf780f66b31419db8f14d', '9ddc3776024b4f20a721f69ab70bcc5368f82598', 'd099b92aa9cf2504311eb8bfcb40209faf2b46e3', 'd30e8f3e565d4a9df831875c383687507606d4f0', '59b17f6d19a52f8aae177476cbcf7ebe4cb8f8c4'}",23,set(),0,"['Yuan Hou', 'A. Cuyt', 'Wen-shin Lee', 'Deepayan Bhowmik']",Yuan Hou,"Yuan Hou, A. Cuyt, Wen-shin Lee, Deepayan Bhowmik",0.0
eb43c6cb1411b9bf12a26f0efd1a1b02b5712c3a,Detecting damage in rudder stocks under load using electro-mechanical susceptance: Frequency-warping and semi-supervised approaches,2021-12-13,"Active piezoelectric transducers are successfully deployed in recent years for structural health monitoring using guided elastic waves or electro-mechanical impedance (EMI). In both domains, damage detection can be hampered by operational/environmental conditions and low-power constraints. In both domains, processing can be divided into approaches (i) taking into account baselines of the pristine structure as reference, (ii) ingesting an extensive measurement history for clustering to explore anomalies, (iii) incorporating additional information to label a state. The latter approach requires data from complementary sensors, learning from laboratory/field experiments or knowledge from simulations which may be infeasible for complex structures. Semi-supervised approaches are thus gaining popularity: few initial annotations are needed, because labels emerge through clustering and are subsequently used for state classification. In our work, bending and combined bending/torsion studies on rudder stocks are considered regarding EMI-based damage detection in the presence of load. We discuss the underpinnings of our processing. Then, we follow strategy (i) by introducing frequency warping to derive an improved damage indicator (DI). Finally, in a semi-supervised manner, we develop simple rules which even in presence of varying loads need only two frequency points for reliable damage detection. This sparsity-enforcing low-complexity approach is particularly beneficial in energy-aware SHM scenarios.",https://www.semanticscholar.org/paper/eb43c6cb1411b9bf12a26f0efd1a1b02b5712c3a,"{'b3ac4df91e296017d0641b4dcc28718d1f215855', '72d2138062e5fda721ad549f3a8dff13c3205f43', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'ffd9b1bd5045211bde8fdef562b9222dd0bfbe18', 'a50b1b43c458870d982f8fb975e0293f2c6294e6', '30359e27c55829d50eec2d8a82c95fbf3b65e74b', '600191af2405228847ee2453f2917847ad45776d', 'e41ba5dc12c79a64dfa905c0328f95976252ffe0', 'd4c5f741e936d210088d9c7ab93550e3578d82e9', 'a4e3b1f6ddb7cf3cb80765b747e83ae2d1126542', '82ee58fc60c47679f8905e9a1397ee4d21272b4d', 'b5a5ebc72c1ccf1a016d772bab70db8fb62caec3', 'f8f126de492df391ecf38303701522b7f830fc26', '09b7bd79997a6acaad0e3d28765525f03631da51', '6409ab7b68a83dfb4c9b5ecfbfb5192c82314623', '5447b71c96aaff6400ccf4267f373f184eec07d2', '95d289837e6a7d4c75992b76e6256815cf0e4364', '09e0960d7018eb63c3895b89ba3adc2ab0048511', '0430b241bdd0b67d37e1143370f8d24fc46d83e9', 'c1905ec452f3a6bfe46e0f8b5141fcc57725e366', '5176a2f31dace77db9135dde7020d2c37f78cca0', 'f99f760ee70a001731657c24546cc3de30c702be', '0ee9dc5d51c196ca30ab25d00b6b6c8bd8b4a4cf', '77facfab31983c2397b1cff57ce6886207b10558', '71b7178df5d2b112d07e45038cb5637208659ff7', '22219853a3990972c32a6498454afc6a35e7c742', 'ad9c438acd1269704ac23e9c9ba5f25fdc897c48', '012c71be103ab1cc20f9e5ac2b891f61cda85647', 'c8c1c0f7956818aaafc029a3efaf94f0e8718b73', '9064c36b8346db11075233fddd322d44b51e1535', '61e5a77dff180aaa97cada6de706c33ce08ff1c4', '6a23045e2d5b8bd069a051cdc1a7993ca2c25be2', '8a2b426450e255fe534b5829acb1f60590a1364a', 'b125693ec99feea77dd9a11803c7a74f1d8be7b1', None, '23da9e6013d91a7f036827e74aff626fb2d61458', 'fcd5fdbe61a653d37aa3d35366bdf44c93bbcecd', '28530dfa0edb0a1f969d9bbd2bb82a71370f1419', 'fa24af669bc11711b18ca4f45e9abb85546ed36e', 'fd7c63ea1492c8e2bb68af78a8af1c698d9cf6b1', '3e708b0cd19818e0c7408765dd922835661f8a24', '85d2d79192de2d6ca988dcfddbc4b2a6c2d98a47', '72d100035573e0fdeceb3e8d8dddc24a9c5f6186', '00b7f44857676600805172e99be6f9f2987e98eb', '5fc15e5624e9ca971d69f42bcc7a6db745916e1d', '2453a964485110581dddc42a945040cc4989d6b5', '5d2723f7216ede478419cc572f06b5765a868c60', '165cdab44826d6fce46b8fe66093732037c5128c', 'c540193c861dcf3d50006fa6a26c794139abab4a', '7433fdb6ff6e6b1d22ffb9b0a93191781f0be07b', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '2393831c2b3df6331bfd79f10f60bcd949e3fead', 'dff419bcae89bad0718d4ceaa48dc55e99a993c7', '8f11cb5fe0f4effcc22779434a4ff964932fdc45'}",54,set(),0,"['Christian Kexel', 'J. Moll']",Christian Kexel,"Christian Kexel, J. Moll",0.0
182d11020bf2842f135f1ec1dcac20237e0dc8b7,A Hierarchical Transformation-Discriminating Generative Model for Few Shot Anomaly Detection,2021-04-29,"Anomaly detection, the task of identifying unusual samples in data, often relies on a large set of training samples. In this work, we consider the setting of few-shot anomaly detection in images, where only a few images are given at training. We devise a hierarchical generative model that captures the multi-scale patch distribution of each training image. We further enhance the representation of our model by using image transformations and optimize scale-specific patch-discriminators to distinguish between real and fake patches of the image, as well as between different transformations applied to those patches. The anomaly score is obtained by aggregating the patch-based votes of the correct transformation across scales and image regions. We demonstrate the superiority of our method on both the one-shot and few-shot settings, on the datasets of Paris, CIFAR10, MNIST and FashionMNIST as well as in the setting of defect detection on MVTec. In all cases, our method outperforms the recent baseline methods.",https://www.semanticscholar.org/paper/182d11020bf2842f135f1ec1dcac20237e0dc8b7,"{'f42f87e4015f1aad3ed464b47c8644214b41748c', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '571b0750085ae3d939525e62af510ee2cee9d5ea', '8388f1be26329fa45e5807e968a641ce170ea078', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '812355cec91fa30bb50e9e992a3549af39e4f6eb', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '5db790198b9acf4e5efe350acdd814238fcacaa7', '1bc042ec7a58ca8040ee08178433752f2c16f25e', 'bb63e3c51b78da88852dac0c67411c8dc930993e', '9d5ec23154fb278a765f47ba5ee5150bd441d0de', '102a2096ba2e2947dc252445f764e7583b557680', 'b110ba174df21a23a9521731d4181261ca5860ed', '62b77e5cb85fc61b84edd532f6d65714be152596', 'c8e4d8ded0624f13cd7763b8e7a62fe7e36da6d3', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'fc68e22bdb22715408d6d45e3ce4ddc42f687a75', '04513c7c0b3a63fde81a996dae064a28d453c17a', '267502d21b44884570fcd95a855821cc3e86e6eb', '35a198cc4d38bd2db60cda96ea4cb7b12369fd3c', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'ccaf15d4ad006171061508ca0a99c73814671501', '10a498003e9204f5fc1328e706510a37e514d8c7', '670f9d0d8cafaeaeea564c88645b9816b1146cef', '346a877564351e4014441a1dc174b0369a759ba5', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '103bdc0e62bc820c142247e0e65501cddc03ed3c', '9af9fcd279f63d25920ac3b1fad92662d8096c8f', '29858b40a15704398aecdca6bd2820f2fcc99891', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'b6371f8c70c2684faefd99fffcc556c3a75dd7f4', '1a3284e3c7bc58a5f453e6573d9107bfb3686b9e', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e8a5f27e7805f8de84ea008d59452ff864271696', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1539fead28c0313de13c9e6dd031ae575e47e868', 'af7c0424dd878a5619fb4ac5448d53db3d2be60a', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', '80455126562cfe6a483e02b3446a3f30b8e9f229'}",43,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', 'b1464ca857593c049873421db2f37bf2d0ff676d'}",3,"['Shelly Sheynin', 'S. Benaim', 'Lior Wolf']",Shelly Sheynin,"Shelly Sheynin, S. Benaim, Lior Wolf",6.976744186046512
b9ca44d3501a101200ecedb8812d5a2c7eebc24b,"Self-supervise, Refine, Repeat: Improving Unsupervised Anomaly Detection",2021-06-11,"Anomaly detection (AD), separating anomalies from normal data, has many applications across domains, from security to healthcare. While most previous works were shown to be eﬀective for cases with fully or partially labeled data, that setting is in practice less common due to labeling being particularly tedious for this task. In this paper, we focus on fully unsupervised AD, in which the entire training dataset, containing both normal and anomalous samples, is unlabeled. To tackle this problem eﬀectively, we propose to improve the robustness of one-class classiﬁcation trained on self-supervised representations using a data reﬁnement process. Our proposed data reﬁnement approach is based on an ensemble of one-class classiﬁers (OCCs), each of which is trained on a disjoint subset of training data. Representations learned by self-supervised learning on the reﬁned data are iteratively updated as the data reﬁnement improves. We demonstrate our method on various unsupervised AD tasks with image and tabular data. With a 10% anomaly ratio on CIFAR-10 image data / 2.5% anomaly ratio on Thyroid tabular data, the proposed method outperforms the state-of-the-art one-class classiﬁer by 6.3 AUC and 12.5 average precision / 22.9 F1-score. methods, such as distribution-augmented contrastive learning rotation prediction and its improved version, and denoising autoencoder. For MVTec benchmarks, we use CutPaste (Li 2021) as the baseline and compare to its version with SRR integration. For both experiments, we use the ResNet-18 architecture, trained from random initialization, using the hyperparameters from (Sohn 2021) and (Li et al., 2021). The same model and hyperparameter conﬁgurations are used for SRR with K = 5 classiﬁers in the ensemble. We set γ as twice the anomaly ratio of training data. For 0% anomaly ratio, we set γ as 0.5. Finally, a Gaussian Density Estimator (GDE) on learned representations is used as the OCC. trainable representations. We demonstrate the state-of-the-art AD performance of SRR on multiple tabular and image datasets from various applications. We provide detailed analyses on the key contributing factors of SRR, which we hope to provide further guidance in AD research. Lastly, we extend SRR to the scenario of not possessing any information on the anomaly ratio. We leave some important aspects, explainability and reliability of AD, to future work.",https://www.semanticscholar.org/paper/b9ca44d3501a101200ecedb8812d5a2c7eebc24b,"{'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'e061d23b68e7d4aac5aece4794c044c80e638dca', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '8c7e9d9bc9009fd5ca7028af6e37f3851af1ad6b', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '20ba55ee3229db5cb190a00e788c59f08d2a767d', '299847adf3ee558a760475ffa364facac3ebbb16', '99475e45a843e85d726d0877a4951cf8823927b6', '5db790198b9acf4e5efe350acdd814238fcacaa7', '00a1077d298f2917d764eb729ab1bc86af3bd241', 'a4c94b221062d0737ee967affa80ce2110cc50c0', '94559c249d204110296c39ed4af2042cc4468e68', '0aa29099a0afca6a46df4ab6c9db8cd99ccaddc4', '7313c770c84af50aa8e34ec21c8e50413f99c89f', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'd612d7c21d4130a457968273d79c2c2f6946953d', 'e7c883497fd3e9838ead70ce97b1f53331cebc70', '04513c7c0b3a63fde81a996dae064a28d453c17a', '4dafbbc0cd8eb3e9967dd6b8bfce216a4dd3c1fc', '498e003901f8287e89e5064477cd22dd47e49d61', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', '297e83bc6d4498ad2e2906092e2b3df1b7621c26', 'c3c0aaa9f961f0c81d664b0f9a030871de215b79', '6af440915b8a0718c93be1cf61905e41e620484a', '8b45e9e795079abcd1b75e7d5dadb5eb00e3b78a', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '732750bec3b4d8c0108d6daed642500765d5c0ca', 'e9b3da7ef244d233acf307dbf0ec01237e05cd0f', 'a7c828184693a453a6c2867dee233ed054b2012e', '278841ab0cb24c1abcb75e363aeed1fa741c8cc4', '59da587c46f695a0b7867b68a22d832ca92999f3', '5d90f06bb70a0a3dced62413346235c02b1aa086', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', 'ce435482acc0e195be8d8f002b2655b4c7b08be6', '1152d9bfb6cbfda1b919ff6e9013f48344f9926f', '18839a9a29722918e91dcb8ac676240ca770021b', '3a2ef5c27e7140f819a4c99444b7d4fd533dca59', '3cbc2d53063794a45b41c75c246fea7eb2857a98', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '8cb44f06586f609a29d9b496cc752ec01475dffe', 'c42816f497d663c681df20d48a6e66a5632600d8', '34008f26cec7fae1f60b8da38abb6b012bf83e13', 'fd9c9077eaaaa4381ff9751bacdd898fa7a4f5c0', '17a620afc87f5266e3fd8b3f308c883cc2c2b7c7', 'ca4edb65a0664804e4819c5c809d0dfba9bdb2df', 'd7b968f3c9356e0a8d6d295d5eb37cdc748e64b9', 'c0d30aa1b12a9bceda14ab1d1f2489a2dddc8277'}",58,"{'498e003901f8287e89e5064477cd22dd47e49d61', '78d80c343d36baaf89f18e12d325cf6309fb6c8f'}",2,"['Jinsung Yoon', 'Kihyuk Sohn', 'Chun-Liang Li', 'Sercan Ö. Arik', 'Chen-Yu Lee', 'Tomas Pfister']",Jinsung Yoon,"Jinsung Yoon, Kihyuk Sohn, Chun-Liang Li, Sercan Ö. Arik, Chen-Yu Lee, Tomas Pfister",3.4482758620689653
bc6549edf4e0219329846f8045d58453a1841123,On the Pitfalls of Using the Residual Error as Anomaly Score,2022-02-08,"Many current state-of-the-art methods for anomaly localization in medical images rely on calculating a residual image between a potentially anomalous input image and its (“healthy”) reconstruction. As the reconstruction of the unseen anomalous region should be erroneous, this yields large residuals as a score to detect anomalies in medical images. However, this assumption does not take into account residuals resulting from imperfect reconstructions of the machine learning models used. Such errors can easily overshadow residuals of interest and therefore strongly question the use of residual images as scoring function. Our work explores this fundamental problem of residual images in detail. We theoretically define the problem and thoroughly evaluate the influence of intensity and texture of anomalies against the effect of imperfect reconstructions in a series of experiments. Code and experiments are available under https://github.com/FeliMe/residual-score-pitfalls.",https://www.semanticscholar.org/paper/bc6549edf4e0219329846f8045d58453a1841123,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6be216d93421bf19c1659e7721241ae73d483baf', '67bd5b3a67a6dedd26b6c4e6b279158433069a7d', '2a64030d34abc67343bbacdcdb0748d104203a32', 'e2963e39e5a5a45a89edf7ca71929a719bee12f9', '9a395b281496e9cc6278ac85b278a1e86bf72e46', '7d3e76a1f129b49ff88a84d0eb1c32b0f83f74ad', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', '673377fa6f2cd6f013c095b3e4c05ce48482ab38', 'd07284a6811f1b2745d91bdb06b040b57f226882', 'd82800c79dd335297336fe10b1a60d47706e4296', '18c29e07f159b836125db6c7a432ba44d74f2d41', '97f43437e45867a6843ef8278d34a1cf4f811c14', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '7a905f54ad0221fc4367eec05168deddd45c4d9b', None, '0c5ed0c30375703306f36d341d31772f3bd5af47', '326e00443733d3c43a353e09a27ae1959ced49af', '41747cbdbed84762dfbfc305254c97021279dc6e', '87e9842de97fc610ba69f0e8bc3e13b9619787b9', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '13c1e50d2bd916e6d33987d29acbe7ef57c6e9a7', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'e9df6d7fa6b380c5db0ad4f29b9c32219aca05fe', '5ad2476610312f380dd4e6475ee706199560b21a', '580062407427236ced45253a2ff7df2e147a81e2', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1'}",28,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '13c1e50d2bd916e6d33987d29acbe7ef57c6e9a7'}",2,"['Felix Meissen', 'B. Wiestler', 'G. Kaissis', 'D. Rueckert']",Felix Meissen,"Felix Meissen, B. Wiestler, G. Kaissis, D. Rueckert",7.142857142857143
e021d59638966a6fbb36854cc2cf1045de7a62d2,Inverse-Transform AutoEncoder for Anomaly Detection,2019-11-25,"Reconstruction-based methods have recently shown great promise for anomaly detection. We here propose a new transform-based framework for anomaly detection. A selected set of transformations based on human priors is used to erase certain targeted information from input data. An inverse-transform autoencoder is trained with the normal data only to embed corresponding erased information during the restoration of the original data. The normal and anomalous data are thus expected to be differentiable based on restoration errors. Extensive experiments have demonstrated that the proposed method significantly outperforms several state-of-the-arts on multiple benchmark datasets, especially on ImageNet, increasing the AUROC of the topperforming baseline by 10.1%. We also evaluate our method on a real-world anomaly detection dataset MVTec AD and a video anomaly detection dataset ShanghaiTech to validate the effectiveness of the method in real-world environments.",https://www.semanticscholar.org/paper/e021d59638966a6fbb36854cc2cf1045de7a62d2,"{'01625cba9f8a783994377d4f35aa765242faab4f', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'ec5d26aaf2e6902ca28effa0f94c9556571160b8', '599fd051c9438011ec5b581983c89e8922b4a5e6', '1c06870e1ecc63e120e45a2283ca4b72c153e867', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '5db790198b9acf4e5efe350acdd814238fcacaa7', '9acc51b06f54b07836fad4cc24633187dc21317f', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', '59bb8d6c3eec8f925710db4d2488e2a23167d3e8', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '941b0be328d6eb370121828acff3acf300e0745a', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', '5435a9ab36a308cef10bc725104e8f778ed3a328', '36653f8705b56e39642bcd123494eb680cd1636b', 'ba10c37a6a24276f5e67a22a71d0d511c01cf5e1', '8acbe90d5b852dadea7810345451a99608ee54c7', '10a498003e9204f5fc1328e706510a37e514d8c7', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '6af440915b8a0718c93be1cf61905e41e620484a', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '5694e46284460a648fe29117cbc55f6c9be3fa3c', '580396c680951b7ff93defcac7cfe085dfe1814e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '8381157eae4fbf8908d0312a9642f8e69e944449', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'c92ee6ff32fa4833fa1c2bdf29284e2a58ddb640', 'fbc6562814e08e416e28a268ce7beeaa3d0708c8', 'f198043a866e9187925a8d8db9a55e3bfdd47f2c'}",43,set(),0,"['Chaoqin Huang', 'Jinkun Cao', 'Fei Ye', 'Maosen Li', 'Ya Zhang', 'Cewu Lu']",Chaoqin Huang,"Chaoqin Huang, Jinkun Cao, Fei Ye, Maosen Li, Ya Zhang, Cewu Lu",0.0
f98dbe64ed6fa8925048291fcceb625d704fb294,Self-Supervised Anomaly Detection: A Survey and Outlook,2022-05-10,"—Over the past few years, anomaly detection, a subﬁeld of machine learning that is mainly concerned with the detection of rare events, witnessed an immense improvement following the unprecedented growth of deep learning models. Recently, the emergence of self-supervised learning has sparked the development of new anomaly detection algorithms that surpassed state-of-the-art accuracy by a signiﬁcant margin. This paper aims to review the current approaches in self-supervised anomaly detection. We present technical details of the common approaches and discuss their strengths and drawbacks. We also compare the performance of these models against each other and other state-of-the-art anomaly detection models. Finally, we discuss a variety of new directions for improving the existing algorithms. 1",https://www.semanticscholar.org/paper/f98dbe64ed6fa8925048291fcceb625d704fb294,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6eedf365c6b580a6fc201eab867f1608f09adbae', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '99382657c0afc9e8946c45e5d799281e0e9adc7d', 'afc11a384ed298f2980f6a1547ef0aa3cb5573c6', 'db787640c9b42416ff8d7015546e667e58267177', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '1c125949603054332399b196187b7391f793b59d', '5db790198b9acf4e5efe350acdd814238fcacaa7', '9fea25c41f0c25fc356f3ec41aee2b06493125a1', '9436440748a52254deb7d7391bfd564bbf139286', '27a030b1a014fd1458320eaf836f3cfc93966158', 'ab96c776f96e10f10d88ac5abbe9335afe935c81', '4c94ee7df6bc2bfcac76703be4f059a79010f7e5', '38643c2926b10f6f74f122a7037e2cd20d77c0f1', '62b77e5cb85fc61b84edd532f6d65714be152596', '5b55d69c4b5f9a371f04944453283ed36ddb90ce', '9277dc70c74bcadf80dab11c28ead83fd085deec', '04513c7c0b3a63fde81a996dae064a28d453c17a', '912b0b7879ca99bf654a26bbb0d50d4b8e0ed6c0', '37595f7a51982d776e57c7280b9445474d90f0be', '16a4c3c21020dddbc93301ad785610c8a6db91bf', 'bbbe62e768b626706727c5fd2eeaa7a78c032ece', '498e003901f8287e89e5064477cd22dd47e49d61', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', 'bee2aeac46f73e14105a3205502de9879692d3fe', 'eb8b7e33cce31471fedb579eb32432e95973fa01', 'eae7d5b15423a148e6bb32d24bbabedfacd0e2df', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'fbf26e1085ac3b038f47d4d1945ebda45d5e57fb', 'adb73fdced3990ce47e97c323f47ee1a90cd3a31', '799623e8252bab8034e51b7f2d3b3a527f0a56fa', '13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'add2f205338d70e10ce5e686df4a690e2851bdfc', 'f0cb853084fb2c97ed0eb61ad012e651bb12bdf1', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'd7c10ec5fe238cf2b5e296ea70822e7aef0131c8', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '275aaca7621b2ee4ff81cd37162f6c9a90f306e4', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '9fae16c72ef5048cc3912c585a820ac9c83ac590', 'a4731547554302b8859453ed3b8478dce99ef081', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'f215dde930dce032d682692f54cb5c77af694d0f', '71a0d7f73b2d2477ae3dfa4abf9df4dcb6d03117', '793fa365083be47b0e92e35cf19400347acd7cbd', '8a9d84d86ac0d76e63914802f9738325c3bece9c', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '19862af96b6af51e879e6e3f1d3d421af5427005', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9acc51b06f54b07836fad4cc24633187dc21317f', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', 'e7c883497fd3e9838ead70ce97b1f53331cebc70', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '405b6ff2ea2ec9a7c7d6b18ac951dc778892ffcf', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', 'ed389fc1f51ec10b0446eb4d9a82a21bd44cf2d7', 'af5b1a35271efd17ff3d5ddd152bacc96dff0e81', '2abc929a001e5503eb29c828bb5cc4ce35241a14', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '61a41a428fa2cc3d7967f4454621ac2d115388ae', '39361b3507c9f8b0a97780568b645f80a208d78a', None, '4edf00ac407cb2db9ed62ed69fe5d69984b7ca37', '9ac074098d3c48234258b1a9ee8a0ad7e748a9e0', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '5aa26299435bdf7db874ef1640a6c3b5a4a2c394', 'e010584f68816b306fa038ca812d0c8b4ba011a9', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '6c8949e989a50cc2516669d1785b99ed8e6f4e59', '6bbec2104e48df02f5319af6cfd5320411f9dec1', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '1f5cfe35ada7bba999508ebc216deab4df77840b', 'edc144b404d9debe523cd4114d61deb20e5e8601', '599fd051c9438011ec5b581983c89e8922b4a5e6', '1ba1de0f143bd3166c9961acc869e123651d9836', '197ec03481b5e845fb4d34dd99a4b8e844fdabcc', '075c541203ffdfc29d48abc06bde2a0f6a97be16', '6ff1eb9cdf64a464bf43b54d852456e9ddf55b28', '9bf531bf77c6fb8e4de771d24b117715b19ce8d1', 'd0697fb970ba92e970bf39ebf25561a8fee61cd6', '6af440915b8a0718c93be1cf61905e41e620484a', '38f93092ece8eee9771e61c1edaf11b1293cae1b', '10f8d1106e49fa07c1dab8bd200e76896ee9dd13', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '0aaa5f51faa9a5c03f788009cbf2288988880278', 'cc384cff27d8a609f89f9e915c26bf31c39749a1', '155b7782dbd713982a4133df3aee7adfd0b6b304', '8f45d7624129a7d5fcd0e18354ee4a396c74d6c2', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '9e66b328144102f57f14b5b47620d3bc19c684b8', '4db2f23a5ad2259b90aa9b0545d27cd44337515a', '058bec13449f05cece18c3e32040bb388b049a7e', '184ac0766262312ba76bbdece4e7ffad0aa8180b', '94192bcdf3507e3543910c03b16bd06c5338fd47', '31f5fa100bb9acae50d44003340a4419637c3e55', '0fe615dc0a422100e85cfb7e26c9306c481f6c75', '45535b86c60661dd4c4e4f375abae80937563499', 'aa6d323bd08aea5d61a3c68466e863cce1db0a02', '8d54db5ec8f2719fb37d98cb1d47ff48838c0370', '80c8b42417f70ff6ed21b3b11e0eed791f2b7e50', '5187df17503f78c7e063c2ea0a707e3e59c48235', '4659b40f6e71d663065a7f32dff8c8f86a748c43', 'de28c165623adabcdba0fdb18b65eba685aaf31d', 'b110ba174df21a23a9521731d4181261ca5860ed', '00a1077d298f2917d764eb729ab1bc86af3bd241', 'cfaae9b6857b834043606df3342d8dc97524aa9d', '2edaed797a483c5c978c49753abe4b5d3b19c771', 'd40ee5dd758c525dfb9932d726bb4e844b7b8478', 'f0e54c9a679cf40b79da747519f2da710ec4daed', '4c02fa0dca6a2a8a34a687b11c303de7f6b8f252', '0bdd74925d662a78efdf130d953dff97a131d12a', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'd89ef05495ff8e83eaea9b7c0831be092d6cf314', 'e4e112e4bc508071bdb797af3968dbe512b543bc', '8e63784bd5a24d5e3035e2a11753e65e6e56625d', 'c3f372c32e721c861d51c0ff78542e01de9f1560', '948c81cb849299b099c97b3220e4f680e1f1e4da', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '5771af144ce1d4d783a0af70c190a74e5123d0a0', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', 'd7adcb62e45c8b0fd4a97f45ffc8fe3045f487c2', 'c35b9a59851c55e680ed46a315f7539eb7b7025b', '1d011918890db7c5fac80c152488a4792661f434'}",136,"{'931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '19862af96b6af51e879e6e3f1d3d421af5427005', 'ab96c776f96e10f10d88ac5abbe9335afe935c81', '62b77e5cb85fc61b84edd532f6d65714be152596', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', 'e4e112e4bc508071bdb797af3968dbe512b543bc', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '45535b86c60661dd4c4e4f375abae80937563499'}",26,"['H. Hojjati', 'Thi Kieu Khanh Ho', 'N. Armanfard']",H. Hojjati,"H. Hojjati, Thi Kieu Khanh Ho, N. Armanfard",19.11764705882353
232b3dff35e9bf6ac31ece24dfcaa5713343e27d,Guest Editorial: Special Issue on Performance Evaluation in Computer Vision,,,https://www.semanticscholar.org/paper/232b3dff35e9bf6ac31ece24dfcaa5713343e27d,"{'2d5c1c8fe422432e845e8bbda92c661a1bf9cc89', '18bb573ab638f5ed7f1b65c92fc866736a757d19', 'cb19ceddac67896e317bf1fef3cae514f9891f2b', '14c88059503461afdab6d59c3e56914b6690eb02', '2fc913467a577f2771c0f5d2a502e3d1ada460be', '44990f618f46f02da321b1043a64e72d5f7c0486', '114126ae225d2107f5a64f38e1b13cb89e2bd5ea', '55d8f5e31f046a53fb87f0d49b0f8d36b1ef58d6', '3b6a481ac5e55b5f59889c74ffdf0937b0fa84d8', '17daa4d4cc2f0ab03c3c1f9a3c47d597c185650e', '07917c1b08a12bb7744d05872b2d937702b0964a', 'e284bc13c2b76d0d0c7ad61d976f8a9d3eef8461', '6cdbe49de9f897530c34cd63e9ffa81d7f09b42a', '021f956ab3bc13008e87d24f42feeced61eb5916', '32ff7b038d6f90ab7c497448ec1503392734a3c0', '61ac7a63a32590a183b4669006c4ff228510bd9a', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '629730d6e23ad6e6e49db648ccd1f2af5d6bf7e3'}",19,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Daniel Scharstein', 'Angela Dai', 'D. Kondermann', 'Torsten Sattler', 'K. Schindler']",Daniel Scharstein,"Daniel Scharstein, Angela Dai, D. Kondermann, Torsten Sattler, K. Schindler",5.2631578947368425
8e47e13d28418b5666303c92480c7bdc08456e93,Few-Shot Defect Segmentation Leveraging Abundant Normal Training Samples Through Normal Background Regularization and Crop-and-Paste Operation,2020-07-18,"In industrial product quality assessment, it is essential to determine whether a product is defect-free and further analyze the severity of anomality. To this end, accurate defect segmentation on images of products provides an important functionality. In industrial inspection tasks, it is common to capture abundant defect-free image samples but very limited anomalous ones. Therefore, it is critical to develop automatic and accurate defect segmentation systems using only a small number of annotated anomalous training images. This paper tackles the challenging few-shot defect segmentation task with sufficient normal (defect-free) training images but very few anomalous ones. We present two effective regularization techniques via incorporating abundant defect-free images into the training of a UNet-like encoder-decoder defect segmentation network. We first propose a Normal Background Regularization (NBR) loss which is jointly minimized with the segmentation loss, enhancing the encoder network to produce distinctive representations for normal regions. Secondly, we crop/paste defective regions to the randomly selected normal images for data augmentation and propose a weighted binary cross-entropy loss to enhance the training by emphasizing more realistic crop-and-pasted augmented images based on feature-level similarity comparison. Both techniques are implemented on an encoder-decoder segmentation network backboned by ResNet-34 for few-shot defect segmentation. Extensive experiments are conducted on the recently released MVTec Anomaly Detection dataset with high-resolution industrial images. Under both 1-shot and 5-shot defect segmentation settings, the proposed method significantly outperforms several benchmarking methods.",https://www.semanticscholar.org/paper/8e47e13d28418b5666303c92480c7bdc08456e93,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '346f813f3aee101cc288da86c2cf9aad024bb32a', 'ae1c89817a3a239e5344293138bdd80293983460', 'fd9f5693a34fb839fcc39be83c1835aaee0210e8', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '3d3eec2b29f705c7b044b44497302d39596b5554', '599fd051c9438011ec5b581983c89e8922b4a5e6', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '945b53ede48dae40af9870030fc4985a119cd1b8', '237c0c16d2843a91b277ebe05a892ca0787d8b57', '9acc51b06f54b07836fad4cc24633187dc21317f', '0269073e07faaafa4df7b3d7ddac96e6dccf853d', 'de28c165623adabcdba0fdb18b65eba685aaf31d', 'dc58da4ebf70aca8364e91245b9e4ddc79c5a773', '5e83ab70d0cbc003471e87ec306d27d9c80ecb16', 'e8180ad45ed5ca732e492db32aa85e769836132e', '931c9f7860dc8909b339c816020241c3b7fb0451', 'f06ff5f719eb9cd939dde8fc9b199b17adcbc75f', 'ed17929e66da7f8fbc3666bf5eb613d302ddde0c', '91b33e7a08fa030abf7ba550972b6f4944d9b7cc', '452a7342012df5f937480584dc722d7cb426879b', 'a40f97770296c7fca2e5361cbceba3f4aae399e0', '317aee7fc081f2b137a85c4f20129007fd8e717e', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '6af440915b8a0718c93be1cf61905e41e620484a', 'b36a5bb1707bb9c70025294b3a310138aae8327a', 'bfe284e4338e62f0a61bb33398353efd687f206f', '42b0a8f757e45462e627e57f9af7e9849dcdacdf', None, '2984e527510e7e7c0eadb339a6172c05a6919b5e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",36,set(),0,"['Dongyun Lin', 'Yanpeng Cao', 'Wenbin Zhu', 'Yiqun Li']",Dongyun Lin,"Dongyun Lin, Yanpeng Cao, Wenbin Zhu, Yiqun Li",0.0
913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e,VT-ADL: A Vision Transformer Network for Image Anomaly Detection and Localization,2021-04-20,"We present a transformer-based image anomaly detection and localization network. Our proposed model is a combination of a reconstruction-based approach and patch embedding. The use of transformer networks helps preserving the spatial information of the embedded patches, which is later processed by a Gaussian mixture density network to localize the anomalous areas. In addition, we also publish BTAD, a real-world industrial anomaly dataset. Our results are compared with other state-of-the-art algorithms using publicly available datasets like MNIST and MVTec.",https://www.semanticscholar.org/paper/913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e,"{'1f604ad152339e0a734f05002e6810c72b949611', 'f33de7b2fa5425391f5afa81b85818d03325cb0e', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2172552b917ef3757b0af47d17fce18586d56cba', 'ce9edb785f28c81bd7c2864940ed001429178e1e', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '732c21998e251d64cd58b6a86886ee5907efeaa5', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '388645c44061f6e88fff0ecdad2f622936207d67', 'f076e4355c0facf111716dcab2837803367dd2d8', '88ecd1aa9148c59782cb35ffd6c9b08084087ad8', '357e32e0769a05b831a993c68631f9ff8ff62111', 'df8294254b229e1751de70db5988273f97e218a0', '5096d5817c4ed89635d9f065c79a44a2601e939f', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', 'b37b3086add419e4679255366d61d4e70896651e', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'de39bccb3ed4da6f5b89b3a99cb25e89c35c102e', 'f8d37cf4c4a2f15acd7c6ab2b4b4f25a3f3d7f9c', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '70f9968a356d840040a1c9207906f60376dc6bd4', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '4fd62d384b792511441c2f358b25726012e13a48', '41747cbdbed84762dfbfc305254c97021279dc6e', '4ad090484636e926285abb2dfe3b449c56692528', '8381157eae4fbf8908d0312a9642f8e69e944449', 'd4ca18249446328c86d9da295a21c679aea1ed77', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",31,"{'f33de7b2fa5425391f5afa81b85818d03325cb0e', '41747cbdbed84762dfbfc305254c97021279dc6e', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",4,"['P. Mishra', 'Riccardo Verk', 'Daniele Fornasier', 'C. Piciarelli', 'G. Foresti']",P. Mishra,"P. Mishra, Riccardo Verk, Daniele Fornasier, C. Piciarelli, G. Foresti",12.903225806451612
e13d3f39cb9d03c57fef1344a825c163160dd8e7,Superpixel Masking and Inpainting for Self-Supervised Anomaly Detection,,"Anomaly detection aims at identifying abnormal samples from the normal ones. Existing methods are usually supervised or detect anomalies at the instance level without localization. In this work, we propose an unsupervised method called Superpixel Masking And Inpainting (SMAI) to identify and locate anomalies in images. Specifically, superpixel segmentation is first performed on the images. Then an inpainting module is trained to learn the spatial and texture information of the normal samples through random superpixel masking and restoration. Therefore, the model can reconstruct the superpixel mask with normal content. At the inference stage, we mask the image using superpixels and restore them one by one. By comparing the mask areas of the original image and its reconstruction, we can identify and locate the abnormal regions. We conducted a comprehensive evaluation of SMAI on the latest MVTec anomaly detection dataset, and it shows that SMAI plays favorably against state-of-the-art methods.",https://www.semanticscholar.org/paper/e13d3f39cb9d03c57fef1344a825c163160dd8e7,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '375b98f955774e5438b76dd51e9a94ac68955258', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'd468363414b9ec6507ff24cbeefecb4828f52f6b', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '156b0af3dc5b6a223790c141b6031d1fa0ca56da', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '0670fa6d12ec904e0d969c2218bd32a241dc4435', 'a228ce656599fe1413ed0671c260b5dad1190e3e', 'b3c785b99ec147049caa47f707f337b717705970', 'b762ecb0624005831f2f3d8eb626d53e8eca4b6c', 'd0b8b2f997ed98202a01c7fab2175cdc17b53ec1', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '59eafd78cccc2f37e93f5609e8dbf600c8d04349', '3cc74013661e23f66e26fbe677c74ce568f61919', None, '02ed10d295328c932c00555891f976c4aef25ae8', 'caa0fd34e50bb417fae3ee32f667e78fe5b198bc', 'e4845fb1e624965d4f036d7fd32e8dcdd2408148', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '739d084e486702dbdad01d668f77b431228bae9d', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '1a0912bb76777469295bb2c059faee907e7f3258', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",27,set(),0,"['Zhenyu Li', 'Ningyang Li', 'Kaitao Jiang', 'Zhiheng Ma', 'Xing Wei', 'Xiaopeng Hong', 'Yihong Gong']",Zhenyu Li,"Zhenyu Li, Ningyang Li, Kaitao Jiang, Zhiheng Ma, Xing Wei, Xiaopeng Hong, Yihong Gong",0.0
e4f64fa70b05470f9d14674e15437e398f7a76e1,D4Net: De-deformation defect detection network for non-rigid products with large patterns,2021-02-08,,https://www.semanticscholar.org/paper/e4f64fa70b05470f9d14674e15437e398f7a76e1,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'fb37561499573109fc2cebb6a7b08f44917267dd', '95e90e62828e0bf262ec12c0961bc398e3c062e7', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', 'f6e0856b4a9199fa968ac00da612a9407b5cb85c', '9217e28b2273eb3b26e4e9b7b498b4661e6e09f5', 'df67d46e78aae0d2fccfb6212d101a342259c01b', '656d86b2593f87575bcc4f056dad3d18db29eb0c', 'e36f4834182eeeedf2a918837337a6f75a80aed1', 'c468bbde6a22d961829e1970e6ad5795e05418d1', '59a8bf1acf451923b1931db9ef7ca9091d975f34', '1d2105616d122389efbd1b0ac7c04c0c2f8ac996', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'ed17b491d4facb1cd5b45a70f644bc7476879e51', '1e34d711b76f8d996b5cc1041875480489c144ca', '68bf80e31d16f10308a6d78c8a73d82a951d1fd7', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5db1b742cd18678ed08a813970bfaba3527df037', '1a0912bb76777469295bb2c059faee907e7f3258', 'fbc6562814e08e416e28a268ce7beeaa3d0708c8'}",22,set(),0,"['Xuemiao Xu', 'Jiaxing Chen', 'Huaidong Zhang', 'Wing W. Y. Ng']",Xuemiao Xu,"Xuemiao Xu, Jiaxing Chen, Huaidong Zhang, Wing W. Y. Ng",0.0
76077e1e12908b525907e7c3419368291f5965ab,Benchmarking Unsupervised Anomaly Detection and Localization,2022-05-30,"Unsupervised anomaly detection and localization, as of one the most practical and challenging problems in computer vision, has received great attention in recent years. From the time the MVTec AD dataset was proposed to the present, new research methods that are constantly being proposed push its precision to saturation. It is the time to conduct a comprehensive comparison of existing methods to inspire further research. This paper extensively com-pares 13 papers in terms of the performance in unsupervised anomaly detection and localization tasks, and adds a comparison of inference efﬁciency previously ignored by the community. Meanwhile, analysis of the MVTec AD dataset are also given, especially the label ambiguity that affects the model fails to achieve full marks. Moreover, considering the proposal of the new MVTec 3D-AD dataset, this paper also conducts experiments using the existing state-of-the-art 2D methods on this new dataset, and reports the corresponding results with analysis.",https://www.semanticscholar.org/paper/76077e1e12908b525907e7c3419368291f5965ab,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '3b3aefbbdb64e5812f133f220b3f129a36a30065', '4758baad6b22c61682e7f7182bb93723046f36f5', '5da4eb1135d5827ce30e099bda377a19f3a52730', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '5435a9ab36a308cef10bc725104e8f778ed3a328', '04513c7c0b3a63fde81a996dae064a28d453c17a', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '498e003901f8287e89e5064477cd22dd47e49d61', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '7edbd1ee743632893de81d117c05120774dc36f4', '6af440915b8a0718c93be1cf61905e41e620484a', '70f9968a356d840040a1c9207906f60376dc6bd4', '45f490710b4dd6697dba4c9b385a49554501711a', None, 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '8381157eae4fbf8908d0312a9642f8e69e944449', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', 'dc8301b67f98accbb331190dd7bd987952a692af', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",38,"{'95a26eafabf06b1fc5dec6c460a927cf5964e97e', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '3b3aefbbdb64e5812f133f220b3f129a36a30065', '4758baad6b22c61682e7f7182bb93723046f36f5', '5da4eb1135d5827ce30e099bda377a19f3a52730', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '498e003901f8287e89e5064477cd22dd47e49d61', '0eb80e81580568ce9d70ad1c2495aef188a9587f', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",19,"['Ye Zheng', 'Xiang Wang', 'Yu-Hang Qi', 'Wei Li', 'Liwei Wu']",Ye Zheng,"Ye Zheng, Xiang Wang, Yu-Hang Qi, Wei Li, Liwei Wu",50.0
d4d7063dab04985c8f4c355d0931b1cfb79da18f,ALGAN: Anomaly Detection by Generating Pseudo Anomalous Data via Latent Variables,2022-02-21,"In many anomaly detection tasks, where anomalous data rarely appear and are difficult to collect, training using only normal data is important. Although it is possible to manually create anomalous data using prior knowledge, they may be subject to user bias. In this paper, we propose an Anomalous Latent variable Generative Adversarial Network (ALGAN) in which the GAN generator produces pseudo-anomalous data as well as fake-normal data, whereas the discriminator is trained to distinguish between normal and pseudo-anomalous data. This differs from the standard GAN discriminator, which specializes in classifying two similar classes. The training dataset contains only normal data; the latent variables are introduced in anomalous states and are input into the generator to produce diverse pseudo-anomalous data. We compared the performance of ALGAN with other existing methods on the MVTec-AD, Magnetic Tile Defects, and COIL-100 datasets. The experimental results showed that ALGAN exhibited an AUROC comparable to those of state-of-the-art methods while achieving a much faster prediction time.",https://www.semanticscholar.org/paper/d4d7063dab04985c8f4c355d0931b1cfb79da18f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2cbb8de53759e75411bc528518947a3094fbce3a', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '84de7d27e2f6160f634a483e8548c499a2cda7fa', '8388f1be26329fa45e5807e968a641ce170ea078', 'c342c71cb23199f112d0bc644fcce56a7306bf94', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '4d376d6978dad0374edfa6709c9556b42d3594d3', 'c959a9dfbea3fb3059d13a61645a5ac9a8161efd', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '7536bce1007a765fd097a7cc8ea62208a8c89b85', '1c4e9156ca07705531e45960b7a919dc473abb51', '3dd9ddf2594d7d63af5d361154992ef2abf6d593', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '77afac8f4d7f47c8b34371d8f8355cefbea1d4f6', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'c53352a4239568cc915ad968aff51c49924a3072', '5435a9ab36a308cef10bc725104e8f778ed3a328', '851ff5f13fbff7023717c3913f2df4a7551a374a', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '9df5c75cbd9617d4b2855464835539ffe48ab58b', 'a93632237958800217341d7bad847200afdd60e3', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'c19e71fb84c9a2b06af2ae51e33f3b84cc6be507', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '23ae911ceb9134f3a27719faab5d5d297a2f4e8e', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '52113c06f0da6002d80bb11fb9c47260f4ebbbe1', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', None, '1b17f1fca40568285af1a71d85799263a2ff6ba6', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', 'fa62b0a1ef618ee2595f06f1af9744ad63938a63', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', '8381157eae4fbf8908d0312a9642f8e69e944449', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '3d76e4a420ee27ca5101648e7ea7d717e73207c6', '30895c61bb836f2cae7ef5ba6516886f746a7153'}",52,"{'30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '23ae911ceb9134f3a27719faab5d5d297a2f4e8e', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",8,"['Hironori Murase', 'K. Fukumizu']",Hironori Murase,"Hironori Murase, K. Fukumizu",15.384615384615385
bbbb6d1740b937a7dd511576652336e1607ac813,Anomaly Detection via Reverse Distillation from One-Class Embedding,,"In this supplementary material, we present more details on our reverse distillation method for anomaly detection.Specifically, we describe the architectures of our proposed Reverse Distillation, especially the student decoder design, in Appendix A . Appendix B elaborates the implementation and results for one-class novelty detection. More visualizations on MVTec [2] for anomaly detection and localization are provided in Appendix C. Finally, We discuss future work that may alleviate the limitations of current work in Appendix D. Our code is available at https://github.com/hq-deng/RD4AD.",https://www.semanticscholar.org/paper/bbbb6d1740b937a7dd511576652336e1607ac813,"{'2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '292b78282340ccfa7cfd1b0dbd7c38c2b39a2230', '1c4e9156ca07705531e45960b7a919dc473abb51', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', None, '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '83dfe3980b875c4e5fe6f2cb1df131cc46d175c8', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d'}",15,"{'78661cecf81340be9bd5720ac5ae97dc0e037bb9', '78d80c343d36baaf89f18e12d325cf6309fb6c8f'}",2,"['David Sattlegger', 'C. Steger']",David Sattlegger,"David Sattlegger, C. Steger",13.333333333333334
49130e2084f99c59150a86d4f1be6623a694386b,PANDA: Perceptually Aware Neural Detection of Anomalies,2021-04-28,"Semi-supervised methods of anomaly detection have seen substantial advancement in recent years. Of particular interest are applications of such methods to diverse, real-world anomaly detection problems where anomalous variations can vary from the visually obvious to the very subtle. In this work, we propose a novel fine-grained VAE-GAN architecture trained in a semi-supervised manner in order to detect both visually distinct and subtle anomalies. With the use of a residually connected dual-feature extractor, a fine-grained discriminator and a perceptual loss function, we are able to detect subtle, low inter-class (anomaly vs. normal) variant anomalies with greater detection capability and smaller margins of deviation in AUC value during inference compared to prior work whilst also remaining time-efficient during inference. We achieve state-of-the-art anomaly detection results when compared extensively with prior semi-supervised approaches across a multitude of anomaly detection benchmark tasks including trivial leave-one-out tasks (CIFAR-10 - $\mathbf{AUPRC}_{avg}$: 0.91; MNIST - $\mathbf{AUPRC}_{avg}$: 0.90) in addition to challenging real-world anomaly detection tasks (plant leaf disease - AVC: 0.776; threat item X-ray - AVC: 0.51), video frame-level anomaly detection (VCSDPedl - AVC: 0.95) and high frequency texture with object anomalous defect detection (MVTEC - $\mathbf{AUC}_{avg}$: 0.83).",https://www.semanticscholar.org/paper/49130e2084f99c59150a86d4f1be6623a694386b,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6be216d93421bf19c1659e7721241ae73d483baf', 'c3113eaad326a955ba96c11b7b65d0c065fb2054', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '9d4ab51a78b8a076db3a7c0f7e41223200423ddb', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '8388f1be26329fa45e5807e968a641ce170ea078', '5c6ad7e2a16a025d94a9a5e1214dd601a56b2a3d', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'db787640c9b42416ff8d7015546e667e58267177', 'e8b8a7778ace2a02f8db6fe321a54520c6b283ca', '5db790198b9acf4e5efe350acdd814238fcacaa7', '1856809b8bcd0ba7b2c294201718018ead419cb7', '89968e1e66533d616026f8ddf88dad5c173059c6', '0bdd74925d662a78efdf130d953dff97a131d12a', '9d5290fadb7625862a966e0330bd0f9e111fc99d', '43bdb693883000b83753e971a21ea8c4678c65d9', '5435a9ab36a308cef10bc725104e8f778ed3a328', '60fef33549f57f5cbb6712a510c3a444ab682429', '803a984ab5cdbc2b4619b4b005687acf23cef98d', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', 'a21d8d27caca866d8f107116a2c90a2ed24b0b7a', 'c466d579a727466b756126c21eaf0c03c6238b60', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '1eb1c5f369da4f90c8f763f778a21c49cc605117', 'b9b6bc6ec1c0fde2d1164d3b1b1421245a5d1132', '4a36fe2ba575504c7114f735a18ad16fa97b353d', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', 'aae932cf9c2434f52b03991fcab050a61a960d48', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', '108010c1cf56460664567ab9831df1dadf7c4911', None, '32a40b045e665db39e120c12338f9f1238b0690b', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'eb42cf88027de515750f230b23b1a057dc782108', '3e2da7c1c7dfc7960d1515b61f32fdc55359eea7', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'f39575803d8fee8fefd3ab3753e656f58bf97d7d', '1db6e3078597386ac4222ba6c3f4f61b61f53539', '731a2844c5af6b072d3b404ecabbb488cdad9d46', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",48,{'b32be13cd0fcd516e8b859c36a02917f1a68ab9c'},1,"['Jack W. Barker', 'T. Breckon']",Jack W. Barker,"Jack W. Barker, T. Breckon",2.0833333333333335
5bc6dafef9f7eefc31b51384115c6eae4eeefad8,Automated Fabric Defect Detection and Classification: A Deep Learning Approach,2021-12-14,"A computer-based intelligent visual inspection system plays a major role in evaluating the quality of textile fabrics and its demand is continuously increasing in the textile industry, especially when the quality of textile is to be considered. In this paper, we propose an AI-based automated fabric defect detection algorithm which utilizes pre-trained deep neural network models for classifying possible fabric defects. The fabric images are enhanced by pre-processing at various levels using conventional image processing techniques and they are used to train the networks. The Deep Convolutional Neural Network (DCNN) and a pre-trained network, AlexNet, are used to train and classify various fabric defects. With the exiting textile dataset, a maximum classification accuracy of 92.60% is achieved in the conducted simulations. With this accuracy, the detection and classification system based on this classifier model can aid the human to find faults in the fabric manufacturing unit.",https://www.semanticscholar.org/paper/5bc6dafef9f7eefc31b51384115c6eae4eeefad8,"{'4afa35e9f220d065805d3e42ff5bd42bb8c82f59', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b028fa54288aa25b46cf014394c12a3828022991', 'ec348eebcc919d89174c292b6ff3b7f2d54537f5', '7b64455d7d4aeeb7c0a9563267b6e0318a8a7e30', '769ef3d5021cd71c37d2c403f231a53d1accf786', '2cf37672f7225284936cd50da0452a830b950643', '32a4e56fe9f633c9c499eaed5c2fc35e72d177cf', 'c81792250747548b0d3c7df72045e3c740f074ff', '7e50deaa917178c6469898ae37142ba531f130c9', 'b93ece58d0653895adde6e7ca9ba63015f5d0a11', 'bed674e60ec6c51ae98d893bf3e410922928197f', '08a1d83f77222e8344242dd6afd14ca56117f127', '3e0d8667c6cfb58ecdb5f495f30a6c6894d7d86e', 'edeea32645724a4d7591b2530ed54d1af4d3aeac', '818be4cc16eb0129ada31027533fb477b13fe03a', 'be2aef31b4cf8d5e0fb1404dcf205f429464382e', 'ede435f15984e88bd46b1d427c43c3bcfb4c6f32', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', None, 'd0eb83bd7563ca18e2ca24ccf113c844f4c18841', '782a1fc0871f4ec3ba3e15b75f8eea9833769cff', '1c802eecedcbe651560905085dd3d59083aaa1d5', '5dbd7c2ba7bc494e94e840241d7d5468b230e78f', 'bb48ed21ffc9399db166a0c58d1e7a9b784a58d7', '6a02125708a36965342f85690317066ded123244', 'ae181fea2a7f06c54c28687064cd213b3995e006', '76d45d0985acedb3bfa5ff7599883b7968c5f140'}",28,set(),0,"['N. Sandhya', 'Nihal Mathew Sashikumar', 'M. Priyanka', 'Sebastian Maria Wenisch', 'Kunaraj Kumarasamy']",N. Sandhya,"N. Sandhya, Nihal Mathew Sashikumar, M. Priyanka, Sebastian Maria Wenisch, Kunaraj Kumarasamy",0.0
21275eb2a8cf85d193f36d6639784016b1a8ceda,Defect Classification and Detection Using a Multitask Deep One-Class CNN,2022-07-01,"Defect classification and detection have been explored using convolutional neural networks (CNNs). Normally, a large set of training images containing defects and the associated annotation data are required by these approaches. However, such a large set of images is usually difficult to collect because defects are rare and annotation is time-consuming and expensive. To address these issues, we propose to use a multitask deep one-class CNN for defect classification. Compared with supervised classification methods, this CNN does not require abnormal images and annotated data for training. Specifically, we build a stacked encoder–decoder autoencoder for learning feature representation from normal images. The encoder is used as a feature extractor based on the hard sharing scheme of multitask learning. A one-class classification (OCC) objective learned as a hypersphere using minimum volume estimation is appended to it. Together the encoder and the OCC objective lead to a deep one-class classifier. To train both the autoencoder and one-class classifier end-to-end, a multitask loss function is built. Given an unknown sample, the distance between its feature representation and the center of the hypersphere is used as the anomaly score. Furthermore, defect detection is implemented using a moving-window scanning method on top of the deep one-class classifier. The proposed approach achieves better performance than its counterparts trained using a two-stage method. For defect detection, our approach achieves results almost as good as the supervised method even without using any annotated data. We attribute the promising results to the advantages of multitask learning. Note to Practitioners—Building and evaluating vision-based nondestructive testing (NDT) techniques require many examples of abnormal images, which may not be easy to acquire. This article describes a method that does not require abnormal images for training a convolutional neural network (CNN) in order to perform one-class defect classification (outlier detection). We also applied the method to defect detection with promising results. We include results of experiments demonstrating that better performance can be obtained using our method compared to a set of baselines. Although the proposed method does not use abnormal images for training, it still produces results that are almost as good as the supervised learning-based CNN approaches. This study provides a solution to the challenge encountered by the industrial inspection community when enough abnormal samples are hard to obtain.",https://www.semanticscholar.org/paper/21275eb2a8cf85d193f36d6639784016b1a8ceda,"{'a1a19aaddf57c0546357d890d9269092ba0afb26', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'f289a2e5958dfecaa1f57f625a8601a1524562ba', '687c2897cae256aa983c56db9de8b6fabcec58b9', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '732c21998e251d64cd58b6a86886ee5907efeaa5', 'bc1e4bb713ef239966a4976dedb82846b12c34bb', '13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986', 'a8e8f3c8d4418c8d62e306538c9c1292635e9d27', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'f076e4355c0facf111716dcab2837803367dd2d8', 'e95cf80f757bf25c14e7767d70d400fff19b04dc', '00e6834700e9805cb1618433f05915c261a6ba08', '1c168275c59ba382588350ee1443537f59978183', 'c57bdea0b66dc94f4b164ad72e22184952ef241a', '9257c2e07df6bed95054383cb635808c1864154d', 'cd69b4cb74582a5a20963c7790fcd98a735528df', '4f8d648c52edf74e41b0996128aa536e13cc7e82', '14d9be7962a4ec5a6e55755f4c7588ea00793652', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '658a5162f2a7e4c2961d6460ebebaf0d5868bfe9', '6bf92f55b2ef024b0e81f5e8bd08e92328947bb7', '7ce1c97d2f0c6990d81146eac78c32f326ebd17f', '6af440915b8a0718c93be1cf61905e41e620484a', '00695a31a80221c7125e49885a4767896ec2c4f7', 'da5cbf88abe4d1e9ba711c390c2c08151f86fe2c', '45f490710b4dd6697dba4c9b385a49554501711a', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', None, 'e56de92881663e20230b0b187f7112fe48310cf9', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', 'eb42cf88027de515750f230b23b1a057dc782108', '63de0ad39d807f0c256f851428f211e8d5fcd3bb', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'e694658fd17759315087faa5b11e8c947432e7bd', 'd7a1d5e6b2da522cb17581cb2016dc7ad24fc030', '20764b1b54813f8e8dbfe82b10feb5ebebf72a7f', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",40,set(),0,"['Xinghui Dong', 'C. Taylor', 'Tim Cootes']",Xinghui Dong,"Xinghui Dong, C. Taylor, Tim Cootes",0.0
4d5ac321892646c4fa1ae5c78b3cb5ff16a30393,Normal Image Generation-Based Defect Detection by Generative Adversarial Network with Chaotic Random Images,,,https://www.semanticscholar.org/paper/4d5ac321892646c4fa1ae5c78b3cb5ff16a30393,"{'6364fdaa0a0eccd823a779fcdd489173f938e91a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '0597aba86088282423e7c2d2deb6fca4075e7a91', '2788a2461ed0067e2f7aaa63c449a24a237ec341', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",7,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c'}",2,"['Hiroki Kobayashi', 'Ryo Miyoshi', 'M. Hashimoto']",Hiroki Kobayashi,"Hiroki Kobayashi, Ryo Miyoshi, M. Hashimoto",28.571428571428573
ac2a8e4ae9b6dfa3c9c7e9135abafd5136f837c7,Improving Novelty Detection using the Reconstructions of Nearest Neighbours,2021-11-11,"We show that using nearest neighbours in the latent space of autoencoders (AE) significantly improves performance of semisupervised novelty detection in both single and multi-class contexts. Autoencoding methods detect novelty by learning to differentiate between the non-novel training class(es) and all other unseen classes. Our method harnesses a combination of the reconstructions of the nearest neighbours and the latent-neighbour distances of a given input’s latent representation. We demonstrate that our nearest-latent-neighbours (NLN) algorithm is memory and time efficient, does not require significant data augmentation, nor is reliant on pretrained networks. Furthermore, we show that the NLN-algorithm is easily applicable to multiple datasets without modification. Additionally, the proposed algorithm is agnostic to autoencoder architecture and reconstruction error method. We validate our method across several standard datasets for a variety of different autoencoding architectures such as vanilla, adversarial and variational autoencoders using either reconstruction, residual or feature consistent losses. The results show that the NLN algorithm grants up to a 17% increase in Area Under the Receiver Operating Characteristics (AUROC) curve performance for the multi-class case and 8% for single-class novelty detection.",https://www.semanticscholar.org/paper/ac2a8e4ae9b6dfa3c9c7e9135abafd5136f837c7,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'de4dd10635f4a9be0418b56d3b5ec2c05f73f9cb', '7dfbf31808ebb45df081712d9010599c9d7d2bee', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'e8b8a7778ace2a02f8db6fe321a54520c6b283ca', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'f076e4355c0facf111716dcab2837803367dd2d8', '00a1077d298f2917d764eb729ab1bc86af3bd241', '6bbdd6785bf24cdd1ee6c3e159fed34aebaca98f', '295aca7669f54cdc746c595088693bb102855b9f', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'ca04f6fb87815426e1bec8f7fc0dcbbaf9f35814', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'ba10c37a6a24276f5e67a22a71d0d511c01cf5e1', 'f7174c5c29c3904cc2d23f26be2b896a5bc715b4', '498e003901f8287e89e5064477cd22dd47e49d61', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'a0e8f4348968195c80494b7a4245edb91a252c93', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '04730f91137fbfc8e371c3e0e1483b8ee251696c', '70f9968a356d840040a1c9207906f60376dc6bd4', 'c367d10860cc88be75e5561a36ba8e1e44cb8933', '48f9a48aa5b1230b05a443d2d531e6441a541686', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '4cfd8f903506865e7ccf28b0a07ee3c551487e92', '5f61089d3d548a515f01b473f0119137d1f340d4', '888dbb50bd63a94e349081b27b78c671607452f4', '9eb1b16fbd4786eaac91f308d75609b9321868ce', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'c0c07935977e70e71d296535729fc718636d76c4', None, '41747cbdbed84762dfbfc305254c97021279dc6e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '5d90f06bb70a0a3dced62413346235c02b1aa086', '2910bec6d4de87e22be5119cef3c488d2ae50e2a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', 'f42b865e20e61a954239f421b42007236e671f19', 'd2fe8bdc0d638ce6f082b4a0cd08d999f4e9e8d3', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'e7bd06dd41a271e7e6ff2734fe0da466f18f3750'}",58,"{'295aca7669f54cdc746c595088693bb102855b9f', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', '41747cbdbed84762dfbfc305254c97021279dc6e', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'f7174c5c29c3904cc2d23f26be2b896a5bc715b4', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '498e003901f8287e89e5064477cd22dd47e49d61'}",12,"['Michael Mesarcik', 'E. Ranguelova', 'A. Boonstra', 'R. V. Nieuwpoort']",Michael Mesarcik,"Michael Mesarcik, E. Ranguelova, A. Boonstra, R. V. Nieuwpoort",20.689655172413794
9fcfebba36e1e6db85a00e55c33f83c560d4e61e,Weakly Supervised Detection of Marine Animals in High Resolution Aerial Images,2022-01-12,"Human activities in the sea, such as intensive fishing and exploitation of offshore wind farms, may impact negatively on the marine mega fauna. As an attempt to control such impacts, surveying, and tracking of marine animals are often performed on the sites where those activities take place. Nowadays, thank to high resolution cameras and to the development of machine learning techniques, tracking of wild animals can be performed remotely and the analysis of the acquired images can be automatized using state-of-the-art object detection models. However, most state-of-the-art detection methods require lots of annotated data to provide satisfactory results. Since analyzing thousands of images acquired during a flight survey can be a cumbersome and time consuming task, we focus in this article on the weakly supervised detection of marine animals. We propose a modification of the patch distribution modeling method (PaDiM), which is currently one of the state-of-the-art approaches for anomaly detection and localization for visual industrial inspection. In order to show its effectiveness and suitability for marine animal detection, we conduct a comparative evaluation of the proposed method against the original version, as well as other state-of-the-art approaches on two high-resolution marine animal image datasets. On both tested datasets, the proposed method yielded better F1 and recall scores (75% recall/41% precision, and 57% recall/60% precision, respectively) when trained on images known to contain no object of interest. This shows a great potential of the proposed approach to speed up the marine animal discovery in new flight surveys. Additionally, such a method could be adopted for bounding box proposals to perform faster and cheaper annotation within a fully-supervised detection framework.",https://www.semanticscholar.org/paper/9fcfebba36e1e6db85a00e55c33f83c560d4e61e,"{'585bf7bea8fa5267738bc465611d6f197e0f87dd', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '8fe466fbca2d741495e5293a181aabfe08829b56', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '7507babaa7e9dcd71e9abd287e30c7b2651fa16f', '44405c7049e2788d89287f40a7082759e731b3cf', '75309c1d5c01f78dc6def2623f561e3043fbd804', '3d62f4092f47a97a0e1740131de1bf07f97e6633', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', '59dfc716839617a314ec86686da2ecc0c6deedda', '90f72fbbe5f0a29e627db28999e01a30a9655bc6', '1c4e9156ca07705531e45960b7a919dc473abb51', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '71b7178df5d2b112d07e45038cb5637208659ff7', 'a62c5449a65c5590c93423ddfc76bd46d0469684', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'dbd5680b05443589121dfef3f094abd3e2b2d10a', '312ae526360f04b7807fa929797b183a78828adc', None, 'a75c9e95499d0846913e14b5278044aea18f8979', '87900e34846eaf18791a77e71cc07cfdc4a42df9', 'c1f750abf77f9f8a4ffcaf167f908d0638e6e66b', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '7990c98d56c5a2cbf12211fbe1c37918274ccd20', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'ec7be35f0348777d14e005a726a0de3114b3b9e0', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', '2a6f7f0d659c5f7dcd665064b71e7b751592c80e'}",38,"{'1ed9eaf526786704d81462c7f9960d9d3ef0cb84', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",6,"['P. Berg', 'D. S. Maia', 'M. Pham', 'S. Lefèvre']",P. Berg,"P. Berg, D. S. Maia, M. Pham, S. Lefèvre",15.789473684210526
a76fa4d6a75ecf4ca0ebf271365368525f680352,Visual structural inspection datasets,2022-07-01,,https://www.semanticscholar.org/paper/a76fa4d6a75ecf4ca0ebf271365368525f680352,"{'4675b6b4075ddf91df71cc0677c3b36df0ac46bc', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0a348c3607cf6908a46f4662433235c9c002df8a', '0b006c52cdb6f5ca7ebb6e8fef7e2eef084b69ef', '061afb6b8d44f4fc3f336fd3c1bd657cd1c9b677', 'b553e3e3fb3068a5290ade7ce70068c3ef9979a7', 'dd5646d25400deb3c7507793eb11544641e05aa7', 'd4f714834d1e830120c1c433cc2f6bcc07e6d66c', 'eab7943ae386f3ef99e06660af68cc98da68fe17', 'bf102cee3ed4fead258d5f7bb4e30c31ac34e78c', 'ff7bcaa4556cb13fc7bf03e477172493546172cd', '70053087f9ba6f75524f3c116813d40deb115dcc', 'ce711e917b9f6a4abd2d3555714a90a280c9fa44', '309efec8dee7fe8230fc33983a1ed1a5fefbf408', 'eb42cf88027de515750f230b23b1a057dc782108', 'f3b05b9db3cc4f509e3bce93e9ffad28fd39ee4f', 'ea4bbba761cfc483a664bd98ef90ec672efdcdaa', 'b1f88dae446b6fd23a4b664de96dc93886dc7af8', '2b7c208c34dd4a186f5d6d327bc94ec7397cc766', '9d2e91537ef822946a9be524a50127d3c32172b4', 'b118a429960f4c86d05b57a534f00c0a6125b2ae', 'f61f0383c3a6d88dd63c0dd38f7a740a57d872f8', 'fcc1063d75d6ad6de1f4f048e20a26145a870efb', '94d5cbe9fdd3b9f781c5f99799d036361a610491', '016f2f74a1d8b042d8b7d54dd1f11a614f676f96', '2941488b503121f9e8e5b09b7bdf28568b6e39e0', '16f29e8c05ed856af195283588b0307da2430f61', '35aeb27e14b6cb32e7505eb77d8863d180c1de0b', '3a85243fd616cec8eb61194fd5f9b84550c1f1df', 'b595b1f5f740f4b51d550f3a111b3ff865da030a', '12b22799537e1d20470af81883097b0ebf12635e', 'fa230c37ec094187fd4fdc9dd28fd4ac7e958aab', '4db1f653eb24b0b7e59f4815da571037d847b302', 'a4faeb68c39eda9fa87834a54d13b6b1e1d7d92b', 'f3b6935b279bc81ef4005a37fad1608228b30617', '471abf7b1aa551a82f87b110a405e2f6a5d01798', 'c09b54c9048b44fafd339d4724fb5bbb8ef589af', 'e7c866024467fa928ce2fbd2372917e138ecfcee', 'a78f8d0c1d6bf1b2a96ec2e50a8cc9cefbf6f8eb', '20d3c8710b03c31cc6cb86a6fd964478586c4e34', '109e820695e68f8d14e80e319cbeca271c34271e', '2ccf2cbc169167628abaca8e69f480d6a3137ab8', '068092d3d238f3da54cb03d22dc9724270dbe56c', '0c8094e734425b50950230ba4f238f24ad037932', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '8c9b773553a0187547364ee3b6142a04e02ed84f', '17c4fb4230851a54ae66f24ddc03c878bdaab91f', '9a5fccf14e84e200d21ecc7a965305f5840e19d6', '91ceeef577d0841c44fdabb54c0cbdee88788bb9', '9bfa1119a6ab551de51756a8b331654b94e5586f', '15a4e2a15f20ed77609a70fb268cbcfafa21df54', 'a66d3b34bd49eff21c39965a1debe555055ed32d', '003bf0cdc622b5e3a42d96ab799fb7f51226acfd', '682ebbb775df642261e7ef7ca72d7d4e7247dc7a', '69c30694a9e1cb73c71e0c57794388dc06a4ae0d', '0c80675351ac78af37b53436403b7bf4ed60bb4e', '4d3b047f645c68fd7f4bacf189964d4b5356f691', 'dbd854408fc3d321b2058ec510d7be438bd9d1c0', '4c753f5ab22fe05777dbef32d706fa029e0be1af', 'e8a5f27e7805f8de84ea008d59452ff864271696', '8a2005deba3f1cf9d35298a4b0d40dc2fb480bd5', 'c1b47d7a9520e8ba46047b9eb2d122c44d521743', '301e975080b0b2d703797abc780efd82306f435a', '61199b751fdbe43155a9dd36e2ab3741c7bdc94a', '3bc952ae352ecf9d173b4ce5295eed29bb18613c', '001a982346e40c8a8f4e670b5e76459432447b9d', '3dd02233f060bfe1973cda1e0eee25b762276208', '58c5db20f4b6ef23bda12d813c7014f0db3c234c', '0f389d6d3f1aed1748c086f4f212c3f309d7e547', '85b6fe85ff17f4e0b2dcc7d1f04b4a1bf490e330', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '9217e28b2273eb3b26e4e9b7b498b4661e6e09f5', 'bab9e71e13da27c6caa87cd677814839e9809f2c', '36df22f68f2e8b106b0be03f61b8ce2abfa92de3', '0c337400294b1f04dfdd73af1e4effe82ba75f4e', '84d0e29805235df433ee1bd74f44a6916dc2ef2f', 'e663e20b30a2fdb87af2a31938f99d0cdfb1c417', 'b1a69bb2350bdbea26be521d190efef92721de06', '117be3cc49f316466b3ce72948b24d25550940b5', '347e837b1aa03c9d17c69a522929000f0a0f0a51', 'd9f6c6f2121aad4af56e58e0214362b8bf54c781', '91afe1c3d707e7d2ab54080328a9851c3c26757c', '021fa253ebd9c5d78ee52b545a1ee915f0dafe27', '08cc923c0386cdc92630bcc3cb00a337a0d91212', 'e11f0ae5fb3fd2a299303286a8d4048ece51a255', '1c44a17065c0254656c6887f32bf40d2876d5996'}",86,{'b32be13cd0fcd516e8b859c36a02917f1a68ab9c'},1,"['Eric L Bianchi', 'M. Hebdon']",Eric L Bianchi,"Eric L Bianchi, M. Hebdon",1.1627906976744187
1c0165247ce1d56a9de7be50ca6c4a49f0db4a82,Self-Supervised Masking for Unsupervised Anomaly Detection and Localization,2022-05-13,"—Recently, anomaly detection and localization in multimedia data have received signiﬁcant attention among the machine learning community. In real-world applications such as medical diagnosis and industrial defect detection, anomalies only present in a fraction of the images. To extend the reconstruction- based anomaly detection architecture to the localized anomalies, we propose a self-supervised learning approach through random masking and then restoring , named Self-Supervised Masking (SSM) for unsupervised anomaly detection and localization. SSM not only enhances the training of the inpainting network but also leads to great improvement in the efﬁciency of mask prediction at inference. Through random masking, each image is augmented into a diverse set of training triplets, thus enabling the autoencoder to learn to reconstruct with masks of various sizes and shapes during training. To improve the efﬁciency and effectiveness of anomaly detection and localization at inference, we propose a novel progressive mask reﬁnement approach that progressively uncovers the normal regions and ﬁnally locates the anomalous regions. The proposed SSM method outperforms several state-of-the-arts for both anomaly detection and anomaly localization, achieving 98.3% AUC on Retinal-OCT and 93.9% AUC on MVTec AD, respectively.",https://www.semanticscholar.org/paper/1c0165247ce1d56a9de7be50ca6c4a49f0db4a82,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '3e0a7244028e303c94a33d824848d1a9555f4785', 'd100f625580dd6df123c69abff1d094e2d745613', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '5db790198b9acf4e5efe350acdd814238fcacaa7', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '580396c680951b7ff93defcac7cfe085dfe1814e', '6d3b00381c619912337c60897307322ba4edff3b', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '5b2193c44f2925807c5978a24da3381324969c40', 'cbb2fa7b7e55e0251ca79c2077d6f753f766d961', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '32323526b61685d007f4d2a62b23b8669e602fa8', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'd336c75d6f3b50d447cf5f59f413c94200f09bdb', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '4758baad6b22c61682e7f7182bb93723046f36f5', '2dd4b5e8633a5587ce2ebf73284134f21d1bc6a9', '8acbe90d5b852dadea7810345451a99608ee54c7', 'badbd3a3df684fc8f7032c4577fb92fb1a743243', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'd3b614f11969127a08447c41257b3a7b58766d18', None, '32bc9334ad0edaec29540320b9f00c9a7aab81f8', '41747cbdbed84762dfbfc305254c97021279dc6e', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '086015aa2c44bd2ebd95ab6a1a562e57177c7fa8', '9a679663be4981d99b79f28dc946ac24344935d6', '9ae92f2d70e5d88e28ea2ae540f9f50715f80285', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '616b246e332573af1f4859aa91440280774c183a', 'ec5d26aaf2e6902ca28effa0f94c9556571160b8', '599fd051c9438011ec5b581983c89e8922b4a5e6', '5a5a491cb632abc75eaec550c4fd7206949e628b', '6139ed57b3fe91915991897723aed6a98cd32f82', '364128bcce9836d60e685bb717b80f30e25092e0', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '5a7f8cf379b9786327b52bcf0cd386b4988877bd', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '19d13084ea644842e42802ec7aac2fb977ed7584', 'c9f86e77861771e53e4749f0def5e2b1a662afac', '6af440915b8a0718c93be1cf61905e41e620484a', 'e8a5f27e7805f8de84ea008d59452ff864271696', '109eef0f2319c6173b7cc22120254f01746ef77a', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '8381157eae4fbf8908d0312a9642f8e69e944449', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', 'f0c5991dbb130fa6b5de011cf7a04f6ed815ef68', '6f68ce1e03c56c186256dac689a21f6405ae8d96', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '88ece7e67fbc19ac180867221e65cf096e70ffbb', '01625cba9f8a783994377d4f35aa765242faab4f', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '136b780c7fb8fa8ed7306bcd251c691194add059', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '3b98c57895ecb5b4fe04a530c38087b88749154c', 'e858bcc487cea96695102db9bdafe3c5d4269d04', 'f21cbe7625d60b80bf622a7361931b36fc35a68e', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '941b0be328d6eb370121828acff3acf300e0745a', '5435a9ab36a308cef10bc725104e8f778ed3a328', '36653f8705b56e39642bcd123494eb680cd1636b', 'a997f1ecd85e1467d11252741d188fac8db22722', '91a73e9c6cbba422ee50e287f1bfa9ba30f6922b', 'c2b733a79db700b971327a58ef42699fe8a416aa', 'a7a54fd569c955cd639d34809d95fa485691bf4c', 'd743c1b674ae539ef387252b8400a8b06c3ecf20', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '67715ed6334a4c0d76e6552178b2f04d2b525081', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40'}",82,"{'4758baad6b22c61682e7f7182bb93723046f36f5', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd3b614f11969127a08447c41257b3a7b58766d18', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e'}",10,"['Chaoqin Huang', 'Qinwei Xu', 'Yanfeng Wang', 'Yu Wang', 'Ya Zhang']",Chaoqin Huang,"Chaoqin Huang, Qinwei Xu, Yanfeng Wang, Yu Wang, Ya Zhang",12.195121951219512
5048eb4319bdb22dc8932d1506045d3e27f64e5b,DOC3-Deep One Class Classification using Contradictions,2021-05-17,"This paper introduces the notion of learning from contradictions (a.k.a Universum learning) for deep one class classiﬁcation problems. We formalize this notion for the widely adopted one class large-margin loss (Sch¨olkopf et al., 2001), and propose the Deep One Class Classiﬁcation using Contradictions (DOC 3 ) algorithm. We show that learning from contradictions incurs lower generalization error by comparing the Empirical Rademacher Complexity (ERC) of DOC 3 against its traditional inductive learning counterpart. Our empirical results demonstrate the ef-ﬁcacy of DOC 3 compared to popular baseline algorithms on several real-life data sets.",https://www.semanticscholar.org/paper/5048eb4319bdb22dc8932d1506045d3e27f64e5b,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '27222787908c3a1c6fb6c4b5cb5ef8b2542f1b3c', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '4064696e69b0268003879c0bcae6527d3b786b85', '6bfc934c8a316230929ff1ea67a1777c8ccda26e', 'a9b4fc31e6c0253a8924d6fcd19c70c4ac6f3db2', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'da762b4908aa7570fc6880cadd20718986569afa', 'fa7cd1d209ca348710a0f017e26d278799265ed3', '8ff61b8e097ccdb784a35b466ba9e130c2502513', 'ab96c776f96e10f10d88ac5abbe9335afe935c81', 'b110ba174df21a23a9521731d4181261ca5860ed', '00a1077d298f2917d764eb729ab1bc86af3bd241', '0bc1084d3dcb1f1198aee488a3bcdda82e62cf63', '94559c249d204110296c39ed4af2042cc4468e68', 'a58cb3f7efaecf9005a853bb503575f76f80b84f', '02480b5d060eb4cb2228ac7e824fda22b29c3e9e', '295aca7669f54cdc746c595088693bb102855b9f', 'af34fd2d34dc2d3ca9c731f456c164473a12cef1', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '04513c7c0b3a63fde81a996dae064a28d453c17a', '46d18d6dae5e25836670a9efe34daef8f201e3c1', '3956fb1ad99346cf2022baf217e7985db25eb5ce', '154df96b95e8b9635771442244fe48b125933bb1', '009f35c0e453f2435efd8d8ef8086b76b294967a', '6af440915b8a0718c93be1cf61905e41e620484a', '6ce0ff082da032789b16a040c3137585556524c7', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a0f9f3c338dd84b054dabcbd50b725f2b3609ad9', '49dff3a5207474b13e4a04617356c54b39aa5a72', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'b9a81ca3b8fc0ca0fab3ef4dad489f94d8dd2550', None, 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', '40f941682d98f7472215dcfe27e8ee796d3e2bdd', 'a7c828184693a453a6c2867dee233ed054b2012e', 'b27033b100dd92e34624c261ef80a6bd7f9aaaf1', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '536cd640a751a97c69dca07937296ccfcb024744', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', '3177da1c2dcab4374c8048e63f3d21c279683b77', 'a8db789522b9375396bd91de631342740ba19a12', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'f4156a05a47fdeda30638e10954d3674cc056ab6', 'c079f1cf7ebc9d8b0ab2df632e650da6d489650c', 'c9d1cab147454af4e57a280d8d38a88b6c1ffb8a', 'f9cc7e2c400b4ab509e47d158017cd1cbf526792', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', 'b993cfb0321fc546ca6265dcd7859c0c72e2ee25', '1d033b30f38642e4b6dd146bb8b464bfb58aad96', '46200b99c40e8586c8a0f588488ab6414119fb28'}",58,"{'295aca7669f54cdc746c595088693bb102855b9f', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '363c81a08858df8dd7d1bde79c6e002e3b19f900', 'ab96c776f96e10f10d88ac5abbe9335afe935c81'}",5,"['S. Dhar', 'Bernardo Gonzalez Torres']",S. Dhar,"S. Dhar, Bernardo Gonzalez Torres",8.620689655172415
1f528877c4d8d5df3b3abbfa64379677d451956b,Attention Guided Anomaly Detection and Localization in Images,2019-11-19,"Anomaly detection and localization is a popular computer vision problem involving detecting anomalous images and localizing anomalies within them. However, this task is challenging due to the small sample size and pixel coverage of the anomaly in real-world scenarios. Prior works need to use anomalous training images to compute a threshold to detect and localize anomalies. To remove this need, we propose Convolutional Adversarial Variational autoencoder with Guided Attention (CAVGA), which localizes the anomaly with a convolutional latent variable to preserve the spatial information. In the unsupervised setting, we propose an attention expansion loss, where we encourage CAVGA to focus on all normal regions in the image without using any anomalous training image. Furthermore, using only 2% anomalous images in the weakly supervised setting we propose a complementary guided attention loss, where we encourage the normal attention to focus on all normal regions while minimizing the regions covered by the anomalous attention in the normal image. CAVGA outperforms the state-of-the-art (SOTA) anomaly detection methods on the MNIST, CIFAR10, Fashion-MNIST, MVTec Anomaly Detection (MVTAD), and modified ShanghaiTech Campus (mSTC) datasets. CAVGA also outperforms the SOTA anomaly localization methods on the MVTAD and mSTC datasets.",https://www.semanticscholar.org/paper/1f528877c4d8d5df3b3abbfa64379677d451956b,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '8388f1be26329fa45e5807e968a641ce170ea078', '37a18be8c599b781cc28b6a62d8f11e8a6a75169', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'e8b8a7778ace2a02f8db6fe321a54520c6b283ca', 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', '94bbc4ea271c918705876b60d98d227a0ab55a43', 'f7b032a4df721d4ed2bab97f6acd33d62477b7a5', '1856809b8bcd0ba7b2c294201718018ead419cb7', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'e399a626ba21fafb19b3661603ec9724058e951b', '2622d2467f19bc60427f8ea495515e7da82316c9', '2f95858858ad0c811738dee8ae921b81de94a961', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '7800c02a555ac0e80f41c17754191efe418c8127', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', 'bd8f77b7d3b9d272f7a68defc1412f73e5ac3135', '410ad524c2d9b0f833e2aee87a35dc2efc9c8b01', '35a48d7099f2fd8c40e09de61e509ea0a846cbef', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '8ad9e4b45d9750a3644dbe037c45313bd8683a45', '1695e0392c3ad1c867f8518eb43fcccf815718e6', 'b4cfbefc7cc3217c133c75d48ace1cddc078d870', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'f5b0d51ca54fd1b7268486393679dd612d482f64', '22aab110058ebbd198edb1f1e7b4f69fb13c0613', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'ec679c45e88fa25fec32c30bc7c1b7d7fd0facec', 'a90226c41b79f8b06007609f39f82757073641e2'}",42,set(),0,"['Shashanka Venkataramanan', 'Kuan-Chuan Peng', 'Rajat Vikram Singh', 'Abhijit Mahalanobis']",Shashanka Venkataramanan,"Shashanka Venkataramanan, Kuan-Chuan Peng, Rajat Vikram Singh, Abhijit Mahalanobis",0.0
9103e1cc46c00fac68a6350797cb7695a68e74c4,Explaining the Predictions of Unsupervised Learning Models,,,https://www.semanticscholar.org/paper/9103e1cc46c00fac68a6350797cb7695a68e74c4,"{'d5d7b3c75c5a7bbc605236e7c722ecfb2cf8824e', 'c9a6c7bfe831f2b154deac4409c35633c63ef326', '101e5c392c4658eb93aa385c2875c1b22bafa63d', '26dd2c208e4ead7e6632591fb1a469694a235c6f', '442e10a3c6640ded9408622005e3c2a8906ce4c2', '0e80b93160f6a3c07c16da605880d335ca6b1363', '8f04029d1d83f41eaebf5a216ebecf2a61ff6dc0', '9360e5ce9c98166bb179ad479a9d2919ff13d022', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '29069976eb7f828de91ed243cd12fd99fef56d94', 'aa541b4da41869a35f8a6f1ea18c5f93cea0d9e1', 'e46e683a1167990f8778335b4536c27b624be0cf', '6df11b0bb0244d4d36e8955436067cc5d19734fa', '00a1077d298f2917d764eb729ab1bc86af3bd241', '11ea864eca24af40f3b48ee297c55f156c1eca3c', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'd4bbcc842f22547eaf5884251eaa68251895dccb', 'f7325d232c7ac7d2daaf6605377058db5b5b83cc', 'fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5', 'a14d0102e05b34fb0caec09013f0f9ce0f0fa26d', '64f260cac1a9b2240b748b8106d2339f25b98565', 'b034b5769ab94acf9fb8ae48c7edb560a300bb63', '1a2a770d23b4a171fa81de62a78a3deb0588f238', '17a273bbd4448083b01b5a9389b3c37f5425aac0', 'ac84f464aa17bfabe676646ffe33941ef01d2402', '4f51a64793d3b2a60e9e5846c31dae023cf5c69a', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', '20f69cc41c87b8abdf36761c623d65713daeab3b', '2f66d008f37665df60aea2e8fa1c3d7265bd9bce', '9f539ed852e7b64b2e62ec090fdaaf633cce28a2', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '7a59fde27461a3ef4a21a249cc403d0d96e4a0d7', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '48f9a48aa5b1230b05a443d2d531e6441a541686', '5091316bb1c6db6c6a813f4391911a5c311fdfe0', '43a4011c51b2e7fb4512a2ef434536a62f849962', '7715bb1070691455d1fcfc6346ff458dbca77b2c', 'e1ce8d00729f9e61eeb315f3cbd7b5354706adbd', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e720172b00149854d6f6adfbfc54c31049cefc1c', 'eb42cf88027de515750f230b23b1a057dc782108', 'f302e136c41db5de1d624412f68c9174cf7ae8be', 'ef9bbc83dea84df3711de01de56f2b7f91bae068', '69115684eb15614b1219366ef93ddc23682b1cac', 'c02dfd94b11933093c797c362e2f8f6a3b9b8012', '0f84a81f431b18a78bd97f59ed4b9d8eda390970', 'dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71', '6fd9202d20223de321d744e05bc7b197a98e6c1a', '4e6238c8613b5b81f81552939bce33296aedfbfe', 'a3d1937f3416ac7281adf22bc3d9c5cb3e007b0a', 'b94c7ff9532ab26c3aedbee3988ec4c7a237c173', '4c2420d8960ef73ec86838ac26be00b82555575d', '0e1f153576c7f9f2628cdd34a1067c4d26bdc096'}",54,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972'}",3,"['G. Montavon', 'Jacob R. Kauffmann', 'W. Samek', 'Klaus-Robert Müller']",G. Montavon,"G. Montavon, Jacob R. Kauffmann, W. Samek, Klaus-Robert Müller",5.555555555555555
c8c70d1a201f41af78b4e3f11810d0f8c6c452b3,A Benchmark for Anomaly Segmentation,2019-11-25,"Detecting out-of-distribution examples is important for safety-critical machine learning applications such as self-driving vehicles. However, existing research mainly focuses on small-scale images where the whole image is considered anomalous. We propose to segment only the anomalous regions within an image, and hence we introduce the Combined Anomalous Object Segmentation benchmark for the more realistic task of large-scale anomaly segmentation. Our benchmark combines two novel datasets for anomaly segmentation that incorporate both realism and anomaly diversity. Using both real images and those from a simulated driving environment, we ensure the background context and a wide variety of anomalous objects are naturally integrated, unlike before. Additionally, we improve out-of-distribution detectors on large-scale multi-class datasets and introduce detectors for the previously unexplored setting of multi-label out-of-distribution detection. These novel baselines along with our anomaly segmentation benchmark open the door to further research in large-scale out-of-distribution detection and segmentation.",https://www.semanticscholar.org/paper/c8c70d1a201f41af78b4e3f11810d0f8c6c452b3,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '1b7ef1a7df32d8d38efbb7aca9a9b2468d0da224', 'afc4cc092f990644ff7a11dc7ab60519920cbc9d', '106150b707a31f0825bdae44eca4139b715547d6', 'eb73aa1b023be05b5ed5e88bbf92c9a787af3671', 'e525ba29497bab9b530ea7b056dd0128be22c48a', '927ee108115e03cc14c70e567b044e66423fb54b', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'c8c494ee5488fe20e0aa01bddf3fc4632086d654', '07e559fb8d929e077bb1028e38599f4c1086b345', '431ba9fae8fccad1665979d455c6307786e47318', '547c854985629cfa9404a5ba8ca29367b5f8c25f', '4dcdae25a5e33682953f0853ee4cf7ca93be58a9', '10a83f9a07c803ceef8e09e12ad606dc74ea76b8', '2da694d7f494265a8193f17dfc492c577ad4db1e', '36653f8705b56e39642bcd123494eb680cd1636b', 'f69f237073ef04043fdbd5bb6844b5b2da8e0930', '71b7178df5d2b112d07e45038cb5637208659ff7', 'e5243a084492250f1d662897a65016df56c72f51', '95cab693b3beb905c95f776e89e41b11c3f55d70', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '229e105fd4d34815e476702dd5ca4362943c475d', '6a2ed19ac684022aa3186887cd4893484ab8f80c', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '6ff2a434578ff2746b9283e45abf296887f48a2d', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '82635fb63640ae95f90ee9bdc07832eb461ca881', '18c125ce0f64e85577f7d30132cf0e92ec664bf4', 'a7c828184693a453a6c2867dee233ed054b2012e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '7cd316505f52aa337ef8a2aff10bc6bf1df561d0', 'f986968735459e789890f24b6b277b0920a9725d', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6', '0ec48ac86456cea3d6d6172ca81ef68e98b21a61', '1031a69923b80ad01cf3fbb703d10757a80e699b', '2daa90492b5509b33567eaf49360926f0e79f286', 'b9a2361c146d977040aeab96562e6b9dfd3e59fa', '032db195efd97fe2bcd20c4ad04628c70ff4e79c', '6f321e268990e3e1a792d4bcf829600caab41e1e', 'd2c733e34d48784a37d717fe43d9e93277a8c53e'}",43,{'10a83f9a07c803ceef8e09e12ad606dc74ea76b8'},1,"['Dan Hendrycks', 'Steven Basart', 'Mantas Mazeika', 'Mohammadreza Mostajabi', 'J. Steinhardt', 'D. Song']",Dan Hendrycks,"Dan Hendrycks, Steven Basart, Mantas Mazeika, Mohammadreza Mostajabi, J. Steinhardt, D. Song",2.3255813953488373
23ae911ceb9134f3a27719faab5d5d297a2f4e8e,History-based Anomaly Detector: an Adversarial Approach to Anomaly Detection,2019-12-26,,https://www.semanticscholar.org/paper/23ae911ceb9134f3a27719faab5d5d297a2f4e8e,"{'02227c94dd41fe0b439e050d377b0beb5d427cda', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'afc4cc092f990644ff7a11dc7ab60519920cbc9d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '7d2a45b6375ac996efc3b6d811ecb3fc3a2dd405', 'afc11a384ed298f2980f6a1547ef0aa3cb5573c6', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '77e08e09f3a41c43b4674434d3ea278d91b2480f', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '1322719978980a831e1aee78aa80a141379c44dd', '98fa8f7b28f43830a22612be53bb393cf421bbc1', '9acc51b06f54b07836fad4cc24633187dc21317f', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'a03bda078490e8ee991a1f86b53f27df7cf93a14', '4d8abae45a5492ed2399fd5e25eeade8ac0bfa0f', 'e0641f1d83bd66238de1c085cdbfa495e7154ad3', 'c8924e3265e3f16af3177e619cf68a5ef764442f', '785daff3495b45fb1f78e375a86779d02ad4afd3', '0bdd74925d662a78efdf130d953dff97a131d12a', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '53599f3748b73f5d3bbddab646905b5b8e7d3210', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '4fe30c04f2cc9176da7da34833a682d22a9e0d0b', '9d5290fadb7625862a966e0330bd0f9e111fc99d', '3d069f1af4ef6ccdebe256d038a17270f02ef2a1', '21b786b3f870fc7fa247c143aa41de88b1fc6141', 'ca51e00b0314a2b3b0b1d5ffabe7b15a61c8a733', '6507909a8f77c88144c3a67b9336bd1c85e84cac', 'a57b50cfa4136171ef04c3ef9ed8d08acfe6ea9e', 'f4d38c99b8064efba89adddcfac91c85b9e687e9', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'ca73ce2623aa93bf32b88f7fb998af9576aed20f', '5d90f06bb70a0a3dced62413346235c02b1aa086', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '84af0bbe339c1adbc9d075dee99b9d4f86a186c5', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1db6e3078597386ac4222ba6c3f4f61b61f53539', '19b14bc5ca655db8b0a60eb06c6bfe681dfd30f9', '61a697e0ca3a000b0067ccc2b4b400c3cf2575a6', 'db20d81d40243d66ff90f11b5c6f058d43d3701f', '33ac2a87d1a0677bd8895ef3cd1c14b8a2bd5af9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '0936352b78a52bc5d2b5e3f04233efc56664af51', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",51,set(),0,"['Pierrick Chatillon', 'C. Ballester']",Pierrick Chatillon,"Pierrick Chatillon, C. Ballester",0.0
4b182347b943548fe6479393bb24adac21740675,Registration based Few-Shot Anomaly Detection,2022-07-15,". This paper considers few-shot anomaly detection (FSAD), a practical yet under-studied setting for anomaly detection (AD), where only a limited number of normal images are provided for each category at training. So far, existing FSAD studies follow the one-model-per-category learning paradigm used for standard AD, and the inter-category com-monality has not been explored. Inspired by how humans detect anomalies, i.e., comparing an image in question to normal images, we here leverage registration, an image alignment task that is inherently generalizable across categories, as the proxy task, to train a category-agnostic anomaly detection model. During testing, the anomalies are identified by comparing the registered features of the test image and its corresponding support (normal) images. As far as we know, this is the first FSAD method that trains a single generalizable model and requires no re-training or parameter fine-tuning for new categories. Experimental results have shown that the proposed method outperforms the state-of-the-art FSAD methods by 3%-8% in AUC on the MVTec and MPDD benchmarks. Source code is available at: https://github.com/MediaBrain-SJTU/RegAD",https://www.semanticscholar.org/paper/4b182347b943548fe6479393bb24adac21740675,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd5b692f690207d59fd21b19c4a510fd7c3f6caa8', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '689c97982f0ef6d8b0df3ec33a3abe29b8f97c1f', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '8e180ffb0c4bfe4db41a245637042a28fc98d891', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '99c8ada76d6891259d1b73dbc2cd9021e00d3ca4', 'e858bcc487cea96695102db9bdafe3c5d4269d04', '182d11020bf2842f135f1ec1dcac20237e0dc8b7', '62b77e5cb85fc61b84edd532f6d65714be152596', '39ca5df5a480178fe0308fb3fc6eed30838af71e', '5a7f8cf379b9786327b52bcf0cd386b4988877bd', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '941b0be328d6eb370121828acff3acf300e0745a', '507a0be8e4b33b8578f69e999bf6fd009422e1c6', 'b41b23ef5a34c83f2bf9d4a9e98f8ed065f61918', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'b1464ca857593c049873421db2f37bf2d0ff676d', '997dc5d9a058753f034422afe7bd0cc0b8ad808b', '1c46943103bd7b7a2c7be86859995a4144d1938b', '1d0ded7af9059198d8bbb49ca1674f05b9018919', '1c0165247ce1d56a9de7be50ca6c4a49f0db4a82', 'c889d6f98e6d79b89c3a6adf8a921f88fa6ba518', '29c887794eed2ca9462638ff853e6fe1ab91d5d8', '6af440915b8a0718c93be1cf61905e41e620484a', 'bfe284e4338e62f0a61bb33398353efd687f206f', '55ba9652caea8e5c12408085fcb32b0eb7862c71', 'a1068be6f66ae6a56b7dffbdfabc73b253de0ab3', '0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d', '580396c680951b7ff93defcac7cfe085dfe1814e', 'fe87ea16d5eb1c7509da9a0314bbf4c7b0676506', 'c269858a7bb34e8350f2442ccf37797856ae9bca', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '48c6d0d7e3fabf4692bd03fc8b7263e55ee1d584', '8381157eae4fbf8908d0312a9642f8e69e944449', 'f0c5991dbb130fa6b5de011cf7a04f6ed815ef68', 'e5349e937545d3f3d18d254bd21d695e7350ea8e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",47,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '1c0165247ce1d56a9de7be50ca6c4a49f0db4a82', '182d11020bf2842f135f1ec1dcac20237e0dc8b7', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '8e180ffb0c4bfe4db41a245637042a28fc98d891', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'e5349e937545d3f3d18d254bd21d695e7350ea8e', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",12,"['Chaoqin Huang', 'Haoyan Guan', 'Aofan Jiang', 'Ya Zhang', 'Michael W. Spratling', 'Yanfeng Wang']",Chaoqin Huang,"Chaoqin Huang, Haoyan Guan, Aofan Jiang, Ya Zhang, Michael W. Spratling, Yanfeng Wang",25.53191489361702
43e15ca0c27b7e2e6137393b2e56c8587fc08d6d,Unsupervised Industrial Anomaly Detection via Pattern Generative and Contrastive Networks,2022-07-20,"—It is hard to collect enough flaw images for training deep learning network in industrial production. Therefore, existing industrial anomaly detection methods prefer to use CNN-based unsupervised detection and localization network to achieve this task. However, these methods always fail when there are varieties happened in new signals since traditional end-to-end networks suffer barriers of fitting nonlinear model in high-dimensional space. Moreover, they have a memory library by clustering the feature of normal images essentially, which cause it is not robust to texture change. To this end, we propose the Vision Transformer based (VIT-based) unsupervised anomaly detection network. It utilizes a hierarchical task learning and human experience to enhance its interpretability. Our network consists of pattern generation and comparison networks. Pattern generation network uses two VIT-based encoder modules to extract the feature of two consecutive image patches, then uses VIT-based decoder module to learn the human designed style of these features and predict the third image patch. After this, we use the Siamese-based network to compute the similarity of the generation image patch and original image patch. Finally, we refine the anomaly localization by the bi-directional inference strategy. Comparison experiments on public dataset MVTec dataset show our method achieves 99.8% AUC, which surpasses previous state-of-the-art methods. In addition, we give a qualitative illustration on our own leather and cloth datasets. The accurate segment results strongly prove the accuracy of our method in anomaly detection. task learning that include pattern generation and comparison stages. The pattern generation network tries to learn the regulation of texture and generate an accurate and reliable image, which makes it robust to texture change. Here we select the state-of-the-art VIT-based network since it pays more attention to global feature, which makes the generative image have an excellent performance on recovering the texture details. The next pattern comparison network tries to find out the differences and locate the anomaly position by a Siamese network [9, 10]. We observe that the",https://www.semanticscholar.org/paper/43e15ca0c27b7e2e6137393b2e56c8587fc08d6d,"{'061d6d5f3df0db70b12f9e90bec327e19b7259c1', 'f8433b595a8fb92b0f23655215ec12bf5f965d1a', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '23ca99cc5b24ff959e195879413fdf66f26e8373', 'd84c62734eb07141495421da1fdf9ed211ea4f93', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'c8b25fab5608c3e033d34b4483ec47e68ba109b7', '4d376d6978dad0374edfa6709c9556b42d3594d3', 'ea7cfe7f2340584cbe653da6077ee7c213e49b92', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'adcf9bdac7f05ba2bc003256a6794974aa571e0c', 'e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60', '6e36fc1485ee735796a6ac39ff8155bb2c4f7017', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0', 'de9949331c81cc8697d48dfd1b9f54d604a7d85a', 'dffe0f7cd102210333ef533761753a909aa03294', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '69d7086300e7f5322c06f2f242a565b3a182efb5', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', '6351ebb4a3287f5f3e1273464b3b91e5df5a16d7', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",29,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'd84c62734eb07141495421da1fdf9ed211ea4f93', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",10,"['Jianfeng Huang', 'Chenyang Li', 'Yimin Lin', 'Shiguo Lian']",Jianfeng Huang,"Jianfeng Huang, Chenyang Li, Yimin Lin, Shiguo Lian",34.48275862068966
8856da785a44be3d674f388814b1771f1dce462f,Reproducibility report: Towards Visually Explaining Variational Autoencoders,,"The paper by Liu et al. [7] claims to develop a new technique that is capable of visually explaining Variational Autoen3 coders (VAEs). Additionally, these explanation maps can support simple models to get state-of-the-art performance 4 in anomaly detection and localization tasks. Another claim they make is that using these attention maps as trainable 5 constraints leads to improved latent space disentanglement [7]. The validity of these claims will be tested by reproducing 6 the reported experiments and comparing the outcomes with the ones of Liu et al [7]. 7",https://www.semanticscholar.org/paper/8856da785a44be3d674f388814b1771f1dce462f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '4544bfe6ca04b540bf55e481b2d96b3f3bb99d5c', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '9f1ac1a1f79e8a829d0acf3a3bf35ed1512d3e53', 'e3b5c2fecec38ab3a7139fcc45814073f1369248', 'd19356ce442d9c04625b3a253f370feaf00ea6a0', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '62b77e5cb85fc61b84edd532f6d65714be152596', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'd43c4fcb5469c495ad74861dcc65246b00204904', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '497d645d7b81dd0a6e8db2deccd77097ac94bc4e', 'aae932cf9c2434f52b03991fcab050a61a960d48', None, '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '027b9a21d6ee849b3268c45df10a44cc3d7b7c24', 'a90226c41b79f8b06007609f39f82757073641e2', '04541599accc47d8174f63345ce9c987ef21685b'}",21,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb'}",6,['Daisy van den Berg'],Daisy van den Berg,Daisy van den Berg,28.571428571428573
fa919ac8e19c997c46ad6d9362f243ae0d34a7df,A Survey of Visual Sensory Anomaly Detection,2022-02-14,"Visual sensory anomaly detection (AD) is an essential problem in computer vision, which is gaining momentum recently thanks to the development of AI for good. Compared with semantic anomaly detection which detects anomaly at the label level (semantic shift), visual sensory AD detects the abnormal part of the sample (covariate shift). However, no thorough review has been provided to summarize this area for the computer vision community. In this survey, we are the first one to provide a comprehensive review of visual sensory AD and category into three levels according to the form of anomalies. Furthermore, we classify each kind of anomaly according to the level of supervision. Finally, we summarize the challenges and provide open directions for this community. All resources are available at https://github.com/M-3LAB/awesomevisual-sensory-anomaly-detection.",https://www.semanticscholar.org/paper/fa919ac8e19c997c46ad6d9362f243ae0d34a7df,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '6ec00ff233c19b47ef44dd57cdb22a7385586c0c', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'babd88f02ff8d131f1907785fc6fd0ff2da4a1e0', '71161727c75b4ad325158b47ca5560b8c3fb8547', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'a75eda54cf0cbf07c042551cf1bdc084f882547e', '927ee108115e03cc14c70e567b044e66423fb54b', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '232b26f231122f6332d66244e5ad61d8225312a2', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '799cad8f31b0908354c3802e83f2daf3025a3ad1', '7c75203739f5f89e109b11144d170d4d3f2a6abc', '083faacdad8283a28f4bb13d76f966fd89c1c5d8', '820f81f4263ad84b581e2b0feec563db0c64ff9b', '5da4eb1135d5827ce30e099bda377a19f3a52730', '968e91c7b6948bbe4abcb85467cec8b623d35940', 'b44313836f435c8c774f9123cc29a38ad8deb7bd', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '50e84132a1e405fd04ec59a72093ba30d9a74281', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'c6af93925826c0c918f6aed7261c62f6ba5ed6df', '67f2d17418e6f4a147aa8b5a5006a47da227faf7', 'f4327b978dec52f16b089c222c43543f8ecf4717', 'c0731e3d9dc5450901ca2a0365f53350aedfef09', 'b1464ca857593c049873421db2f37bf2d0ff676d', '0945840c6ca76f2a011b460581ce39072585b4af', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', '967af3930617d1ce227fb769400b57c63dc71aec', '5ce94aa26436bbef8c2eaf3bd995a67c0f344c93', '6e703183e0069bd973066b01cb75c11aaa70f9f8', 'ca6b11604b05fe9f84ff8f170b899839625a9246', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'd95e39ecf1c9041c21b751f6b16babf97805f517', 'c0df4a52eff06bcd3a1c079e540d24b3442fbe95', None, '4b5279eee26c4a4a88351a599b740be0a071672f', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '7768f83d396d68a917caf525c82f6de756884be6', '1ef28e214b28baf4b4079a2752e6bef208a4a277', '41747cbdbed84762dfbfc305254c97021279dc6e', 'ce05ebc31e7aa8e4152673bb240b9f8d27ebea21', '982b88429d0907eeea3e80eb09c949096c50d20c', 'abfab930a183a809b93993456ec8ca7e2478033f', 'cf122c84af8c85e15c3dffaca4069dd455b56a1e', '008f12ade9837a018fe93d6ba019ae66aefd3987', '8ee35ed698527d9695c872e3b76715fec4ef69ad', 'aeb4b2edb14b682da4b216a7fad3f4155c7324fb', 'bff013da42d934d513ea186ba2e772a68d034586', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '3adcfd254b271bcc2fb7e2a62d750db17e6c2c08'}",53,"{'820f81f4263ad84b581e2b0feec563db0c64ff9b', '6ec00ff233c19b47ef44dd57cdb22a7385586c0c', 'cf122c84af8c85e15c3dffaca4069dd455b56a1e', '5da4eb1135d5827ce30e099bda377a19f3a52730', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '93040f8a5d10e8fde279e18d353aa3dca2873900', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'b1464ca857593c049873421db2f37bf2d0ff676d', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e'}",13,"['Xi Jiang', 'Guoyang Xie', 'Jinbao Wang', 'Yong Liu', 'Chengjie Wang', 'F. Zheng', 'Yaochu Jin']",Xi Jiang,"Xi Jiang, Guoyang Xie, Jinbao Wang, Yong Liu, Chengjie Wang, F. Zheng, Yaochu Jin",24.528301886792452
206c2e79b5f1b4541b85f47517666961ed49500e,Improved anomaly detection by training an autoencoder with skip connections on images corrupted with Stain-shaped noise,2020-08-29,"In industrial vision, the anomaly detection problem can be addressed with an autoencoder trained to map an arbitrary image, i.e. with or without any defect, to a clean image, i.e. without any defect. In this approach, anomaly detection relies conventionally on the reconstruction residual or, alternatively, on the reconstruction uncertainty. To improve the sharpness of the reconstruction, we consider an autoencoder architecture with skip connections. In the common scenario where only clean images are available for training, we propose to corrupt them with a synthetic noise model to prevent the convergence of the network towards the identity mapping, and introduce an original Stain noise model for that purpose. We show that this model favors the reconstruction of clean images from arbitrary real-world images, regardless of the actual defects appearance. In addition to demonstrating the relevance of our approach, our validation provides the first consistent assessment of reconstruction-based methods, by comparing their performance over the MVTec AD dataset [1], both for pixel- and image-wise anomaly detection. Our implementation is available at https://github.com/anncollin/AnomalyDetection-Keras.",https://www.semanticscholar.org/paper/206c2e79b5f1b4541b85f47517666961ed49500e,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2788a2461ed0067e2f7aaa63c449a24a237ec341', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '8388f1be26329fa45e5807e968a641ce170ea078', '9acc51b06f54b07836fad4cc24633187dc21317f', 'a9e438c1e66917379509165fc40f335514870b56', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '3443f018ad37ac486254d574918363b2fd7552c7', '5435a9ab36a308cef10bc725104e8f778ed3a328', '90e4f12fa8fb126d0f416c8b61bfb5f73f8b7b74', '25757e7819eeb8829d3524474f973b79befd7b59', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '10f8d1106e49fa07c1dab8bd200e76896ee9dd13', None, 'ff7bcaa4556cb13fc7bf03e477172493546172cd', 'c09a4d90754628015c311e9c51f4b3ab888c796e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', '401ec2881b20ce7d6dc07c274a1d8f821d4c3841', '2a417a16473e2bcb1c98cd7814bc106760925e60', '572bdf59c34df16c1ade08590001f1b106cdf6b3', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",28,"{'d9d7ab13ce305ccee309c989a2341d72b1252070', 'e021d59638966a6fbb36854cc2cf1045de7a62d2'}",2,"['Anne Collin', 'C. D. Vleeschouwer']",Anne Collin,"Anne Collin, C. D. Vleeschouwer",7.142857142857143
2c3024d9d6a73f75c9963be4376d4c0f1787425b,An Empirical Investigation of 3D Anomaly Detection and Segmentation,2022-03-10,"Anomaly detection and segmentation in images has made tremendous progress in recent years while 3D information has often been ignored. The objective of this paper is to further understand the benefit and role of 3D as opposed to color in image anomaly detection. Our study begins by presenting a surprising finding: standard color-only anomaly segmentation methods, when applied to 3D datasets, significantly outperform all current methods. On the other hand, we observe that color-only methods are insufficient for images containing geometric anomalies where shape cannot be unambiguously inferred from 2D. This suggests that better 3D methods are needed. We investigate different representations for 3D anomaly detection and discover that handcrafted orientation-invariant representations are unreasonably effective on this task. We uncover a simple 3D-only method that outperforms all recent approaches while not using deep learning, external pretraining datasets, or color information. As the 3D-only method cannot detect color and texture anomalies, we combine it with 2D color features, granting us the best current results by a large margin (Pixel-wise ROCAUC: 99.2%, PRO: 95.9% on MVTec 3D-AD). We conclude by discussing future challenges for 3D anomaly detection and segmentation.",https://www.semanticscholar.org/paper/2c3024d9d6a73f75c9963be4376d4c0f1787425b,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '940dd2fa074ad97d5e8efa7e867b1f4460cfb8d5', '732c21998e251d64cd58b6a86886ee5907efeaa5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'b73e2d40da901ad3da3813670a51c52803d7af7e', 'db787640c9b42416ff8d7015546e667e58267177', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'e52e37cd91366f07df1f98e88f87010f494dd16e', '348a56827bc988dca0100e53c1a33797266e4406', '00a1077d298f2917d764eb729ab1bc86af3bd241', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', '5da4eb1135d5827ce30e099bda377a19f3a52730', '94559c249d204110296c39ed4af2042cc4468e68', '1c4e9156ca07705531e45960b7a919dc473abb51', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '2880ac931c11176aee6d42a7e7bb0703aacde3f9', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '5c8fe9a0412a078e30eb7e5eeb0068655b673e86', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'be49dbac8e395dba3e8f918924ffe4a55dec34ca', '1fbbe6fcf6465bab87b9ae55bc5fd23c528f24b9', '278c9a78d4505cfaf6b709df364dbd1206a017c1', '48ddd9101a90fe65e3061de69626741b843ff5e4', '6af440915b8a0718c93be1cf61905e41e620484a', '7c8a51d04522496c43db68f2582efd45eaf59fea', 'cdd553c54d5769ec218a8ea921e27144a6b1aadb', 'fe1b412ce7a4a36664734c4cad97b939b6ea6015', '4cab9c4b571761203ed4c3a4c5a07dd615f57a91', '41747cbdbed84762dfbfc305254c97021279dc6e', 'cd382609f0029aae042e91a5a46b3dc2ba58a321', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '108291a9ac15c5384f4a55f0b6b7e89a1dbe40d8', '4d39ee7cca8fedf792570724255a4357aa41dbf8', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '6dbc8145124d338a96ee59bc745f0bbce1f00c76', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",47,"{'5da4eb1135d5827ce30e099bda377a19f3a52730', '41747cbdbed84762dfbfc305254c97021279dc6e', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', 'cd382609f0029aae042e91a5a46b3dc2ba58a321', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",11,"['Eli K. Horwitz', 'Yedid Hoshen']",Eli K. Horwitz,"Eli K. Horwitz, Yedid Hoshen",23.404255319148938
77e4a693fb36adc7596afe74b5b8686599a4c800,SsaA: A Self-supervised auto-Annotation System for Online Visual Inspection and Manufacturing Automation,2022-08-08,"Recent trends in cloud computing technology ef-fectively boosted the application of visual inspection. However, most of the available systems work in a human-in-the-loop manner and can not provide long-term support to the online application. To make a step forward, this paper outlines an automatic annotation system called SsaA, working in a self-supervised learning manner, for continuously making the online visual inspection in the manufacturing automation scenarios. Beneﬁt from the self-supervised learning, SsaA is effective to estab-lish a visual inspection application for the whole life-cycle of manufacturing. In the early stage, with only the anomaly-free data, the unsupervised algorithms are adopted to process the pretext task and generate coarse labels for the following data. Then supervised algorithms are trained for the downstream task. With user-friendly web-based inter-faces, SsaA is very convenient to integrate and de-ploy both of the unsupervised and supervised algorithms. So far, the SsaA system has been adopted for some real-life industrial applications.",https://www.semanticscholar.org/paper/77e4a693fb36adc7596afe74b5b8686599a4c800,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'd87b34710435774c45a38267466d49609a93aeb4', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '092c275005ae49dc1303214f6d02d134457c7053', '3a7fa673ff8ec4ec2f322473de005f3cd09ea820', '73c07e0a998576bb9d9409e5eed713788c0be037', '370b680057a6e324e67576a6bf1bf580af9fdd74', '8c6033dc0da4ab260c90b296bba117513fc85099', '29d5f0b9cc680c172009b583e59fc79663604353', 'bc6dff14a130c57a91d5a21339c23471faf1d46f', 'd82800c79dd335297336fe10b1a60d47706e4296', 'd99f2dd98822706006f61642f7118c0aaa3b58af', '7101bc1c316740d99cd87185586829291a983a1d', '38f93092ece8eee9771e61c1edaf11b1293cae1b', None, '132a8547513c1a2a1e10e827282d50683d6542ce', '5a088dee7e364cda88d91ffc50dc21442cd22811', 'f28e387d4229c5f690ce4570a391c0f47e7155c7', '1299a6489b93b3d0c5112593b04ea10af10bba80', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270'}",21,{'95a26eafabf06b1fc5dec6c460a927cf5964e97e'},1,"['Jiawei Li', 'Bolin Jiang', 'Y. Liu', 'Chengxiao Luo', 'Naiqi Li', 'Bin Chen']",Jiawei Li,"Jiawei Li, Bolin Jiang, Y. Liu, Chengxiao Luo, Naiqi Li, Bin Chen",4.761904761904762
abeba7567a85d598186119518068452dc93fa729,Subspace Modeling for Fast Out-Of-Distribution and Anomaly Detection,2022-03-20,"This paper presents a fast, principled approach for detecting anomalous and out-of-distribution (OOD) samples in deep neural networks (DNN). We propose the application of linear statistical dimensionality reduction techniques on the semantic features produced by a DNN, in order to capture the low-dimensional subspace truly spanned by said features. We show that the feature reconstruction error (FRE), which is the (cid:96) 2 -norm of the difference between the original feature in the high-dimensional space and the pre-image of its low-dimensional reduced embedding, is highly effective for OOD and anomaly detection. To generalize to intermediate features produced at any given layer, we extend the methodology by applying nonlinear kernel-based methods. Experiments using standard image datasets and DNN architectures demonstrate that our method meets or exceeds best-in-class quality performance, but at a fraction of the computational and memory cost required by the state of the art. It can be trained and run very efﬁciently, even on a traditional CPU.",https://www.semanticscholar.org/paper/abeba7567a85d598186119518068452dc93fa729,"{'77cf1b068da9adf55ae84115f7206747368c4198', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '9cd70ca81b4653aa2048002273c5ac9c36641390', '2c948ab13b9ecfa35374913710f849e806297e18', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '802168a81571dde28f5ddb94d84677bc007afa7b', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'afcd6da7637ddeef6715109aca248da7a24b1c65', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'b1464ca857593c049873421db2f37bf2d0ff676d', '0936352b78a52bc5d2b5e3f04233efc56664af51', '562e7f497eff8363825abad8d0008a42ce00eb49', '6ff2a434578ff2746b9283e45abf296887f48a2d', '9dd6e0d34a98fe2e2a9d2ae875c551ca4377e40d', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', None, 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '94f7f1ccd7e25c4d5f997d66365b00231478e987', '2e8d62277e40d465343e8dfb32ecc246f320540e', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', 'f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6', '3537fcd0ff99a3b3cb3d279012df826358420556', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",24,"{'9cd70ca81b4653aa2048002273c5ac9c36641390', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'b1464ca857593c049873421db2f37bf2d0ff676d', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",5,"['I. Ndiour', 'Nilesh A. Ahuja', 'Omesh Tickoo']",I. Ndiour,"I. Ndiour, Nilesh A. Ahuja, Omesh Tickoo",20.833333333333332
3b383b68d498e82a5f34ef1fae9be3f7cf58f249,LEA-Net: Layer-wise External Attention Network for Efficient Color Anomaly Detection,2021-09-12,"The utilization of prior knowledge about anomalies is an essential issue for anomaly detections. Recently, the visual attention mechanism has become a promising way to improve the performance of CNNs for some computer vision tasks. In this paper, we propose a novel model called Layerwise External Attention Network (LEA-Net) for efficient image anomaly detection. The core idea relies on the integration of unsupervised and supervised anomaly detectors via the visual attention mechanism. Our strategy is as follows: (i) Prior knowledge about anomalies is represented as the anomaly map generated by unsupervised learning of normal instances, (ii) The anomaly map is translated to an attention map by the external network, (iii) The attention map is then incorporated into intermediate layers of the anomaly detection network. Notably, this layer-wise external attention can be applied to any CNN model in an end-to-end training manner. For a pilot study, we validate LEA-Net on color anomaly detection tasks. Through extensive experiments on PlantVillage, MVTec AD, and Cloud datasets, we demonstrate that the proposed layer-wise visual attention mechanism consistently boosts anomaly detection performances of an existing CNN model, even on imbalanced datasets. Moreover, we show that our attention mechanism successfully boosts the performance of several CNN models.",https://www.semanticscholar.org/paper/3b383b68d498e82a5f34ef1fae9be3f7cf58f249,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '9893fc0ddcf1ecd398b00b788d7bcd9027e22ea2', '969bc38ea067dd22a47a44bcb59c23807037c8d8', '1e462fdaa752c3f62d5e3ef0be04fdd97f045a64', 'de95601d9e3b20ec51aa33e1f27b1880d2c44ef2', '0c908739fbff75f03469d13d4a1a07de3414ee19', 'f7b032a4df721d4ed2bab97f6acd33d62477b7a5', 'bd1dad58964790cf2e0045b2bc2a07d275f37789', '0abe0151c95618a024bc96f887bceaf3767e06b9', 'e8874d7d585ae1c355e186efdcc9f704b3d43b49', '3f611458b84ca8756c863916b33d12c704687127', '76444b1a166f41d437fa5ed443244acc518e7d6c', 'a228ce656599fe1413ed0671c260b5dad1190e3e', '83d074cc5051ade0c08d66180e4a04d2c112fa97', '3a34bc8949d42f6088fb4e668660c7031fbca23f', 'df67d46e78aae0d2fccfb6212d101a342259c01b', '5f6da0095b30d02f79d1c4222ba795733c75167c', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', None, '77d30cf9a34fb6b50979c6a68863099da9a060ad', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e90dfb06f1bdffbe465f231d087a60027d79da05', '3e2da7c1c7dfc7960d1515b61f32fdc55359eea7', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '369f43ced18846e0818607e5d4a35c1803db8fb3', 'f3fc96377dc3456948fd3431ce940258926ce04e', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '8cb34cbdcf65c23ef98430441b14a648c4e8d992', '3a173a2042b3d18d21f59187f1e5d7d83e791635', '5fc7af3f77cd81af4947da742ff6dc063714a3db'}",34,"{'3a34bc8949d42f6088fb4e668660c7031fbca23f', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",2,"['Ryoya Katafuchi', 'T. Tokunaga']",Ryoya Katafuchi,"Ryoya Katafuchi, T. Tokunaga",5.882352941176471
13c1e50d2bd916e6d33987d29acbe7ef57c6e9a7,Challenging Current Semi-supervised Anomaly Segmentation Methods for Brain MRI,2021-09-13,,https://www.semanticscholar.org/paper/13c1e50d2bd916e6d33987d29acbe7ef57c6e9a7,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '2a64030d34abc67343bbacdcdb0748d104203a32', 'e2963e39e5a5a45a89edf7ca71929a719bee12f9', 'ae97c81b45780dc91e18eb84236d8a40a290b329', '95c4c21f580db269ee81e18143de781771061661', '9a395b281496e9cc6278ac85b278a1e86bf72e46', 'b72771c316d60190aff053ef8a216ba57d62f541', '83d83640b4c3eb2cbd2b857e17de8e5f9f1ef476', '673377fa6f2cd6f013c095b3e4c05ce48482ab38', '62b77e5cb85fc61b84edd532f6d65714be152596', '4714f863564b32be86dab6f2cd7ef8fbecc9bafb', 'd82800c79dd335297336fe10b1a60d47706e4296', 'e597dea9e64485ceae8b86551e596ce42e205b89', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '7a905f54ad0221fc4367eec05168deddd45c4d9b', '2cebf0212380f83b7171fb5660f842c8d7043f60', 'a2fcf53f0aef0bfaec6353676c4f1d4e36aab5c0', '87e9842de97fc610ba69f0e8bc3e13b9619787b9', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'e9df6d7fa6b380c5db0ad4f29b9c32219aca05fe', '5ad2476610312f380dd4e6475ee706199560b21a', '580062407427236ced45253a2ff7df2e147a81e2', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",27,"{'62b77e5cb85fc61b84edd532f6d65714be152596', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b'}",3,"['Felix Meissen', 'G. Kaissis', 'D. Rueckert']",Felix Meissen,"Felix Meissen, G. Kaissis, D. Rueckert",11.11111111111111
775247047d0b56950ba5ea77d4a29772eca95c1b,Deep Learning for Anomaly Detection,2020-07-06,"Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This article surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in 3 high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages, and disadvantages and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.",https://www.semanticscholar.org/paper/775247047d0b56950ba5ea77d4a29772eca95c1b,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b', 'a1850e377567259b3f38a404e5d8f28e7babee5a', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '5db790198b9acf4e5efe350acdd814238fcacaa7', '195d0a8233a7a46329c742eaff56c276f847fadc', '4d8abae45a5492ed2399fd5e25eeade8ac0bfa0f', 'a4cec122a08216fe8a3bc19b22e78fbaea096256', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', '33e76c6cb61235986e832e8d35757ce502c02ecc', 'fc70fa3bedc32c0f49c42f0822788638c5847c79', 'e98afa396d081e81256c3e7e26395311cc111b7e', '60fef33549f57f5cbb6712a510c3a444ab682429', '3ebdaff354142c66d05d0216d5efa6e8040f9cd6', '5fc5c5a4e489e781de434567d946e6eb65c44f60', 'c43d954cf8133e6254499f3d68e45218067e4941', 'b20e564edbef25009fa1baa2c369437c89147e61', '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'a86f5ae89a0332c1cecac4502492b8e334896887', '1ffcb27536ab5436e6d753919ab27ac1a44b4b69', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', '1d38ee16ed990689c3a85160dbc20e22b72afb6d', '331de2ba0881229bd299a71245217943e53b0ecf', 'a7c828184693a453a6c2867dee233ed054b2012e', '372e39cd2f5b5c506fad3d3f69f23992f3d8e3a8', 'eb42cf88027de515750f230b23b1a057dc782108', '977560251c2bd4c28a6c7c707c29f4091c5e6247', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'fbf26e1085ac3b038f47d4d1945ebda45d5e57fb', 'bfc57fbd7053227d22cba5dd4e067d0ae3fa455b', '6869ab1f42e30b415829de9928f7e4a606113601', 'af7c0424dd878a5619fb4ac5448d53db3d2be60a', '2c37826357c18148f6f0773d22f7a4488831c1c4', 'd8021847ed0e3f26b53416c2a254a85451ee5f1e', '1d033b30f38642e4b6dd146bb8b464bfb58aad96', '2a5648a078ca2c0547877e6d26aedb90d8eadc01', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'd9cb449af41b6da76c98475ff268b3ef06d6dec1', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '67c678d04908f534f37804bfc8e30de106595577', '1ad15c08556c8f8e3739703857ea01077ce738c5', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'ae74522002f9093fbf63a20efb57d80ee2f4f564', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864', 'df787a974fff59f557ed1ec620fc345568aec491', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '1bc042ec7a58ca8040ee08178433752f2c16f25e', 'e9b1ba025413b86f2a01d11fb1cd571c1a0d7c16', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '52b7bf3ba59b31f362aa07f957f1543a29a4279e', '0025fc4f00c21960297fbdf83220d6bde75da645', '355b4e74774798c177c82943eef925d66a2bb2ce', '41285e207f2bfb861d3aee7c1557a9b8525745af', 'd9ae299d42b418467655d5e5c40881f70308e2d5', '267502d21b44884570fcd95a855821cc3e86e6eb', 'd261faca1e34a42b11336a3287021b812f20469b', '1eb1c5f369da4f90c8f763f778a21c49cc605117', 'fff09ec5380f72dd67a26439e8e5fe7132ecb242', '6e36fc1485ee735796a6ac39ff8155bb2c4f7017', '90902e16f4e8ff5e3c4bf0f971380af5753aacdd', 'bd292d03a78be8252d7c1502f05e14a56db64b54', None, '4cb3fd057949624aa4f0bbe7a6dcc8777ff04758', '1134a0e4d079ea1a6d32a75022956491a561e601', '5f61089d3d548a515f01b473f0119137d1f340d4', 'dd8eb6662c515381ad78059d59c85a1e70fa35ab', '5d38cf6afbb34b8785106ac78720892a10b5aa5f', 'c129e8025fffa065edb5b27dd7c2269abc0a138b', '74fae15b0aa3c67d700254d3bb806b935dd410cd', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '4f180e8a1a2ea4b182719318bd6fe4380aa4f52c', '4c729c317045bcf2a85cfc3157225e61c3cb6c1a', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '336f43085e1140824e0c116ac7c76f9135c28e61', '5ece646d13786df1d84ff8eb2bfbc736dd337378', '1db6e3078597386ac4222ba6c3f4f61b61f53539', '2932c27534879345a1ff9c753c95ac60f8469179', '8e23d99764eef23b2240150c96768db8e1668a8c', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', '0985b9cc77f64a76aea1d78a3508672ff092705a', 'b0b30afd54e45d650908dab1290b8f6e93a97581', '0a77313fa10a864e14f538c73d417d7b4d6f320e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'c4bc3d8703ced63750a5b9ac3ddd4514fada596c', '98b1a92bbbce20d828a5d4ea618cb4b49212aeaa', '14edcd37e697f0bbb495962c3b5a3c141410bf37', 'a48a8b2085262a7f9658368088eca756e400d5ae', 'dcd9f5d61bc9a70c40be84a8d78fbee822ffcd9e', '450ae94f84eba33e2ed60a1ea9657fbe93989c51', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'cea967b59209c6be22829699f05b8b1ac4dc092d', '68f6fe021bd8efd8baf648138a8fe2182858e7cb', 'f076e4355c0facf111716dcab2837803367dd2d8', 'bc5a67aa59bf49850d702dc5aecfa231d0952f6c', 'ca14dce53be20d3d23d4f0db844a8389ab619db3', '7bd05d7130b3cb64d3f8c8481810e4a2e8b935f6', '290ff9a05058ec14e4cfa7bdb716f5b007ee06eb', 'c53352a4239568cc915ad968aff51c49924a3072', 'b05b67aca720d0bc39bc9afad02a19f522c7a1bc', '524ea0edcf43532b55e087f1bcee48168a985194', '3febb2bed8865945e7fddc99efd791887bb7e14f', '154df96b95e8b9635771442244fe48b125933bb1', '17fa1c2a24ba8f731c8b21f1244463bc4b465681', '7435de8b486e561442d9df8bc6afcb1f4167c5ad', 'df2b0e26d0599ce3e70df8a9da02e51594e0e992', 'fefeded74334e5eafa47c5df6de2837fe3b7502d', '3c439ef038419f9db396628ed9766af568625f31', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', '792250ae660b7c25f85eeea7dcae623e4301d97c', '1e3ed42ed413570a701fae5c4d5db0c5d45edd22', '5d45e2cbe8cff587ea9ca4d6d8584757b8b6c311', '488bb25e0b1777847f04c943e6dbc4f84415b712', '6af440915b8a0718c93be1cf61905e41e620484a', 'cc8bc7965cc5a1250cc202f5cc63dc53960e8679', 'f30b10bb58e49138cbf33e625746c87b662a9e7d', '7a59fde27461a3ef4a21a249cc403d0d96e4a0d7', 'e3ce36b9deb47aa6bb2aa19c4bfa71283b505025', 'aae932cf9c2434f52b03991fcab050a61a960d48', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '6ff2a434578ff2746b9283e45abf296887f48a2d', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'c8c422850207355cfd4433d7b4f95cfee3d3525e', 'b94043a133e3d07ed0b1cfc036829e619ea0ba22', '8381157eae4fbf8908d0312a9642f8e69e944449', 'a8db789522b9375396bd91de631342740ba19a12', 'bcfdbb6b8911272139170ef4b24e31d9145093e7', '184ac0766262312ba76bbdece4e7ffad0aa8180b', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', '3df952d4a724655f7520ff95d4b2cef90fff0cae', '882e06d18c0fc0645ae559633eb178a7a41cfe79', '9cc912ae25797e5f7c0d73300d3968ad8339b411', 'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '43d75d3a22db904d052d4c435e2d1f22be3887e0', '368a8fbf6304a192a67f614d032510e5a4100552', 'ca56df64a351f873c8c138874326a6f64eec011d', '571b0750085ae3d939525e62af510ee2cee9d5ea', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', 'd9e8925a5ccbb1db50c69dd6ccc18fe567f7fe12', '70d3bf78ca2d9f4582c9d3e5aafb539de05ce13d', 'aa7128ed81808cad1ce19fa122a30a616eca2914', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', 'a4c94b221062d0737ee967affa80ce2110cc50c0', 'dce59bd5efe2fa014390594f0876bad34a0dfabc', 'f44ff4fc0ed0142cb18472a5ba421bb538aa837e', 'e3116ebb52c152deae918a04c34441ac0d956b8a', '3c57a1aa483d8bffe1339914b80d2913f2dc8376', 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', '36653f8705b56e39642bcd123494eb680cd1636b', 'a513d6aa5f696e2e202f19c2411ec205a915acaa', '2d8400cf12a9a1592a8ee19a85c476ec52312779', 'c9359c13b4f4b058380e4ea3387044012e65bd2a', '0d64856887512b728e24a762086e8a97ea6eeb59', 'd2c1a3d4ca9ee51d7956853ea9f33886131589db', 'fcadb2bac99550adcdbd8578eb246eb9e264ecf3', '17eeaa7bfbadbcd92d5bacdda2e2f5760454eed9', '0e5f3a914302e777ffaa9306e8cb0c857b21fb9d', 'e9672150c4f39ab64876e798a94212a93d1770fe', '103bdc0e62bc820c142247e0e65501cddc03ed3c', '875594b5167c4deb234cc898558640d04fefd866', '8610e46dde43ed804cac7d11d36c8c67a2aef84a', '48b9d350a0f20fdce7c8edc198fb3b3350600157', '06b26678cda5f243338f43b18b7532228273a7f0', '68c6b394a3f7b66266d3b4bc338427f5bcf23bd3', '7ea692f3ca356533122c35a152866c98b52d645e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '84af0bbe339c1adbc9d075dee99b9d4f86a186c5', '225ab689f41cef1dc18237ef5dab059a49950abf', '0e7af8e91b8cb2cea1164be5ac5d280b0d12c153', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', 'fbadc3f6d71ef5ceb57fbc88d925125a83e14f55', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'fc89bc3776c98bb75887868fb35d1a30f11fbd69', '598fe25743f9492c5c1ba30274ea446f65426d85'}",181,set(),0,"['Guansong Pang', 'Chunhua Shen', 'Longbing Cao', 'A. V. Hengel']",Guansong Pang,"Guansong Pang, Chunhua Shen, Longbing Cao, A. V. Hengel",0.0
de3ee106844e5a9922da0068ad255baae0dfb805,AdaFilter: Adaptive Filter Design with Local Image Basis Decomposition for Optimizing Image Recognition Preprocessing,2021-01-10,"Image preprocessing is an important process during pattern recognition which increases the recognition performance. Linear convolution filtering is a primary preprocessing method used to enhance particular local patterns of the image which are essential for recognizing the images. However, because of the vast search space of the preprocessing filter, almost no earlier studies have tackled the problem of identifying an optimal preprocessing filter that yields effective features for input images. This paper proposes a novel design method for the optimal preprocessing filter corresponding to a given task. Our method calculates local image bases of the training dataset and represents the optimal filter as a linear combination of these local image bases with the optimized coefficients to maximize the expected generalization performance. Thereby, the optimization problem of the preprocessing filter is converted to a lower-dimensional optimization problem. Our proposed method combined with a higher-order local auto-correlation (HLAC) feature extraction exhibited the best performance both in the anomaly detection task with the conventional pattern recognition algorithm and in the classification task using the deep convolutional neural network compared with typical preprocessing filters.",https://www.semanticscholar.org/paper/de3ee106844e5a9922da0068ad255baae0dfb805,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '7c6409ec154ba64f5eb63d8c6e9f419ce1472289', 'defafc2bb5ce486b774bc523ee8624dcbd8fbef3', '03911c85305d42aa2eeb02be82ef6fb7da644dd0', 'eff7b57c5458f2ea4c72dfe2d1fc6d6ab52d9f70', 'f856e53d07faa98ffe54749ebd1e8ae15b54c1c3', '0adce2edf7b2bc2120c10d63b7313516fe662e4e', '2f4df08d9072fc2ac181b7fced6a245315ce05c8', '0025fc4f00c21960297fbdf83220d6bde75da645', 'aedb8df8f953429ec5a6df99fda5c5d71dbee4ff', '4282a344671189e17c9c9e00e329fe2d0fa71769', '2d06a16892e23a88a768b8bfd00871c3548f3ab5', '95ed254ca6c74102e1b24507b3ea7b9fa2754838', 'ee1477dcbf768cd589cdcf45ca8f9427666dfe4d', '577d19a115f9ef6f002483fcf88adbb3b5479556', '1a2a770d23b4a171fa81de62a78a3deb0588f238', 'ca1d23be869380ac9e900578c601c2d1febcc0c9', 'e6ee49a4b2c61fb2a5af1bec39ef43d019c46f48', '5edd7de96492be3d187c04ff527cef275f7d95df', '9cbee65df71671fc364e928f5e6505dc71ab9e00', 'e6e2322d7ee5890800a2cd81afe80c99aac3a433', 'd5cec2e4f53a0e749b9ea22697578917fdff00aa', '2f03f5ffec3befdfe8a32ef177c5f70ea63c8b09', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', None, '076493eb657b6589df5686e4240a82ca14e1c14b', '67ce626c4c0180081c91d7b3e136a5da9e648b92', '261ba60c1e16ca169c3ca9703ea70c9384c325a1', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '8ecd85f76778c454a476ac473dd1d6b40d9973ce', 'f659ad5758ba6dd37b9c075588cdc26bc74dc2ad', '787827850b614135f6b432603afc90b58a8cc665', '4cdf2fad22afc865999747336c7399fe422e6e8e', '69e68bfaadf2dccff800158749f5a50fe82d173b', '67b93cbb21bc96cbef307b855f7f418eda97fdc7', 'bf7159c21a9225fb78f94c5016bf0c764f08b4d6'}",36,set(),0,"['Aiga Suzuki', 'Keiichi Ito', 'Takahide Ibe', 'N. Otsu']",Aiga Suzuki,"Aiga Suzuki, Keiichi Ito, Takahide Ibe, N. Otsu",0.0
c0ee89b75ebbd8c14677f312817d48eacc711350,Heimdall: an AI-based infrastructure for traffic monitoring and anomalies detection,2021-03-02,"Since their appearance, Smart Cities have aimed at improving the daily life of people, helping to make public services smarter and more efficient. Several of these services are often intended to provide better security conditions for citizens and drivers. In this vein, we present Heimdall, an AI-based video surveillance system for traffic monitoring and anomalies detection. The proposed system features three main tiers: a ground level, consisting of a set of smart lampposts equipped with cameras and sensors, and an advanced AI unit for detecting accidents and traffic anomalies in real time; a territorial level, which integrates and combines the information collected from the different lampposts, and cross-correlates it with external data sources, in order to coordinate and handle warnings and alerts; a training level, in charge of continuously improving the accuracy of the modules that have to sense the environment. Finally, we propose and discuss an early experimental approach for the detection of anomalies, based on a Faster R-CNN, and adopted in the proposed infrastructure.",https://www.semanticscholar.org/paper/c0ee89b75ebbd8c14677f312817d48eacc711350,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '3c5c8ac2e99c28685a9c019c27e8ace7516748a1', '74298daec5d7bdf797e7fc2a62e3bc2a000c7910', '1cb1bfd9af5bda1f712605695e47d37c03522652', '6019691e7b53395f285a6967acc20f19d466cbad', 'ba4eec4a53013e4a5ae0151d3722627f68a676c0', '47122148621ae8df7bd1e3bf7614f11f0cb2be82', '4b8ecd100d6640fd7659be2715c86b7a9103240b', '3e3b48d1299b9e737371008e9ef09177b608236e', 'e4cf38764a431713a2b0d03807ec216a4f351e6d', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', '220c088b3e8819222afe4de92e6c75eeb5493957', '9a8be994e7069236d94e30c4c7b481988effc106', 'e3feb314a07f37e07b5b9807de0d88184ad0cebd', 'd0c29ad9d6541eaf3eb2e3adae1d0b820e8329fd', 'd60f38af2c326ebcd9b2464db41a12df23bf7788', 'e782da8e76b7489b34895a494e044a2b0b1636af', '3283bcd7dd00e0925bfa3824bc7d18af4ad22514', '008ff4a7bbde72a3332d9272043124ea0931072d', '9b9be9b6664c210897c8953e29d37f8d0cfb6601', 'c107d8ebe53ed184fe932a278e7eca2e91956410', '76914a111c0a9f4b2185cfe819d0ad010cd20a69', '990829bf6874675c1a55d90313072a7c2687bf51', '5534f654e6cac7d167035ffb119f959a0b008ae3', '856d1726137d80ed6a2eb4f2e838ea1e328c6c91', '3c74fcf4d623b44c6ef6c3405b192641dc0996e0', 'd3cdc922532b0e200b34f0ffea9503628f037ff8', '77e01a9ee971b8b93a7b01c18febe62cf1e382fc', '5092cc7f292ae39f81c56fcd43fe4dc20b74e9ea', '336fd11c4071bd0e681f64b16f163808a12571fc', '8e756cf70ef779742f11196e2376fe81a85aa29b', 'c8c6ee5c9fdfae7ea7c130d6e54577c321db5b67', '35840e026a096b7487b0e94df0f04690a5035a62', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', 'd05b4c84a2e194d0e9697c2a191ad85866995f1d'}",35,{'9a8be994e7069236d94e30c4c7b481988effc106'},1,"['A. Atzori', 'Silvio Barra', 'S. Carta', 'G. Fenu', 'A. Podda']",A. Atzori,"A. Atzori, Silvio Barra, S. Carta, G. Fenu, A. Podda",2.857142857142857
02805f18989b7e77f30ee13defd6fecfcd0f499f,Student-Teacher Feature Pyramid Matching for Anomaly Detection,2021-03-07,"Anomaly detection is a challenging task and usually formulated as an one-class learning problem for the unexpectedness of anomalies. This paper proposes a simple yet powerful approach to this issue, which is implemented in the student-teacher framework for its advantages but substantially extends it in terms of both accuracy and efficiency. Given a strong model pre-trained on image classification as the teacher, we distill the knowledge into a single student network with the identical architecture to learn the distribution of anomaly-free images and this one-step transfer preserves the crucial clues as much as possible. Moreover, we integrate the multi-scale feature matching strategy into the framework, and this hierarchical feature matching enables the student network to receive a mixture of multi-level knowledge from the feature pyramid under better supervision, thus allowing to detect anomalies of various sizes. The difference between feature pyramids generated by the two networks serves as a scoring function indicating the probability of anomaly occurring. Due to such operations, our approach achieves accurate and fast pixel-level anomaly detection. Very competitive results are delivered on the MVTec anomaly detection dataset, superior to the state of the art ones.",https://www.semanticscholar.org/paper/02805f18989b7e77f30ee13defd6fecfcd0f499f,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '02227c94dd41fe0b439e050d377b0beb5d427cda', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '5db790198b9acf4e5efe350acdd814238fcacaa7', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '388645c44061f6e88fff0ecdad2f622936207d67', '2528a82dd2266600d4ee2b54165556a984de94d4', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'f076e4355c0facf111716dcab2837803367dd2d8', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '1c4e9156ca07705531e45960b7a919dc473abb51', '62b77e5cb85fc61b84edd532f6d65714be152596', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', '9277dc70c74bcadf80dab11c28ead83fd085deec', '1a2a770d23b4a171fa81de62a78a3deb0588f238', 'c53352a4239568cc915ad968aff51c49924a3072', '1c46943103bd7b7a2c7be86859995a4144d1938b', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', 'a0e8f4348968195c80494b7a4245edb91a252c93', '45f490710b4dd6697dba4c9b385a49554501711a', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, '5f61089d3d548a515f01b473f0119137d1f340d4', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '563143c5f4fed0184c1f3e661917da94cfed1d46', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'c08f5fa876181fc040d76c75fe2433eee3c9b001', '317c172f314f8cb634f7569ed5bf3ae7dd25c313', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",47,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",7,"['Guodong Wang', 'Shumin Han', 'Errui Ding', 'Di Huang']",Guodong Wang,"Guodong Wang, Shumin Han, Errui Ding, Di Huang",14.893617021276595
09fded76f4a64e13de81e247548f47af0032ba8f,GrainSpace: A Large-scale Dataset for Fine-grained and Domain-adaptive Recognition of Cereal Grains,2022-03-10,"Cereal grains are a vital part of human diets and are important commodities for people’s livelihood and international trade. Grain Appearance Inspection (GAI) serves as one of the crucial steps for the determination of grain quality and grain stratiﬁcation for proper circulation, storage and food processing, etc. GAI is routinely performed manually by qualiﬁed inspectors with the aid of some hand tools. Automated GAI has the beneﬁt of greatly assisting inspectors with their jobs but has been limited due to the lack of datasets and clear deﬁnitions of the tasks. In this paper we formulate GAI as three ubiquitous computer vision tasks: ﬁne-grained recognition, domain adaptation and out-of-distribution recognition. We present a large-scale and publicly available cereal grains dataset called GrainSpace . Speciﬁcally, we construct three types of device prototypes for data acquisition, and a total of 5.25 million images determined by professional inspectors. The grain samples including wheat, maize and rice are collected from ﬁve countries and more than 30 regions. We also develop a comprehensive benchmark based on semi-supervised learning and self-supervised learning techniques. To the best of our knowledge, GrainSpace is the ﬁrst publicly released dataset for cereal grain inspection, https://github.com/hellodfan/GrainSpace .",https://www.semanticscholar.org/paper/09fded76f4a64e13de81e247548f47af0032ba8f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '02758d77ef3a840712047bbb8b29c3646b83fb54', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '70e536bc31e783dfa6d0bd9f10ec2c41d6a1c986', '6e4214742ceb61a413ead02937e4cdbf5a8d7240', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', 'c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716', 'c8c494ee5488fe20e0aa01bddf3fc4632086d654', 'db787640c9b42416ff8d7015546e667e58267177', 'c8b25fab5608c3e033d34b4483ec47e68ba109b7', '0d725e4fea8bbaf332d6a8d424ebecbd547a3851', '518a7c79968a56d63a691d42f8378be6c776167e', '86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6', '496c6db97a4f16e6bc9e4d63af420eb66f900f74', '2f7e8d0cfe601b9bb3d07d7783ecd80424994517', '73c07e0a998576bb9d9409e5eed713788c0be037', '71b7178df5d2b112d07e45038cb5637208659ff7', '88347a6fe854f1d38e20f1c5cef4e85ca30dbe37', 'e5abaa1d3249ed10403d611807213b0d0767719f', '317aee7fc081f2b137a85c4f20129007fd8e717e', '92cb9fc499f738634c8fedbd7c0aa2b67a5a38ce', 'd052e4b50a70db555490aa2852d9b7d4798028e8', '8b47b9c3c35b2b2a78bff7822605b3040f87d699', '8bf44420253011259084de15e76b5aaa5fd25547', 'c1bb309731ac6e5842c4cbaf376b6cf849a71fd5', '6af440915b8a0718c93be1cf61905e41e620484a', 'f5e28b2fce249d06b2e75f8c27c2af5f4b5c2cd4', 'c947c89c4a709ad27fe4590294589196642b0214', '73f76a40ed20aa3c6a8e27e4db4a8c102e7b4c6d', '7c403f5194bf68a97f12d3d2274f5420bf68f8b0', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', None, '82635fb63640ae95f90ee9bdc07832eb461ca881', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'cc46fc50cbae566b89fa0cf2f8fc7bd81d901f31', '8d1782218b82f321b54608297dcadd242eb9beb3', 'de298319e32ae423e9ff2e18ee48d5b1c8b18d15', 'c42816f497d663c681df20d48a6e66a5632600d8', '9171e83fb98299e14cbb3673437a0495a213767a', '8162d90993c7081617877a4a0bc6305dfeab24d2', '3a6efd7e687c817c63e5858e326b52b74dd13ff1', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '0ceb0778ecc49ab17f711d0a006714f5063e44ef', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270'}",46,set(),0,"['Lei Fan', 'Yiwen Ding', 'Dongdong Fan', 'Donglin Di', 'M. Pagnucco', 'Yang Song']",Lei Fan,"Lei Fan, Yiwen Ding, Dongdong Fan, Donglin Di, M. Pagnucco, Yang Song",0.0
912a659ba09887c3abc99dc3ec5818bd1a36e1ec,Natural Synthetic Anomalies for Self-Supervised Anomaly Detection and Localization,2021-09-30,". We introduce a simple and intuitive self-supervision task, Natural Synthetic Anomalies (NSA), for training an end-to-end model for anomaly detection and localization using only normal training data. NSA integrates Poisson image editing to seamlessly blend scaled patches of various sizes from separate images. This creates a wide range of synthetic anomalies which are more similar to natural sub-image irregularities than previous data-augmentation strategies for self-supervised anomaly detection. We evaluate the proposed method using natural and medical images. Our experiments with the MVTec AD dataset show that a model trained to localize NSA anomalies generalizes well to detecting real-world a priori unknown types of manufacturing defects. Our method achieves an overall detection AUROC of 97.2 outperforming all previous methods that learn without the use of additional datasets. Code available at https://github.com/hmsch/natural-synthetic-anomalies .",https://www.semanticscholar.org/paper/912a659ba09887c3abc99dc3ec5818bd1a36e1ec,"{'05e882679d61f4c64a68ebe21826251a39f87e98', '67bd5b3a67a6dedd26b6c4e6b279158433069a7d', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '5db790198b9acf4e5efe350acdd814238fcacaa7', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '8afa6dd9f9ac46462a1fb70a757c4ae1cd45bbf6', '94c951bb90d0b86e056668aaadd2d5459ace5bc3', 'cff4cb74f4466bd0407977e40ef0be9f444c63ea', 'b022f2a277a4bf5f42382e86e4380b96340b9e86', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '97f43437e45867a6843ef8278d34a1cf4f811c14', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '0b5c5c0e5172d3e5c09c23240d083b99c01a2fc9', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '6af440915b8a0718c93be1cf61905e41e620484a', '6507909a8f77c88144c3a67b9336bd1c85e84cac', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '48f9a48aa5b1230b05a443d2d531e6441a541686', '18c125ce0f64e85577f7d30132cf0e92ec664bf4', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '4bec59a9940f2a111594c5b7ea1ccf2419ada04b', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '1cb5dea2a8f6abf0ef61ce229ee866594b6c5228', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', '6dbc8145124d338a96ee59bc745f0bbce1f00c76', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",36,"{'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '48f9a48aa5b1230b05a443d2d531e6441a541686', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '37595f7a51982d776e57c7280b9445474d90f0be', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",12,"['Hannah M. Schlüter', 'Jeremy Tan', 'Benjamin Hou', 'Bernhard Kainz']",Hannah M. Schlüter,"Hannah M. Schlüter, Jeremy Tan, Benjamin Hou, Bernhard Kainz",33.333333333333336
ead24c591a410223c3b00ffd0fea194da93c1744,MemSeg: A semi-supervised method for image surface defect detection using differences and commonalities,2022-05-02,"Under the semi-supervised framework, we propose an end-to-end memory-based segmentation network (MemSeg) to detect surface defects on industrial products. Considering the small intra-class variance of products in the same production line, from the perspective of differences and commonalities , MemSeg introduces artificially simulated abnormal samples and memory samples to assist the learning of the network. In the training phase, MemSeg explicitly learns the potential differences between normal and simulated abnormal images to obtain a robust classification hyperplane. At the same time, inspired by the mechanism of human memory, MemSeg uses a memory pool to store the general patterns of normal samples. By comparing the similarities and differences between input samples and memory samples in the memory pool to give effective guesses about abnormal regions; In the inference phase, MemSeg directly determines the abnormal regions of the input image in an end-to-end manner. Through experimental validation, MemSeg achieves the state-of-the-art (SOTA) performance on MVTec AD datasets with AUC scores of 99.56% and 98.84% at the image-level and pixel-level, respectively. In addition, MemSeg also has a significant advantage in inference speed benefiting from the end-to-end and straightforward network structure, which better meets the real-time requirement in industrial scenarios. pre-trained ResNet18 [14] as an encoder. From the perspective of differences and commonalities, MemSeg introduces simulated abnormal samples and a memory module to assist the model learning in a more oriented way, and thus accomplishes the semi-supervised surface defect task in an end-to-end manner. At the same time, in order to fully fuse the memory information with the high-level features of the input image, MemSeg introduces a multi-scale feature fusion module (MSFF Module) and a novel spatial attention module, which greatly improves the model precision of anomaly localization.",https://www.semanticscholar.org/paper/ead24c591a410223c3b00ffd0fea194da93c1744,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '19862af96b6af51e879e6e3f1d3d421af5427005', '42a60886538872c7e5b768cd50dfac3115d08c7d', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '1c46943103bd7b7a2c7be86859995a4144d1938b', 'cb8e3a8a4a552ec8ef7461117a5c9c49829d962b', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '7edbd1ee743632893de81d117c05120774dc36f4', '9c24454b071bc8e96ea46c5064a7bddf07cca464', None, '70cf7c785952375e8061c92235aa20e94b02ecd4', '18c125ce0f64e85577f7d30132cf0e92ec664bf4', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'a414c2111a042c0e53f4cb4297ddb39a3801fc1e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '72564a69bf339ff1d16a639c86a764db2321caab', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'd08775cf2bebcffa05c6fa506f687ef56953f128', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '3d4a9205306bd01149e13db325ad0f6d5814d49a'}",31,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '62b77e5cb85fc61b84edd532f6d65714be152596', '3d4a9205306bd01149e13db325ad0f6d5814d49a', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '9277dc70c74bcadf80dab11c28ead83fd085deec', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '19862af96b6af51e879e6e3f1d3d421af5427005', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",12,"['Minghui Yang', 'Peng Wu', 'Jing Liu', 'Hui Feng']",Minghui Yang,"Minghui Yang, Peng Wu, Jing Liu, Hui Feng",38.70967741935484
7dc0ca9af81df5be8909dec8acbc2bf82acf5f87,P-WAE: Generalized Patch-Wasserstein Autoencoder for Anomaly Screening,2021-08-09,"Anomaly detection plays a pivotal role in numerous real-world scenarios, such as industrial automation and manufacturing intelligence. Recently, variational inference-based anomaly analysis has attracted researchers’ and developers’ attention. It aims to model the defect-free distribution so that anomalies can be classified as out-of-distribution samples. Nevertheless, there are two disturbing factors that need us to prioritize: (i) the simplistic prior latent distribution inducing limited expressive capability; (ii) the strong probability distance notion results in collapsed features. In this paper, we propose a novel Patchwise Wasserstein AutoEncoder (P-WAE) architecture to alleviate those challenges. In particular, a patch-wise variational inference model coupled with solving the jigsaw puzzle is designed, which is a simple yet effective way to increase the expressiveness of the latent manifold. This makes using the model on highdimensional practical data possible. In addition, we leverage a weaker measure, sliced-Wasserstein distance, to achieve the equilibrium between the reconstruction fidelity and generalized representations. Comprehensive experiments, conducted on the MVTec AD dataset, demonstrate the superior performance of our proposed method. 1",https://www.semanticscholar.org/paper/7dc0ca9af81df5be8909dec8acbc2bf82acf5f87,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'f3111f0e764698f6d9d85cc4023d84ed6f7859cc', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '732c21998e251d64cd58b6a86886ee5907efeaa5', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'a181fb5a42ad8fe2cc27b5542fa40384e9a8d72c', 'd8daa2f46de22a0bf06ec5174d4fdbc650d4239b', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5db790198b9acf4e5efe350acdd814238fcacaa7', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '75aa1f1a04b5f2bb6bf9afb662711121edde9eda', '0b9f95f73bd2d732b1372040e2a4d7c8f3fc594c', '07b056a23b225fa4fc54cda80a8e6c2c74760541', '5cbab8e9eb649b1a908208061e8fe135d9c91f43', '4758baad6b22c61682e7f7182bb93723046f36f5', '732f76b0a2aa5d255d60cb6e29257d9fb292a6f4', 'ec75b87ddbd9ca88fb5cea408db59aad44424296', '8976e91ccae57a20c29f3c9d88bf45b19973c952', '4aea3547974399a32d7aa7c007b10bd665e93fab', '3bc63a1a3c0a5bb66af7bb61c34e379658820f90', '295aca7669f54cdc746c595088693bb102855b9f', '920e0e85ca67d487731a33a74dba1f13204cc102', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '62b77e5cb85fc61b84edd532f6d65714be152596', '6745c95b88ff9b12401a9ba6f4007f036be591a0', '97f403cfc932c137af78f83afdcf377c6f04b144', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '4b07c418a40fdedbefeca7e78afe2b8a1c473537', '16d70e8af45ca0ae2c1bb73f3be6628518d40b8f', 'bc6dff14a130c57a91d5a21339c23471faf1d46f', 'f69f237073ef04043fdbd5bb6844b5b2da8e0930', 'c289a21439402eb0998df46c769ce9c4971e854b', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', 'fbd389f324506a30a6302a36fa99c9ee4ff8fce8', 'f4fcda45da5eab0752942867b68f9fbdfa59da4a', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', '1c46943103bd7b7a2c7be86859995a4144d1938b', '18c29e07f159b836125db6c7a432ba44d74f2d41', '29831b8830e278c8c28e45c8e9c41c619c89f86a', '6875e331328e30a35e6e8d88bbe6ce75d6d1b16b', '8050826d4765fa5aa6237690c65eabd5b91cc796', '1f528877c4d8d5df3b3abbfa64379677d451956b', 'aae4efb3d412d585ea0dec03f933397c93caf989', '6af440915b8a0718c93be1cf61905e41e620484a', '415229903f91a1f3fc7404f5e5997fde025c221d', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'e7070b52403920d914d483285a42addb2de9ef2b', 'aae7c875fc7531233c2a3ebefa31a33f1a0d7f49', None, '0d86fbca1fbdb7c8e5a10c2d2c5a0ff3e07eea15', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '25badc676197a70aaf9911865eb03469e402ba57', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '63e44ed835034533a43aa956044eebc8d219d170', '8412fde054871160e0ec06007bbef587ad726ba0', '891b02aee809c5f2c14ee3722b045393cd3266d9', 'b3e9745126a0d65246dffd2e946bb44f46fe7673', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '032db195efd97fe2bcd20c4ad04628c70ff4e79c', 'decf00b8de306194296f68edf6ab9f344caaa28d', 'fc937d5bf0958457f158bd915bd378a0da51216e', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '6f68ce1e03c56c186256dac689a21f6405ae8d96', 'a90226c41b79f8b06007609f39f82757073641e2', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",70,"{'4758baad6b22c61682e7f7182bb93723046f36f5', '1f528877c4d8d5df3b3abbfa64379677d451956b', '295aca7669f54cdc746c595088693bb102855b9f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '62b77e5cb85fc61b84edd532f6d65714be152596', 'efabba68912e88a1eb2e9714ff4681b8478ceb83'}",7,['Yurong Chen'],Yurong Chen,Yurong Chen,10.0
641d0382a2904e43e147f797dcf21568e62ce8af,Domain-Generalized Textured Surface Anomaly Detection,2022-03-23,"Anomaly detection aims to identify abnormal data that deviates from the normal ones, while typically requiring a sufficient amount of normal data to train the model for performing this task. Despite the success of recent anomaly detection methods, performing anomaly detection in an unseen domain remain a challenging task. In this paper, we address the task of domain-generalized textured surface anomaly detection. By observing normal and abnormal surface data across multiple source domains, our model is expected to be generalized to an unseen textured surface of interest, in which only a small number of normal data can be observed during testing. Although with only image-level labels observed in the training data, our patch-based meta-learning model exhibits promising generalization ability: not only can it generalize to unseen image domains, but it can also localize abnormal regions in the query image. Our experiments verify that our model performs favorably against state-of-the-art anomaly detection and domain generalization approaches in various settings.",https://www.semanticscholar.org/paper/641d0382a2904e43e147f797dcf21568e62ce8af,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '41c67d04be2d1632c0d3b0880c21c9fe797cdab8', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'b26d5d20b073828898087f99b81736c0629c1798', '231af7dc01a166cac3b5b01ca05778238f796e41', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'ba6ba7f488c1ece0803f4b9e1c83a3196d061610', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '1dac467c4a1c84c50ccb664e83272d893647a980', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', '41747cbdbed84762dfbfc305254c97021279dc6e', '8dbfe0db2a3ec5b9d73e13817aa64426db168af1', '305882ccefcdfbbaaff201bb96eac380bc62e439'}",17,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040'}",4,"['Shang-Fu Chen', 'Yu-Min Liu', 'Chia-Ching Lin', 'T. Chen', 'Yu-Chiang Frank Wang']",Shang-Fu Chen,"Shang-Fu Chen, Yu-Min Liu, Chia-Ching Lin, T. Chen, Yu-Chiang Frank Wang",23.529411764705884
7b24c1a6fac6ac75f55568b4de87b12a14328dbd,72‐3: Deep Learning Based Visual Defect Detection in Noisy and Imbalanced Data,2022-06-01,,https://www.semanticscholar.org/paper/7b24c1a6fac6ac75f55568b4de87b12a14328dbd,"{'0891d7aae5f41ebcc6f48f127bbdaac4c9f92be4', '6482d8c757bce9b0d208d37d4b09e4805faae983', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '5d6ae67e569f974360b107060c23cbb8a13b0687', '6af440915b8a0718c93be1cf61905e41e620484a', '82c77a88969ac0e3a4e55c9a7dc5ced4afee0225', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'c09a4d90754628015c311e9c51f4b3ab888c796e', '33d6aa6c41ce3000161d9b5eea910a5b78e14330', 'f11d69fac609917da82f697758cd694c0f01a730'}",10,set(),0,"['Qisen Cheng', 'Shuhui Qu', 'Janghwan Lee']",Qisen Cheng,"Qisen Cheng, Shuhui Qu, Janghwan Lee",0.0
4caabcee97045960308fc8372a611d36211e5b14,Informative knowledge distillation for image anomaly segmentation,2022-04-01,,https://www.semanticscholar.org/paper/4caabcee97045960308fc8372a611d36211e5b14,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '74ce29833fba25a02ba74c2d60b18acfeb5b4766', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '168f2b01c996ba7f43416ff6d2c62867fffbc502', 'bc38dbf06fe17b3c81001dcb939ae0f0a432f0b6', '9acc51b06f54b07836fad4cc24633187dc21317f', '1728cb805a9573b59330890ba9723e73d6c3c974', '441555b5cd09703e55c03e70bd2c9f82c0ffcf9b', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '271a667fe50bcc779c254774e8ca967faa054a83', 'e1a03f6b28ecb5b49db6397cdcbcc2adbec35df8', '1c46943103bd7b7a2c7be86859995a4144d1938b', 'c47fb40c71a70242c1320804139e1640e940e6c0', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '48f9a48aa5b1230b05a443d2d531e6441a541686', '9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08', 'fb52b5d8c07326cc8f618d525ae162e1a89f1009', '71d39d08707e71a6d233e85e864dd9ed4e22110c', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '775247047d0b56950ba5ea77d4a29772eca95c1b', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '08b66b00a9ce6ab8090668f9f848c5659617bae9', '0efb841403aa6252b39ae6975c1cc5410554ef7b', '02805f18989b7e77f30ee13defd6fecfcd0f499f', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '5954f7aee33d7334cfa0516b0b81b41bdaf7c238', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",35,"{'775247047d0b56950ba5ea77d4a29772eca95c1b', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '08b66b00a9ce6ab8090668f9f848c5659617bae9', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', '02805f18989b7e77f30ee13defd6fecfcd0f499f', '62b77e5cb85fc61b84edd532f6d65714be152596', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'fb52b5d8c07326cc8f618d525ae162e1a89f1009', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",11,"['Yunkang Cao', 'Qian Wan', 'Weiming Shen', 'Liang Gao']",Yunkang Cao,"Yunkang Cao, Qian Wan, Weiming Shen, Liang Gao",31.428571428571427
427694c173453e816d5d37545bec79b2589e9d1e,A Cognitive Memory-Augmented Network for Visual Anomaly Detection,2021-07-01,"With the rapid development of automated visual analysis, visual analysis systems have become a popular research topic in the field of computer vision and automated analysis. Visual analysis systems can assist humans to detect anomalous events (e.g., fighting, walking alone on the grass, etc). In general, the existing methods for visual anomaly detection are usually based on an autoencoder architecture, i.e., reconstructing the current frame or predicting the future frame. Then, the reconstruction error is adopted as the evaluation metric to identify whether an input is abnormal or not. The flaws of the existing methods are that abnormal samples can also be reconstructed well. In this paper, inspired by the human memory ability, we propose a novel deep neural network (DNN) based model termed cognitive memory-augmented network (CMAN) for the visual anomaly detection problem. The proposed CMAN model assumes that the visual analysis system imitates humans to remember normal samples and then distinguishes abnormal events from the collected videos. Specifically, in the proposed CMAN model, we introduce a memory module that is able to simulate the memory capacity of humans and a density estimation network that can learn the data distribution. The reconstruction errors and the novelty scores are used to distinguish abnormal events from videos. In addition, we develop a two-step scheme to train the proposed model so that the proposed memory module and the density estimation network can cooperate to improve performance. Comprehensive experiments evaluated on various popular benchmarks show the superiority and effectiveness of the proposed CMAN model for visual anomaly detection comparing with the state-of-the-arts methods. The implementation code of our CMAN method can be accessed at https://github.com/CMAN-code/CMAN_pytorch.",https://www.semanticscholar.org/paper/427694c173453e816d5d37545bec79b2589e9d1e,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', '309494da0769345cb35ca0b7b0aae8143eee85a2', 'a3b7a9dff171c8e9885143bdbb3c4b1d5bb181dd', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', 'be8c6c69f3e357bfad2987e45b62cff7e7474378', 'd2cb80a6a162e94e5b700a9096f45b91e4646200', '599fd051c9438011ec5b581983c89e8922b4a5e6', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '516668a41d6106232a7cd56d20d3b3da343e5f36', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'eac7287d7ef69252358c1fbddedf123e11012370', 'b7ff3a64e8368bab59cf03be32bc9b77cb22a2fe', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', 'df0402517a7338ae28bc54acaac400de6b456a46', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '77afac8f4d7f47c8b34371d8f8355cefbea1d4f6', '32f078a7478d1ec2169599500a4507aceaccdda7', '3bb5a439a0d610a7eac68f73068cdd278b8c9775', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '2a505ae2db0810d8b5a2585cf84219ef4b614865', '355d44f53428b1ac4fb2ab468d593c720640e5bd', '792250ae660b7c25f85eeea7dcae623e4301d97c', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '70f9968a356d840040a1c9207906f60376dc6bd4', 'aae932cf9c2434f52b03991fcab050a61a960d48', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', None, '3f9bf69ab107d97509878ac09424095202acefcf', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '8381157eae4fbf8908d0312a9642f8e69e944449', '731a2844c5af6b072d3b404ecabbb488cdad9d46', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '71ae756c75ac89e2d731c9c79649562b5768ff39', '22a3267240b3018fe34fb465a75f5eee6d35e51c', '0936352b78a52bc5d2b5e3f04233efc56664af51', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",46,set(),0,"['Tian Wang', 'Xing Xu', 'Fumin Shen', 'Yang Yang']",Tian Wang,"Tian Wang, Xing Xu, Fumin Shen, Yang Yang",0.0
053446d434747dfeda598bfe11fcd8f9aa31dae3,Mutual Consistency-Ensured Bi-Directional GAN for Anomaly Detection,2021-01-05,,https://www.semanticscholar.org/paper/053446d434747dfeda598bfe11fcd8f9aa31dae3,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '05355e895988589f19d67ed5de7c727a7de706c7', '84de7d27e2f6160f634a483e8548c499a2cda7fa', '4d376d6978dad0374edfa6709c9556b42d3594d3', '61d3dccb4eca3acf43a46d5c294061ea8069e1e4', 'c43d954cf8133e6254499f3d68e45218067e4941', '8acbe90d5b852dadea7810345451a99608ee54c7', 'ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7', 'f0a0c0f0d6a7ff53abea40a8c0c678ed570bf851', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'fcf43325529c8b1cc26aeb52fd5d7e532abb0a40', 'ab559473a01836e72b9fb9393d6e07c5745528f3', 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', '353ecf7b66b3e9ff5e9f41145a147e899a2eea5c', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'b2b8ab163fb0183325dd3458e3cbaad2f8bf265e', '22aab110058ebbd198edb1f1e7b4f69fb13c0613', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",19,set(),0,"['Hiroaki Aizawa', 'Kyosuke Komoto', 'Kunihito Kato']",Hiroaki Aizawa,"Hiroaki Aizawa, Kyosuke Komoto, Kunihito Kato",0.0
8ddd68ba618c5c0bb327b874cec731ddf6764bd0,Leveraging pre-trained Segmentation Networks for Anomaly Segmentation,2021-09-07,"Employing representations generated by large-scale training in a transfer-learning setting achieves state-of-the-art anomaly segmentation results when applied to the visual inspection task. Current approaches, however, focus exclusively on features of pre-trained classification networks, which are known to posess lower spatial resolution than segmentation or object detection networks. In our work, we investigate whether features extracted from pre-trained segmentation networks can be used to further improve anomaly segmentation performance in the transfer-learning setting. To this end, we apply state-of-the-art transfer-learning methods to encoder-decoder based segmentation networks. Results show that the encoders of pre-trained segmentation networks yield improved anomaly segmentation performance compared to their pre-trained classification counterparts. However, no consistent improvements can be observed yet regarding the decoders of the pre-trained segmentation networks. Together, this demonstrates that pre-trained segmentation networks can be used to further improve transfer-learned anomaly segmentation performance and that additional research is required to fully unleash their potential.",https://www.semanticscholar.org/paper/8ddd68ba618c5c0bb327b874cec731ddf6764bd0,"{'d03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b5375995ab8d679a581ffcc2f2e8d3777d60324b', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '02470bed70e38f6a3e69031784e802007a3a1cd3', '5913d3cbf8c389a8fdfe3fd5f2e880a0da03ba5a', '368c72c2298e5f8276398b2cb198702281eac4f8', '441555b5cd09703e55c03e70bd2c9f82c0ffcf9b', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '8a8cfa45b4c0d071fbffa091c02670b19c94b693', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'fa97c2238a16e9226f386ecffe22095e3d3d9dff', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '82635fb63640ae95f90ee9bdc07832eb461ca881', '41747cbdbed84762dfbfc305254c97021279dc6e', '4d756d1801f89a276c7230fb8ab775ee002c5776', '2e8d62277e40d465343e8dfb32ecc246f320540e', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'c172304a4e95bbc6759dcee3a2b9cca4f840c229'}",27,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '48f9a48aa5b1230b05a443d2d531e6441a541686', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",12,"['Oliver Rippel', 'D. Merhof']",Oliver Rippel,"Oliver Rippel, D. Merhof",44.44444444444444
45535b86c60661dd4c4e4f375abae80937563499,Multi-Scale Patch-Based Representation Learning for Image Anomaly Detection and Segmentation,2022-01-01,"Unsupervised representation learning has been proven to be effective for the challenging anomaly detection and segmentation tasks. In this paper, we propose a multi-scale patch-based representation learning method to extract critical and representative information from normal images. By taking the relative feature similarity between patches of different local distances into account, we can achieve better representation learning. Moreover, we propose a refined way to improve the self-supervised learning strategy, thus allowing our model to learn better geometric relationship between neighboring patches. Through sliding patches of different scales all over an image, our model extracts representative features from each patch and compares them with those in the training set of normal images to detect the anomalous regions. Our experimental results on MVTec AD dataset and BTAD dataset demonstrate the proposed method achieves the state-of-the-art accuracy for both anomaly detection and segmentation.",https://www.semanticscholar.org/paper/45535b86c60661dd4c4e4f375abae80937563499,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '19862af96b6af51e879e6e3f1d3d421af5427005', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '04513c7c0b3a63fde81a996dae064a28d453c17a', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'b1464ca857593c049873421db2f37bf2d0ff676d', '18f207d8dab7357f4f674211ec4f150de1c93a0e', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', None, 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'eb42cf88027de515750f230b23b1a057dc782108', '8381157eae4fbf8908d0312a9642f8e69e944449', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '9775d372bfaf889a395dc714e283b6a179e62537', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'd2c733e34d48784a37d717fe43d9e93277a8c53e'}",29,"{'931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '9775d372bfaf889a395dc714e283b6a179e62537', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '19862af96b6af51e879e6e3f1d3d421af5427005', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",14,"['Chin-Chia Tsai', 'Tsung-Hsuan Wu', 'S. Lai']",Chin-Chia Tsai,"Chin-Chia Tsai, Tsung-Hsuan Wu, S. Lai",48.275862068965516
fa1aa090d09dc5d420d0cce37cea72c21e99d36b,Deep One-Class Classification via Interpolated Gaussian Descriptor,2021-01-25,"One-class classification (OCC) aims to learn an effective data description to enclose all normal training samples and detect anomalies based on the deviation from the data description. Current state-of-the-art OCC models learn a compact normality description by hyper-sphere minimisation, but they often suffer from overfitting the training data, especially when the training set is small or contaminated with anomalous samples. To address this issue, we introduce the interpolated Gaussian descriptor (IGD) method, a novel OCC model that learns a one-class Gaussian anomaly classifier trained with adversarially interpolated training samples. The Gaussian anomaly classifier differentiates the training samples based on their distance to the Gaussian centre and the standard deviation of these distances, offering the model a discriminability w.r.t. the given samples during training. The adversarial interpolation is enforced to consistently learn a smooth Gaussian descriptor, even when the training data is small or contaminated with anomalous samples. This enables our model to learn the data description based on the representative normal samples rather than fringe or anomalous samples, resulting in significantly improved normality description. In extensive experiments on diverse popular benchmarks, including MNIST, Fashion MNIST, CIFAR10, MVTec AD and two medical datasets, IGD achieves better detection accuracy than current state-of-the-art models. IGD also shows better robustness in problems with small or contaminated training sets.",https://www.semanticscholar.org/paper/fa1aa090d09dc5d420d0cce37cea72c21e99d36b,"{'6ec00ff233c19b47ef44dd57cdb22a7385586c0c', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '1b7bd7052bfb8ca50485a9236f2e0d2e9be1398d', '790eceaa2cb59fef2634dad40f628346eb07cd3d', '53ab91cf735af3589c58bf6af09de4e799a6bebb', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '04513c7c0b3a63fde81a996dae064a28d453c17a', '60fef33549f57f5cbb6712a510c3a444ab682429', '656f5f724020d259cec9c70f45bf8fc26aed6e4b', '498e003901f8287e89e5064477cd22dd47e49d61', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '46d5cf70365d48ad38ed549fb44cf76810e8f8da', 'd36efb9ad91e00faa334b549ce989bfae7e2907a', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '522b643c937573aa2b060bbcac28c63378b1d2d9', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'e6df192c9b654bc5cc371c55012cf99d85cb61df', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '0f84a81f431b18a78bd97f59ed4b9d8eda390970', 'f5b0d51ca54fd1b7268486393679dd612d482f64', '97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '1728cb805a9573b59330890ba9723e73d6c3c974', '4feef0fd284feb1233399b400eb897f59ec92755', '4758baad6b22c61682e7f7182bb93723046f36f5', '3bb5a439a0d610a7eac68f73068cdd278b8c9775', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, '41747cbdbed84762dfbfc305254c97021279dc6e', '3517b9824def42f3c723c6c63eda7ade12d25538', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '8ee35ed698527d9695c872e3b76715fec4ef69ad', 'b602ec9c89e38a3f226085d621adadabad96cb6b', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '732c21998e251d64cd58b6a86886ee5907efeaa5', '0c908739fbff75f03469d13d4a1a07de3414ee19', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '1f528877c4d8d5df3b3abbfa64379677d451956b', '3c4f0260a6e35b5d5276ecd3d8c1081aacd161ff', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '4463dc4a32b948f0230f3b782cbfecaf1c9e5b1d', '0c5ed0c30375703306f36d341d31772f3bd5af47', '8381157eae4fbf8908d0312a9642f8e69e944449', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '6f68ce1e03c56c186256dac689a21f6405ae8d96', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '510a24375b5166842cae47f2e54052846704e8f4', '5435a9ab36a308cef10bc725104e8f778ed3a328', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '1442cb4613c99924f500ebdc2a7fdaf2e9080da5', 'fcadb2bac99550adcdbd8578eb246eb9e264ecf3', 'f538dca4def5167a32fbc12107b69a05f0c9d832', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '38d4b5a464652a4afb4f043f141976f5c71c1e6b', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '08f99af9f5d6d351201ee4563e407bf37bc164fd', '554cb0e8a604701ca78f2d782f2a26119eadaa81', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '0936352b78a52bc5d2b5e3f04233efc56664af51'}",79,"{'6ec00ff233c19b47ef44dd57cdb22a7385586c0c', '4758baad6b22c61682e7f7182bb93723046f36f5', '1f528877c4d8d5df3b3abbfa64379677d451956b', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '498e003901f8287e89e5064477cd22dd47e49d61', '41747cbdbed84762dfbfc305254c97021279dc6e', '3d3745f59c6a910ce0b4ebec35d4077792d2f486', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",15,"['Yuanhong Chen', 'Yu Tian', 'Guansong Pang', 'G. Carneiro']",Yuanhong Chen,"Yuanhong Chen, Yu Tian, Guansong Pang, G. Carneiro",18.9873417721519
16737655cfe8e94cb0fa8633255aa3dac3de8189,AdeNet: Deep learning architecture that identifies damaged electrical insulators in power lines,2021-03-02,"Ceramic insulators are important to electronic systems, designed and installed to protect humans from the danger of high voltage electric current. However, insulators are not immortal, and natural deterioration can gradually damage them. Therefore, the condition of insulators must be continually monitored, which is normally done using UAVs. UAVs collect many images of insulators, and these images are then analyzed to identify those that are damaged. Here we describe AdeNet as a deep neural network designed to identify damaged insulators, and test multiple approaches to automatic analysis of the condition of insulators. Several deep neural networks were tested, as were shallow learning methods. The best results (88.8%) were achieved using AdeNet without transfer learning. AdeNet also reduced the false negative rate to ∼7%. While the method cannot fully replace human inspection, its high throughput can reduce the amount of labor required to monitor lines for damaged insulators and provide early warning to replace damaged insulators.",https://www.semanticscholar.org/paper/16737655cfe8e94cb0fa8633255aa3dac3de8189,"{'a7bfb9bbe2e3d6dfa980e5e40b1f447f007984a3', 'b7c8bca92da9e79df1bf9060e028263e770a600e', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'fd7e38e1bb1e6f621a10c0c2648bb0b5e7989a94', '5db790198b9acf4e5efe350acdd814238fcacaa7', '4d376d6978dad0374edfa6709c9556b42d3594d3', '60a1a5b868e3a669b0e916506f3dda7636b2a4dd', 'd69bc4302cc9b17d63329c1bc9b9001901718edc', 'f4ab17c567d49e85d33b313f813e567c7ccf761e', 'c8183ddce60e8413a616dd8aaf9ca185bd6dc9bf', 'facf56ab4cd06ac2970530a0c425df7a6a8a3d45', '0688541ac650568afbb6cb4765d2e269a56331b2', 'b1464ca857593c049873421db2f37bf2d0ff676d', '21937ecd9d66567184b83eca3d3e09eb4e6fbd60', '66040f158933393a22fefb9e6d60f45f0a02b560', 'ba013acca784bfea74241c879e18b72984950493', '9c24454b071bc8e96ea46c5064a7bddf07cca464', None, '732750bec3b4d8c0108d6daed642500765d5c0ca', '4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0', '832807bc2f2bed75295a66aecdcdecdc1ee960b2', '5c8b10ce81e47ca3eca2778f7116f4f26a457d9b', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'b313751548018e4ecd5ae2ce6b3b94fbd9cae33e', 'eb42cf88027de515750f230b23b1a057dc782108', 'dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d', '96d1bf51b3aa118696ce18dc45924e5ca8b9d885', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', '7ad57061bdb6687b58cdc6312be93468a916046a', 'd807119a9d0a5de9bbd750619324ee9dcfac05b1', 'e6fa88f4af68aa7be4ae91940892eee52571997c', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",37,{'b1464ca857593c049873421db2f37bf2d0ff676d'},1,"['Ademola Okerinde', 'L. Shamir', 'W. Hsu', 'T. Theis']",Ademola Okerinde,"Ademola Okerinde, L. Shamir, W. Hsu, T. Theis",2.7027027027027026
ee18580b267693d8cf906d191f07d171248a588e,"Frontiers of Computer Vision: 26th International Workshop, IW-FCV 2020, Ibusuki, Kagoshima, Japan, February 20–22, 2020, Revised Selected Papers",,,https://www.semanticscholar.org/paper/ee18580b267693d8cf906d191f07d171248a588e,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'da3a1dbac9c73973c1bdb832d6030b4802f13a45', '89c03327f45064f1fbfcd152f7fc0148d08d5acb', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '877a0ce8bc0457837e7c43dd0eb99e11ba4d84d6', 'a3a4471e82260f573d240cc34aeff431cf236571', 'e64e2935a7d2565f8d29250fec9f039ed0767cde', '0ab99aa04e3a8340a7552355fb547374a5604b24', '7a8e4e692dcd15c8631841c1efa2b00249023458', '8f10de82e931b2816f227e6044b7f61257d7e1e3', 'cac33f91e59f0a137b46176d74cee55c7010c3f8', '2f4df08d9072fc2ac181b7fced6a245315ce05c8', '29283cc438d42a29d68950c5ffee7009c6efc048', 'bd7d18aee6f43baeda78eea356d2a6497c07c8f7', '8a756d4d25511d92a45d0f4545fa819de993851d', '45b4e7eed084c816e8f7b82fba266919036847bd', '5fc5c5a4e489e781de434567d946e6eb65c44f60', 'c24b4e365e2234a8c2654b6db4dca288b6421a4d', '1c46943103bd7b7a2c7be86859995a4144d1938b', 'da9e411fcf740569b6b356f330a1d0fc077c8d7c', '288f41a655a178bf28d5883f68aa95807edbc950', 'b07c322346fece3023566a18254f4be8b24ef72e', '634ef5b071d48d7bb67a1a7c1f1aad0884046082', 'f46318bf67ab6b30284f125ac8bb6f9a7503595e', '217a21d60bb777d15cd9328970cab563d70b5d23', '126535430845361cd7a3a6f317797fe6e53f5a3b', '3439b34a7b71745d95fcbef5bbc0a64d787cf1e9', '60422427c4273153ccff5bde487304c58ee81ad2', 'fd4defba71c686946351f5e7a090c7aa8136d32f', '50ba65f0dc271c4af6a8423dc6a9c4d91eaf37da', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', '40bd9e5e5b551cea7a81e25a7554007f506579cd', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '09769e80cdf027db32a1fcb695a1aa0937214763', 'e096d2df525de8ed7c977525c04f5092d9b34455', 'c75180ab22b80b7ac3c8853a934ac515313b9aad', '2e32cee268cb8df668f86157e2019fec916f6b07', 'b69fe5a837277ddbea5215d6bacd3a902e9d11ce', 'b1ab9410cd3b10bc5b6f9c7fad90cb29b34a984d', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', 'fac36fa1b809b71756c259f2c5db20add0cb0da0', '74ff6d48f9c62e937023106629d27ef2d2ddf8bc', '9e530267e44a95066d9c99f4776a33f12f4c2ad0', 'c1e472f277a5010be62c9c97ea0ef5327d8622f8', 'fdc50c47e8e895b34722dadcb887d8b9addbf5b2', '50951e021663281c586b2c11e637e21dc1a52d2c', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', '20fdb80044b03861bcd8445c2c0d3b5491d3efdb', '7b82860088d2eee4bb53c2af0b78835701834535', 'ccaf15d4ad006171061508ca0a99c73814671501', '4cab9c4b571761203ed4c3a4c5a07dd615f57a91', None, 'fa083c7ecc63d236cc55bf785a2446704e484c3f', '3120324069ec20eed853d3f9bbbceb32e4173b93', 'a42aff222c6c8bc248a0504d063ef7334fe5a177', 'e632f0c2e5e0b91588b3874889fa2d535ed1d3ca', 'a770dc4141c070e8586c70ada7abd61dbd137164', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5aa26299435bdf7db874ef1640a6c3b5a4a2c394', '074e39a1c533993dcc829d9996c6518608d01e49', '1d3dd9aba79a53390317ec1e0b7cd742cba43132', 'd977ab15dc0d76a2ac31b59682c188a2dbb09cfa', '0709f019c495a97b2a0369ded5ec18fe52e8672c', '9d9aced120e530484609164c836da64548693484', 'bca6cd7c3a09a2317c678a9acc8dc3a0bc83b460', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'aab873234597bc5d97ef31317d8bbf7d7e8ae5e2', '80c134b7d7a3185a29ed803824ee63c12057bb87', '8d8da0c52d27cca72968c0ebbaada074cf4701a7', '7414ee3352cbf78f5a522af6404694056eadef4a', 'c70c6dafc7276177225f4604cb285db07881aa6f', '2eab80b250b58bce19edcac6c6f9a9fab274afce', '80c3b84fddd0ddece79500af5e1afbd2b40e7ef8', '871f47c80e738e9710e4e0f2afb9855f1ee1d6e3', 'fc315b6740424f45a1b1a04131cdfd3f724dd084', 'ab21376e43ac90a4eafd14f0f02a0c87502b6bbf', 'e4e20e7d7f1d488dc98c9c827052eca071d04565', '6c229b997678e9e28e1b8fb45270abe24f42e254', '0bbe1336be701dac110b0d8145e83b87710704e6', 'c520b6253c1d3d2eb29aeb5e300d5d45385c9cfa', '1e4746b90b1fbbdb69a7348b90c0ed6315409345', '39e1c9b8d38bfed261674e24e9ef6bd1695b4b77', '768e0f32723b4bc51500c3c44cde70800208e97c', '339093c7ed71919ce59a7e78979a77abd25bad0c', '2f7ae3361b2aafa24fc289252a9cad8f1135edae', 'c81c20109c809cfc47565a9477c04ee005d424bf', '501b6c66c3fe68083be0f1ef31718432496a2c94', '6bdacaf992b0394cc73ff94fcbf6b31483406286', 'f8aeb7ef9646cdc9329b485736625a5324b87015', '5f0850ec47a17f22ba2611a5cb67a30cb02cf306', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', '3aa21de1a7c97e0458e10ed5730ce160bb436caa', '50c582bff5fb1a515f0e9d5f2104c78769eb4d3e', 'c19c9d693a405ca98d67e5e6697e1bc73604b817', 'd2efe575c931cf923e47ec5c7f444d53aae549cd', 'f5c204f0940e7bd92157e9b29aaa320828194d03', '234edfe687fba9791c4ac34303f0ed34a4baaed6', 'b5f2ee4e890115f7a61821c92b7666513c9b7591', '44e0e1b429c9fe6047844979bd4ea617b80873ce', '84a64f0d9ff4aecbdb99ba83236a3dfc88c5c3f0', '3a83d8595e6727269c876fcebd23ee9ddd524b76', '7d33cfacc334024049e5200815a2c85699bdd8e1', '6b9a94ab39838770a9249c6c92f8857a0dda4274', '7e99d71ec8c32bea7b0bd708951f8bde567b82e9', '9e572e8c011aee0de63e45a0c6fe41e74cb664b9', '231af7dc01a166cac3b5b01ca05778238f796e41', '45db76270416a42517a21c63a77e9c4260fa979a', '5e6c76289330adbf2dfa342b3749058b299bd1ca', '4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0', '7952f7753c12a75c4669bf618a893807f247a179', 'e4f61c3898d4392d9e4fbfa16d993bb94daefb49', '2796c448023b78fd77f3a4b57966f257c5e654c2', '2ba0873996bc8295102edfc5c9613a3cb96e3a9f', '311bc4e48838d8e5ef619df3ce0bc598aba788a1', '5c0edc899359a69c3769da238491f93e7a2f6d6d', 'e15cf50aa89fee8535703b9f9512fca5bfc43327', '598fe25743f9492c5c1ba30274ea446f65426d85', 'e4345c7542443b0ca6ff287d34238a2ee88620bd', '07b726c0cea3fab4262521f44d2fe3147283a283', 'bdea06b8b46d87cf677a6014f9a35b8c0e078347', '3036bae2d3bdff4cbec5a2f59a6c7cd8c09fca4c', '168c64fa2f42f1683ee2cdba9621ac825f5d946d', '874e55f90fb47f67d3219f9fa233d50c7e5cf976', '471908e99d6965f0f6d249c9cd013485dc2b21df', '848938e6199bad08f1db6f3239b260cfa901e95f', '8bfbe564450bd2f1188cd23486a3503f02d24872', '7922b7c8adab2b469242dadc1e1b73e3bad7ba25', 'e81d2f6f029b22ec0a021a37ebe17a9426216aca', '836d5ddbecdb51f9ca21255743e399a267f7f6a4', '744fe47157477235032f7bb3777800f9f2f45e52', 'e94655ad5216d966fc1e0793b96e6df0caca0bf1', 'e452bd6870c883fc6da667c2450e8d39d0ab8152', '6c7cf406a47048730c1a08d46cb0166b16566524', 'b20e564edbef25009fa1baa2c369437c89147e61', '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'f364570d1892a9a8327778b63b064bce4fb22bbf', '58acc16bb633fd0cef2d53e0ed35f6eb4956ff89', 'f6b72b81a13678dc00cdfd66dfe8ae607046e098', '5eb4c55740165defacf08329beaae5314d7fbfe6', '339505e355043d0cf8191242511c0c2d837dd595', '96350ffbd6e201cf21f509401148ea7674c6e82d', '5ae09141458cde3dfd7630f9c26b9b7894479b92', 'adbf573fff1a63ce417561ec12fa404b6d3fc687', 'caa74faf3b57647d3212cabf2125a6bd5442ad17', 'b1afd5740cdb03295f14e6c993b8d36844956dce', '7beb0b1a5f30f9a2ef6774d787241ca72c78b77d', '8388f1be26329fa45e5807e968a641ce170ea078', '7574b7e5a75fdd338c27af5aeb77ab79460c4437', '6ffcfd38af04468e0b885e575e9cd755d3ec7052', 'fdb98f5a7015de0956ef8d4e468257dc3079b5e5', 'c7a4ec359a3362ff377e0ba1c97a57c9eee053d9', '162ea969d1929ed180cc6de9f0bf116993ff6e06', 'a9ec68a9a8e22cda27d86d18efe7c5d551a0dcf6', '34eec4cb7b71b8533b2fe1e34c65786b0c7c0e4b', 'ffd4c27826aa60bd2a5511666cba60b2d09b2f97', '8dcfeeac195424c49832be94f3f4c04b8c173da2', '8acbe90d5b852dadea7810345451a99608ee54c7', '74e81a3e457fb5a37d1b294793453d09aeeeade7', 'd1f6e1a666d3d87171f9f1fdc453339e6520f40c', '9299ad70f81789c8b681d3510f2d5237d4717482', '1a3e542b908e6af7923b04d4738e45e5bac10dcb', 'e9d694da176792c0f16acc8e17afa49680bd4801', 'b3b262de503bd160ffcfd33e180d4e56fb41e53b', 'd384dbcda90fddf9c345f091a45e0d730d3c1033', '908091b4a8757c3b2f7d9cfa2c4f616ee12c5157', 'd1a7eb1666c51860777e1a0d2763c0ae91d004da', '529d10764cafcc57afe5b8ad84a6b1921b41c207', '9ba98e77c35bf2ad886122b12c8d6d5e199e3acf', '2097923990ad6d188bd9afc69a1f8abc0580076b', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '473ef3eb1bbc9d8185e84dd9b13bc2b4438fdee3', 'f9c2b4d7650024b91e78acf84039e4f241da0a90', '5d1321eff5f4e4dbf599a97f213383b27e28e8aa', '1b3bcb1d1880bf1c1b2e2bc580357357a8dd1329', '540339c32eaf41962740583bfa415a5a0ff9d932', '33aaa25346ba6796a0055a42cfa1932053878ba3', '0f41ed3b0b0e8b17f02afcc1e5a24d3580f28ae9', '44664932b3f01bcfa781ab7a78632b4e2bbf71a9', '72e7f4edad44394d2bf63bb134707c8f991761c6', 'c7d33ee754054a0a8e8f38175979a9c1c78d89e2', '9bdab4b9cb5e73cb1ce67a3752b21347f183f456', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '2f087cdde2ea34b911b3e9917b90fd3d42070eeb', '45aa47293d70bbed4d93725ed9858bf6dfcd81a1', '80bfcf1be2bf1b95cc6f36d229665cdf22d76190', 'e804e639e76643bdb0f472d41f63990fd27b5488', 'e67c8fc52a82633e6781ca0df5002d7fa1165bd0', 'cc10002d0a8d7251c65d89268c81c23304216ec0', 'b8ff9b30a34d8db32ce500ea2329fa423a50614e', '9db13f90ca2d5977b0cdde75a1fba36bfb989082', '2f27494962b473158eea1b5edd917fdb13de59fb', '094ac7510d1723cb9c2da01db47291322aa29025', '364d9e665c163c47c307495135e2b69d3cf0529b', '36a50144f6a671bccdc28417891bcd36a55ec3fe', '261a2cb5ac0b550f8174d3d75f436c6d7b73e872', 'b16a583ee173f222c690242aaff7925838893fe8', '4f57f5d1c2ab1e3f2a996024f7086b8cc4abce5b', 'a4b09fe27dc38a7646877440d76947cdcc895d4c', '27a8487e320a744b3c6cd63f9eee75dfe0eb8296', '61d3dccb4eca3acf43a46d5c294061ea8069e1e4', '1a2a770d23b4a171fa81de62a78a3deb0588f238', 'd19c274cb0e8b70d6cbeb138e13269a89ebe7889', '96dadc1ba64f470def8d39c89ec06b353f1d776e', '61008a07996a7daa84d4923de293bffc5f50f4d1', '92807212aa51cd1d8323edc4d65e44bff1b1c25f', '5cdaac0ad7d74366d33474abeac809115a3515bd', 'f5ff57d6c63026675a54fff3071f9c4db48e5975', '4eef6626626131fbef104a8f38efa06772b49a89', '47214fe92eca2618dbbf7da40ad5f18850ee8369', 'ce8c76bfedc5d86faabf0d49dc42a4924f75876d', '2967711a9df8aa79b087e80cfb799afd0d452687', '82635fb63640ae95f90ee9bdc07832eb461ca881', 'c1994ba5946456fc70948c549daf62363f13fa2d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'c68e9f63dd5a652875381aa5028528f4d92b0fc0', '64892a2793505fe02b2dcc6791d8936aa99eb86e', '12b7699ff0950f55301b4edcf2fcf868aeda6fa6', '406875af5ea47deab3d72e6fba429295dc5ff6da', 'ad655c25e052fa4eeed53421344aca6f239c4c9d', 'db9477cadfecad1d9fa2f0f6aa7d58900b4f864a', '3f38a959708c8cb7f920f02b51db2335b6ab5b1b', '8c328bc048449131d98b545eaa3c99f8356c5620', '5c59d0418d7d21e830e8c1bfacacd69062aa3b7d', 'eedeead944e87708e2120983e6beb1f578617485', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', 'ec490b4930ee2a9892cee95e43c4e24f1d7ca964', 'bcb3e62c913096292d75f7b52b3d595ce70127e2', '5418b2a482720e013d487a385c26fae0f017c6a6', 'a61cd948eee1cddc9353713884f4179d4d61354e', '0d5240b21d07ab0c8fc3192e589b4677a5dc7f7d', 'e2e040d3f75ff4e4c04b281f46163806f80ebcce', '7e7c1ff03a4c68bc9d1ae8f896557fd6bd25ceed', 'ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7', '2175280c524add3e4226efbfada3f63607d02700', '035c0a712e7d153cc138efea14f85e3bb98e11c7', 'f0af6b3292047cf98bc433604a046c5189551d24', 'eb42cf88027de515750f230b23b1a057dc782108', 'f63a796b46d710c301c9fe8e974dea30133eb627', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '25ced017dfdd782451915f25fefb30f2d4298096', 'f0bd3179797eb77ef5252921c579034d68b37e9b', '25d8e3c14c584f02a9ffb8c3b5d91e668396ee1d', '201e15bc49ae2f0618c05cd0cc37eb72ae442fc2', '4ace72f12491a7c06967a6011c4bef004192d767', 'ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921', '05355e895988589f19d67ed5de7c727a7de706c7', 'bc4cfc075e406f9f5c621fe27a3e0002eec4a8b3', '9c6d223eac55c14ef94447211a7855a032beb11a', 'a6f1dfcc44277d4cfd8507284d994c9283dc3a2f', '138f2b16d1bd28097787b4e7d925a866cc0209bd', 'b9e43395663f74c581982e9ca97a0d7057a0008c', '3956886aae467a112de7148ab8ed2514876ac9d8', '1ff64cee66e66cf9c402ad754a63175e8e578c7a', 'b3daa22ab8f6ede403c8acf842fb8a427d3c1e62', '4d53c1e9468581c90cc321e8defeff7486435947', '8801dd50f3ced66525e9caaf2dd84d3a256023c7', '317aee7fc081f2b137a85c4f20129007fd8e717e', '9d7a50cf8198db1ffa3ff6f1df57192ee3f53fdd', 'a750e60a696f934168a022c01dd41d6aecc1a8be', 'ae4e96913be354bd512c242b9340b689923279ea', 'ee07d502c11c8ef8a152b6feef22695249d0764a', '05d308b08d179ca8a04f45aac9613e8066381584', '5f5ca978d1e7004c830a60bce8a0c17e8d5dde99', 'eb58f837f97b14518743a3360cf2e11dd562f394', '7e6957b2a571ece3a752d639cc116c8b54637a58', '23ffaa0fe06eae05817f527a47ac3291077f9e58', 'ef2682086be349565ba812e11f6575f70bcec3d8', '942af80e3bacc95bb2e73e9e2b3853fdb42da406', 'c08ad38a640ab1d575b2cd3a3f6da3d7a2d7dabb', '4dd799688f799cdfc601650cc9578e902749613e', '6ad64519e5e703a14605e0393654a7c49d18efd0', '1dbe6021ddb511b70cfc30373ed9cd699af06bdd', '786388dc472bb9605122761feb628c23fadf0bdb', 'faa98e73eeee551c40923c896817ab640925ce20', '5a16f8887e165eb946e3f681042eff82cd398324', '9e60942aa15670ed9ee03af3c0ae011fa4966b7c', 'b0c065cd43aa7280e766b5dcbcc7e26abce59330', '7a953aaf29ef67ee094943d4be50d753b3744573', 'a7f0f887ec8d089d579c04a4ca3a8fd3e48afb08', 'e712a5e4d83e1d3a3e9d2d8f67c6612e7b40eca1', '26b7cbda277ad63f1c1e3b8e8aa617278c9f0a8f', 'dd6d044696df5e4353ff7c92b8009e1201c85129', '26e2ca763087be09e3799ad294302aa91077942d', '70ec156f7e6de0275c7e4e95e35f1bc1e92e29b3', '1f9a9153f15655ea8a07186d42307d6d43032d7d', 'd78b6a5b0dcaa81b1faea5fb0000045a62513567', '9e8db1519245426f3a78752a3d8360484f4626b1', 'bb30a99fc4f26002ac18f66dfc64e86e5e55a664', 'e8a5f27e7805f8de84ea008d59452ff864271696', 'edb61be35363db146cb8e0d915d05ed93d020bbb', '7670002597ee3ea8678bb995d4fd2783fee21dbb', '361b19d2c00d086fa8ef860374f5e1d862fd2f30', 'ffa1cc9b8cdb532dfe5c73230d561edb853d67ff', '920bc904bd46a318d08009eaa0f9f2acd4f5e356', 'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '0a38dbd2f804da5869611ad00947ed877e5f2cc5', '571b0750085ae3d939525e62af510ee2cee9d5ea', '84de7d27e2f6160f634a483e8548c499a2cda7fa', '591f4c766677116532f38f7123dc2fd36a353217', 'e1ec11a1cb3d9745fb18d3bf74247f95a6663d08', '0a5790a82cc5512e9a44b87c13d937add5443b4e', '0bb74a5d81e237a941129ee7a9825ba9964a340c', '4019017bdba93208d8018482a6d68ba730798ede', '8445898c13b89eefd858fbac9734a0fc10e0bcc3', 'b0ddb08612a5483000e8e58ffa12a1660a411a9e', '7ffdbc358b63378f07311e883dddacc9faeeaf4b', '0b4619355f37adbca1ede364eac7c2ac377e6b9d', '9b5c6848c0f280f9aa046b4d705200ef6b24265d', 'f9b90d3c1e2c3d0f3d9a94e6a0aea5e3047bca78', '41d08fb733f3e50ac183490f84d6377dffccf350', '6933c70c747e6a8103f68f1a1db80185401d537b', '93cff536e6844f7b581bd6c947d6fe1d098919bc', '7eb89cbdfdde8cb6071a48fb44173a757f51bfd5', '9cb1c501144314f1514c9f9e6a6687fbf4880f8d', 'ab559473a01836e72b9fb9393d6e07c5745528f3', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'b55e4b3b40aabefde108f3c417c1b1774f6b39b7', 'c512bc16b5635822d233a334767bb3c554027925', '111fd833a4ae576cfdbb27d87d2f8fc0640af355', '22aab110058ebbd198edb1f1e7b4f69fb13c0613', '20f1bb0d8cfed0b2f9c698c08330f30444d4710c', 'f70d2bf71770c4b30ecd2258782b0cb3395a0721', '595380df34e54ed97de85200c424c207dc1bdcfd', '284486850a28ce4b1f7d1236b7b926be8306391e', '7f4e7d7240dec6d4187eccd428e706f3918f4622', 'c7191b7ca5c4e7504bf3fc8666d732ea7d380d92', 'a2f9c78b094ccd50cbb175193d2993735d39c6a6', '38cbe7360a453f9ec32c629c235e4f065b1690f5', 'f01b512314420d53fa4209d732aba1ed77977730', '0cd92defaf84263fe06d521f47e05acbca7b803f', 'b365b8e45b7d81f081de44ac8f9eadf9144f3ca5', 'f2264d05eaf42572bfdd779f72cfadcafcc0c5f3', 'df24af3ee6a5cb289cff353611ff05855d9b22c2', 'b5ebf37ce170f13a905f7feba9fb7096b49fb8b3', 'af669483ecc4d16df9715d1db67a84cad5a97bf5', 'b5d96c49651b892a44db9cdad689feedf4b12ced', '20f915dcacd8963cc9c9020c1df09cf7393c8b01', '325c5ee0186211648654f0b6e84e8dad4b384701', '6c7e53facbb5cb00885c198acb5ea8d8d14c8c90', 'b61a3f8b80bbd44f24544dc915f52fd30bbdf485', '40afeb2bd3138f0b5a5036a6fc5afadcaf325a8c', '63b059cdad77906ff381515b3cfac21757e5e64c', '24b905c00a8c0f3e6e2d6d54ca438a9fa27d7aba', '343442426f69e53a997364e85ae1a6b76e9ea0d1', '01e52e55c5e8c65668f84dc9e2411df0d2c79cb7', '56b464d01ac9f516e7078426327e31833010205c', '5cc27ba9ea61c3240eb249fc9b56dd42b7fb86e3', '29d1b9a6e6ff0a4216d10dd31376467d55e788a3', 'b6438f4fc1b0e89d1319f2de1ca663255b8ee190', 'deebb63fa7f7ed1ffcfbcdff733b8652736d1e6f', '998e4143748c9bc4b2869b7e555a576d2947538d', '29b356abbca4b74f5d87508c17b5d940bb9e5cf5', 'e1ed45247074aafc0fed0b1c7253a3e96785b583', '61ce67533d2dd6605c907146658ccdbc4778a5d8', '0ee785e587debd357f92723ba9f2983c9636f28b', '4d376d6978dad0374edfa6709c9556b42d3594d3', 'b158a006bebb619e2ea7bf0a22c27d45c5d19004', 'd5797afa6cc07daba9e1414593595e8e3f41fc5c', 'a87cc499cf101b3697cacc65094b4b6590e0d061', 'c92a91278cc82b35049378f859f082575ec76d0d', '39d80c420d5019595540c780c7173a6b73b73cdc', 'd25c65d261ea0e6a458be4c50c40ffe5bc508f77', 'c13cb6dfd26a1b545d50d05b52c99eb87b1c82b2', 'b3df1ffb8a6856f20be51243406f2fdbe2a335ba', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'e52f35ff2975f273dccaabe8e0dcdf6d3926f161', '59d4cedf1b990b5d053e513a01c9322fb08e8083', 'fb8cf663a71bf31f59557a35d36aaf8c465b50af', 'c433d6963362c7146b3d248d4081ca54839ba56b', 'e2e039cd7dd148ccd361bd9e9b490e8d5b7749d3', '53a4d3f674607d8df60c3a3b183ed435d135295d', 'c92236a472a3eea843ab4c856002098e7fb2d8a3', '1db6e3078597386ac4222ba6c3f4f61b61f53539', 'ddfe21619e3186cf4215ed660858317a52cee123', 'adf696769df0e66735d4946e5bd484bf542a9dfe', '0eafafc3bb6c0cf90f18c8c63c7b3fc492a5c56c', 'f3d9774850cbd955f2376b61894db91e680b755a', '3ed7d8825adc152f93991ff8c4e3c6517f2899d6', '7534dfaaa049f59b4fb1582852d8012e4d8c0ab8', '064709b719f527535746e776999c0448d8944013', 'bf17dd8b1221e6c0221d393b6f6a7d313dd8f56d', '1788c7d96b8842915f5e9a48a0f0f5a55a25ec4c', '211642f9ae25bfcd68bb664146f448b4cc84a9ec', '616b246e332573af1f4859aa91440280774c183a', '10b496ad48513f8585aa56f2c682159357858960', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '89a4618d9af12b98af656f9d620256e7cfcd4a1c', '8b5ff695d2bafa45f6bc50927b3142cc93601c59', 'aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406', '8126ff46baccd2b748a2d91371f1db4f291a6587', '64c8217cc46df711f294cdd823d04ff2cc602280', 'e83da70c3e21f552db836761c40510b35ae4d228', 'e9de1bc61d25a10c27a8aae840b00f15f578438b', '1b67ba788a63a6fa007007ea6f8494e60f45f080', 'a9032d632e04399e46efe0668d8b19993aff6dbc', 'c289204917272d21915c6c4859d5f48a65cf80f9', '604c77d3dad385fcabd418d2ebeadb7ad0791b12', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', '344f8b60de22a69771486c38c0bcaa71ac95a1ff', 'adc4e63b58cf4092420533fd877b8c29f8e2ec1d', '38b6540ddd5beebffd05047c78183f7575559fb2', 'ba3114a33e1df41b75865ac4495ec18cb40e5b88', '5f0c0c8fe0a7a36f7545194a197bc16f22b0b93d', 'b81314337371900a93a81e80459efc71270ea408', '5a6e62b8b961ffee3d86934a94c6fd51b787b8eb', 'd887c44a1241c3d400fdb4cc95deca4c4565783d', 'df5b2c4b05d110c34ae97a98eb2150ad72c46958', '9e776cb92b2501a526d2afa4ec22547521a168ac', 'b99a389eea084b718a6f7888bc84806e66df46be', 'ba5ed8526b5c7e4ae3c6ebd652f245f23dff0af8', 'b4035bb1dc4514a72f069d911011ab5845ca1591', 'd689d31745c4b5c258014d3a8397f8647d66271e', 'cee8e66fb21c5340debdab49350699e68b5be352', '5c8a6874011640981e4103d120957802fa28f004', '43e0a0bbad8c611f43c6ba8198f2691e6d89716c', '9074834849f166857bc40320eb0f2d82e82f3dc9', 'd6473533e89e5f946a6ff3ad07c6a74ee9b47672', 'c9aca7e2fcf61fde9bce30af7d104010bee98e62', 'b8084d5e193633462e56f897f3d81b2832b72dff', '4c8ca80632002e4b42b5e12d1c1c729dc52a9d71', '0bdd74925d662a78efdf130d953dff97a131d12a', '8ad26e30fa4a86db68028e49f5b19a136cc3b5dd', 'ba0dfca191265ffd6630291dcd59c14150e8b22a', '428db42e86f6d51292e23fa57797e35cecd0e2ee', '9217e28b2273eb3b26e4e9b7b498b4661e6e09f5', '8a3bf4d403a39ed33f0fa8cf78dc906d6130595f', 'dd4d0deada31ff5ff7495cafce16ff50ad99b0c0', '59a2793b12cc05533468dba546a28c5f7f98bbca', '460aa06503000f121f6eb8970e4c0ba5f1386f50', '96cd35fcb8862ac6b309931a30be69fbac555123', 'da5eb8d6f2eeab595716cd57b9340d06c761a981', 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', 'eac6c20f44d02ec2e27fb6629e938446291cdce1', '350d507f5d899e4d7293b1aa951aa0f81b9fd30a', '8031dadcec9ff338e6c136ef43aac8f7d6931980'}",436,"{'e021d59638966a6fbb36854cc2cf1045de7a62d2', '1ff64cee66e66cf9c402ad754a63175e8e578c7a'}",2,"['S. Jung', 'Simone Diniz Junqueira Barbosa', 'Phoebe Chen', 'A. Cuzzocrea', 'Xiaoyong Du', 'Orhun Kara', 'Ting Liu', 'K. Sivalingam', 'D. Ślęzak', 'T. Washio', 'Xiaokang Yang', 'Junsong Yuan', 'R. Prates', 'W. Ohyama']",S. Jung,"S. Jung, Simone Diniz Junqueira Barbosa, Phoebe Chen, A. Cuzzocrea, Xiaoyong Du, Orhun Kara, Ting Liu, K. Sivalingam, D. Ślęzak, T. Washio, Xiaokang Yang, Junsong Yuan, R. Prates, W. Ohyama",0.45871559633027525
19ac86e7ac8d42f02e6936b7ee820ef6cc1ff752,Improved Anomaly Detection Based on Image Reconstruction and Global Template Features for Industrial Products,,"Anomaly detection in industry applications is a challenging problem when negative (defective) samples are unavailable, especially in the case where there are missing parts or foreign objects occupied a relatively large region. Conventional reconstruction-based approaches cannot guarantee the restored image being a normal one, leading to poor segmentation results. In this work, we propose an unsupervised anomaly detection approach to tackle the problem of large-area anomaly detection by incorporating global template features into an Auto-Encoder like reconstruction model. In particular, our model infers the value of each pixel based on both the surrounding local-neighborhood information and the global information encoded at the same pixel position. During the reconstruction phase, any abnormal features are then replaced with normal ones, avoiding over-reconstruction of large-area abnormalities. The experimental results in comparison with other methods demonstrate its effectiveness for industrial anomaly detection.",https://www.semanticscholar.org/paper/19ac86e7ac8d42f02e6936b7ee820ef6cc1ff752,"{'efabba68912e88a1eb2e9714ff4681b8478ceb83', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '2a417a16473e2bcb1c98cd7814bc106760925e60', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', '46786ce31ff75adc402cabd0df489bba43b5643b', None, '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '0936352b78a52bc5d2b5e3f04233efc56664af51', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '206c2e79b5f1b4541b85f47517666961ed49500e'}",17,"{'2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', '46786ce31ff75adc402cabd0df489bba43b5643b', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '206c2e79b5f1b4541b85f47517666961ed49500e'}",7,"['H. Tang', 'Guanghuan Hu', 'Wenli He', 'Qianxi Tu']",H. Tang,"H. Tang, Guanghuan Hu, Wenli He, Qianxi Tu",41.1764705882353
a823665b0fcd3f64fe08260d0da4e5ad49e19992,Improving generalization with synthetic training data for deep learning based quality inspection,2022-02-25,"Automating quality inspection with computer vision techniques is often a very data-demanding task. Specifically, supervised deep learning requires a large amount of annotated images for training. In practice, collecting and annotating such data is not only costly and laborious, but also inefficient, given the fact that only a few instances may be available for certain defect classes. If working with video frames can increase the number of these instances, it has a major disadvantage: the resulting images will be highly correlated with one another. As a consequence, models trained under such constraints are expected to be very sensitive to input distribution changes, which may be caused in practice by changes in the acquisition system (cameras, lights), in the parts or in the defects aspect. In this work, we demonstrate the use of randomly generated synthetic training images can help tackle domain instability issues, making the trained models more robust to contextual changes. We detail both our synthetic data generation pipeline and our deep learning methodology for answering these questions.",https://www.semanticscholar.org/paper/a823665b0fcd3f64fe08260d0da4e5ad49e19992,"{'63c98a8d300db1d54b06b0c6712011693aac2fa3', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '34adc3101810bc4d5ef84b4136455a89b9c86c27', 'aa5741c74b7fac10680c1cfbdd49d9ffb5751a68', '1d5972b32a9b5a455a6eef389de5b7fca25771ad', 'c3703cef687796c642c41191e4b2bfc8a493576a', 'c9030bab89325427f0fc7d639a0e0b735dd4c3bd', '92e4bccf9ab17244dcefc50a547e87a23e1fd3bb', 'db787640c9b42416ff8d7015546e667e58267177', '8c92054c26fb4c6dd7435bc99fbb8af3323eae1b', '5b8013f4425b6b889a514e95fe6355a83c64d1ea', '022622e024890d6e044ac50e2da6b44c59bdf418', '7705d1e2aa1cf19367613c14159cfaed47a8b74a', 'a5694a6fc3963af6cc1e6ce9afddf4ee96d8f738', '429aea828954ba77da9cb3a1a8dfd4d9ea4d7101', '4feef0fd284feb1233399b400eb897f59ec92755', '10951c1d6e3e8d7cc98593bec2ec8723733ba9dd', 'b4255c0bc1ae0eef07b2d38c3271646f9b3bff60', '502169d1ba1c25abd99c7f5f454474cfaa420a8b', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', 'a573ecb0960d0d2c115c0ad3fc971aa6cdb578eb', 'afe088dc92e0cc905bef086fbd23eaa8f1a43cd1', '12a91c9d4a55fc93f15f4acef078c8908af3c9b9', '185c5278c741c98bea3201866b6c68265a6e1af4', '569ef4e3c9f5ae968fc94000c12d212a2b679907', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '45557cc70cd6989ab6b03e5aeb787e34299099f7', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '3f4b29a0cc51f1ba8baaf99ac008f3acf18d04df', '1d2fe1f395467549a1986490762808b16121bf0e', 'd81421695d5d429a47eefe266986d197d7b313f2', None, 'dad716738c65b0bdada587e1f74486dd992d9a2a', '9b6e4cbf1f8d6fbf09017769ae65ff90234e0aa0', 'd52ff4da17d41ea239de10dd2a68ae18f6a85d28', '36fc659c321e4f67ed274117334ddab41353bb91', '320b227027030fc291de2896fc3c6da49d7614be', '72564a69bf339ff1d16a639c86a764db2321caab', '7802e7e3fcb7bd0a0c44762b53470416e7d290a9', '5d1864d759d272c5dc928b641d113527a3e81f99', '3c47192d40b1138f4e757948c64bb846c38c53ba', '0495d9df8eb84dcdab4e5536179823cd26279949', 'd34aaf35f433dbb51681a91a2eed37a3926346e9'}",43,{'d52ff4da17d41ea239de10dd2a68ae18f6a85d28'},1,"['Antoine Cordier', 'Pierre Gutierrez', 'Victoire Plessis']",Antoine Cordier,"Antoine Cordier, Pierre Gutierrez, Victoire Plessis",2.3255813953488373
8abccac72519a9b393772ff9612ea2446eee11ae,Semi-supervised anomaly detection for visual quality inspection,2021-11-30,,https://www.semanticscholar.org/paper/8abccac72519a9b393772ff9612ea2446eee11ae,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'bb2d6d2f2ab11f6117020c24d190279014233910', '8ac5b3cb778d34ac2175d3cc08eb46c96b949954', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'b0e5ec93c2648ec25a5afd51dc6ba9f171615abd', 'bd2818b607cbad13a8e573434ec9599bba30821d', 'a29f2bd2305e11d8fe139444e733e9b50ea210d6', 'f6260978f30443388f4df5f7ab7c267a06edb750', '5eb11520c489dd1fdfad384ba6caa8446af4cf30', '1da1abd55f12d3cf015a43dd2cf7cca5b85fb8a8', 'e62a40492cad57f859a07891cc43eee4d31f3a0b', '7b09e8039adb50bd453f08fb690f56a7a22f9d5a', '128d8b6d1faf9b58bf1349559c11b2988c6f0a5e', '03a5b2aac53443e6078f0f63b35d4f95d6d54c5d', '71b7178df5d2b112d07e45038cb5637208659ff7', 'c7ecc47b4c982e1127c8742c6715ea099b3a799a', '27c2b5fb13f01c1b809de2ae2efbdb14c4fd0763', 'e50e1e9d9f436b707a899e40c884af529cc13cd1', '7039c82cbc186b8232fdbbde5d47cf96883dbd87', '25757e7819eeb8829d3524474f973b79befd7b59', 'd1edd4c9305cd4e080312ba28d8242a5a49cbd99', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '57fa261e2b0d961aa9408ee64fd5ccc6382c99b6', 'd99a736f3488278e6c1fce291756fb027b7d4764', 'f8efa979a9c513f615e086e75aca7e7225157587', '7072ff35ac2b3aed22f6404928f619d4ecd2a25b', '9bdc92e5a9abfc5302c30d905dd011e9400d6fc8', '35a48d7099f2fd8c40e09de61e509ea0a846cbef', '6df78554ce36056bcdca4012768bdd877855a1f3', 'c4741afdffe56dc66e5bf6a73d85d60db40b8de9', 'd95ded0f2ca2cb74606f6ab8f37211e6c57053be', '2910bec6d4de87e22be5119cef3c488d2ae50e2a', '5380f83db62e7ed55d199e2e5f4bb155d92877d4', 'bc5f19883a01273c21d86248c97672f624d603eb', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1237ef615cd34e7ba261829992c49fc778190541', '5ef32f47c30377fea9cd8af63fd9b72e26d3ae95', '8fd0e087b07a0551611bf9f9d8b93cfb7f823653', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', 'f5e4c1992820b944fb0b4915a6460ecca6fc295e', '424561d8585ff8ebce7d5d07de8dbf7aae5e7270', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",43,set(),0,"['Paolo Napoletano', 'Flavio Piccoli', 'R. Schettini']",Paolo Napoletano,"Paolo Napoletano, Flavio Piccoli, R. Schettini",0.0
e26851c89afcfb1a0fe00292590c9f6e830c4ec0,Beyond Dents and Scratches: Logical Constraints in Unsupervised Anomaly Detection and Localization,2022-02-22,,https://www.semanticscholar.org/paper/e26851c89afcfb1a0fe00292590c9f6e830c4ec0,"{'6364fdaa0a0eccd823a779fcdd489173f938e91a', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', 'd3b614f11969127a08447c41257b3a7b58766d18', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'a3b041214f751557b10d63b9c0f753f75bf5d1b2', '71b7178df5d2b112d07e45038cb5637208659ff7', '35a48d7099f2fd8c40e09de61e509ea0a846cbef', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'c8924e3265e3f16af3177e619cf68a5ef764442f'}",13,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', 'd3b614f11969127a08447c41257b3a7b58766d18'}",2,"['Paul Bergmann', 'Kilian Batzner', 'Michael Fauser', 'David Sattlegger', 'C. Steger']",Paul Bergmann,"Paul Bergmann, Kilian Batzner, Michael Fauser, David Sattlegger, C. Steger",15.384615384615385
d9a6e15cf36730a3d6152c49a26fcc3ccd5fa31f,Detection and segmentation of image anomalies based on unsupervised defect reparation,2021-07-24,,https://www.semanticscholar.org/paper/d9a6e15cf36730a3d6152c49a26fcc3ccd5fa31f,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'dd8502990c6a7c40e95237be1f22c0fc3ac64e39', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', 'f758105945486ab89bb569130ef778ef9d43d5bd', 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', '588fae3352c2ef5654f346e37e9da0b00840a55a', '1d552c84152b278d4397d8efcfe108022038b646', '7342236608a62494ce357e95d5ebecdf8657c357', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '8a3bf4d403a39ed33f0fa8cf78dc906d6130595f', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', 'a1b3d8a94323122d63a1ec31c1d722d30c509cb4', '35a48d7099f2fd8c40e09de61e509ea0a846cbef', 'd21ebaab3f715dc7178966ff146711882e6a6fee', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', '6b0bbf3e7df725cc3b781d2648e41782cb3d8539'}",23,{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b'},1,"['Wenting Dai', 'Marius Erdt', 'A. Sourin']",Wenting Dai,"Wenting Dai, Marius Erdt, A. Sourin",4.3478260869565215
c57f635178c2c194723c5e0b899e4894ec68682e,Proximally Sensitive Error for Anomaly Detection and Feature Learning,2022-06-01,"Mean squared error (MSE) is one of the most widely used metrics to expression diﬀerences between multi-dimensional entities, including images. However, MSE is not locally sensitive as it does not take into account the spatial arrangement of the (pixel) diﬀerences, which mat-ters for structured data types like images. Such spatial arrangements carry information about the source of the diﬀerences; therefore, an error function that also incorporates the location of errors can lead to a more meaningful distance measure. We introduce Proximally Sensitive Error (PSE), through which we suggest that a regional emphasis in the error measure can ‘highlight’ semantic diﬀerences between images over syntactic/random deviations. We demonstrate that this emphasis can be leveraged upon for the task of anomaly/occlusion detection. We further explore its utility as a loss function to help a model focus on learning representations of semantic objects instead of minimizing syntactic reconstruction noise.",https://www.semanticscholar.org/paper/c57f635178c2c194723c5e0b899e4894ec68682e,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', 'e72f626074252b7e17ebc48d9fd4a4cd9d231359', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '4306ca8c940e3860be8c75e3e012cd9bf58f4b58', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'b2431e63e5dec9d4819e94614c6f497651adde02', '5db790198b9acf4e5efe350acdd814238fcacaa7', '9ebb5c0d6d54707a4d6181a693b6f755ec8a45a9', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', 'c8924e3265e3f16af3177e619cf68a5ef764442f', '6d96f946aaabc734af7fe3fc4454cf8547fcd5ed', 'd1734a69c7185ba79250795c55aab2f6d168f780', '0d2336389dff3031910bd21dd1c44d1b4cd51725', 'be9a17321537d9289875fe475b71f4821457b435', '355d44f53428b1ac4fb2ab468d593c720640e5bd', 'f1aba0cf4ab82a01ee2aeb6a1f43c4bafe598bb7', 'd47f8587ad5080c831548cb3f36d7745b545882c', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '37c59035e9985cda2321b2bdcb4849335210ac85', 'ccf415df5a83b343dae261286d29a40e8b80e6c6', '8af51d2d74a40ff1c2bed8bba36b7f957d9a1af5', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",25,"{'48f9a48aa5b1230b05a443d2d531e6441a541686', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",2,"['Amogh Gudi', 'Fritjof Büttner', 'J. V. Gemert']",Amogh Gudi,"Amogh Gudi, Fritjof Büttner, J. V. Gemert",8.0
6a4f7514cf25a36b746b09eab4a2576a12961cb0,Catching Both Gray and Black Swans: Open-set Supervised Anomaly Detection,2022-03-28,"Despite most existing anomaly detection studies assume the availability of normal training samples only, a few labeled anomaly examples are often available in many real-world applications, such as defect samples identiﬁed during random quality inspection, lesion images conﬁrmed by radiologists in daily medical screening, etc. These anomaly examples provide valuable knowledge about the application-speciﬁc abnormality, enabling signiﬁcantly improved detection of similar anomalies in some recent models. However, those anomalies seen during training often do not illustrate every possible class of anomaly, rendering these models ineffective in generalizing to unseen anomaly classes. This paper tackles open-set supervised anomaly detection, in which we learn detection models using the anomaly examples with the objective to detect both seen anomalies (‘gray swans’) and unseen anomalies (‘black swans’). We propose a novel approach that learns disentangled representations of abnormalities illustrated by seen anomalies, pseudo anomalies, and latent residual anomalies (i.e., samples that have unusual residuals compared to the normal data in a latent space), with the last two abnormalities designed to detect unseen anomalies. Extensive experiments on nine real-world anomaly detection datasets show supe-rior performance of our model in detecting seen and unseen anomalies under diverse settings. Code and data are available at: https://github.com/choubo/DRA",https://www.semanticscholar.org/paper/6a4f7514cf25a36b746b09eab4a2576a12961cb0,"{'97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f', '162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '1b7bd7052bfb8ca50485a9236f2e0d2e9be1398d', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '57b2198f9a8df773425aa6cc88c9870cb07779e2', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'f6a4b57eb5850b8457ab1aca799943d256f9c00d', 'a4a0a1e2b573affc16de38b7fff91f6e2507140b', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '599fd051c9438011ec5b581983c89e8922b4a5e6', '53ab91cf735af3589c58bf6af09de4e799a6bebb', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '732c21998e251d64cd58b6a86886ee5907efeaa5', '232b26f231122f6332d66244e5ad61d8225312a2', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '5db790198b9acf4e5efe350acdd814238fcacaa7', '8109587a56d53c6ba30fe19ba9aa4d9213ec91a0', '1d3258abdfdc9262a3c5736a4619869a39d17120', '4758baad6b22c61682e7f7182bb93723046f36f5', '3a712fe261cbc40089048b60b36e5bb99781552e', '79cfb51a51fc093f66aac8e858afe2e14d4a1f20', 'f19092561296244e1dafe7d799e7906e96a63773', '3471032918f2e6fd65677ad491a79ffa14b1c289', 'b44313836f435c8c774f9123cc29a38ad8deb7bd', 'ed17929e66da7f8fbc3666bf5eb613d302ddde0c', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '73c07e0a998576bb9d9409e5eed713788c0be037', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '93040f8a5d10e8fde279e18d353aa3dca2873900', '0820ccfdba775c304bedb9c3d82ee8758e0a416b', '04513c7c0b3a63fde81a996dae064a28d453c17a', '267502d21b44884570fcd95a855821cc3e86e6eb', 'bdabc13bc819f84356eaeb7b087855f5457d990d', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'a43f7d6a751a6ad8667272f1176d2f15dbd8feb6', 'd094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c', '6af440915b8a0718c93be1cf61905e41e620484a', 'c48def9076e58095c4aea49a8daa931af1990701', 'd3b614f11969127a08447c41257b3a7b58766d18', '6ff2a434578ff2746b9283e45abf296887f48a2d', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '0c5ed0c30375703306f36d341d31772f3bd5af47', 'bc4136536e7a80c01120bff309160936b6b95eb1', None, '41747cbdbed84762dfbfc305254c97021279dc6e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '10ae15147d0bc0d6d06ceaae28165bf8646ae478', '5d90f06bb70a0a3dced62413346235c02b1aa086', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '72564a69bf339ff1d16a639c86a764db2321caab', '8381157eae4fbf8908d0312a9642f8e69e944449', '8ed98bd58c799718d6fd389e2218bb89b1ecb9d7', '736018160f8e6f6bd9b2a9101cd13ee67e573097', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '3cf2a7f796921e01e6e794da193a244c3b793b04', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', '759d9a6c9206c366a8d94a06f4eb05659c2bb7f2', '180300ff8282220c76c7c41ded4d9d8c1be4d3fc', 'b602ec9c89e38a3f226085d621adadabad96cb6b', 'f24dc0f3c1cc1da6c4fd12e1a65f55a6d82bb8ed', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'fa1aa090d09dc5d420d0cce37cea72c21e99d36b', '491b149544eff61778c216a4eb869ec0b008f346', '598fe25743f9492c5c1ba30274ea446f65426d85', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '6a7364f6ed2846ea2b705336a4c49dd287102a50'}",73,"{'4758baad6b22c61682e7f7182bb93723046f36f5', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'fa1aa090d09dc5d420d0cce37cea72c21e99d36b', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd3b614f11969127a08447c41257b3a7b58766d18', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '93040f8a5d10e8fde279e18d353aa3dca2873900', '180300ff8282220c76c7c41ded4d9d8c1be4d3fc', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e'}",13,"['Choubo Ding', 'Guansong Pang', 'Chunhua Shen']",Choubo Ding,"Choubo Ding, Guansong Pang, Chunhua Shen",17.80821917808219
6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d,Multiresolution Knowledge Distillation for Anomaly Detection,2020-11-22,"Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the ""distillation"" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert’s knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.",https://www.semanticscholar.org/paper/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d,"{'0410659b6a311b281d10e0e44abce9b1c06be462', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '599fd051c9438011ec5b581983c89e8922b4a5e6', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '10b219619e88931fabb674037bbb633682775136', '043470c64627c074e1a7634a2508ee7e4ec98cd7', '8bdfb96e2865ad0d1e263f04fc0dab134052d64e', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', 'b110ba174df21a23a9521731d4181261ca5860ed', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'c53352a4239568cc915ad968aff51c49924a3072', '04513c7c0b3a63fde81a996dae064a28d453c17a', 'c43d954cf8133e6254499f3d68e45218067e4941', '8acbe90d5b852dadea7810345451a99608ee54c7', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '10a498003e9204f5fc1328e706510a37e514d8c7', '8dc8f3e0127adc6985d4695e9b69d04717b2fde8', 'dd6d044696df5e4353ff7c92b8009e1201c85129', '8c2087063ace28ce2ca8a8efdd45c637234a8450', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '1df011fcb4c0ad43b5d1ce3b4d867ec1be114cd7', 'a0e8f4348968195c80494b7a4245edb91a252c93', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'c468bbde6a22d961829e1970e6ad5795e05418d1', 'd3b614f11969127a08447c41257b3a7b58766d18', 'a25fbcbbae1e8f79c4360d26aa11a3abf1a11972', 'f538dca4def5167a32fbc12107b69a05f0c9d832', None, 'c2b733a79db700b971327a58ef42699fe8a416aa', 'c09a4d90754628015c311e9c51f4b3ab888c796e', 'cd85a549add0c7c7def36aca29837efd24b24080', '41747cbdbed84762dfbfc305254c97021279dc6e', 'cfb1b0eda682b70c789cb92ced891e38cd2b759c', 'e8a5f27e7805f8de84ea008d59452ff864271696', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', '0f84a81f431b18a78bd97f59ed4b9d8eda390970', '401ec2881b20ce7d6dc07c274a1d8f821d4c3841', '9235d511dea04aa563a577ab236506b8eb8242ff', 'dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71', 'f5b0d51ca54fd1b7268486393679dd612d482f64', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '746cf281d8198310b1242048bf4fd90e0486f1a9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",57,"{'d9d7ab13ce305ccee309c989a2341d72b1252070', 'd3b614f11969127a08447c41257b3a7b58766d18', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '41747cbdbed84762dfbfc305254c97021279dc6e', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f'}",5,"['Mohammadreza Salehi', 'Niousha Sadjadi', 'Soroosh Baselizadeh', 'M. Rohban', 'H. Rabiee']",Mohammadreza Salehi,"Mohammadreza Salehi, Niousha Sadjadi, Soroosh Baselizadeh, M. Rohban, H. Rabiee",8.771929824561404
d9d7ab13ce305ccee309c989a2341d72b1252070,Iterative energy-based projection on a normal data manifold for anomaly localization,2020-02-10,"Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. Indeed, an autoencoder trained on normal data is expected to only be able to reconstruct normal features of the data, allowing the segmentation of anomalous pixels in an image via a simple comparison between the image and its autoencoder reconstruction. In practice however, local defects added to a normal image can deteriorate the whole reconstruction, making this segmentation challenging. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoencoder's loss function. This energy can be augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. By iteratively updating the input of the autoencoder, we bypass the loss of high-frequency information caused by the autoencoder bottleneck. This allows to produce images of higher quality than classic reconstructions. Our method achieves state-of-the-art results on various anomaly localization datasets. It also shows promising results at an inpainting task on the CelebA dataset.",https://www.semanticscholar.org/paper/d9d7ab13ce305ccee309c989a2341d72b1252070,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd891dc72cbd40ffaeefdc79f2e7afe1e530a23ad', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'c61b43acd00d73e58fade68b8eb7c3ae875fc60c', 'd3dd00e24f96bae7ad780ac5fdb0c14194d5cb74', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d', 'ca42e4d7021d4e563bbeae7db35c1ce09fe38bfa', 'e858bcc487cea96695102db9bdafe3c5d4269d04', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '67a3276174a209812a04c539fad8b764168e4047', '06fad023ef0274e7d6727ecbd1ef46887a6806df', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'e763e059cead07d1c03646bfb8cb4a0a75ffc3ef', '2c740e574eea66fdcf473e15ed2c228baef2eccd', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '622107e35327a8759b967ae6a6c654bdab738f91', '4dbe992c46e664d8c4b9c6359dac6e775b9c5b5c', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",25,set(),0,"['David Dehaene', 'Oriel Frigo', 'Sébastien Combrexelle', 'P. Eline']",David Dehaene,"David Dehaene, Oriel Frigo, Sébastien Combrexelle, P. Eline",0.0
604a317e7b99cf6a9d9fb8756eaa7277edf6b7fe,PAEDID: Patch Autoencoder Based Deep Image Decomposition For Pixel-level Defective Region Segmentation,2022-03-28,"Unsupervised pixel-level defective region segmentation is an important task in image-based anomaly detection for various industrial applications. The state-of-the-art methods have their own advantages and limitations: matrix-decomposition-based methods are robust to noise but lack complex background image modeling capability; representation-based methods are good at defective region localization but lack accuracy in defective region shape contour extraction; reconstruction-based methods detected defective region match well with the ground truth defective region shape contour but are noisy. To combine the best of both worlds, we present an unsupervised patch autoencoder based deep image decomposition (PAEDID) method for defective region segmentation. In the training stage, we learn the common background as a deep image prior by a patch autoencoder (PAE) network. In the inference stage, we formulate anomaly detection as an image decomposition problem with the deep image prior and domain-specific regularizations. By adopting the proposed approach, the defective regions in the image can be accurately extracted in an unsupervised fashion. We demonstrate the effectiveness of the PAEDID method in simulation studies and an industrial dataset in the case study.",https://www.semanticscholar.org/paper/604a317e7b99cf6a9d9fb8756eaa7277edf6b7fe,"{'01625cba9f8a783994377d4f35aa765242faab4f', 'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '9cd70ca81b4653aa2048002273c5ac9c36641390', 'c123cb0b034211825ad992ebbfe406c1d39d3bb2', 'ce4e9cc4b1616ad5574d8d33cd88ffb74ec44473', '3e7be940c471a275c90e09d71e565919e2ec5123', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', 'dac2fd7011dcd83590a75cae6fdf428301c97ed9', '261a2cb5ac0b550f8174d3d75f436c6d7b73e872', '4758baad6b22c61682e7f7182bb93723046f36f5', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '5176a2f31dace77db9135dde7020d2c37f78cca0', '77a1ca2df0871df21f85c2c2ca110946e350cfa5', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'dd023b06e9c03ec317c01f16df153ac8f2218c79', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'c27824577439a90d4e5d05ed9a7147b132d7e92c', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'c02a08d30aa070a5039ec4a7d92b3e7419b85976', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, '3a6c9b81cc77f2d66dfec3d567a125b526c58ddd', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'eb42cf88027de515750f230b23b1a057dc782108', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",35,"{'4758baad6b22c61682e7f7182bb93723046f36f5', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '9cd70ca81b4653aa2048002273c5ac9c36641390', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '41747cbdbed84762dfbfc305254c97021279dc6e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['Shancong Mou', 'Mengsi Cao', 'Haoping Bai', 'Ping Huang', 'Jianjun Shi', 'Jiulong Shan']",Shancong Mou,"Shancong Mou, Mengsi Cao, Haoping Bai, Ping Huang, Jianjun Shi, Jiulong Shan",25.714285714285715
d6b666f6f8159e5384059b30d697a09819c39962,Improved Subspace Method for Supervised Anomaly Detection with Minimal Anomalous Data,,"In conventional anomaly detection methods, the classifier is usually trained only with normal data. However, real-world problems may present a very small amount of anomalous data. In this paper, we propose an improved subspace method for anomaly detection that has the ability to utilize a very small amount of anomalous data. Our method introduces an objective function that minimizes the average projection length of anomalous data into the conventional objective function for the subspace method. This formulation enables a normal subspace that considers the distribution of anomalous data to be learned, thereby improving the anomaly detection performance. Furthermore, because the information about anomalous data is provided in the form of the average projection length, stable detection can be expected even when an extremely small amount of anomalous data is used. We used MNIST and the CIFAR-10 dataset to evaluate the effectiveness of the proposed method, which yielded a higher anomaly detection performance compared with the conventional normal model or classifier model under conditions in which very little anomalous data are obtainable. The performance of our method on CIFAR-10 was assessed by imposing the constraint that only four or five anomalous data samples could be used. In this test, our method achieved an average AUC of 0.263 points higher than that of the state-of-the-art method using only normal data.",https://www.semanticscholar.org/paper/d6b666f6f8159e5384059b30d697a09819c39962,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'f75e3be069b159baf1a3b2bd3aa9a7e06d03c227', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '8ff61b8e097ccdb784a35b466ba9e130c2502513', '718c68c25886484c922d6d33702a726cdd27ca3a', '00a1077d298f2917d764eb729ab1bc86af3bd241', '114e1354cee7a687ae694f7d8134c7afc87abb47', '95ed254ca6c74102e1b24507b3ea7b9fa2754838', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '2952193893091128ceae148f244fae8b6a9ce4ff', '4f2934870251ba75e80f3b395e56d834d5aadfd4', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', '3bb5a439a0d610a7eac68f73068cdd278b8c9775', '4c65c5f32a8c47505f763b00c4e65a859856a3b3', None, '0ae633545d240360f0b5eee788ff8e8c53894a1e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', 'e41b32583e19885e7692c1168a3e241cef6e898a', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'be86da00efdd8c2a7fdeb2334605796c24b370f0', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",29,set(),0,"['Fumito Ebuchi', 'Aiga Suzuki', 'M. Murakawa']",Fumito Ebuchi,"Fumito Ebuchi, Aiga Suzuki, M. Murakawa",0.0
093c848fc2ca5072cdb5d789e537058c73e93b81,Deep learning for the quality control of thermoforming food packages,2021-11-08,,https://www.semanticscholar.org/paper/093c848fc2ca5072cdb5d789e537058c73e93b81,"{'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '1f0c1c81045ea14a25977d83cae6955d3c35edfa', '937b9e56e8ada5fb5ef633e4c7ce9a90089c465d', '96054ad1cc4c334022f0985df69156b2f035b97d', '8452941a175c899628c679523da952b18f63e335', '86e622ed20ea5591eac83495761b7842c0f4f37e', '75f81139f218304e6e749c766bab9861b2465e59', '123ed3de989d4014bfcb6ee6224d30a978033809', 'afc34c04622f0e29b6867704d11f87fae4b5090e', 'c9f9ea536a5ceafc2ada25c0752d818b7b7028a4', 'd53ed2cd6a5c3483c013df6a35cf0b08632065fb', '5433dc54eeb36b7d7b041efa19557efe2536eba4', 'ee8c33a09b94377741c8c4e12cfc9174b9bcc7a1', '98fdb0352e529db7f0b2e79c9d102536ba0206ce', 'dd9de71453d048cb97df08f26ea92099c8e2f3cd', '66062f08350fa0bea1101ea774577d4f1eb3065d', 'f8f9d24a2fa12af808026a6192eaa060bd4f31eb', '3a1efd7ae29fdecdefaad8d7f4ed0bf38e92a22e', '930b3ddca35925880e2c778ea74066529f063b85', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '2ff33bd4abe1178ea6075a169b49fa45a80dd827', '48f9a48aa5b1230b05a443d2d531e6441a541686', None, '68a42eda3b0c2e07dee3ccec840942bb1419bf1e', '5694e46284460a648fe29117cbc55f6c9be3fa3c', 'eb89b17dbab7736d3a303cc1758948cf4acdae00', '28d1e28ab213881a5aea0e87686835e103948967', '93d6c0665abe64c05ecef9e0ea21a8533a7519ff', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'b60c4612466273a611ba9e6078935954cd009762', 'cdd3d72ab72f54feb644722e083258a491a782b6', 'fb41177076327c40dee612f30996739e20cf1bd7', '99aea98cbc3f886b9ba954b20745ae234a70ea42', '80d800dfadbe2e6c7b2367d9229cc82912d55889'}",35,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Núria Banús', 'I. Boada', 'Pau Xiberta', 'Pol Toldrà', 'Narcís Bustins']",Núria Banús,"Núria Banús, I. Boada, Pau Xiberta, Pol Toldrà, Narcís Bustins",2.857142857142857
bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6,One-Class Classification: A Survey,2021-01-08,"One-Class Classification (OCC) is a special case of multi-class classification, where data observed during training is from a single positive class. The goal of OCC is to learn a representation and/or a classifier that enables recognition of positively labeled queries during inference. This topic has received considerable amount of interest in the computer vision, machine learning and biometrics communities in recent years. In this article, we provide a survey of classical statistical and recent deep learning-based OCC methods for visual recognition. We discuss the merits and drawbacks of existing OCC approaches and identify promising avenues for research in this field. In addition, we present a discussion of commonly used datasets and evaluation metrics for OCC.",https://www.semanticscholar.org/paper/bd6262ebdd1a865e8e6859ab7dd8dc576d2a90e6,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '5db790198b9acf4e5efe350acdd814238fcacaa7', '83dfe3980b875c4e5fe6f2cb1df131cc46d175c8', '4e8a2af88d09b15c557c44c441259547df613289', '0430b241bdd0b67d37e1143370f8d24fc46d83e9', 'c107662b9531cc3b513a256a47cfd3c98e00c51f', '77afac8f4d7f47c8b34371d8f8355cefbea1d4f6', '8765f22fbcdcf610a08b01db01edc4b8cc67d082', '7fcb90f68529cbfab49f471b54719ded7528d0ef', '51c1519a57a65351a713a3d74f8d477105df0ec3', '292b78282340ccfa7cfd1b0dbd7c38c2b39a2230', '41071dbbbcbb27af3fec70de045f19c28535f5b7', 'c4f92f208f8bb85ab64a0482be592b594c16ca16', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', 'c0c07935977e70e71d296535729fc718636d76c4', '90624d044e8ee5db8a9996315afdad6f8225a74f', '7aa38b85fa8cba64d6a4010543f6695dbf5f1386', '3f600e6c6cf93e78c9e6e690443d6d22c4bf18b9', 'a0622cb2a1662293a0820f09ecd1301952a7485a', '49bdeb07b045dd77f0bfe2b44436608770235a23', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'abef2966d391e9d1b93611f48201004d3581b9ee', 'd891dc72cbd40ffaeefdc79f2e7afe1e530a23ad', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '684732677d91a93b115f57e8d671ef7f5f13ee14', 'a6f1dfcc44277d4cfd8507284d994c9283dc3a2f', '10b219619e88931fabb674037bbb633682775136', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '9acc51b06f54b07836fad4cc24633187dc21317f', '330008af4074ef0e2b21787677783827d6a15056', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', 'd079a2f877f554e00f71a6975435d8325987bdf5', '195bec771d31eff04c8b0324878d2338ab594527', '7928e47cca13d9d012952a311e405fa661e99071', '67f2d17418e6f4a147aa8b5a5006a47da227faf7', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', 'd516daff247f7157fccde6649ace91d969cd1973', '00695a31a80221c7125e49885a4767896ec2c4f7', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '70f9968a356d840040a1c9207906f60376dc6bd4', '4cab9c4b571761203ed4c3a4c5a07dd615f57a91', 'e86f71ca2948d17b003a5f068db1ecb2b77827f7', None, '13eb4d8d61fa320fde0d049a6b4bcde6e550118f', 'c72bb6c83db08e17e2736bc1d2cf439fe1f71905', '41747cbdbed84762dfbfc305254c97021279dc6e', '2910bec6d4de87e22be5119cef3c488d2ae50e2a', '843959ffdccf31c6694d135fad07425924f785b1', '1b5abd95c44c712c367fb26e8f78f0dfa7c3be99', '0afeba5f60d004e45ecfb3ef5081a1c2505e5b31', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '27222787908c3a1c6fb6c4b5cb5ef8b2542f1b3c', '0f810d38b26a7d1c5c7fddd7879b4ffa5fdc81d4', '599fd051c9438011ec5b581983c89e8922b4a5e6', '732c21998e251d64cd58b6a86886ee5907efeaa5', '2530cfc7764bda1330c48c0c8e2cd0e0c671d7e1', 'd1dbf643447405984eeef098b1b320dee0b3b8a7', '66fb7d519c59333aadfd0cbadd143d05661ef52f', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '1972c73d96353e57599962fd6059572801382212', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '6af440915b8a0718c93be1cf61905e41e620484a', '114a32bc872f160b58f503aca13f887556b5006e', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '9eb1b16fbd4786eaac91f308d75609b9321868ce', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', '844012b752d1ff68b800a686a9480d752239af38', '8213dbed4db44e113af3ed17d6dad57471a0c048', '63de0ad39d807f0c256f851428f211e8d5fcd3bb', '775247047d0b56950ba5ea77d4a29772eca95c1b', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'd5eec41043d91964879c4c745c7165f823967f29', '8381157eae4fbf8908d0312a9642f8e69e944449', 'f5a3598028cd375071a38f90f1b2122308e3a100', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '7c6546027bb3bd39fd6cab7395a4e3bb05248601', 'e7c4665ce36a53484f8a7b7dfa821a9f6273eab4', 'f6e0fb4c77906bc23fe59a8f848ce62ba9687181', '47638197d83a8f8174cdddc44a2c7101fa8301b7', '4d790c8fae40357d24813d085fa74a436847fb49', 'e8874d7d585ae1c355e186efdcc9f704b3d43b49', '1a2a770d23b4a171fa81de62a78a3deb0588f238', '232253872a7f0d757dea7ea28f4bdf4bc3607b24', 'be012ed29fc4fc366d6b39514679d838eec1f056', '276194e96ebd620b5cff35a9168bdda39a0be57b', 'df40ce107a71b770c9d0354b78fdd8989da80d2f', 'd094fb0af5bc6a26fa9c27d638c4a3a0725d8b5c', '8012c4a1e2ca663f1a04e80cbb19631a00cbab27', '1643f48027cd18aeaf713bf7b5b18bb91a765503', '82635fb63640ae95f90ee9bdc07832eb461ca881', 'a7a54fd569c955cd639d34809d95fa485691bf4c', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '3a2ef5c27e7140f819a4c99444b7d4fd533dca59', '9d868ed92f1c78d1f696a26c71176a6a33a72423', 'f685d8a883604d62c039b2334a854fa34eee2289', '12d0cf8ae5ffe1b89345e1dcead22be592d844b2', '967d532a66dab7edcb818b0f9dc59fe8da7dc171', '317c172f314f8cb634f7569ed5bf3ae7dd25c313', '3b1aaac41fc7847dd8a6a66d29d8881f75c91ad5'}",101,"{'16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '775247047d0b56950ba5ea77d4a29772eca95c1b', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b'}",4,"['Pramuditha Perera', 'Poojan Oza', 'Vishal M. Patel']",Pramuditha Perera,"Pramuditha Perera, Poojan Oza, Vishal M. Patel",3.9603960396039604
5ec98d7f12a1be79b592e18f785174d6744b7474,A Novel Algorithm for Exact Concave Hull Extraction,2022-06-23,"Region extraction is necessary in a wide range of applications, from object detection in autonomous driving to analysis of subcellular morphology in cell biology. There exist two main approaches: convex hull extraction, for which exact and efficient algorithms exist and concave hulls, which are better at capturing real-world shapes but do not have a single solution. Especially in the context of a uniform grid, concave hull algorithms are largely approximate, sacrificing region integrity for spatial and temporal efficiency. In this study, we present a novel algorithm that can provide vertex-minimized concave hulls with maximal (i.e. pixel-perfect) resolution and is tunable for speed-efficiency tradeoffs. Our method provides advantages in multiple downstream applications including data compression, retrieval, visualization, and analysis. To demonstrate the practical utility of our approach, we focus on image compression. We demonstrate significant improvements through context-dependent compression on disparate regions within a single image (entropy encoding for noisy and predictive encoding for the structured regions). We show that these improvements range from biomedical images to natural images. Beyond image compression, our algorithm can be applied more broadly to aid in a wide range of practical applications for data retrieval, visualization, and analysis.",https://www.semanticscholar.org/paper/5ec98d7f12a1be79b592e18f785174d6744b7474,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2881d778dbd07734d5073d05c47b3e5187d05756', '9cce4c9e69318aef56a274612f8df62ade63622f', '55f3d65831599ee5b2f424d347c7ca9bf43f6fb8', '415d230e0f92249312ac27629a451f8113b45653', '765fb369aae50c0ac941a6b69e9af8cd1416fc7e', 'c8e2c67c05b299f2452720531b91324d5007d97a', '9d55c6f6fe553d82433e75b852d1a15c26433b4a', 'f7ba875a21f73d61b349654526fb5a632e3a19cb', '445cd6635b404e7fbca5477951f666d1531db686', '2baf7eadbced13b1a7296b9c9dc40f5cedbecf63', 'cb3f9a164d99bbfab6eee5aad05697a03114f497', '180cecf9b0f9b8ef5bbac6a3fd53f9004acc63a7', '192e3271d658b27b23c7cbbce178a74ccc1002db', 'e94a1262e5717804d9dffb4ebe9e1580c99d6661', 'a618c3fd59a44f8789678cc367ca017c47bd0b47', '65d3e7fa7b452611aa729ac789d4373d6ee505b0', '04b9e4192eca063b95ca65db901e1cccfb0ecd6f', 'aee92aab4fa565436fee6f1c619c9ee7e9592685', 'ff65b602512242b8186d22eef69e1fdedd125d64', '8782ed7f180cfb86d94c04705a1919eded93319f', 'fb464b0a222e5f10fb5ebc796fa330cd3647aabb', '635b89466d4e13170bdcdd10a341e8c87cac0003', '554bb6f21e3196b53c6057b8203fba161a0a1bf4', None, 'f1a17b7c4cae4513731f6d81b433e338cf4114eb', 'fd29d0d7f6a83186083f600645d72523a1ed31cc', '28af17091c09f38dfa5d09cefd50ec6e46b4415a', 'f0775ea7e8a99c871f70a673d940a7bb1a6a9d3f', '2e6b927524523709a480ee9124283d3a376af078', '536a4e1a137c5fc125b2a0c9e7c20b9e39e5efeb', 'c1994ba5946456fc70948c549daf62363f13fa2d', '51a0d761e577dcc7ca88bafab037794eb5d742a4', 'c22707d464cd1991dfb0f6e9d16c3d8b5ac3bbbf', 'f25af3b9b9473157d86495e3762572b2fd2d910c', 'f60c43592b2925002583556ffc9a4e765b2f657f', '0250f9026b540ae05e2b6528b3c9064e6db637dd', '251c39c1b9372f3055cd53d0001fc122bfb2e418', '319a3450f9909043d46eb7ceb4299efceb984d4f', '8073363bb0fa845ce18e0fda1740ac1eaefb612c', 'b80d9e1d3a8ff72e2af1014a2521dd6463a67335', '1d4816c612e38dac86f2149af667a5581686cdef', 'fe055b3f6282f40962ccd2f9bc83a64b14234ede', 'a840e0b61b5398a41b8f22b2782746b4c6bf1d47', 'd6a2d35954d5dcf426b44c06523d247f8319b9f2', 'cb6aeb8d584bd5f5a28a4029b6a2bff47f703eb3'}",46,set(),0,"['K. VanHorn', 'M. Çobanoğlu']",K. VanHorn,"K. VanHorn, M. Çobanoğlu",0.0
568a93409f91e959b075ffee9435204b4f15569c,Generative Cooperative Learning for Unsupervised Video Anomaly Detection,2022-03-08,"Video anomaly detection is well investigated in weaklysupervised and one-class classification (OCC) settings. However, unsupervised video anomaly detection methods are quite sparse, likely because anomalies are less frequent in occurrence and usually not well-defined, which when coupled with the absence of ground truth supervision, could adversely affect the performance of the learning algorithms. This problem is challenging yet rewarding as it can completely eradicate the costs of obtaining laborious annotations and enable such systems to be deployed without human intervention. To this end, we propose a novel unsupervised Generative Cooperative Learning (GCL) approach for video anomaly detection that exploits the low frequency of anomalies towards building a cross-supervision between a generator and a discriminator. In essence, both networks get trained in a cooperative fashion, thereby allowing unsupervised learning. We conduct extensive experiments on two large-scale video anomaly detection datasets, UCF crime and ShanghaiTech. Consistent improvement over the existing state-of-the-art unsupervised and OCC methods corroborate the effectiveness of our approach.",https://www.semanticscholar.org/paper/568a93409f91e959b075ffee9435204b4f15569c,"{'a7bfb9bbe2e3d6dfa980e5e40b1f447f007984a3', '6ec00ff233c19b47ef44dd57cdb22a7385586c0c', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '563b0f67e36678b352e05100377205ae5d34a9d7', '84ccbe667e1185b6c3ddac09a2f76baf95d97914', '6043b154857df6121df7579a980213550bac3e79', 'ba4eec4a53013e4a5ae0151d3722627f68a676c0', '6a67e6fbbd9bcd3f724fe9e6cecc9d48d1b6ad4d', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '68661cad6ee64aa0b0eea029a50b65286525a58a', '992847be33f4bf7afbe66e198cb20a53e00dfa76', '232b26f231122f6332d66244e5ad61d8225312a2', 'b62aea705b72252d24949cffc019517402a012ae', 'beda25eb336165a5872318bae4d59e98c9b47846', 'ce9edb785f28c81bd7c2864940ed001429178e1e', 'e1820e33e0347c4e9e625b640c7156faefe74159', '0c908739fbff75f03469d13d4a1a07de3414ee19', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'a03bda078490e8ee991a1f86b53f27df7cf93a14', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', '6a8acb6db2a835f83782b2968dd42a4a14709461', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '8f28873be3601c5a2736996eba543cf51950a381', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '523909d26ea94eaa0dd0285ba6ea0cd00a0aa7ca', '9d5290fadb7625862a966e0330bd0f9e111fc99d', '8ab37c7d1cc5e5b9f509ede2748f78525673db1b', '60fef33549f57f5cbb6712a510c3a444ab682429', 'e1976a516fda5e0e164c5ae7d7ad89dd09387116', '31cbbce38417c704df5dc5f6c4bef46d38b0e190', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '3727443e7c0bb819846a1f98e6efd772d34824c9', '799426e24403a50bb9012f59c890fccd46375e20', 'f06a12928307e17b1aff2b9f4a6c11791f19b6a7', '23b559b5ab27f2fca6f56c0a7b6478bcf69db509', '1442cb4613c99924f500ebdc2a7fdaf2e9080da5', 'b9bdc61d63d75d82f24de21be26f61879df5a01b', '87ecaaf627d441e5f42465a237a3e3a2c10da5d1', 'ef8d42105b06d2bb06b2177921a6415e44d5a90d', '50a93a118d5826369d2d28ed87216bde08fdb1b4', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', '048ef48f58156ab9f8eb4c1126e090194459e699', '8e2dedacea9a3e50b77afb6e64e5fb8a7ee7efa1', 'd716435f0cb0cac56237f74b1ced940aabce6a2b', '68f861693fbcb52f9bf1c6709f0d59d7ec28d759', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', None, 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '3dab77815d36acfda913e48738ce1f63dde4b336', '7768f83d396d68a917caf525c82f6de756884be6', '4a762c74d6c1f66b1d7a6a439f35c5c30e37c53f', '41747cbdbed84762dfbfc305254c97021279dc6e', 'ceb4040acf7f27b4ca55da61651a14e3a1ef26a8', '38d4b5a464652a4afb4f043f141976f5c71c1e6b', '08f99af9f5d6d351201ee4563e407bf37bc164fd', 'e6df192c9b654bc5cc371c55012cf99d85cb61df', '61d0125cd9f5aba4aef3e1db911f77be67a4e8c8', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '086015aa2c44bd2ebd95ab6a1a562e57177c7fa8', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '094ac7510d1723cb9c2da01db47291322aa29025', 'f780a8fe6eb184e34c03823fa1b2bcd4b5b4fb7c', 'e5366a704ffa3b41aacd385f3c087ec3fd566934', '2bdc82fbdbc060ba28930a62aaf174ac14ea71ff', '6f68ce1e03c56c186256dac689a21f6405ae8d96', '598fe25743f9492c5c1ba30274ea446f65426d85'}",68,"{'6ec00ff233c19b47ef44dd57cdb22a7385586c0c', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', '41747cbdbed84762dfbfc305254c97021279dc6e'}",3,"['M. Zaheer', 'Arif Mahmood', 'M. H. Khan', 'Mattia Segu', 'F. Yu', 'Seung-Ik Lee']",M. Zaheer,"M. Zaheer, Arif Mahmood, M. H. Khan, Mattia Segu, F. Yu, Seung-Ik Lee",4.411764705882353
807347357a79f239768aeb83b7b0201755a8569e,Derinlemesine Özellik Piramit Ağı Kullanarak Yüzey Hata Tespiti,2021-09-16,"Surface defect detection is one of the most important quality control components in manufacturing systems. The application of automatic surface defect detection methods in production systems is an important factor in ensuring high-quality products. In this study, depthwise separable convolution-based Deep Feature Pyramid Network (DÖPA) architecture was developed for automatic surface defect detection. In this network architecture, the learned parameters of the pre-trained VGG19 network architecture were used. MT dataset with defect detection images was used to test the performance of the proposed model. In experimental studies, 86.86% F1-score was obtained using the proposed DOPA architecture. These results showed that the proposed model was more successful than the existing studies.",https://www.semanticscholar.org/paper/807347357a79f239768aeb83b7b0201755a8569e,"{'2895770450e9cdfa4bfa42ea035b0a2397205e95', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '08b361036d68c16a57a1b17e0d623ef10a02d4ee', '354923bc917ac774438a048b87db9fabed4d757e', '3647d6d0f151dc05626449ee09cc7bce55be497e', 'deeca6a996b9b099d56c694a4c31c92ac1c4d5e2', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', '4e18c5f3883b1b78014421ffbde360156e75adda', '484d1e02b5c47c0245a41acb97d32bf7a70d0737', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '9ba7cb21073685cb2104db1b7e1f801bb7142e0a', 'edeea32645724a4d7591b2530ed54d1af4d3aeac', '645c4c200f9f396cf234841d98804888f699a8af', '1d2105616d122389efbd1b0ac7c04c0c2f8ac996', 'd81421695d5d429a47eefe266986d197d7b313f2', None, 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', 'eb42cf88027de515750f230b23b1a057dc782108', 'fd661fcc8b47c3d1dae2a56ece20ae68c3c25b10', '46d4a2b7ccf38b80b09574cf17544ff2297a8fbf', '2db34372d9ca2f3f3383227a241ae33f0e28c6fd', 'b0f6a0738676f38b60301f346ad7929fd2df1855', 'f1698a8507f195e38db4afdd3d3f18246a8d8806'}",23,{'2895770450e9cdfa4bfa42ea035b0a2397205e95'},1,"['Hüseyin Üzen', 'İlhami Sel', 'Muammer Türkoğlu', 'D. Hanbay']",Hüseyin Üzen,"Hüseyin Üzen, İlhami Sel, Muammer Türkoğlu, D. Hanbay",4.3478260869565215
068f66cf1f3cf0af4a1870e7bd322dbae3fb5092,Anomaly detection using improved deep SVDD model with data structure preservation,2021-05-01,,https://www.semanticscholar.org/paper/068f66cf1f3cf0af4a1870e7bd322dbae3fb5092,"{'198d308169e7b95aced6e6b65918a548be20235d', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '4c5d4d3fbe83eb97824661ca847caed7bb4c0da3', '2193246d4c30c31c95e4351f552666821f136cca', '19bba9a35e84786a877c36c566c9ef0aac92cd26', 'c27b5b13da3a1b53f251dbfe2a90900a95fafaaa', '810ea1f016e816b992ac31f8ce7a838b589dac3a', '306609a4abdae3c3f21fb11581d35911a4772012', 'a4cec122a08216fe8a3bc19b22e78fbaea096256', '67f2d17418e6f4a147aa8b5a5006a47da227faf7', '482f0873f43c5195c0990f673161bf783bbe5c32', '2749d31dd2aa439546dffa26385ca7e9c1c3e5bb', '03538806e21be89bfddf72195a1e0e84b404b06d', 'd9f0e1c7e240597992232840f7cb96ceeefa1940', '8905ea0b3b3c8b43d618286fc10c20c6b8031b05', '11adf0f13cdad89aa54ee25eb2557133cc1b6ec0', '6af440915b8a0718c93be1cf61905e41e620484a', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', 'aeee98c90799cd44dde4046754cff27c8ed28d44', '6a0e4209529b827cd86a52a4766968001a3f187c', 'eb42cf88027de515750f230b23b1a057dc782108', '8267d5baf76e6d8e9956df19c560e27718a602bf', '2e9004339cac38f685b24e901d8afb0011132dd7', 'e5522451782dde5ba2da65c8231a05b36309f536', '7babf7fb5b47372125200951a5735be41afa332c', '7094a0d24d398dc87bf2a830ff6f5d67d5e8749a'}",27,set(),0,"['Zheng Zhang', 'Xiaogang Deng']",Zheng Zhang,"Zheng Zhang, Xiaogang Deng",0.0
ddb7e2eb60b82c4267caffd43e0d5da4b60d1888,TSCDNet+: A highly robust substation anomaly detection method,2021-11-01,,https://www.semanticscholar.org/paper/ddb7e2eb60b82c4267caffd43e0d5da4b60d1888,"{'5eca15a355b2a9a1e80879e850afe49d3c398c53', '598fe25743f9492c5c1ba30274ea446f65426d85', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '2c55647cf5566ca3fa5a3b57b243a02ca8c08de4', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '5234caf3bcc1edb0b38554b4ffddf5a46877dd45', '3ff8d0718222ac247e9f5ca3d7d6047624eff5d5', '773c00e803b99f2be4ba9630fe3bb5198566b59c', 'de95601d9e3b20ec51aa33e1f27b1880d2c44ef2', 'c9117bb5b2c167479e2c30e12cb06b05d2698816', 'a3f73cc43c53094eb393eb6ae50e7edafc675155', '66ce56946214ab496c260012d828f7883ebfca22', 'a4c94b221062d0737ee967affa80ce2110cc50c0', '738165f33c50b059e87b14d8b4a129230e14eacd', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'a7dce2dc565e92b69db608195f3d59662469f924', '5435a9ab36a308cef10bc725104e8f778ed3a328', '22d056f13fbb41aa4d3a6bbd3a25019a1ce3c09e', 'f13d885a35707f774f27949dbae6bcdd74ca8537', 'b702cf22afb725b1bf9d633ffdd96cfb00a87253', 'e2bedc5f82c3f298e948a0e0fcfdd8b367fd4331', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', 'af5fbe3f88fe22e24fbde0a23c79d983f6e9af76', '91336c65cddd8546745f67a1b860c2595904ac15', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '718d8d40d089a60215b6ac3d4d892578243aaf4a', '6220117c492f20d4be0e65dc39a4de7857e3f43c'}",31,{'2c89b183df320c3ef698989bdc5d1d4731c4d65d'},1,"['Hua Zhengyuan', 'Weicheng Xie', 'Liu X. Wei', 'Changquan Song', 'Yefei Zhang', 'Jing Junmin']",Hua Zhengyuan,"Hua Zhengyuan, Weicheng Xie, Liu X. Wei, Changquan Song, Yefei Zhang, Jing Junmin",3.225806451612903
d8f7dffd734c2754da3899728475d5bbe2b5e295,Attention Map-guided Two-stage Anomaly Detection using Hard Augmentation,2021-03-31,"Anomaly detection is a task that recognizes whether an input sample is included in the distribution of a target normal class or an anomaly class. Conventional generative adversarial network (GAN)-based methods utilize an entire image including foreground and background as an input. However, in these methods, a useless region unrelated to the normal class (e.g., unrelated background) is learned as normal class distribution, thereby leading to false detection. To alleviate this problem, this paper proposes a novel twostage network consisting of an attention network and an anomaly detection GAN (ADGAN). The attention network generates an attention map that can indicate the region representing the normal class distribution. To generate an accurate attention map, we propose the attention loss and the adversarial anomaly loss based on synthetic anomaly samples generated from hard augmentation. By applying the attention map to an image feature map, ADGAN learns the normal class distribution from which the useless region is removed, and it is possible to greatly reduce the problem difficulty of the anomaly detection task. Additionally, the estimated attention map can be used for anomaly segmentation because it can distinguish between normal and anomaly regions. As a result, the proposed method outperforms the state-of-the-art anomaly detection and anomaly segmentation methods for widely used datasets.",https://www.semanticscholar.org/paper/d8f7dffd734c2754da3899728475d5bbe2b5e295,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'abef2966d391e9d1b93611f48201004d3581b9ee', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '732c21998e251d64cd58b6a86886ee5907efeaa5', '8388f1be26329fa45e5807e968a641ce170ea078', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', 'e74f9b7f8eec6ba4704c206b93bc8079af3da4bd', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '156b252f1891e5f89cb10d7cd02a7e02025cffa9', '547c854985629cfa9404a5ba8ca29367b5f8c25f', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', '1a00dc525da31292e3734cbae2de681f114e30b1', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', 'ed17929e66da7f8fbc3666bf5eb613d302ddde0c', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '46d5cf70365d48ad38ed549fb44cf76810e8f8da', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'f5a3598028cd375071a38f90f1b2122308e3a100'}",34,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '41747cbdbed84762dfbfc305254c97021279dc6e'}",5,"['J. Song', 'Kyeongbo Kong', 'Ye In Park', 'Suk-Ju Kang']",J. Song,"J. Song, Kyeongbo Kong, Ye In Park, Suk-Ju Kang",14.705882352941176
5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9,Fully Convolutional Cross-Scale-Flows for Image-based Defect Detection,2021-10-06,"In industrial manufacturing processes, errors frequently occur at unpredictable times and in unknown manifestations. We tackle the problem of automatic defect detection without requiring any image samples of defective parts. Recent works model the distribution of defect-free image data, using either strong statistical priors or overly simplified data representations. In contrast, our approach handles fine-grained representations incorporating the global and local image context while flexibly estimating the density. To this end, we propose a novel fully convolutional cross-scale normalizing flow (CS-Flow) that jointly processes multiple feature maps of different scales. Using normalizing flows to assign meaningful likelihoods to input samples allows for efficient defect detection on image-level. Moreover, due to the preserved spatial arrangement the latent space of the normalizing flow is interpretable which enables to localize defective regions in the image. Our work sets a new state-of-the-art in image-level defect detection on the benchmark datasets Magnetic Tile Defects and MVTec AD showing a 100% AUROC on 4 out of 15 classes.",https://www.semanticscholar.org/paper/5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9,"{'1bac0cd5adebba3adb668ec38930fe2f1344d576', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '9f09e600318fc7d5332755d82cb1b7ffb464c270', '5db790198b9acf4e5efe350acdd814238fcacaa7', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '58996dc0102302ef5d734ea7fea27dd52e7f3e4d', '90f72fbbe5f0a29e627db28999e01a30a9655bc6', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '137ef7a9efa1c106e01581519c04c2db7bc4dd57', 'c53352a4239568cc915ad968aff51c49924a3072', '8086d054446bb816b11098b300b9c426a78e512f', '37595f7a51982d776e57c7280b9445474d90f0be', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'b1464ca857593c049873421db2f37bf2d0ff676d', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '10a498003e9204f5fc1328e706510a37e514d8c7', '3c3698ce314a77271b566713edb2911f921299e3', '75cb21fa931e957941c0237a1030aa36209bae36', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '01b6affe3ea4eae1978aec54e87087feb76d9215', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', None, '6303bac53abd725c3b458190a6abe389a4a1e72d', 'c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '666af169c4e106152a8bf91fb32166c4aa84b9da', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '6a97d2668187965743d1b825b306defccbabbb4c', 'd40ad31c8639e23877bcdc149cc337560ee91b6a', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', '7cb2bedc49377b3cab3ddfbd3aff13e57af49880', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",43,"{'37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",5,"['Marco Rudolph', 'Tom Wehrbein', 'B. Rosenhahn', 'Bastian Wandt']",Marco Rudolph,"Marco Rudolph, Tom Wehrbein, B. Rosenhahn, Bastian Wandt",11.627906976744185
65ce769c5a8d6f6d407e154871f8ffafe0cc4354,Data Analysis using Riemannian Geometry and Applications to Chemical Engineering,2022-03-23,"We explore the use of tools from Riemannian geometry for the analysis of symmetric positive definite matrices (SPD). An SPD matrix is a versatile data representation that is commonly used in chemical engineering (e.g., covariance/correlation/Hessian matrices and images) and powerful techniques are available for its analysis (e.g., principal component analysis). A key observation that motivates this work is that SPD matrices live on a Riemannian manifold and that implementing techniques that exploit this basic property can yield significant benefits in data-centric tasks such classification and dimensionality reduction. We demonstrate this via a couple of case studies that conduct anomaly detection in the context of process monitoring and image analysis.",https://www.semanticscholar.org/paper/65ce769c5a8d6f6d407e154871f8ffafe0cc4354,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '67dadbfc05da7ef2aae92eb812c974603fcc6c13', 'b5b3dc4389e904933c1c8fc36d15398e904a288f', '0189961bf20b2c9dc33ef6162e561a7ec432c6ce', '9bc8bdb1488966f6291b670f684e16b886637584', '1f4115e57b3848be4fbf69268b5d9cc96e8e06e1', '43d695e896f62619d9f7ead753686bafb8fa912e', '905540053ecb4aa2e9abbf3b5e2a44a07d2a5900', 'f5f71eb50edc1affe822defc8163ba822907fd6f', 'e1bcf33b4c955c4d6842d0ce5097b2b451a6a690', '36f33584cc346cfc52b736fdc8eab87b91d1dc1d', '33e46a618fdb22d46951f548d6ceeb384e7f1687', '11df91d80bdf329ec830b9852c4d1bc1a9ac5d1f', 'f7b4c27abb76dff4c017849049541f3fc91e77be', 'e3316e823ebdf64f082b7124d88183f9ba045245', '7c1a9f0f2efdfae7ea2071df0add4839cf33a0a2', 'baf0a448bd8e1b23a571882dc8e54ee47e5524e9', 'a4bea9dc428072b60110d3762cd42cc519a191d2', '12693a0c4837536e20885feccda2942fec372229', '36f4ec0e5fe080c77d1f851490847833c89ed964', 'a02c7e9c4b50aede55e7e3396caf7adc3414c90d', '0a15503913d0c6d493a812033f98ef04da39b317', 'b3f8348133c1d2f76f1dc1272f748a0b28874d80', 'bf4c1819546ec255d3997c8f5f9674282370e6eb', 'fd579d0231979aeaf80cda8ca5cfa6d4e3a929d9', None, '42f8aacf5f3b731706bbecc5db101d3decdc5db2', '11647c4d6867daaa90e67850f36d2cd8e614acdc', '58b285f90fa40ab2f26216096b7eb4b331841218', 'b101128f5ee8cb04e0273b92a74610ad5c279b09', '5639b7f9fa090112cc1cacb146a0873920f58f8e', '344f8669902ad069a5f5883579384ebc2e2b64ab', 'bf22cba131e9f9aab4eb5acb8f8ca7e256c46c1b', '400be635de58c0a88d724624b9860b5966112fc3', '6b3fca55100ed362b22fc8c15db3e0740168d394', '737c0ca32e35b3b8fc9bea05aebc5c94a17ab296', '29580626129d00992feac5dbbccbe5a538b3caa8', '5391957fff3b81c93b06bf36ca7fd7b44abe2449', 'd361a9d2c51ac45f62e99fefa1fa5659a7cf1037', '1609419f9427f87584436530914b3c8201ec31c5', '504ebe26cfb82dabfba6f3be6ed939bbb46991ec', '315395d301c293ef827257ac2f3cc9696d72f01d', 'bf86896c23300a46b7fc76298e365984c0b05105', '1970dbd84d5a78c18f4b54e90262eb695635a173', '454ad65e94b885c3f577576c910821cece5e2179'}",45,set(),0,"['Alexander D. Smith', 'Benjamin Laubach', 'Ivan Castillo', 'V. Zavala']",Alexander D. Smith,"Alexander D. Smith, Benjamin Laubach, Ivan Castillo, V. Zavala",0.0
78d80c343d36baaf89f18e12d325cf6309fb6c8f,CutPaste: Self-Supervised Learning for Anomaly Detection and Localization,2021-04-08,"We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",https://www.semanticscholar.org/paper/78d80c343d36baaf89f18e12d325cf6309fb6c8f,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '598fe25743f9492c5c1ba30274ea446f65426d85', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'd03ca175e2b2745126e792fdc31dfadae4c63afa', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2788a2461ed0067e2f7aaa63c449a24a237ec341', '3688c559acaab98a9a7c00f7b3fab882b851868e', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', '4feef0fd284feb1233399b400eb897f59ec92755', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'b022f2a277a4bf5f42382e86e4380b96340b9e86', 'ed17929e66da7f8fbc3666bf5eb613d302ddde0c', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'd6e78069dbbb35592f013187ef3432286def8f18', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', '04513c7c0b3a63fde81a996dae064a28d453c17a', '37595f7a51982d776e57c7280b9445474d90f0be', 'b1464ca857593c049873421db2f37bf2d0ff676d', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '10a498003e9204f5fc1328e706510a37e514d8c7', 'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '379daa0dabeffa72b9a0d8c48b361236c03fb302', '5647d92d8e7248cd2d4770edfe0688c1c0a2181b', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '45f490710b4dd6697dba4c9b385a49554501711a', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '4b83c2ec2c5119057979ae64cf4b5d1aef04466b', 'c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d', '41747cbdbed84762dfbfc305254c97021279dc6e', 'e4bde6fe33b6c2cf9d1647ac0b041f7d1ba29c5b', '206c2e79b5f1b4541b85f47517666961ed49500e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', '925182b91f51f8f2b747f7829e9d25ffc2729e5d', '4bb3301a284d646b4c1ffabcca78ee85c11d1cda', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', '1c6d990c80e60aa0b0059415444cdf94b3574f0f', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'eb35fdc11a325f21a8ce0ca65058f7480a2fc91f', '8a916608e81eea5d7494e577c8563cae44a1b8c6', '6869ab1f42e30b415829de9928f7e4a606113601', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '1d033b30f38642e4b6dd146bb8b464bfb58aad96', '46200b99c40e8586c8a0f588488ab6414119fb28', '75a838cbc1541858b9c484001cade327640dc280'}",65,"{'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '62b77e5cb85fc61b84edd532f6d65714be152596', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'b1464ca857593c049873421db2f37bf2d0ff676d', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '38ca689c2f916c648ea3ecb1043facbc4bea0d4f', '206c2e79b5f1b4541b85f47517666961ed49500e'}",13,"['Chun-Liang Li', 'Kihyuk Sohn', 'Jinsung Yoon', 'Tomas Pfister']",Chun-Liang Li,"Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, Tomas Pfister",20.0
1bab6ab41efb8e80002888f99aef1431d678f5d7,Removing Class Imbalance using Polarity-GAN: An Uncertainty Sampling Approach,2020-12-09,"Class imbalance is a challenging issue in practical classification problems for deep learning models as well as for traditional models. Traditionally successful countermeasures such as synthetic over-sampling have had limited success with complex, structured data handled by deep learning models. In this work, we propose to use a Generative Adversarial Network (GAN) equipped with a generator network G, a discriminator network D and a classifier network C to remove the class-imbalance in visual data sets. The generator network is initialized with auto-encoder to make it stable. The discriminator D ensures that G adheres to class distribution of imbalanced class. In conventional methods, where Generator G competes with discriminator D in a min-max game, we propose to further add an additional classifier network to the original network. Now, the generator network tries to compete in a min-max game with Discriminator as well as the new classifier that we have introduced. An additional condition is enforced on generator network G to produce points in the convex hull of desired imbalanced class. Further the contention of adversarial game with classifier C, pushes conditional distribution learned by G towards the periphery of the respective class, compensating the problem of class imbalance. Experimental evidence shows that this initialization results in stable training of the network. We achieve state of the art performance on extreme visual classification task on the FashionMNIST, MNIST, SVHN, ExDark, MVTec Anomaly Detection dataset, Chest X-Ray dataset and others.",https://www.semanticscholar.org/paper/1bab6ab41efb8e80002888f99aef1431d678f5d7,"{'e60b8cd6cddb08e27e0e4158eed5fad3680f177e', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '3492dacab1ba96093ee26e1035af88d93c452325', '956033dea20c86242739a3b77a95080eedcb324b', '5cd47e5d004d75fe773a252bde35b56d5d56ce06', '12e94e888a9966738c56430abff7ed7fa452221b', '7ed1705f5aeddde0cfb076df37fae0a20c64e79d', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'c3be9cfae1e49799abae236d30e5e078249af949', 'dea93ce6290554c508a2029e60c2b5ce3640ebae', '95dfdc02010b9c390878729f459893c2a5c0898f', 'c88dbaa5d8f4c915e286be5e38b5599038220493', 'b3d8dffb73bc93de239998548386c84177caa2ad', 'f9163156eeba67762a7441db48fe6720106137cd', '8074bd92913e2eaef031a832126e515f80b06996', '16408af0fea79a138537cab1e4c0966ac10c8c01', '8c55e2743e25cf87d9539ea24b235c8353844ee7', 'c789f8e3f40f57335aef2565f4d2bac69d2941d8', '9845e3f144376c349b6204e47fe425d10f672e91', 'd9646e51c29525800633c8014ebabb4c6a5a8018', '7391e65f9a1488753570f2a0eb4fd73836f4d85a', 'eaa8c743ac2ec922edb99fce089dbf34d1472747', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', '180cf927c0db46dfc4921fdd36e77071cef09ad8', '2f85b7376769473d2bed56f855f115e23d727094', '5dbe09fc20bb315d85a306bca47766bea1d6151d', '42ef50955a7f12afad78f0bd3819dbc555580225', 'da9e411fcf740569b6b356f330a1d0fc077c8d7c', 'ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7', '1e4870524f8de44d4f18c8f9f80eb797dfd25c89', '73cad80229fa453f08ae7518c8555b35d39fd499', None, '4dc8b255f9aaf933e68ab8b81d4c1d909f87efe6', '4f8c4fd0174c75cafc31b66812da61840c6454f2', '2501d0bf0c2affe64afeefaf0be9defad29df040', '235b9812305cff3df849394ac7b70a2c04a4685c', '14bea7d2b82623c20de967478b5c254822f0e5b0', '9d4bb6ec511c5dd4c6c97224b59cf4cdf4dc0746', '31622dee41d13f90a099025425dcfb88d0970e60', '0f03eb384cc4fef927d1160eab9e4da95e13148a', '543f21d81bbea89f901dfcc01f4e332a9af6682d', '353ecf7b66b3e9ff5e9f41145a147e899a2eea5c', '5d90f06bb70a0a3dced62413346235c02b1aa086', '2e2089ae76fe914706e6fa90081a79c8fe01611e', '8cb44f06586f609a29d9b496cc752ec01475dffe', 'ce2fb9e8a37623d465fe3aa7a6f85d7f9cf62443', 'e5041701a60bc02066b6ade9ffd52823391cc8b8', '34f25a8704614163c4095b3ee2fc969b60de4698'}",49,set(),0,"['Kumari Deepshikha', 'Anugunj Naman']",Kumari Deepshikha,"Kumari Deepshikha, Anugunj Naman",0.0
410fb9c0a527b8dbae034e2a8e25dc325fdd5e74,Automatic detection of defects in high reliability as-built parts using x-ray CT,2020-08-20,"Automatic detection of defects in as-built parts is a challenging task due to the large number of potential manufacturing flaws that can occur. X-Ray computed tomography (CT) can produce high-quality images of the parts in a non-destructive manner. The images, however, are grayscale valued, often have artifacts and noise, and require expert interpretation to spot flaws. In order for anomaly detection to be reproducible and cost effective, an automated method is needed to find potential defects. Traditional supervised machine learning techniques fail in the high reliability parts regime due to large class imbalance: there are often many more examples of well-built parts than there are defective parts. This, coupled with the time expense of obtaining labeled data, motivates research into unsupervised techniques. In particular, we build upon the AnoGAN and f-AnoGAN work by T. Schlegl et al. and created a new architecture called PandaNet. PandaNet learns an encoding function to a latent space of defect-free components and a decoding function to reconstruct the original image. We restrict the training data to defect-free components so that the encode-decode operation cannot learn to reproduce defects well. The difference between the reconstruction and the original image highlights anomalies that can be used for defect detection. In our work with CT images, PandaNet successfully identifies cracks, voids, and high z inclusions. Beyond CT, we demonstrate PandaNet working successfully with little to no modifications on a variety of common 2-D defect datasets both in color and grayscale.",https://www.semanticscholar.org/paper/410fb9c0a527b8dbae034e2a8e25dc325fdd5e74,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'ada6b3f7a01cbe55c306f28c4abb6422dee713e6', 'd65c2cbc0980d0840b88b569516ae9c277d9d200', '744fe47157477235032f7bb3777800f9f2f45e52', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '8388f1be26329fa45e5807e968a641ce170ea078', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '22aab110058ebbd198edb1f1e7b4f69fb13c0613', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'c2b733a79db700b971327a58ef42699fe8a416aa', '2f85b7376769473d2bed56f855f115e23d727094', 'ceb2ebef0b41e31c1a21b28c2734123900c005e2', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",17,set(),0,"['Kevin M. Potter', 'B. Donohoe', 'Benjamin Greene', 'Abigail Pribisova', 'Emily A. Donahue']",Kevin M. Potter,"Kevin M. Potter, B. Donohoe, Benjamin Greene, Abigail Pribisova, Emily A. Donahue",0.0
f7174c5c29c3904cc2d23f26be2b896a5bc715b4,Latent Feature Decentralization Loss for One-Class Anomaly Detection,2020-09-08,"Anomaly detection is essential for many real-world applications, such as video surveillance, disease diagnosis, and visual inspection. With the development of neural networks, many neural networks have been used for anomaly detection by learning the distribution of normal data. However, they are vulnerable to distinguishing abnormalities when the normal and abnormal images are not significantly different. To mitigate this problem, we propose a novel loss function for one-class anomaly detection: decentralization loss. The main goal of the proposed method is to cause the latent feature of the encoder to disperse over the manifold space, such that the decoder can generate images similar to those in a normal class for any input. To this end, a decentralization term designed based on the dispersion measure for latent vectors is also added to the existing mean-squared error loss. To design a general solution for various datasets, we restrict the latent space by designing a decentralization loss term-based upper bound of the dispersion measure. As intended, a model trained with the proposed decentralization loss function disperses vectors on the manifold space and generates constant images. Consequently, the reconstruction error increases when the given test image is unknown. Experiments conducted on various datasets verify that the proposed function improves detection performance improved by about 1% while reducing training time by 48%, without any structural changes in the conventional autoencoder.",https://www.semanticscholar.org/paper/f7174c5c29c3904cc2d23f26be2b896a5bc715b4,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'd891dc72cbd40ffaeefdc79f2e7afe1e530a23ad', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '3b98c57895ecb5b4fe04a530c38087b88749154c', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', 'c68cd22de315a14587120e98bb02fdcf51edec46', 'd4f11472e808b6667712910113833de9ce7b0a65', 'db787640c9b42416ff8d7015546e667e58267177', '4d8abae45a5492ed2399fd5e25eeade8ac0bfa0f', '93bab0ee410a5504d31e95afb2d43ac2da7dbdd7', '2981e8267135dae55c0c061ee214e888ecbef099', '77f0a39b8e02686fd85b01971f8feb7f60971f80', 'e2b7f37cd97a7907b1b8a41138721ed06a0b76cd', '5435a9ab36a308cef10bc725104e8f778ed3a328', '1c46943103bd7b7a2c7be86859995a4144d1938b', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', None, 'b8f9e19c52ad33dcbb766a0b016d58c89d8e48f1', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '9fa3720371e78d04973ce9752781bc337480b68f', 'eb42cf88027de515750f230b23b1a057dc782108', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '8381157eae4fbf8908d0312a9642f8e69e944449', '40addc9c5d6ab5668fe347806e94546e80e66595', '4cfd770ccecae1c0b4248bc800d7fd35c817bbbd', '7f2f4874b3cf4b6379c9824bf9eed0821dcfd018', '967d532a66dab7edcb818b0f9dc59fe8da7dc171', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",33,set(),0,"['E. Hong', 'Y. Choe']",E. Hong,"E. Hong, Y. Choe",0.0
b1464ca857593c049873421db2f37bf2d0ff676d,Same Same But DifferNet: Semi-Supervised Defect Detection with Normalizing Flows,2020-08-28,"The detection of manufacturing errors is crucial in fabrication processes to ensure product quality and safety standards. Since many defects occur very rarely and their characteristics are mostly unknown a priori, their detection is still an open research question. To this end, we propose DifferNet: It leverages the descriptiveness of features extracted by convolutional neural networks to estimate their density using normalizing flows. Normalizing flows are well-suited to deal with low dimensional data distributions. However, they struggle with the high dimensionality of images. Therefore, we employ a multi-scale feature extractor which enables the normalizing flow to assign meaningful likelihoods to the images. Based on these likelihoods we develop a scoring function that indicates defects. Moreover, propagating the score back to the image enables pixel-wise localization. To achieve a high robustness and performance we exploit multiple transformations in training and evaluation. In contrast to most other methods, ours does not require a large number of training samples and performs well with as low as 16 images. We demonstrate the superior performance over existing approaches on the challenging and newly proposed MVTec AD [4] and Magnetic Tile Defects [14] datasets.",https://www.semanticscholar.org/paper/b1464ca857593c049873421db2f37bf2d0ff676d,"{'1bac0cd5adebba3adb668ec38930fe2f1344d576', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5db790198b9acf4e5efe350acdd814238fcacaa7', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '58996dc0102302ef5d734ea7fea27dd52e7f3e4d', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '90f72fbbe5f0a29e627db28999e01a30a9655bc6', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'c53352a4239568cc915ad968aff51c49924a3072', '8086d054446bb816b11098b300b9c426a78e512f', '10a498003e9204f5fc1328e706510a37e514d8c7', '3c3698ce314a77271b566713edb2911f921299e3', '75cb21fa931e957941c0237a1030aa36209bae36', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '01b6affe3ea4eae1978aec54e87087feb76d9215', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', None, 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '666af169c4e106152a8bf91fb32166c4aa84b9da', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', '6a97d2668187965743d1b825b306defccbabbb4c', 'd40ad31c8639e23877bcdc149cc337560ee91b6a', '7cb2bedc49377b3cab3ddfbd3aff13e57af49880', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",31,set(),0,"['Marco Rudolph', 'Bastian Wandt', 'B. Rosenhahn']",Marco Rudolph,"Marco Rudolph, Bastian Wandt, B. Rosenhahn",0.0
efabba68912e88a1eb2e9714ff4681b8478ceb83,Image Anomaly Detection Using Normal Data Only by Latent Space Resampling,2020-12-03,"Detecting image anomalies automatically in industrial scenarios can improve economic efficiency, but the scarcity of anomalous samples increases the challenge of the task. Recently, autoencoder has been widely used in image anomaly detection without using anomalous images during training. However, it is hard to determine the proper dimensionality of the latent space, and it often leads to unwanted reconstructions of the anomalous parts. To solve this problem, we propose a novel method based on the autoencoder. In this method, the latent space of the autoencoder is estimated using a discrete probability model. With the estimated probability model, the anomalous components in the latent space can be well excluded and undesirable reconstruction of the anomalous parts can be avoided. Specifically, we first adopt VQ-VAE as the reconstruction model to get a discrete latent space of normal samples. Then, PixelSail, a deep autoregressive model, is used to estimate the probability model of the discrete latent space. In the detection stage, the autoregressive model will determine the parts that deviate from the normal distribution in the input latent space. Then, the deviation code will be resampled from the normal distribution and decoded to yield a restored image, which is closest to the anomaly input. The anomaly is then detected by comparing the difference between the restored image and the anomaly image. Our proposed method is evaluated on the high-resolution industrial inspection image datasets MVTec AD which consist of 15 categories. The results show that the AUROC of the model improves by 15% over autoencoder and also yields competitive performance compared with state-of-the-art methods.",https://www.semanticscholar.org/paper/efabba68912e88a1eb2e9714ff4681b8478ceb83,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '7d76a09aa363685bc0f04a502ed853dc09a574e2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '47c8fc6b7dfd23d9eb3b314c04486d07d2af0e50', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '8da5704ca149b5ec56a2a584154030b07f4ed0fd', 'd03513c4f95939b8397a01b8986cdd7dd44ce550', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'ae97c81b45780dc91e18eb84236d8a40a290b329', 'eff2df8ac9155480bf768606b09b7852f0c5f0c6', '59bb8d6c3eec8f925710db4d2488e2a23167d3e8', 'c8924e3265e3f16af3177e619cf68a5ef764442f', 'd1f66ae01457fbdd3fde50ff8cc9e3e02b8464ed', '08e15f8b48be499081294d39dc9e7be86b6fc7ed', 'f466157848d1a7772fb6d02cdac9a7a5e7ef982e', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'e5614f59dc657d7add799373712dd5baee68f330', '1f528877c4d8d5df3b3abbfa64379677d451956b', '63eb7986f726c7a8cf14b720fa6eba3ab168c4a4', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'b5e853572b2f3134acafa76d5ae80b9f28c7dca8', None, '788f6cbdf0e8cfa365903bd261dcaaf18de4c435', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'ade63626c3617d2e894ae9302369dea6cd130e92', 'bb5018951e0d869769af9336052acad0fe4b36bb', '63c53e35b25e09a3432e4f4dd786f5d539304f30', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'ec9a7793c5e35a6ff1730269934ad49788928338', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', 'd1c424c261c577958917055f72fb9e2ad0348865', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', '66ccd943eebb652af13b6096c6edc3407eb510e5', '0936352b78a52bc5d2b5e3f04233efc56664af51', 'c0f10f73a1fa28b9a42553ea16451070cc30b01e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '065060a16109fa4763e41cfa5c30e80a2a666c99'}",42,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '1f528877c4d8d5df3b3abbfa64379677d451956b'}",3,"['Lu Wang', 'Dongkai Zhang', 'Jia-yi Guo', 'Yuexing Han']",Lu Wang,"Lu Wang, Dongkai Zhang, Jia-yi Guo, Yuexing Han",7.142857142857143
0c99cdf9fe41e5af3616b7d0eb8f3d1b8c07a9e6,A Contrario multi-scale anomaly detection method for industrial quality inspection,2022-05-03,"—Anomalies can be deﬁned as any non-random struc- ture which deviates from normality. Anomaly detection methods reported in the literature are numerous and diverse, as what is considered anomalous usually varies depending on particular scenarios and applications. In this work we propose an a contrario framework to detect anomalies in images applying statistical analysis to feature maps obtained via convolutions. We evaluate ﬁlters learned from the image under analysis via patch PCA, Gabor ﬁlters and the feature maps obtained from a pre-trained deep neural network (Resnet). The proposed method is multi-scale and fully unsupervised and is able to detect anomalies in a wide variety of scenarios. While the end goal of this work is the detection of subtle defects in leather samples for the automotive industry, we show that the same algorithm achieves state-of-the-art results in public anomalies datasets.",https://www.semanticscholar.org/paper/0c99cdf9fe41e5af3616b7d0eb8f3d1b8c07a9e6,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '1a4f4e417bd14f10d15b6ce821c756c0670b1213', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '89a4618d9af12b98af656f9d620256e7cfcd4a1c', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'f412bb31ec9ef8bbef70eefc7ffd04420c1365d9', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '8ea22449703c0b9c1b949ed3190d2ca3a47ed1bd', 'd03513c4f95939b8397a01b8986cdd7dd44ce550', 'ec76ea04ccb07048c2abb527774888b6a33c7edc', '19862af96b6af51e879e6e3f1d3d421af5427005', '89e1b679d4de5bbb6108d2c3e4b691b670bbf949', '62b77e5cb85fc61b84edd532f6d65714be152596', 'e09f2a6e0a3f480b230e1ae8574010916b1ba9f7', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '03787aeb62d883729813f67b322a74f24cd0edd5', 'ca2e917e2f399010da6bb9ba989c01fd406ddcb6', '1281e443d2cf1c1dd71ed3b7b0376d408d0958af', '27ce5a120a86632dd56f869ee65656b7d7312a3a', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', None, 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', 'e2dc6b0d1f0454e990778b412c92b9048c2115cd', 'a50f88e5e335e29d71fcec97b3309671574a4576', '3517b9824def42f3c723c6c63eda7ade12d25538', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '394f6127e5362e9b5bfb0122b2c19234d2eb04fe', '9c842b2926fd60b9e6ff80fee28c65e7c1ae5f1d', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c'}",35,"{'931dffdd56d60b6b9619a9f5ea8b533ec1ccdf04', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '62b77e5cb85fc61b84edd532f6d65714be152596', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'cc63b87a654e28aefe60250e950572bfb3d7e2ea', '498e003901f8287e89e5064477cd22dd47e49d61', '19862af96b6af51e879e6e3f1d3d421af5427005', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['Matías Tailanián', ""Pablo Mus'e"", 'Álvaro Pardo']",Matías Tailanián,"Matías Tailanián, Pablo Mus'e, Álvaro Pardo",25.714285714285715
11b404c52301dceef6419f1c55916b99204d638a,AutoAno: Anomaly Localization with Self-supervised Multi-scale Feature and Multivariate Gaussian Estimation,2021-12-14,"Anomaly localization in images has long been challenging and valuable for both research and real-world applications. Popular methods for anomaly localization are with Auto-Encoder variants and existing GAN-based models, and have obtained decent outcomes. However, these generative models have significant limitations, such as the over-powerful generalization capacity in anomaly data. To address this problem, in this paper, we propose AutoAno, a self-supervised learning model that leverages both multi-scale feature and multivariate Gaussian estimation to achieve robust anomaly localization. In detail, our method extracts multi-scale features from the patches of an image, which can simultaneously consider global, contextual, and local features, so that contains richer semantic information to anomaly localization. We then employ multidimensional Gaussian distribution to estimate the low-dimensional representation for the normal samples in training data. Notably, we discard the commonly used reconstruction loss, and instead use the distance between multi-scale feature and the estimated Gaussian distribution to detect and localize the anomalies. To verify the effectiveness of our work, we compare AutoAno with the prevailing models with extensive experiments on benchmark and real-world datasets. The empirical results demonstrate that our model outperforms the state-of-the-art models significantly.",https://www.semanticscholar.org/paper/11b404c52301dceef6419f1c55916b99204d638a,"{'d03ca175e2b2745126e792fdc31dfadae4c63afa', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '7463c0b948cd8ade6d7ffe3bafa6b75e114b51aa', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'c71dead165366c1e985bb4385b29bb9b07325fea', 'fffbf0cbafa24f17fe5db8582efaa3406ebd08a4', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'c53352a4239568cc915ad968aff51c49924a3072', '67107f78a84bdb2411053cb54e94fa226eea6d8e', '5435a9ab36a308cef10bc725104e8f778ed3a328', '37595f7a51982d776e57c7280b9445474d90f0be', '60fef33549f57f5cbb6712a510c3a444ab682429', '317aee7fc081f2b137a85c4f20129007fd8e717e', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', 'a4e86e9df17292555c10e1023fd2dd1cf635ab35', 'd3b614f11969127a08447c41257b3a7b58766d18', None, 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'c707517507873bc2cdc489b6fd9af74770468c48', '9de4e9efeda53a366b17d9aa188b15604e6245c3', '41747cbdbed84762dfbfc305254c97021279dc6e', '206c2e79b5f1b4541b85f47517666961ed49500e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'e8a5f27e7805f8de84ea008d59452ff864271696', '775247047d0b56950ba5ea77d4a29772eca95c1b', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb42cf88027de515750f230b23b1a057dc782108', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '184ac0766262312ba76bbdece4e7ffad0aa8180b', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",43,"{'775247047d0b56950ba5ea77d4a29772eca95c1b', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'd3b614f11969127a08447c41257b3a7b58766d18', '9277dc70c74bcadf80dab11c28ead83fd085deec', '37595f7a51982d776e57c7280b9445474d90f0be', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', '41747cbdbed84762dfbfc305254c97021279dc6e', '206c2e79b5f1b4541b85f47517666961ed49500e'}",9,"['Qiang Tong', 'Meixue Sun', 'Bo Wang', 'Dianyu Liu']",Qiang Tong,"Qiang Tong, Meixue Sun, Bo Wang, Dianyu Liu",20.930232558139537
cdfff974b7f35f0f54c00f1b8412b5b4703a52b7,Unsupervised Anomaly Detection and Localisation with Multi-scale Interpolated Gaussian Descriptors,,"Current unsupervised anomaly detection and localisation systems are commonly formulated as one-class classifiers that depend on an effective estimation of the distribution of normal images and robust criteria to identify anomalies. However, the distribution of normal images estimated by current systems tends to be unstable for classes of normal images that are under-represented in the training set, and the anomaly identification criteria commonly explored in the field does not work well for multi-scale structural and non-structural anomalies. In this paper, we introduce an unsupervised anomaly detection and localisation method designed to address these two issues. More specifically, we introduce a normal image distribution estimation method that is robust to under-represented classes of normal images – this method is based on adversarially interpolated descriptors from training images and a Gaussian classifier. We also propose a new anomaly identification criterion that can accurately detect and localise multi-scale structural and non-structural anomalies. In extensive experiments on MNIST, Fashion MNIST, CIFAR10 and MVTec AD data sets, our approach shows better results than the current state of the arts in the standard experimental setup for unsupervised anomaly detection and localisation. Code is available at https://github.com/tianyu0207/IGD.",https://www.semanticscholar.org/paper/cdfff974b7f35f0f54c00f1b8412b5b4703a52b7,"{'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '790eceaa2cb59fef2634dad40f628346eb07cd3d', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', '5db790198b9acf4e5efe350acdd814238fcacaa7', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '04513c7c0b3a63fde81a996dae064a28d453c17a', '60fef33549f57f5cbb6712a510c3a444ab682429', '656f5f724020d259cec9c70f45bf8fc26aed6e4b', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '46d5cf70365d48ad38ed549fb44cf76810e8f8da', 'd36efb9ad91e00faa334b549ce989bfae7e2907a', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '711cb048076ec8f297efe4cb2c77c1ed95c0ccc4', 'a0e8f4348968195c80494b7a4245edb91a252c93', '9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a', 'e6df192c9b654bc5cc371c55012cf99d85cb61df', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'f5b0d51ca54fd1b7268486393679dd612d482f64', '97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '1728cb805a9573b59330890ba9723e73d6c3c974', '77f0a39b8e02686fd85b01971f8feb7f60971f80', '3bb5a439a0d610a7eac68f73068cdd278b8c9775', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'd3b614f11969127a08447c41257b3a7b58766d18', None, '41747cbdbed84762dfbfc305254c97021279dc6e', '3517b9824def42f3c723c6c63eda7ade12d25538', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '1c713c581f3917c8cf4a100c295eb8a175679d53', '599fd051c9438011ec5b581983c89e8922b4a5e6', '8109587a56d53c6ba30fe19ba9aa4d9213ec91a0', '0c908739fbff75f03469d13d4a1a07de3414ee19', '8f28873be3601c5a2736996eba543cf51950a381', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', '9d5290fadb7625862a966e0330bd0f9e111fc99d', '1f528877c4d8d5df3b3abbfa64379677d451956b', '3c4f0260a6e35b5d5276ecd3d8c1081aacd161ff', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '4463dc4a32b948f0230f3b782cbfecaf1c9e5b1d', '775247047d0b56950ba5ea77d4a29772eca95c1b', '8381157eae4fbf8908d0312a9642f8e69e944449', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', '094ac7510d1723cb9c2da01db47291322aa29025', '048ef48f58156ab9f8eb4c1126e090194459e699', '3c8a456509e6c0805354bd40a35e3f2dbf8069b1', '6f68ce1e03c56c186256dac689a21f6405ae8d96', '9cc912ae25797e5f7c0d73300d3968ad8339b411', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'a03bda078490e8ee991a1f86b53f27df7cf93a14', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'e399a626ba21fafb19b3661603ec9724058e951b', '510a24375b5166842cae47f2e54052846704e8f4', '5435a9ab36a308cef10bc725104e8f778ed3a328', '31cbbce38417c704df5dc5f6c4bef46d38b0e190', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '634e2f1a20755e7ab18e8e8094f48e140a32dacd', '1442cb4613c99924f500ebdc2a7fdaf2e9080da5', 'fcadb2bac99550adcdbd8578eb246eb9e264ecf3', 'b9bdc61d63d75d82f24de21be26f61879df5a01b', '559c56678dc3ab0bcd166e18c6e290a2796ab410', '38d4b5a464652a4afb4f043f141976f5c71c1e6b', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '08f99af9f5d6d351201ee4563e407bf37bc164fd', '554cb0e8a604701ca78f2d782f2a26119eadaa81', 'db20d81d40243d66ff90f11b5c6f058d43d3701f', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '84f7f9e121c1285e15cefbfc44bcb3322f73b6aa', '0936352b78a52bc5d2b5e3f04233efc56664af51', '598fe25743f9492c5c1ba30274ea446f65426d85'}",84,"{'775247047d0b56950ba5ea77d4a29772eca95c1b', '1f528877c4d8d5df3b3abbfa64379677d451956b', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', 'd3b614f11969127a08447c41257b3a7b58766d18', 'd9d7ab13ce305ccee309c989a2341d72b1252070', 'b32be13cd0fcd516e8b859c36a02917f1a68ab9c', '41747cbdbed84762dfbfc305254c97021279dc6e'}",7,"['Yuanhong Chen', 'Yu Tian', 'Guansong Pang', 'G. Carneiro']",Yuanhong Chen,"Yuanhong Chen, Yu Tian, Guansong Pang, G. Carneiro",8.333333333333334
b32be13cd0fcd516e8b859c36a02917f1a68ab9c,Anomaly Detection Neural Network with Dual Auto-Encoders GAN and Its Industrial Inspection Applications,2020-06-01,"Recently, researchers have been studying methods to introduce deep learning into automated optical inspection (AOI) systems to reduce labor costs. However, the integration of deep learning in the industry may encounter major challenges such as sample imbalance (defective products that only account for a small proportion). Therefore, in this study, an anomaly detection neural network, dual auto-encoder generative adversarial network (DAGAN), was developed to solve the problem of sample imbalance. With skip-connection and dual auto-encoder architecture, the proposed method exhibited excellent image reconstruction ability and training stability. Three datasets, namely public industrial detection training set, MVTec AD, with mobile phone screen glass and wood defect detection datasets, were used to verify the inspection ability of DAGAN. In addition, training with a limited amount of data was proposed to verify its detection ability. The results demonstrated that the areas under the curve (AUCs) of DAGAN were better than previous generative adversarial network-based anomaly detection models in 13 out of 17 categories in these datasets, especially in categories with high variability or noise. The maximum AUC improvement was 0.250 (toothbrush). Moreover, the proposed method exhibited better detection ability than the U-Net auto-encoder, which indicates the function of discriminator in this application. Furthermore, the proposed method had a high level of AUCs when using only a small amount of training data. DAGAN can significantly reduce the time and cost of collecting and labeling data when it is applied to industrial detection.",https://www.semanticscholar.org/paper/b32be13cd0fcd516e8b859c36a02917f1a68ab9c,"{'74879f53e3e5fa580bdb3e2693861bdf40c0a8c1', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '0597aba86088282423e7c2d2deb6fca4075e7a91', '2788a2461ed0067e2f7aaa63c449a24a237ec341', '4d376d6978dad0374edfa6709c9556b42d3594d3', '5b713f00eb7ebe21064321e73be8f32455a76799', '1ed0dcd304219d8469ae64a6cf17bb75abb92776', '5c9335d9d64ef708f8d7c911ec26aaa9dcb0d1e9', '4b9400c97c12dbc12c010892fe067ec6c6055e34', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '5435a9ab36a308cef10bc725104e8f778ed3a328', '8372d225a287de70a212bb92fc4e8188f35cbcd5', '2f85b7376769473d2bed56f855f115e23d727094', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '3ddda55edf20f59c726c44b5509e603a0e939e47', '86e9db6f23a6a8a7a98c38027440bf51b1bf8450', 'd1edd4c9305cd4e080312ba28d8242a5a49cbd99', None, '414170e0f6959ec452c6da866a61a2a557682f56', '5694e46284460a648fe29117cbc55f6c9be3fa3c', '581f5bf822e701d3dfa80dbb82c5a3ac7633791f', 'aa6f7ad0a06b52a8be89dbd8d056561418276ff2', '41747cbdbed84762dfbfc305254c97021279dc6e', '261e81cba749f70271fa4b7e230328fc1a4a6c96', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '23ffaa0fe06eae05817f527a47ac3291077f9e58', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'c92ee6ff32fa4833fa1c2bdf29284e2a58ddb640', 'e15cf50aa89fee8535703b9f9512fca5bfc43327'}",32,"{'41747cbdbed84762dfbfc305254c97021279dc6e', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",3,"['Tang Tang', 'W. Kuo', 'Jauh-Hsiang Lan', 'Chien-Fang Ding', 'Hakiem Hsu', 'H. Young']",Tang Tang,"Tang Tang, W. Kuo, Jauh-Hsiang Lan, Chien-Fang Ding, Hakiem Hsu, H. Young",9.375
e4e112e4bc508071bdb797af3968dbe512b543bc,SLA2P: Self-supervised Anomaly Detection with Adversarial Perturbation,2021-11-25,"Anomaly detection is a fundamental yet challenging problem in machine learning due to the lack of label information. In this work, we propose a novel and powerful framework, dubbed as SLA2P, for unsupervised anomaly detection. After extracting representative embeddings from raw data, we apply random projections to the features and regard features transformed by different projections as belonging to distinct pseudo classes. We then train a classifier network on these transformed features to perform self-supervised learning. Next we add adversarial perturbation to the transformed features to decrease their softmax scores of the predicted labels and design anomaly scores based on the predictive uncertainties of the classifier on these perturbed features. Our motivation is that because of the relatively small number and the decentralized modes of anomalies, 1) the pseudo label classifier’s training concentrates more on learning the semantic information of normal data rather than anomalous data; 2) the transformed features of the normal data are more robust to the perturbations than those of the anomalies. Consequently, the perturbed transformed features of anomalies fail to be classified well and accordingly have lower anomaly scores than those of the normal samples. Extensive experiments on image, text and inherently tabular benchmark datasets back up our findings and indicate that SLA2P achieves state-of-the-art results on unsupervised anomaly detection tasks consistently.",https://www.semanticscholar.org/paper/e4e112e4bc508071bdb797af3968dbe512b543bc,"{'06671547fd94c44688b10c8cd550242557e55154', 'b804af86fe5212eb7d6e2ac5bf0fa01558c0d209', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'feee6551179612b9691f021b583d8a99b81b9b86', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', 'ba908ea3bfdf5cadcea8e7db9762ce5e522312f5', 'b5781eaafe1aff25a084d83dc38831ea09db42f3', '599fd051c9438011ec5b581983c89e8922b4a5e6', '2a534b203d0d718756a5b7279a93f47810f4cf4c', 'df9010d72c03c158e6bbd57ba88500dab6dca72a', '5db790198b9acf4e5efe350acdd814238fcacaa7', '4d376d6978dad0374edfa6709c9556b42d3594d3', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'adf3b591281688b7e71b254ab931b2aa39b4b59f', 'aedb8df8f953429ec5a6df99fda5c5d71dbee4ff', '983dda1eac92afd1fa6234a713ae07a6008b4534', '00a1077d298f2917d764eb729ab1bc86af3bd241', '67bdefa8dc2cb991beb4b421e14271155de781a5', '64f260cac1a9b2240b748b8106d2339f25b98565', '0d0b1ab01468479c96308a16561e5af460204c3f', 'c53352a4239568cc915ad968aff51c49924a3072', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', '04513c7c0b3a63fde81a996dae064a28d453c17a', '912b0b7879ca99bf654a26bbb0d50d4b8e0ed6c0', '37595f7a51982d776e57c7280b9445474d90f0be', '8215fb083cb4b0ed2b6858b81dcc30fbd0afb6e1', 'ae9bf201f128cabaa4350b54ff6607525c736cd5', '5c8fe9a0412a078e30eb7e5eeb0068655b673e86', '38b3a4447a47a6a6ed1869f3da03352c487f8fe3', 'de7faeadbe7c3b6ddc18e8700378af2a55596000', '1f528877c4d8d5df3b3abbfa64379677d451956b', 'a0e8f4348968195c80494b7a4245edb91a252c93', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, '6cf1d69e447e9687dbd2d92572f44bddbabd8192', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'ddbc185ed132f09673ef048aab0a10a25ee6d27e', '05fb162abd00afc4cb453cad8685191fd199928c', '575a0e97702edcb0621a47b574949bac50e34200', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', '41747cbdbed84762dfbfc305254c97021279dc6e', 'cc384cff27d8a609f89f9e915c26bf31c39749a1', 'a7c828184693a453a6c2867dee233ed054b2012e', 'fa62b0a1ef618ee2595f06f1af9744ad63938a63', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '469a01a8ee42afa3a7dd2740a61d0b46689f2efc', '5d90f06bb70a0a3dced62413346235c02b1aa086', '3a2ef5c27e7140f819a4c99444b7d4fd533dca59', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74', '5f4b1aae83024a4408143baaf47641ab38bcc7e9', 'eea4ca46542125e02cd7b6de60f28c3710b3f7a3', '0fe615dc0a422100e85cfb7e26c9306c481f6c75', 'd2c389c88828728ba4284d66d937f51257840234', 'd8021847ed0e3f26b53416c2a254a85451ee5f1e', '598fe25743f9492c5c1ba30274ea446f65426d85'}",61,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '37595f7a51982d776e57c7280b9445474d90f0be', '1f528877c4d8d5df3b3abbfa64379677d451956b'}",4,"['Yizhou Wang', 'Can Qin', 'Rongzhe Wei', 'Yi Xu', 'Yue Bai', 'Y. Fu']",Yizhou Wang,"Yizhou Wang, Can Qin, Rongzhe Wei, Yi Xu, Yue Bai, Y. Fu",6.557377049180328
502a58aa0807aed227dbb47100718c00433f6604,Clasificación y detección de errores en piezas para inspección industrial,2020-06-23,"This work presents a comparison between feature extractors over a set of industrial parts. The goal of this features is to train a model able to clasify a part into its corresponding class, or discard the part if it contains a significant deviation. The purpose of this comparison is to select the most significant features to improve the clasification with rejection system within Zerogravity3D. This is a product developed by the Technological Institute of Computer Science. Obtains a set of 16 views from the part under inspection and reconstructs it. Currently, it extracts the geometrical features area, volume and standard deviation from the points of the 3D model. Both 2D view features and 3D model features are considered. The histogram of distances to the centroid of the model is proposed to be included along with the existing 3D features extracted. For the views of the part, some classical techniques (such as Zernike and RLBP) and Deep Learning (MVCNN) are considered. Among all feature extractors, Zernike and MVCNN achieved the best results, with a 89.6% and 93.6% precision and 4% and 6.9% error rate, respectively. MVCNN, due to the fact that is a Deep Learning technique, is more computationally expensive than Zernike and therefore takes three times more time to compute (400 ms for MVCNN and 120 ms for Zernike in an Intel(R) Xeon(R) CPU E5-2630 v3 processor). The 3D features proposed achieve a 8.7% increase in precision and a 0.86% reduction on the error rate. However, it doesn’t achieve a precisión (70.84%) comparable to the previous features, although it gets a low error rate (4.05%). Moreover, it is the slowest of all feature extractors (2 seconds), as it requires to perform the 3D reconstruction. RLBP obtains the lowest precision (67.53%) and a higher error rate (14.7%) but it is the quickest, needing just 10 ms to compute the features. The fact that the best results are the ones using the views of the parts allows the removal of the 3D reconstruction phase. Furthermore, the two best options, Zernike and MVCNN, are compared. Due to the computational cost and training risks of MVCNN, Zernike is chosen as the best alternative. This is proposed as a final solution to the project and, finally, the instalation process inside Zerogravity3D is detailed.",https://www.semanticscholar.org/paper/502a58aa0807aed227dbb47100718c00433f6604,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '480da1f275acd6ab1d97de61f8113215ec2c6ea6', 'e0c716aee8e5b960515d3928e84e07baa0fcb7aa', '7f02165e97e99a038bdda0d2a989d713e73e30c0', '1b938308d8da989f91d68c0e9aed92a60a2504a6', '1a2a770d23b4a171fa81de62a78a3deb0588f238', '39fc35fa9e2ad6ffc2f68d3baed8c6bdf412cedf', 'e0c59a78ed656c4c25b33a17680a6ed4a04d5691', '14d9be7962a4ec5a6e55755f4c7588ea00793652', 'f12b2b698d586e219bfa07a56615d1cefb8557e1', '25757e7819eeb8829d3524474f973b79befd7b59', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '303b49275f97649793dfce931cf7ee908ef83c2a', '4cab9c4b571761203ed4c3a4c5a07dd615f57a91', None, '8ba838009fceef57a9937e2439c4499a3d3840e3', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '1ba8376f416e90fe434977ae9f300997667498d2', '5985014dda6d502469614aae17349b4d08f9f74c', '428a251ce5676a779be3a167ce996155d30ee3db', '9b3c7a6ff4eb96889ae0e8cc4a5d642ca4e1169d', '27d274fda9b2f37fee8c5435dfeea2642410749b', 'dea858e6bd4c8baafe952388afe36f868571eb09'}",23,set(),0,['Omar Del Tejo Catalá'],Omar Del Tejo Catalá,Omar Del Tejo Catalá,0.0
c299a47d3472ec236bad4e7d91e29540d3572177,Automated Optical Inspection Using Anomaly Detection and Unsupervised Defect Clustering,2020-09-01,"Neural networks have proven to be extraordinarily successful in many computer vision applications. But the approaches used to train neural networks require large datasets of annotated images, which requires a solid amount of human time to prepare those datasets. To facilitate the adoption of machine learning based technologies in industrial computer vision applications, this paper presents a two-step unsupervised learning approach for anomaly detection with further defect clusterization. In the first stage, the defects are not explicitly learned, but are interpreted as an anomaly or novelty based on the dataset of defect-free samples. In a second stage, the anomalies detected in the first stage are clustered in unsupervised manner and classified into meaningful categories by experts with process knowledge (e.g. critical or non-critical defect). This paper presents a first small dataset containing one industrial object with a complex shape. The object is made of aluminium and is shown both free of defects and defective. Based on this, recommendations are given for an acquisition setup for a large, extensive dataset. Most of the existing papers are studying the approaches for uniform surface (texture) inspection. The specifics of this research is to identify defects on rigid bodies, which exhibit highly non uniform texture in the image. State of the art methods were evaluated and improved to increase the classification accuracy. With a fine-tuned ResNet-18 it was possible to achieve 100% accuracy for defective and defect-free images.",https://www.semanticscholar.org/paper/c299a47d3472ec236bad4e7d91e29540d3572177,"{'2c03df8b48bf3fa39054345bafabfeff15bfd11d', '25757e7819eeb8829d3524474f973b79befd7b59', 'df67d46e78aae0d2fccfb6212d101a342259c01b', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '96f68a831d723dc0d841daa8e5c1f457603140d3', '18111c46d889f59a3b737030a830431a6f7c7c58', 'dbeda91d692925f2c35c867115358e1aca38bfc6', 'e95cf80f757bf25c14e7767d70d400fff19b04dc', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', None, 'd2c733e34d48784a37d717fe43d9e93277a8c53e', 'f11d69fac609917da82f697758cd694c0f01a730'}",13,set(),0,"['J. Lehr', 'Alik Sargsyan', 'Martin Pape', 'J. Philipps', 'J. Krüger']",J. Lehr,"J. Lehr, Alik Sargsyan, Martin Pape, J. Philipps, J. Krüger",0.0
50ce2066fd34ea8a3b37beb141ba32aab8210fed,Unsupervised Anomaly Detection Based on Data Augmentation and Mixing,2020-10-18,"When performing tasks using deep learning, the quantity and quality of data are important. However, in unsupervised anomaly detection, it is difficult to obtain a large amount of high-quality training data. Hence, data are typically extended via rotation, translation, and cutting. However, the typical data augmentation method may generate data far from the original image. To obtain various high-quality training data, we partially use AugMix, a data augmentation method that mixes the original image with images obtained via image processing, such as by rotating the original image. Using this data augmentation, new data can be generated while retaining the features of the original image as much as possible, and the diversity of training data can be enhanced, compared with performing the same image processing. Consequently, the effectiveness of the proposal method for improving the accuracy of unsupervised anomaly detection is confirmed.",https://www.semanticscholar.org/paper/50ce2066fd34ea8a3b37beb141ba32aab8210fed,"{'4feef0fd284feb1233399b400eb897f59ec92755', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb35fdc11a325f21a8ce0ca65058f7480a2fc91f', '34adc3101810bc4d5ef84b4136455a89b9c86c27', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '8388f1be26329fa45e5807e968a641ce170ea078', None, 'a2e667e4382aaa8e02a17d0522c1a910790ab65b'}",9,set(),0,"['Naoya Ishida', 'Y. Nagatsu', 'H. Hashimoto']",Naoya Ishida,"Naoya Ishida, Y. Nagatsu, H. Hashimoto",0.0
f132f752104dc289249e41021199e1d67539f651,Contrastive Predictive Coding for Anomaly Detection and Segmentation,,"Reliable detection of anomalies is crucial when deploying machine learning models in practice, but remains challenging due to the lack of labeled data. To tackle this challenge, contrastive learning approaches are becoming increasingly popular, given the impressive results they have achieved in self-supervised representation learning settings. However, while most existing contrastive anomaly detection and segmentation approaches have been applied to images, none of them can use the contrastive losses directly for both anomaly detection and segmentation. In this paper, we close this gap by making use of the Contrastive Predictive Coding model (Oord et al., 2019). We show that its patch-wise contrastive loss can directly be interpreted as an anomaly score, and how this allows for the creation of anomaly segmentation masks. The resulting model achieves promising results for both anomaly detection and segmentation on the challenging MVTec-AD dataset.",https://www.semanticscholar.org/paper/f132f752104dc289249e41021199e1d67539f651,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '1cae417456711c4da184f5efcd1b7464a7a0661a', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '77f0a39b8e02686fd85b01971f8feb7f60971f80', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '56b49a52057cd8e5497fd5618f031ad701bf6526', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', 'd3b614f11969127a08447c41257b3a7b58766d18', 'e3ce36b9deb47aa6bb2aa19c4bfa71283b505025', None, '41747cbdbed84762dfbfc305254c97021279dc6e', 'eae7d5b15423a148e6bb32d24bbabedfacd0e2df', '8bf6c69bae0956db13aa9129fedc69fdc1256dce', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', '155b7782dbd713982a4133df3aee7adfd0b6b304', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '09bd55b7ea6bbe1c352ca4b04c86fcf1e7d677cb', '7623bf275d0682993fd40044a1c038873ec82608', '94192bcdf3507e3543910c03b16bd06c5338fd47', 'add2f205338d70e10ce5e686df4a690e2851bdfc'}",30,"{'0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', 'd3b614f11969127a08447c41257b3a7b58766d18', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '498e003901f8287e89e5064477cd22dd47e49d61', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', 'd2e6ad4e474666d3d71b92d0892339ffc1c7b972', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",9,"['Puck de Haan', 'Sindy Löwe']",Puck de Haan,"Puck de Haan, Sindy Löwe",30.0
61789b94bd4564d64b66f55aa351fabc680f9f3a,A Nested Autoencoder Approach to Automated Defect Inspection on Textured Surfaces,2021-09-01,"Abstract In recent years, there has been a highly competitive pressure on industrial production. To keep ahead of the competition, emerging technologies must be developed and incorporated. Automated visual inspection systems, which improve the overall mass production quantity and quality in lines, are crucial. The modifications of the inspection system involve excessive time and money costs. Therefore, these systems should be flexible in terms of fulfilling the changing requirements of high capacity production support. A coherent defect detection model as a primary application to be used in a real-time intelligent visual surface inspection system is proposed in this paper. The method utilizes a new approach consisting of nested autoencoders trained with defect-free and defect injected samples to detect defects. Making use of two nested autoencoders, the proposed approach shows great performance in eliminating defects. The first autoencoder is used essentially for feature extraction and reconstructing the image from these features. The second one is employed to identify and fix defects in the feature code. Defects are detected by thresholding the difference between decoded feature code outputs of the first and the second autoencoder. The proposed model has a 96% detection rate and a relatively good segmentation performance while being able to inspect fabrics driven at high speeds.",https://www.semanticscholar.org/paper/61789b94bd4564d64b66f55aa351fabc680f9f3a,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'e85e7458b8b38ae0b77743885856ce870912329c', 'dd8502990c6a7c40e95237be1f22c0fc3ac64e39', '7286011fe383e9d29ece2d9df6251cc626cbbe9a', '87be21423ce6d245c0bf27a516947a63676047dd', '912dd30eabdd7332870d984b86bee32fd95686c0', 'f33b35f675ca3ca310c695be53a27a95925dfb66', 'fadca1cd379e6013efbb29d1de923f90f1af2bb2', 'e62a40492cad57f859a07891cc43eee4d31f3a0b', 'e8180ad45ed5ca732e492db32aa85e769836132e', 'a688da8cf145e93c8e77a2b5888bb1b609fd5205', 'cd02e521facb8c9b634661d5ae302b0e23da58ca', 'fb8e2adf906990107791b49489ede76ea33f21aa', 'c944f84bbfaf1e63617b4fabdfd41322f497cfc7', '7ff03683c1fb824e5cd32fd48253f020f7bcfb7a', '3299df310df522e7f364b04922b15b18926bd418', '5d20c9847c79c7478aff208bdc8dad29823b88eb', '12174778a1adbc467cc55ca04295c055e276df5b', 'e0e11a3459e2848bac92f67ae1c7acc00d38bdc9', '656d86b2593f87575bcc4f056dad3d18db29eb0c', '3339faa058203be9f11d2ab56258cca21d3db53a', None, '849cdf5fdf27a28f3f022583fb77cd75280f1e94', '1dd3faf5488751c9de10977528ab96be24616138', '5db1b742cd18678ed08a813970bfaba3527df037', 'df122da5e33a562a2ffc23ceb96a8827989ac532'}",26,set(),0,"['Muhammed Ali Nur Oz', 'O. Kaymakci', 'M. Mercimek']",Muhammed Ali Nur Oz,"Muhammed Ali Nur Oz, O. Kaymakci, M. Mercimek",0.0
89557df7c0ce4b669fd5c47ab9d022c996f45479,Soft matching network with application to defect inspection,2021-04-28,,https://www.semanticscholar.org/paper/89557df7c0ce4b669fd5c47ab9d022c996f45479,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '7fd32822514dd150852a0d44193e3bb1c61e2778', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'ce2d5b5856bb6c9ab5c2390eb8b180c75a162055', 'ee4a012a4b12d11d7ab8c0e79c61e807927a163c', '4dee7f0bd46fbdd2a96f265977d732ff4348b0d2', 'de95601d9e3b20ec51aa33e1f27b1880d2c44ef2', '06ea68828166f51e7b97b906f149368b95c7eb1a', '5e83ab70d0cbc003471e87ec306d27d9c80ecb16', 'afaabe41563dac2c1ff6accb54107246a44cdcee', 'd28ea3172f8cd4ef01899f9a22fefaae22b78897', '77f0a39b8e02686fd85b01971f8feb7f60971f80', 'fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5', 'ab889b9ec70930577d9fd26f31bbe29b39383c6a', 'af206a6e4214cc0626f11f5891335403d927a9d3', 'b06f2a7460bef1c1ef48c7c3353dbcc864727cc2', '441fbfdcc77187c9f9c41166b5fd42de04de1427', 'cf51d5f69bed98f4c961ccb7ac471f0d93c42cac', '0c5274ab2f2ca11e2bf5ac1faed219e180c3bef7', 'f7b41cc0e1972d914e3f2cea29372555fb228453', '7a92ede0fc11a7cdc8fc9e87e583e5f2d0d8f40c', '7ea1e825f8df939da1960008202767922953ffc4', '3c433b7f69026f6d4e5bbfff966e637b0863073f', 'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36', 'df67d46e78aae0d2fccfb6212d101a342259c01b', '2b970860ce5f6ea116d107667022ea379a9a409c', 'd1edd4c9305cd4e080312ba28d8242a5a49cbd99', '6bfae0653f3bdc2fd08b3b0b37a21c58e11c6db5', 'b3e8260558f0ce5c215b3a1751864232f888d048', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '8c04f169203f9e55056a6f7f956695babe622a38', '156c680c83a4c72b86c5c815343a2d9b9fd07d39', '0cc97cb43a2180db18bc5a3711cb56f26ec70f4c', '77d30cf9a34fb6b50979c6a68863099da9a060ad', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '894eb9401cfd7ed26216cd1ad609943ef65294e9', '03887d5a9829301f6e5cb2d47655db68430f4d16', 'eb42cf88027de515750f230b23b1a057dc782108', '81cc624916ad9eda88a4def247aca8d2f72d1499', 'b2b8ab163fb0183325dd3458e3cbaad2f8bf265e', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', '1f01fc226913ab74e4b1b67d19721ed8d9fce4cb', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '63bc06753e0d38b511ddc07482822c24785e8c9a', 'e15cf50aa89fee8535703b9f9512fca5bfc43327', 'f72683ebdbe426eac958427e977a43a8a0863a20'}",47,set(),0,"['Haodong Zhang', 'Yongquan Chen', 'Bin Liu', 'Xinping Guan', 'Xinyi Le']",Haodong Zhang,"Haodong Zhang, Yongquan Chen, Bin Liu, Xinping Guan, Xinyi Le",0.0
51ba3b33f445199d9f3cddb5b00c7e2927199b0c,Deep Learning for Unsupervised Anomaly Localization in Industrial Images: A Survey,2022-07-21," Abstract — Currently, deep learning-based visual inspection has been highly successful with the help of supervised learning methods. However, in real industrial scenarios, the scarcity of defect samples, the cost of annotation, and the lack of a priori knowledge of defects may render supervised-based methods ineffective. In recent years, unsupervised anomaly localization algorithms have become more widely used in industrial inspection tasks. This paper aims to help researchers in this field by comprehensively surveying recent achievements in unsupervised anomaly localization in industrial images using deep learning. The survey reviews more than 120 significant publications covering different aspects of anomaly localization, mainly covering various concepts, comparisons of the methods reviewed. In reviewing the achievements to date, this paper provides detailed predictions and analysis of several future research directions. This review provides detailed technical information for researchers interested in industrial anomaly localization and who wish to apply it to the localization of anomalies in other fields.",https://www.semanticscholar.org/paper/51ba3b33f445199d9f3cddb5b00c7e2927199b0c,"{'2895770450e9cdfa4bfa42ea035b0a2397205e95', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'fde52ab74c420dcbc0172a979eeeb4c9d36f4e4d', '1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af', '3f8976a36c12173a0a1b458b8c8c4fee01fe9a1c', '5da4eb1135d5827ce30e099bda377a19f3a52730', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'f20d4d60cfb02475043be9fe632b1497671dc25a', 'ca97e64989910a794f0d0e11dbdfcf610cea0bc2', '01ebc98c5df46afa505c029fc5fb930cf9569d00', '85e582b46f3e9f79ca2c6f5c5f2d9a13dfa19f56', '00b46923c31b21f59ab53cf693b6159c3dc4375d', 'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '88927365ced23662f84d55677aa037248effd1df', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'a9b3a9dd494576f54c946aa030fe491eba239b7e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'd70765afccf7125ed408310ca4ba4b5dd0b80520', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'a2d2c830934bbb7e205e8b789fe56736d30c1c80', '9775d372bfaf889a395dc714e283b6a179e62537', '13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'c10fc2e7ae62209320fb779235615c2b8f4ac2c0', 'e5349e937545d3f3d18d254bd21d695e7350ea8e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '9cd70ca81b4653aa2048002273c5ac9c36641390', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '00ec1d0b26dd0221ee0c89a5bcb25e1855825ab3', '84bdd4897a924bf4863dc34576995f952532320e', 'b0e5ec93c2648ec25a5afd51dc6ba9f171615abd', 'f215dde930dce032d682692f54cb5c77af694d0f', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '19862af96b6af51e879e6e3f1d3d421af5427005', 'c8924e3265e3f16af3177e619cf68a5ef764442f', 'd78f2e0d5e3040ad62d5bcd0abca8a8507bff209', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', 'e95cf80f757bf25c14e7767d70d400fff19b04dc', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', 'b6fec9aa7fb4d4abdbf9504a582236c652404218', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '02ffd48179272a4f39f7b7acb89ba98c349723de', '523a3a25b5da622985b82cb9c1a1a04c4e2130bc', 'caa3706a21f97404368fa10a5fe80d5929770618', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '4c4a6a0e8c57e282dc96a100d1db8d9410c3bd67', '57fa261e2b0d961aa9408ee64fd5ccc6382c99b6', '7eb24c2109f75c614cc7aa4c1cac8b643c05e70c', None, 'fb52b5d8c07326cc8f618d525ae162e1a89f1009', '63e5276f62d5185fccb3bee080b00640563c2891', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '85aefb7a0c0e0f7a60b7c453d1767c9dd6b7964a', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '5db1b742cd18678ed08a813970bfaba3527df037', '8ee35ed698527d9695c872e3b76715fec4ef69ad', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '3a6ab170bd646b5497d544f511c75d871affb307', '052680f7631080fcfedcbb83aa98df2617724528', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '75a838cbc1541858b9c484001cade327640dc280', 'f33de7b2fa5425391f5afa81b85818d03325cb0e', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', 'd84c62734eb07141495421da1fdf9ed211ea4f93', 'b5943c566e67545dba80db54e1a28c28e3a44c1e', '0281ea775a33d9a294f9efe16d0b61ed597166a1', '7348b6ad3ab8b17a5d105671341dc3a7c332a6b3', 'c75acecad5c137f050a58c546fd61ae46ece4ebf', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'b227f3e4c0dc96e5ac5426b85485a70f2175a205', '29d5f0b9cc680c172009b583e59fc79663604353', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', 'e4c43bdf9ceeeb918f5c5e947dc4c68b48e3579d', '6af440915b8a0718c93be1cf61905e41e620484a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d', '671a4df62eb5771e4ea3027555317f3da9438a64', '99436caa4a0ad48889316e2484ff9f8c3c2f8c76', '7de3cc199336851abf180047d1240ddecf033d99', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '206c2e79b5f1b4541b85f47517666961ed49500e', '5cfbc7b77f5e5b447e69e48f7711ffb6f6f261eb', '244a6813d9b7fbf2fbd91f2a6e3a425d1d7f67fa', 'bcabeb8345c97394454e3d5365605e08f35c6dde', '02805f18989b7e77f30ee13defd6fecfcd0f499f', '45535b86c60661dd4c4e4f375abae80937563499', '9cc912ae25797e5f7c0d73300d3968ad8339b411', '854c92e791ca2d81fec787736866b892b73b87f6', 'e26851c89afcfb1a0fe00292590c9f6e830c4ec0', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '5435a9ab36a308cef10bc725104e8f778ed3a328', '271a667fe50bcc779c254774e8ca967faa054a83', 'cbe677a5e9870cd829bd041a99d61ae00db48c97', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '7342236608a62494ce357e95d5ebecdf8657c357', 'cdfff974b7f35f0f54c00f1b8412b5b4703a52b7', 'd32e2cfcf6841202edd79888f04f880d2b867413', '9221ae991591154a94b416fa4812e991d06ea5a5', '3b7c49dae915988b3cd8f8d10febf36b0518f988', '9c131f92bea583c33daa94fc5e647de67ef9a96d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '24046c62be024695e9c73768ef6bcf870ca383c0', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '49ae00b9a8539ba1a2a7d77408daad850fd33095', 'a2a1a84bc6be32d981d8fac5da813a0f179a3f75', '46786ce31ff75adc402cabd0df489bba43b5643b', '3bc6573cfc5037541880977290094da71af64f42'}",125,"{'2895770450e9cdfa4bfa42ea035b0a2397205e95', 'f33de7b2fa5425391f5afa81b85818d03325cb0e', 'e26851c89afcfb1a0fe00292590c9f6e830c4ec0', '9cd70ca81b4653aa2048002273c5ac9c36641390', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d', 'd9d7ab13ce305ccee309c989a2341d72b1252070', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '00ec1d0b26dd0221ee0c89a5bcb25e1855825ab3', 'd84c62734eb07141495421da1fdf9ed211ea4f93', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '19862af96b6af51e879e6e3f1d3d421af5427005', '1a7a28740c6eec40f9d8a8c3d987a8fa1b1437af', 'c75acecad5c137f050a58c546fd61ae46ece4ebf', 'd78f2e0d5e3040ad62d5bcd0abca8a8507bff209', '1ed9eaf526786704d81462c7f9960d9d3ef0cb84', '5da4eb1135d5827ce30e099bda377a19f3a52730', '62b77e5cb85fc61b84edd532f6d65714be152596', '5b6b1f438ba40e04a4e3c1e02bd14fe2e66167f9', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '93040f8a5d10e8fde279e18d353aa3dca2873900', 'ed4472cb96d82cb2a8e51b92a6f079b14ec2a040', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'e13d3f39cb9d03c57fef1344a825c163160dd8e7', 'b1464ca857593c049873421db2f37bf2d0ff676d', 'efabba68912e88a1eb2e9714ff4681b8478ceb83', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '0eb80e81580568ce9d70ad1c2495aef188a9587f', '85e582b46f3e9f79ca2c6f5c5f2d9a13dfa19f56', 'caa3706a21f97404368fa10a5fe80d5929770618', '00b46923c31b21f59ab53cf693b6159c3dc4375d', 'cdfff974b7f35f0f54c00f1b8412b5b4703a52b7', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', 'ea68899e52526ce59c1f0b0cbc7cd992a0700383', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '30b99ae0682d42a2010be401dd1d8f7baca9bb5f', '4c4a6a0e8c57e282dc96a100d1db8d9410c3bd67', '7eb24c2109f75c614cc7aa4c1cac8b643c05e70c', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'fb52b5d8c07326cc8f618d525ae162e1a89f1009', '3b7c49dae915988b3cd8f8d10febf36b0518f988', 'd70765afccf7125ed408310ca4ba4b5dd0b80520', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '206c2e79b5f1b4541b85f47517666961ed49500e', '24046c62be024695e9c73768ef6bcf870ca383c0', '8ee35ed698527d9695c872e3b76715fec4ef69ad', 'd08775cf2bebcffa05c6fa506f687ef56953f128', '02805f18989b7e77f30ee13defd6fecfcd0f499f', '11709bfadfd6bbb371f4077bccb7c26d93c39cdd', '49ae00b9a8539ba1a2a7d77408daad850fd33095', '46786ce31ff75adc402cabd0df489bba43b5643b', 'a2d2c830934bbb7e205e8b789fe56736d30c1c80', '9775d372bfaf889a395dc714e283b6a179e62537', '13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'e5349e937545d3f3d18d254bd21d695e7350ea8e', '45535b86c60661dd4c4e4f375abae80937563499', '3bc6573cfc5037541880977290094da71af64f42', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",61,"['Xian Tao', 'Xinyi Gong', 'X. Zhang', 'Shaohua Yan', 'Chandranath Adak']",Xian Tao,"Xian Tao, Xinyi Gong, X. Zhang, Shaohua Yan, Chandranath Adak",48.8
54f75e66ac7d6eafe374e693f272b428bbffd79d,Applications of Generative Adversarial Networks in Anomaly Detection: A Systematic Literature Review,2021-10-22,"Anomaly detection has become an indispensable tool for modern society, applied in a wide range of applications, from detecting fraudulent transactions to malignant brain tumors. Over time, many anomaly detection techniques have been introduced. However, in general, they all suffer from the same problem: lack of data that represents anomalous behaviour. As anomalous behaviour is usually costly (or dangerous) for a system, it is difficult to gather enough data that represents such behaviour. This, in turn, makes it difficult to develop and evaluate anomaly detection techniques. Recently, generative adversarial networks (GANs) have attracted much attention in anomaly detection research, due to their unique ability to generate new data. In this paper, we present a systematic review of the literature in this area, covering 128 papers. The goal of this review paper is to analyze the relation between anomaly detection techniques and types of GANs, to identify the most common application domains for GAN-assisted and GAN-based anomaly detection, and to assemble information on datasets and performance metrics used to assess them. Our study helps researchers and practitioners to find the most suitable GAN-assisted anomaly detection technique for their application. In addition, we present a research roadmap for future studies in this area. In summary, GANs are used in anomaly detection to address the problem of insufficient amount of data for the anomalous behaviour, either through data augmentation or representation learning. The most commonly used GAN architectures are DCGANs, standard GANs, and cGANs. The primary application domains include medicine, surveillance and intrusion detection.",https://www.semanticscholar.org/paper/54f75e66ac7d6eafe374e693f272b428bbffd79d,"{'8cacfdbd3ef6c78b984c3c3195fb271bdda7777a', '755857d27f9742a29360409763112646dec0a8c3', 'dbc7401e3e75c40d3c720e7db3c906d48bd742d7', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '16aedf0e08ca9d6d3350c4135d8879111ff0df21', '0d16298285eb347bf951b302e6f2c8e4dc472253', '87d1116dc6f9925b606040496f774c0678402b65', 'edf73ab12595c6709f646f542a0d2b33eb20a3f4', '194cf02f568470439eb9d27a64dcc99ef9799ab2', 'f6976ac7d684632fcb6b6174c6da563657563b09', '047175fb23f6f152d86e81100ba7140dd2847636', '4d8abae45a5492ed2399fd5e25eeade8ac0bfa0f', '4e8a2af88d09b15c557c44c441259547df613289', '139b8c8e8bf38f199a9210e69aace6697708ea58', '46bc2a73ff36d00357eda4e8051f0b015b63e246', '9c515baf0642dfd5191060a9a371d47e01f53e9f', '3447d8b47a8cf7ce9f04ede314f0ded8172fa470', '4bf8cb1dedf3f780af4f750ea3f03abf71425396', '744fe47157477235032f7bb3777800f9f2f45e52', '82f766d3c572b4c690b439edab5d32b3ba72852e', 'de4df9cd002f7ac04c260b657a8ba91c00ca8bfd', '60fef33549f57f5cbb6712a510c3a444ab682429', 'e0e9d697537067b05019084cee3e408f074fe649', '052b1d8ce63b07fec3de9dbb583772d860b7c769', '641165c959554d8f03314778bd6dfb581d9a469e', 'e09abde2be6cff12ef1043bd91380b0ca4d17586', '10a498003e9204f5fc1328e706510a37e514d8c7', 'ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7', 'fc4e198e34b074a149d9748f515743e11804ebd3', 'ba8a3525d19d71bd1496f07d0da600594cee7f5b', 'ea1356239d23b237251b0a74b71a82ed15829f3a', 'f91bf80c7561a7373677699394dda963dca8aa94', 'd41cc7e2844c6cc5f2b4cd25237075469bc6f014', '296b3bdc9d03597b47ef48ae9bd107cb793b0615', '875634a8eed00a679ee2db9dd6475e19912b124b', '6cf2a49ca49caf78ba85ad5cae5cbb35419da32e', 'a7c828184693a453a6c2867dee233ed054b2012e', '353ecf7b66b3e9ff5e9f41145a147e899a2eea5c', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '0f84a81f431b18a78bd97f59ed4b9d8eda390970', '5472fc060d6d22ed3b055732013ac767eb522fa4', 'cc8a6f5368bd7d657a84b7fce59ff6fe73491715', 'ae37774ff871575b7799411bf87f42eb52634390', 'a757cb86bf6c3a33ff08063f8c4ea0bb034e72b1', '14fbb67fb629dd025cb72067d161315736bc8db9', '30895c61bb836f2cae7ef5ba6516886f746a7153', '4988b6fabc534085896376e13d3eb8d350f1421b', 'cdd07ae7650ca9f4be0ed5419d753c46647e3bf2', 'c3113eaad326a955ba96c11b7b65d0c065fb2054', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '33b1148b8ab1bcd08278e99a6f35490d0fd9dd4d', 'fcce5755177b26211ec8e7c72d8cea10c0984ef2', 'a5dbc9359d1a206439be9cb6ec7191f0a8b74834', '8388f1be26329fa45e5807e968a641ce170ea078', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', 'ff40de55c8782da490f7d4ea1fad533a774385c4', '4d376d6978dad0374edfa6709c9556b42d3594d3', '1e1dbfd5b0237c2a865a4e252a5a90125123a8b6', 'eec6a6a85887b06c2aca9897f069b821057fb331', '537a788857541104fb5d93a157844706fe3ad965', '014ad6b5c003ecf7566570266d43154ac8683758', 'd728744fd9cf8a555652465a21a39f511d062d93', '8c846449cd5f48a68945e9fd0beff44a6785f947', 'e95cf80f757bf25c14e7767d70d400fff19b04dc', 'e268e5ac34fab95d986b3eca01ff785e12d774e0', '279a0c2fec56e24cfa94eb0361223474f1ac07ec', '6f17d4941d962b7b3ec2ccbca97239199dbb5f5f', '5679a9a87f05c99865dbf90a569a24cbd786e73e', 'bca49f6a7d35cf1fe6b8ef531a490c24aeffcd03', 'aa7c4040a814cce4c4819edfc934968ab22433df', '29890a936639862f45cb9a987dd599dce9759bf5', '8acbe90d5b852dadea7810345451a99608ee54c7', 'a47f8794d88c5c27123153c4eb9e08046e2b0c9d', 'd0720adad768f022c10825890e63e297ee4830a5', '4eaa135bcba22a0596515e8f5ee48a26ae6523ab', 'dd14c7af248d011ca48c7eef2dd507d6ff66146c', 'ff4b3bbb455c9cc561ddec097a869140b3c1303d', '1afc2b919d17d20ad5b0ffdf1a77d7df44f976f4', '6e36fc1485ee735796a6ac39ff8155bb2c4f7017', '7697c06e25646891c543aff0e8acf0623b4b0837', '4508fddd8e06cdb43be400228ddd8758ccabcbb3', '7b60621086e42a19354f88fd6bc3af85135a07fd', None, '6392babd20c61ed12267bbf94ab6284cc458b96b', 'c10d8d6838f82ffe3e11060f47ce3bee2e87f318', 'dd2ebc42a1a4491b4179dec0ca8686d5c66f6bfe', '5f61089d3d548a515f01b473f0119137d1f340d4', '13eb4d8d61fa320fde0d049a6b4bcde6e550118f', '3f82744e9357b2b1e32ca5a2f9eefdacf18072a2', '50dc752f3512d3838c120c1a8ff5c035d161b9a0', '9c7da2c47c66afe9a723af75908f0b5c45832e61', '85aefb7a0c0e0f7a60b7c453d1767c9dd6b7964a', '261e81cba749f70271fa4b7e230328fc1a4a6c96', '5a5b0024f2a69cee332ea2a608ec980948bb67ba', 'a226a484cc67974fa18e3be3ebe70e5266d4742f', 'be5094828731e019eedd1639e109af6ebf9e5170', '543f21d81bbea89f901dfcc01f4e332a9af6682d', '9fcadebc4fe00f033ea213a1fa974d46c2852eec', '7ac8f533a18f584387dd412a0a27feb9af1c5c93', 'cd5bd706bc9c4114454deb4006ffbd2e4922327e', 'db51b291a1d78e8625352807f2a4a1f7dc4a0e04', 'e5425dd075193bc7814578c410dbf7d1e2793425', '1db6e3078597386ac4222ba6c3f4f61b61f53539', 'e63c0991e699f65d1e3d241c190a739439e490f7', '29c058bf72369ee5bbc5281f6ffc878cabd64047', '8cb44f06586f609a29d9b496cc752ec01475dffe', '2ba23d9b46027e47b4483243871760e315213ffe', '052680f7631080fcfedcbb83aa98df2617724528', '8d7238eea00059deb446b6309bcae2901c966049', '4c5ad77c847f97b6ea898a4b3940d63448f2f503', 'db358e90eb20db588f97682a23f7bbb5bf9e5975', 'f823fbe23bd34dbcd75eecfa807a37fea6bdd576', '7aac834afa2b48625f80e2b9263cf292919f7620', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', 'fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea', 'd3744325106b2c15b17786b3447bd55d874b54f8', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'afb1666f2a6ccf271ae5e288dfc3d736ccd8ec3c', 'd3167d71de5e345efc5bb6dfd4b9a3d9c4f74084', 'e8b8a7778ace2a02f8db6fe321a54520c6b283ca', '1bdd30a8acc75c58a1bdd4daa4545d5f3971a826', 'e37daeaa20bc8cd68db07641201faf1db3b8c31d', '9a700c7a7e7468e436f00c34551fbe3e0f70e42f', '30f2d1fc88e3e1362ff4bda44d1f521841c6bea4', '2966ecd82505ecd55ead0e6a327a304c8f9868e3', '24bd4101e52e0b8c8c47c864152eabd78646c03d', 'f06c963c473b4067189177b876722a55ae0e8803', '9a6ee80121518fadeb21227f9bd9a0f31dfe49b0', '9d5290fadb7625862a966e0330bd0f9e111fc99d', '7d03ad2958726d574d8e2e1ce97e7ae9f574bb41', 'fefeded74334e5eafa47c5df6de2837fe3b7502d', 'eb6f0dd17a493c5ae3d57961ee2f21d107e55343', '8dafc610c1628643330210342dfa0396f5a50acb', '10a398e55ef003c0c28b43a8da86d8a1f880eadb', '3c4f0260a6e35b5d5276ecd3d8c1081aacd161ff', '4a36fe2ba575504c7114f735a18ad16fa97b353d', '525b5b7c59b1526db51c531d90007424ac9c1fd7', '28dbff2283a9ddbc3057e7765b4b1604a5e16464', '84d8c6fb32dbdc8f184974cce6979e6f4a0e7ccc', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', 'aae932cf9c2434f52b03991fcab050a61a960d48', 'd5c9112bef6b9afbc8633bfa742d53e247244a19', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '7560acae2149e85b78b55a26593d5d2207ea9cea', 'b281aec7972a4726b2709a61b51cacd899425825', '7ece301f8d69674b49c3485af49668ed9f6084c8', '3bbe3daf61f5289e1be418aab825b72fb2134e23', 'e8a5f27e7805f8de84ea008d59452ff864271696', '2391eeabd912e758bf0f19f2b3c01031006937fe', '5d90f06bb70a0a3dced62413346235c02b1aa086', '8b3b369ab326b4bca097470ad5dd29282d59619d', '8381157eae4fbf8908d0312a9642f8e69e944449', '0c9997586868c163e6888a761df950a6f6c7eb70', '43a3e04ebb05095c215ba64e9b07ce96d433e346', '4db2f23a5ad2259b90aa9b0545d27cd44337515a', '184ac0766262312ba76bbdece4e7ffad0aa8180b', 'a3354a71d3c4529cdd9a63bbb3153f7e80919aa4', '6afb4cfeb55015b4f2f3550a34685bf99c441a02', 'c2be8f8c12ff5bca9ef507100fd6714d91cfda85', 'ee70341e75c2dffebbabd24b239cc158ad691ed1', '03e532b37ce12c7eb9afc50d43b68dc63bb557f6', '48234756b7cf798bfeb47328f7c5d597fd4838c2', '72e644dd57afeed6df0ead92e22429cb37560fb7', 'd2c389c88828728ba4284d66d937f51257840234', '3d9f880418a19067a6bcd04a1d81af098f8a3b8a', 'cd8bc5c9cae7ebf86f3c42542d59af11fcf308b0', 'fb843952db5732f56c66102bbf13a0f0b8d811ee', '37902a13044f7e06a1a7b12eb7434d5431367ac2', '11c006797085bdaa0ea26f813036c88e8be120a7', '3492dacab1ba96093ee26e1035af88d93c452325', '571b0750085ae3d939525e62af510ee2cee9d5ea', 'abde697aa7c80d627c35645198bdb01c2aefa342', '197d3b4392c8c561f8b2e70b1ed885cbfa4d3be0', 'cbad76941d480e1b0d8675b5ed9ce076457ef74e', 'd54d8c402785006faaf5de19e81f04eb484a3aa2', 'a088b8fa7cfa177e90ce091f6d76530435d5be9d', '00a1077d298f2917d764eb729ab1bc86af3bd241', 'ff08eccf066723772f0776dc332f75e4ef57654d', 'd7e3f35b8a4b459a961641b365ae9438207756a9', 'fc05a56b30ec4630556621c0b24e982259f898b5', '523b6246febf860709411adb121e9771afec72f8', 'e399a626ba21fafb19b3661603ec9724058e951b', '8086d054446bb816b11098b300b9c426a78e512f', 'bf3a7271860b1667e3ceb84e5bc400d2635ff8b7', '99ba9a59bc7a1fb20892d4709d96f676a604d845', '028a3df5b1e6e1cd83d105e42046126093007d6f', 'df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3', '37a052144b510b8827634c38146b190d8b2c8d0b', 'd100b70de7c3f2edcef1b0fbc1f6f6785fed79c0', '17eeaa7bfbadbcd92d5bacdda2e2f5760454eed9', '8a3bf4d403a39ed33f0fa8cf78dc906d6130595f', '231af7dc01a166cac3b5b01ca05778238f796e41', 'd9ef9fb514d1b8e41eac7d895b0218eb21670223', '2a71fb5e47141d86458a5a034a3d152c8e0bffb6', 'bf741643d5958773d605f011808cb3e83537748d', '8e582d05be98bb6bcb6117a2ee05c930cb7a0668', 'c2b733a79db700b971327a58ef42699fe8a416aa', 'ff6bc649e02db10b2fcdd155c734b291de53826e', 'e6c7c0ad83c94b72c68668ad141e629449b98d03', 'a4a6d2cdf872442e8b4a7bcdfca2c40cf9faa3f2', 'b618f88ebaab51c4d38182e773419478abe44cf8', 'a0cdb1753cf7e4b453606aae932135a569d3f35b', '0fba409648eb6087a1e7d741655967815b9f0377', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '3ec67b40697616a856863f9dcbfc88cb76d5ec8e', '05a5ee724f11c86993cc45214f70f2837d109cee', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '2421f55ec4e9bc24d2a7ccb902bbab12fb05d1fe', '1477bff6a7a899eccc3f9f69a242fe6b6234cce5', '22aab110058ebbd198edb1f1e7b4f69fb13c0613', '80de6f973aa211197e219c66988f583bdba4bc6f', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', '5e2bb96c47ccaa16a4e7192e8fadb3b3e1c3acdc', '352120e91c09a4fba38aba38a554b4d36f2ec74f', '16a7896884841497415b05c0f63373cedca26e80', 'b62d965d0dc0d45c0e845d50467643e8050eaf23', '2ba77abca2ebcb8f040e8ba392a0acbdceb419f4'}",219,set(),0,"['Mikael Sabuhi', 'Ming Zhou', 'C. Bezemer', 'P. Musílek']",Mikael Sabuhi,"Mikael Sabuhi, Ming Zhou, C. Bezemer, P. Musílek",0.0
da8932d53a73b8a2b6c2b39d70c789cda4acee0b,Discriminative-Generative Representation Learning for One-Class Anomaly Detection,2021-07-27,"As a kind of generative self-supervised learning methods, generative adversarial nets have been widely studied in the field of anomaly detection. However, the representation learning ability of the generator is limited since it pays too much attention to pixel-level details, and generator is difficult to learn abstract semantic representations from label prediction pretext tasks as effective as discriminator. In order to improve the representation learning ability of generator, we propose a self-supervised learning framework combining generative methods and discriminative methods. The generator no longer learns representation by reconstruction error, but the guidance of discriminator, and could benefit from pretext tasks designed for discriminative methods. Our discriminative-generative representation learning method has performance close to discriminative methods and has a great advantage in speed. Our method used in one-class anomaly detection task significantly outperforms several state-of-the-arts on multiple benchmark data sets, increases the performance of the topperforming GAN-based baseline by 6% on CIFAR-10 and 2% on MVTAD. What’s more, ablation studies show that absolute position information deteriorates representational learning ability of generative methods in geometric transformation tasks, and has different effects on the representational learning ability of discriminative methods in different geometric transformation tasks, which provides a criterion for the use of position information.",https://www.semanticscholar.org/paper/da8932d53a73b8a2b6c2b39d70c789cda4acee0b,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '14edcd37e697f0bbb495962c3b5a3c141410bf37', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '0e96b0a586e3acfcf1602c0e246c04c6080e2315', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '599fd051c9438011ec5b581983c89e8922b4a5e6', '84de7d27e2f6160f634a483e8548c499a2cda7fa', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', 'c5a14c86ab2b42c96cb630c50a2f3a95835ea1e1', '8201e6e687f2de477258e9be53ba7b73ee30d7de', '9a334566b79bc6c6906e2b5285d5ea50b9b99479', 'db787640c9b42416ff8d7015546e667e58267177', '5db790198b9acf4e5efe350acdd814238fcacaa7', 'ff83aade985b981fbf2233efbbd749600e97454c', '363c81a08858df8dd7d1bde79c6e002e3b19f900', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'b110ba174df21a23a9521731d4181261ca5860ed', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '1a00dc525da31292e3734cbae2de681f114e30b1', '2ec8f7e0257a07d3914322b36072d1bbcd58a1e0', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2', '0a47481e741172f09eca86229561da8aa05bf6b2', '04513c7c0b3a63fde81a996dae064a28d453c17a', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '62f3d3015cee122bd147d7d878c85f70cc15680d', '6af440915b8a0718c93be1cf61905e41e620484a', '00695a31a80221c7125e49885a4767896ec2c4f7', '51cdeeef710d1c84e10beadc8480c137ffe8d328', '127d107493c3b7dd64ceb2a3262b003ff75adddc', '70f9968a356d840040a1c9207906f60376dc6bd4', 'fcf43325529c8b1cc26aeb52fd5d7e532abb0a40', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '5f61089d3d548a515f01b473f0119137d1f340d4', '0bb0c6dfeb8f838470f27cefd0ba42192ecaf90a', 'd14e56568dc5f57ccdae899d84f91e34ad847670', '7437fb168cea92e1df8332ac618f7f07b071aca8', 'fd41e9abc8070d433d1a80cf2470bf9fb377539d', '9fcadebc4fe00f033ea213a1fa974d46c2852eec', 'cde35c87aaabbc617d38f9cfaa2721a2e166d750', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', '63de0ad39d807f0c256f851428f211e8d5fcd3bb', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'e1bb329621de73d08c47beae9b5439a1c244eb1a', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', 'fc1b1c9364c58ec406f494dd944b609a6a038ba6', '1db6e3078597386ac4222ba6c3f4f61b61f53539', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d', 'add2f205338d70e10ce5e686df4a690e2851bdfc', '58c41977428b324819982244628243e4cc715b70'}",53,"{'363c81a08858df8dd7d1bde79c6e002e3b19f900', '211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d'}",2,"['X. Xia', 'Xizhou Pan', 'Xing He', 'Jingfei Zhang', 'N. Ding', 'Lin Ma']",X. Xia,"X. Xia, Xizhou Pan, Xing He, Jingfei Zhang, N. Ding, Lin Ma",3.7735849056603774
75edc647568309b2bd667fa8c202a5f1bf66b2fd,Supervised learning vs. unsupervised learning: A comparison for optical inspection applications in quality control,,"For the establishment of a successful quality management system in companies, the quality control of e.g. newly produced goods or the return of old and used parts is an essential component. One solution for this is the optical inspection of the surface of objects with the help of image processing algorithms. Using the case study of printer cartridges, this paper evaluates the extent to which different methods of machine learning can contribute to a successful quality control. Established methods of supervised learning have the advantage that they are already proven in many applications and have a very high detection accuracy. However, they require a lot of labelled training data and this high effort also means high integration costs. A new approach is a data-reduced variant from unsupervised learning. Here, the algorithm is trained only with defect free objects, for example as they come to a large extent from the production. If the objects are defective, the method from the field of anomaly detection or even novelty detection detects something that is different from the learned norm. This has the advantage that not all defects have to be known beforehand. And this in turn avoids acquiring a large amount of training data for each of these defects. This paper compares the effort required to acquire training data and compares it with the detection accuracy of the different methods in order to give an assessment of the extent to which the use of unsupervised learning methods is beneficial. Newly produced and used printer cartridges are used for this purpose. Image data is acquired from 18 different printer cartridge models. Afterwards they are fully annotated (labelled). A smart separation into training, validation and test data allows the training of supervised and unsupervised methods as well as a complete evaluation regarding the effort for data acquisition, annotation and detection accuracy of the defects. Finally, an outlook for chances and risks of the respective procedures is given.",https://www.semanticscholar.org/paper/75edc647568309b2bd667fa8c202a5f1bf66b2fd,"{'9c24454b071bc8e96ea46c5064a7bddf07cca464', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'c299a47d3472ec236bad4e7d91e29540d3572177'}",4,{'c299a47d3472ec236bad4e7d91e29540d3572177'},1,"['J. Lehr', 'J. Philipps', 'V. Hoang', 'D. V. Wrangel', 'J. Krüger']",J. Lehr,"J. Lehr, J. Philipps, V. Hoang, D. V. Wrangel, J. Krüger",25.0
c2b54d3810256f9faedfe0b5aa3a4c901f1c993e,MSE Loss with Outlying Label for Imbalanced Classification,2021-07-06,"In this paper, we propose mean squared error (MSE) loss with outlying label for class imbalanced classification. cross entropy (CE) loss, which is widely used for image recognition, is learned so that the probability value of true class is closer to one by back propagation. However, for imbalanced datasets, the learning is insufficient for the classes with a small number of samples. Therefore, we propose a novel classification method using the MSE loss that can be learned the relationships of all classes no matter which image is input. Unlike CE loss, MSE loss is possible to equalize the number of back propagation for all classes and to learn the feature space considering the relationships between classes as metric learning. Furthermore, instead of the usual one-hot teacher label, we use a novel teacher label that takes the number of class samples into account. This induces the outlying label which depends on the number of samples in each class, and the class with a small number of samples has outlying margin in a feature space. It is possible to create the feature space for separating highdifficulty classes and low-difficulty classes. By the experiments on imbalanced classification and semantic segmentation, we confirmed that the proposed method was much improved in comparison with standard CE loss and conventional methods, even though only the loss and teacher labels were changed.",https://www.semanticscholar.org/paper/c2b54d3810256f9faedfe0b5aa3a4c901f1c993e,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'c7afd747b5c6b77dc22eaa87a8b22888243842b6', '2788a2461ed0067e2f7aaa63c449a24a237ec341', '50004c086ffd6a201a4b782281aaa930fbfe6ecf', '991544f9333296a7d9e5b9751bca932bb68f54e1', 'e03bbca03dc10c4dfb10eca7439aa1a19233aa5a', '0f17f0c5af9e1f74756b1fa1b98a17a75c0ae469', 'bcfba69c2fadf2efea83be12fda2601f8d4681af', '1f5066018662b7c7d13a57611e6f118b2871d39f', '4feef0fd284feb1233399b400eb897f59ec92755', '79cfb51a51fc093f66aac8e858afe2e14d4a1f20', '78a5e7f605e6997553e86f1bb2ead7fbae5f80c6', '1f6c3f1def78919f06efe050e9403e85d5fa3ac9', '73c07e0a998576bb9d9409e5eed713788c0be037', 'b0c065cd43aa7280e766b5dcbcc7e26abce59330', '2298490e82ff3fd03a3a28bd9c9f307bd897a753', '71b7178df5d2b112d07e45038cb5637208659ff7', '6b7fac87b4ef98eceabfc47fd00a7190b1a48900', '1c46943103bd7b7a2c7be86859995a4144d1938b', '1516fe9eeca6e8bd3d26723f725d222107cb2551', '54036f43acc6c9b49b334270c7237217685f52fb', 'abd1c342495432171beb7ca8fd9551ef13cbd0ff', '64dc671107cfdf98e02e76cbc993732d47210549', '6bf187cf239e66767688ed7dd88f6a408bf465f0', None, '8e3f12804882b60ad5f59aad92755c5edb34860e', '5099d47408251626a4adc6a0f5e93678d8188732', 'ecfdfcd1ef21449a01701122745a7be5ba135e7f', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '72564a69bf339ff1d16a639c86a764db2321caab', '8cb44f06586f609a29d9b496cc752ec01475dffe', '05eb6eb4ea7d2b332295dfa5aeb64d5f47c1e628', '0495d9df8eb84dcdab4e5536179823cd26279949', 'd3806e9fefce863dfec7f6f83537bfb24edb278c'}",34,set(),0,"['S. Kato', 'K. Hotta']",S. Kato,"S. Kato, K. Hotta",0.0
db8c381cbaf80c4323959eccee07c85a76b54839,PANDA - Adapting Pretrained Features for Anomaly Detection,2020-10-12,"Anomaly detection methods require high-quality features. One way of obtaining strong features is to adapt pre-trained features to anomaly detection on the target distribution. Unfortunately, simple adaptation methods often result in catastrophic collapse (feature deterioration) and reduce performance. DeepSVDD combats collapse by removing biases from architectures, but this limits the adaptation performance gain. In this work, we propose two methods for combating collapse: i) a variant of early stopping that dynamically learns the stopping iteration ii) elastic regularization inspired by continual learning. In addition, we conduct a thorough investigation of Imagenet-pretrained features for one-class anomaly detection. Our method, PANDA, outperforms the state-of-the-art in the one-class and outlier exposure settings (CIFAR10: 96.2% vs. 90.1% and 98.9% vs. 95.6%).",https://www.semanticscholar.org/paper/db8c381cbaf80c4323959eccee07c85a76b54839,"{'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '540b5b4919d345e4da3cc4f3e8a7862329bf41a2', 'aab368284210c1bb917ec2d31b84588e3d2d7eb4', 'aa5741c74b7fac10680c1cfbdd49d9ffb5751a68', '34733eaf66007516347a40ad5d9bbe1cc9dacb6b', '4d39ee7cca8fedf792570724255a4357aa41dbf8', 'f9c602cc436a9ea2f9e7db48c77d924e09ce3c32', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '3039962978812c1c2a33135d60673ebdffe2ce55', '6cf1d69e447e9687dbd2d92572f44bddbabd8192', 'f008d9b244fcb393ceb57b42ea165e58a31286bd', '576fab96d98981946fcace0384cdba8f7290a8c5', '5db790198b9acf4e5efe350acdd814238fcacaa7', '922c5fcceeaa0ba8129dc8104bdd3df543a6beba', 'c069629a51f6c1c301eb20ed77bc6b586c24ce32'}",16,set(),0,"['Tal Reiss', 'Niv Cohen', 'Liron Bergman', 'Yedid Hoshen']",Tal Reiss,"Tal Reiss, Niv Cohen, Liron Bergman, Yedid Hoshen",0.0
b6a1cd6bb9bf2befb5da322b2efc5781abed37a7,CAM-UNET: Class Activation MAP Guided UNET with Feedback Refinement for Defect Segmentation,2020-10-01,"This paper tackles the task of defect segmentation by exploiting sufficient normal (defect-free) training images and limited annotated anomalous images. We propose a class activation map guided UNet (CAM-UNet) with feedback refinement mechanism for accurate defect segmentation. We first modify and pretrain the encoder of a VGG-16 backboned UNet to classify normal and anomalous training images. Then, for each of the anomalous training images, a CAM is generated as the prior segmentation information. Based on the CAM, we propose a feedback refinement process to train two decoder networks to progressively improve the segmentation output. Extensive experiments conducted on MVTEC AD dataset show that the proposed method significantly outperforms multiple benchmarking UNet methods in terms of mean IOU.",https://www.semanticscholar.org/paper/b6a1cd6bb9bf2befb5da322b2efc5781abed37a7,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'fd9f5693a34fb839fcc39be83c1835aaee0210e8', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'a5452b678b6a9c4f52178e8cde07082134fb5bef', '237c0c16d2843a91b277ebe05a892ca0787d8b57', '9acc51b06f54b07836fad4cc24633187dc21317f', 'c52902d07bf0ec989a10e74d0ba404f0f9b8339b', '0269073e07faaafa4df7b3d7ddac96e6dccf853d', '317aee7fc081f2b137a85c4f20129007fd8e717e', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '6af440915b8a0718c93be1cf61905e41e620484a', '7a7a18e1f3dddcc351403237ea5255099441d5d5', 'b36a5bb1707bb9c70025294b3a310138aae8327a', '31f9eb39d840821979e5df9f34a6e92dd9c879f2', None, '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', '66e56a96a8faf14c12c5526d0b4a29fb03b42181'}",20,set(),0,"['Dongyun Lin', 'Yiqun Li', 'S. Prasad', 'T. Nwe', 'Sheng Dong', 'Z. Oo']",Dongyun Lin,"Dongyun Lin, Yiqun Li, S. Prasad, T. Nwe, Sheng Dong, Z. Oo",0.0
b6b6a19708eb79a54b2e46d52c52839080d9d3f5,Anomaly Analysis in Images and Videos: A Comprehensive Review,2022-06-15,"Anomaly analysis is an important component of any surveillance system. In recent years, it has drawn the attention of the computer vision and machine learning communities. In this article, our overarching goal is thus to provide a coherent and systematic review of state-of-the-art techniques and a comprehensive review of the research works in anomaly analysis. We would like to provide a broad vision of computational models, datasets, metrics, extensive experiments, and what anomaly analysis can do in images and videos. Intensively covering nearly 200 publications we review i) anomaly related surveys, ii) taxonomy for anomaly problems, iii) the computational models, iv) the benchmark datasets for studying abnormalities in images and videos, and v) the performance of state-of-the-art methods in this research problem. In addition, we provide insightful discussions and pave way to the future work.",https://www.semanticscholar.org/paper/b6b6a19708eb79a54b2e46d52c52839080d9d3f5,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'eda97d858766733004ade4f6deedcd88abefd997', '7a89447be0a176368926f1ef108512f4df5e27be', '2172552b917ef3757b0af47d17fce18586d56cba', '42fd9b081bae46644421f66dbc680cd4416becb3', '080bd9fc763cb4d69044012abc62de23cc8b32d9', '5d76a25936366c6619d2b5e6b74106cdb53a4978', '5db790198b9acf4e5efe350acdd814238fcacaa7', '78d6a459b9e185c0c157605f14947ed013005816', 'aa2d574d01063d802f51cda02db2c51aa43cba41', '6d4c9c923e9f145d1c01a2de2afc38ec23c44253', '40e05552280b879e256917268495de7efcce6636', '8cfec832159107397164abcd09dfa6105c43a29f', '38ff1be1f6b6f53b82ba4527721820dedeb59afc', '7ae4d5ec354f2a54b5cd70395cb12283390d0638', 'bd243d77076b3b8fe046bd3dc6e8a02aa9b38d62', 'b724c3f7ff395235b62537203ddeb710f0eb27bb', '53599f3748b73f5d3bbddab646905b5b8e7d3210', '62b77e5cb85fc61b84edd532f6d65714be152596', '77afac8f4d7f47c8b34371d8f8355cefbea1d4f6', 'c2fb5b39428818d7ec8cc78e152e19c21b7db568', '4ed4dc4df5dbde2677852c33080e3c893bf0a5ba', '45b4e7eed084c816e8f7b82fba266919036847bd', '1e67d3c0b5a725f46cdd88d8457042c2ed96362b', '49133ffa30e0acaf4ea5bd8bbf68c841b02e3f2a', '18f207d8dab7357f4f674211ec4f150de1c93a0e', '417eba8614feacc77212bf46552a0af153a968b2', '10a498003e9204f5fc1328e706510a37e514d8c7', 'b20e564edbef25009fa1baa2c369437c89147e61', '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'b6052dc718c72f2506cfd9d29422642ecf3992ef', '68f861693fbcb52f9bf1c6709f0d59d7ec28d759', 'b61a3f8b80bbd44f24544dc915f52fd30bbdf485', '729e2db22f5b0efe7fe4d23e5a6cd0feb7dbfe66', '91d700be15cd6ce7e37032f64985c98002f37070', '68eaa9acd1febaa57e09fa853ff281c5f28f7ed6', '6e1af25596f035ca9f190876ca972780ba27bc3c', '9979b794d0bd06a1959a6b169f2cf32ba8ba376b', 'a9b3a9dd494576f54c946aa030fe491eba239b7e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '73ceefaa861d5e1ad6a06996fa3793a8b0417bff', 'e41d35d0ccf44fd15bca2e328414bd2de91c09ac', '76be79c45335db6d08efcde7843ae298765d4d63', '461efc87636ff4e48323ffcb9f8fdf79cf736fb0', '3afbb0e64fcb70496b44b30b76fac9456cc51e34', 'e5366a704ffa3b41aacd385f3c087ec3fd566934', 'c6d2b2889fbacd3b00cd9e3eef35ae897f54620e', '245c98b84b3690eb3beb38d0cc49f28ba8daf0fd', '1f604ad152339e0a734f05002e6810c72b949611', '05e882679d61f4c64a68ebe21826251a39f87e98', '97e7c94a78ae17cfb90848c1cfca8c431082a7b2', 'c3113eaad326a955ba96c11b7b65d0c065fb2054', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '52d7ae292f285ab24b050b8d229ac98cd674523c', '50a31ac7866c2cba2b5f580973bfbbbd92569142', '44f3ac3277c2eb6e5599739eb875888c46e21d4c', '39e4c98a180c115684fce2caf3f86a0bf804c06a', '5f5dc5b9a2ba710937e2c413b37b053cd673df02', '3b8076846879dc6e113d934a05b10ef49a34e6a3', 'c71dead165366c1e985bb4385b29bb9b07325fea', '11cb870f9d1f7626104747a116463a38fa0edf41', 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '88573561d2e662f53201971fab6ecf6beceefe73', 'c8924e3265e3f16af3177e619cf68a5ef764442f', 'cec734d7097ab6b1e60d95228ffd64248eb89d66', '5d1596adeac9a058462aa70016204b3dc1f19d93', 'd2fb2fa53021b2776da0fb8b53c54820ed3982cc', '31630d1aa44ef8fcac8e127ed9d7ac57e3c11269', 'febda9d873d87cdc5d80a89c23e8676c487771a7', '50499aa9af9b4be0f5ef3ffbdd24299f3c402586', 'd25c65d261ea0e6a458be4c50c40ffe5bc508f77', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '8acbe90d5b852dadea7810345451a99608ee54c7', '193edd20cae92c6759c18ce93eeea96afd9528eb', '297e83bc6d4498ad2e2906092e2b3df1b7621c26', 'a1571c646749b89e8874a83b817cbfb68bb744ff', '91e647bd24f76e56c11016c7a45e328c0ea6ae24', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '50a93a118d5826369d2d28ed87216bde08fdb1b4', '4cab9c4b571761203ed4c3a4c5a07dd615f57a91', None, '5f61089d3d548a515f01b473f0119137d1f340d4', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', '41747cbdbed84762dfbfc305254c97021279dc6e', '9fcadebc4fe00f033ea213a1fa974d46c2852eec', 'f9c990b1b5724e50e5632b94fdb7484ece8a6ce7', 'b0d2366c1ef1455b7c048f459d678acfa0e7336f', 'e6761ec9557f3b231688d3c491f1104cc0eeb2b0', '06d9ad6d0be56bbd6dafae6e712eb773bf8e88cd', '7989be5b6eaf690d27b02dd22f1e4fff3566ccb4', '731a2844c5af6b072d3b404ecabbb488cdad9d46', 'f9f836d28f52ad260213d32224a6d227f8e8849a', '8f50591a58e6650208b446b0355859252ef4a56a', '1a0912bb76777469295bb2c059faee907e7f3258', '96d7a07237e146c28173767dfc6290a337696c04', '9d9aced120e530484609164c836da64548693484', '37257b1e003d97f617f41a5ccf982566ce0a208b', '74160d96dbe90ad4e7d351139c50364784824252', '224b34acba3597912f8adc288fa8adbb1fca92b4', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '67dccc9a856b60bdc4d058d83657a089b8ad4486', '210f258524deabc3d08cbbea4e4ca5c2a98f4846', '5434ef4c0a383ea2728e7e9481c32d7d08b50f69', '49230ef121fbfe03d5a57cb5982ef2135c3a23ad', '599fd051c9438011ec5b581983c89e8922b4a5e6', '232b26f231122f6332d66244e5ad61d8225312a2', 'ff83aade985b981fbf2233efbbd749600e97454c', 'e37daeaa20bc8cd68db07641201faf1db3b8c31d', 'f09f3589df0710142a1d9a7c339d7d1d1c8ffe87', 'f4852f5385d60e8870e30db5c65392d120e58574', '88ecd1aa9148c59782cb35ffd6c9b08084087ad8', '17342b1c4caccfc499d9ae55a68d7b93285c5d6b', 'bb9e6cb0fbf6f703aa7ecba33286a1095ba950d5', '6398bdca3112c0d535becefeb85ba3e3faaf0276', '14f74743abfbd340aaeeb8509a0503d38e44b78f', 'e7eef2ac4136ec93bd306d2c9c353a13729a4553', 'c50059808a746ffdfe0a4fac73c0df8bfbb2fac7', '8f28873be3601c5a2736996eba543cf51950a381', '9d5290fadb7625862a966e0330bd0f9e111fc99d', 'c53352a4239568cc915ad968aff51c49924a3072', 'dd60b5ed4e31cdda77ba8ce7994bc74ac6832aa7', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'fc1e01c26f4b2bd201f545ec05587a4c7eb1c02b', '3c439ef038419f9db396628ed9766af568625f31', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'c48def9076e58095c4aea49a8daa931af1990701', 'aae932cf9c2434f52b03991fcab050a61a960d48', '9d3f0d47449c7db37d1bae3b70db2928610a8db7', 'bf79f0b8b68d7ba67420aa6f88dc7aa5eddd1d73', '2193e8ad8ae323e094f4d04e5a9f96dc04288067', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'eaef3547ec6c32fe683d58c7789dbff57c585b92', '47195627755d88121af2513646ac41eec8645fb7', '692c508e51e2b943d01caad5c06c1b1c24cb4a23', '3c970725788b5b0f50952a7adbaab86f1c519f32', '248a531fd67f3c4d49f31c7217beca649a4bf651', '527cc8cd2af06a9ac2e5cded806bab5c3faad9cf', '5d90f06bb70a0a3dced62413346235c02b1aa086', '73d5beb01dcdee7ede9a1593725e7accd7f48d10', '775247047d0b56950ba5ea77d4a29772eca95c1b', '9bc95b2fa949b0de6ef028fde359e2a60fceee04', '84a7897cf8542b097d7ceff6e9daa6d97b4ad952', 'c0e55d740d07b16a50b5eb491117b92965d315c9', 'c6e2b633dfa017d8aaa2838f8204007eab77de9e', '094ac7510d1723cb9c2da01db47291322aa29025', '386ffc3ee25b9cb9a2915817fac5a903bf6a88df', '6f68ce1e03c56c186256dac689a21f6405ae8d96', '161ae230158a002de2f72336ff46ced04b9cfaf8', 'eaa6bf5334bc647153518d0205dca2f73aea971e', '120080a57dcd82513015f1a4958e31ec1ffac30b', 'e7b7d97042ad2fdf3a7238a724c9dc3195537bea', 'ce9edb785f28c81bd7c2864940ed001429178e1e', '84de7d27e2f6160f634a483e8548c499a2cda7fa', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', 'c83e26622b275fdf878135e71c23325a31d0e5fc', '6d76d282fec8622cd27c07e5b735ed815ff15daa', '99dff291f260b3cc3ff190106b0c2e3e685223a4', 'a03bda078490e8ee991a1f86b53f27df7cf93a14', 'da171d1fae6030bfb0effdf33b28c55395b977e1', '2bf29868e856621a59dad8adb2c66e21348612ef', '264ef105920d13faf6aa358a2e03b2041e384f79', '0b49f8ca23cb55012118af7c03e90633c423891f', '1a00dc525da31292e3734cbae2de681f114e30b1', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'ee1d50a0c6448253eaf8d1f7f6b00d893419589d', 'ef6e0ffe9ab9a6d595cc47e336cb5f54ace7660e', '5435a9ab36a308cef10bc725104e8f778ed3a328', '56ca1bcc0ee88770e86554ce54471130c9acf0e3', '8086d054446bb816b11098b300b9c426a78e512f', '4f8d648c52edf74e41b0996128aa536e13cc7e82', 'f269d851466ce3fe8a4de2bfb37488cc0d3cd19e', '223dd50c948f22ffc97bb4ae5cc2ee671135f5c3', 'a2812bce010a0548688cd344330fe39a2f4d7381', '2b5bc76044e5c36c1911fc14c73f2618ccdb97d9', '344f3839a34ea363fe2833581ab328387c17c2dc', '02d0ef096d3b39bb83a344393522360aaf69d694', '732750bec3b4d8c0108d6daed642500765d5c0ca', '2f03b36a6e8077701da8fa58c46613bd08b707f4', '91e46a251a17088fcfebc85b999ed4d84ed5e4f3', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '5a9038088181677ed7b1cdb9c6e3fdc59a7db491', '59d56365cabd54c919e023692d3ab6c4cd13fb61', '9ac7632c9367e02b058f5b0b633005af35b4809c', 'db20d81d40243d66ff90f11b5c6f058d43d3701f', '1d41090ba8e597380e7353b6b1f42d6a7d9f83b4', '8a6acba7fb2aad1299fcf35701417e063d410ed4', 'a9542b88c6c792e9f0bc3cad671d88a53b81aa8b', '5f8a46852344f27ec724dcb8d0ef56c7931e70a8', 'e15cf50aa89fee8535703b9f9512fca5bfc43327', '598fe25743f9492c5c1ba30274ea446f65426d85'}",192,"{'775247047d0b56950ba5ea77d4a29772eca95c1b', '0368eddb6a90fb7e21df04ecfdf6e5fca95cf32b', '62b77e5cb85fc61b84edd532f6d65714be152596', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '16a67491ed4bdb6293d1c2be35b0e8bae962cdeb', '41747cbdbed84762dfbfc305254c97021279dc6e', '37257b1e003d97f617f41a5ccf982566ce0a208b', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",8,"['Tung Minh Tran', 'Tu N. Vu', 'Nguyen D. Vo', 'Tam V. Nguyen', 'Khang Nguyen']",Tung Minh Tran,"Tung Minh Tran, Tu N. Vu, Nguyen D. Vo, Tam V. Nguyen, Khang Nguyen",4.166666666666667
3b7c49dae915988b3cd8f8d10febf36b0518f988,Neural Batch Sampling with Reinforcement Learning for Semi-supervised Anomaly Detection,,,https://www.semanticscholar.org/paper/3b7c49dae915988b3cd8f8d10febf36b0518f988,"{'01625cba9f8a783994377d4f35aa765242faab4f', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'ec5d26aaf2e6902ca28effa0f94c9556571160b8', '79ab3c49903ec8cb339437ccf5cf998607fc313e', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '047175fb23f6f152d86e81100ba7140dd2847636', '9acc51b06f54b07836fad4cc24633187dc21317f', '59bb8d6c3eec8f925710db4d2488e2a23167d3e8', 'c1722ab22c236f47aa0a2a0e7736fabc56f58251', '941b0be328d6eb370121828acff3acf300e0745a', '97efafdb4a3942ab3efba53ded7413199f79c054', 'e399a626ba21fafb19b3661603ec9724058e951b', '60fef33549f57f5cbb6712a510c3a444ab682429', '6e5231bc928e304a9532698e727c6acedb543908', '317aee7fc081f2b137a85c4f20129007fd8e717e', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '9c24454b071bc8e96ea46c5064a7bddf07cca464', None, 'ce711e917b9f6a4abd2d3555714a90a280c9fa44', '580396c680951b7ff93defcac7cfe085dfe1814e', '219f7706e28c91dcff3d6c4273ac71868714cac2', 'c81c20109c809cfc47565a9477c04ee005d424bf', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '4c915c1eecb217c123a36dc6d3ce52d12c742614', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', 'cab372bc3824780cce20d9dd1c22d4df39ed081a', '2c740e574eea66fdcf473e15ed2c228baef2eccd', 'df137487e20ba7c6e1e2b9a1e749f2a578b5ad99', '0f50b7483f1b200ebf88c4dd7698de986399a0f3', 'ae37774ff871575b7799411bf87f42eb52634390', 'fb1a7c66fd2c831d545eed695fdbe4a7a453449c', '1a0912bb76777469295bb2c059faee907e7f3258', 'd2c733e34d48784a37d717fe43d9e93277a8c53e'}",38,set(),0,"['Wen-Hsuan Chu', 'Kris M. Kitani']",Wen-Hsuan Chu,"Wen-Hsuan Chu, Kris M. Kitani",0.0
d2e6ad4e474666d3d71b92d0892339ffc1c7b972,The Clever Hans Effect in Anomaly Detection,2020-06-18,"The 'Clever Hans' effect occurs when the learned model produces correct predictions based on the 'wrong' features. This effect which undermines the generalization capability of an ML model and goes undetected by standard validation techniques has been frequently observed for supervised learning where the training algorithm leverages spurious correlations in the data. The question whether Clever Hans also occurs in unsupervised learning, and in which form, has received so far almost no attention. Therefore, this paper will contribute an explainable AI (XAI) procedure that can highlight the relevant features used by popular anomaly detection models of different type. Our analysis reveals that the Clever Hans effect is widespread in anomaly detection and occurs in many (unexpected) forms. Interestingly, the observed Clever Hans effects are in this case not so much due to the data, but due to the anomaly detection models themselves whose structure makes them unable to detect the truly relevant features, even though vast amounts of data points are available. Overall, our work contributes a warning against an unrestrained use of existing anomaly detection models in practical applications, but it also points at a possible way out of the Clever Hans dilemma, specifically, by allowing multiple anomaly models to mutually cancel their individual structural weaknesses to jointly produce a better and more trustworthy anomaly detector.",https://www.semanticscholar.org/paper/d2e6ad4e474666d3d71b92d0892339ffc1c7b972,"{'dc00e2c47411d6d257c979963e4dd2f7d97d5d03', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b65fc8f5e7329f0476bc7280f0ef6b91a8c8484b', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '27222787908c3a1c6fb6c4b5cb5ef8b2542f1b3c', '2c455f0da2bd86a9b9ea432d1485049073d7c63d', '9cd3539312f5ddc59d9af2eab18f2834d44d76f5', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '9acc51b06f54b07836fad4cc24633187dc21317f', 'de28c165623adabcdba0fdb18b65eba685aaf31d', '353b5ed7874b7134ee95021bce60b7ac0ee7e1ed', '6e4e75c88a0801c87f47a171aa69a9914f9129bf', 'e3116ebb52c152deae918a04c34441ac0d956b8a', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', 'f7e72483714da394612298d5855185f13fe21ae9', '17a273bbd4448083b01b5a9389b3c37f5425aac0', '9e7be12082f58cbf7ebdb84a8cbdc897a4e41683', '355692eb86b06a0a23af45c106cfb02c95bf380e', '69fe08fb1aa15bbab4ca26c31cc9302e325870b1', '4f51a64793d3b2a60e9e5846c31dae023cf5c69a', '20f69cc41c87b8abdf36761c623d65713daeab3b', '6af440915b8a0718c93be1cf61905e41e620484a', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '70f9968a356d840040a1c9207906f60376dc6bd4', None, '5091316bb1c6db6c6a813f4391911a5c311fdfe0', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'ef9bbc83dea84df3711de01de56f2b7f91bae068', '69115684eb15614b1219366ef93ddc23682b1cac', 'c9e88f51dfcf15ff9677fcde5bff59bee1f2ca94', 'f5a951b9596be0df5ad7ede180b405c9e97a65c9', '15b18f9dc8cc65a638f15ddcef17a79a07b2faac', 'ae37774ff871575b7799411bf87f42eb52634390', '05e3ddcdd6c2f781d719f903f31cedfaa08a2249', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",37,{'e021d59638966a6fbb36854cc2cf1045de7a62d2'},1,"['Jacob R. Kauffmann', 'Lukas Ruff', 'G. Montavon', 'K. Muller']",Jacob R. Kauffmann,"Jacob R. Kauffmann, Lukas Ruff, G. Montavon, K. Muller",2.7027027027027026
24046c62be024695e9c73768ef6bcf870ca383c0,Anomaly detection of defects on concrete structures with the convolutional autoencoder,2020-08-01,,https://www.semanticscholar.org/paper/24046c62be024695e9c73768ef6bcf870ca383c0,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '133981fcdec11dce6a3ceafa548cdadac9375054', '0535625be630c6a67f4c244ebf3aa61ad088fc70', '2941488b503121f9e8e5b09b7bdf28568b6e39e0', 'ba908ea3bfdf5cadcea8e7db9762ce5e522312f5', 'af7dcf5e823f6e1eaa4aff2afa2912585ea32147', 'dfd5c2d199d830272eb7cfb4049ac5ff885a25d5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '9bfc3bd38cdaec93540b3f147d0475563ea09cb8', '6f4472e311228397e319213ba3ee90bdaef66da3', 'aea2e91f1cd90c0fc9f63790c62600ad2d9a99a6', 'ff8d5fe3a7a75711549c6fa2c951e5b702d4636c', 'bb63e3c51b78da88852dac0c67411c8dc930993e', '1142ff65b9392c3d2f2c19196978a0dcb2ad45c1', '04e645fc3e5a578b8d5d662f0b0070eb1255a3e2', '5b59992ca6b77aaec066a0d3142336d2cb1028f1', '7198f45e979d4e7bb2ad2f8a5f098ab196c532b6', '53226cb05116e39f8aefb0cab75e4e3b83004244', '0278bbaf1db5df036f02393679d485260b1daeb7', '14a74f38561e40f839fbac6c9fb06b085e39f282', 'e91fc6c5e5f083b28ef7b4f06163310cf07e8b0d', 'a4cec122a08216fe8a3bc19b22e78fbaea096256', '1a2a770d23b4a171fa81de62a78a3deb0588f238', '6344120752edb26d7c4d17c55ce4ca3f4adf446f', '2abde28f75a9135c8ed7c50ea16b7b9e49da0c09', '6ea358c63de04be500d1ecfffb6f59617ae8bb2a', '6ccd152b0a97a204105f9e7acab9dd62f446428f', 'bab9e71e13da27c6caa87cd677814839e9809f2c', 'f4e8549edc9114f9f8cc432a522b2a8197393c4a', '2e841edc65d5b59846fc259882a9864468b58bd5', '358b9707c2d45c06e23a264d21390c2ed5a1d7ee', None, '37c949ec31a7e8eef6a8bb68e2daf5f2e8cd902d', '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', '414170e0f6959ec452c6da866a61a2a557682f56', '20d3c8710b03c31cc6cb86a6fd964478586c4e34', 'f5985277e1452ee8d06be1876ed5919fb31c8dad', 'ce24c24674af9c0c10cfc7a1a59fd850fc5f0ce1', '4c753f5ab22fe05777dbef32d706fa029e0be1af', '99436caa4a0ad48889316e2484ff9f8c3c2f8c76', 'd63b884d5ebc739f6e1bdf861fa9276260781404', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '058bec13449f05cece18c3e32040bb388b049a7e', 'c1f277de5326780c3a37eac4424338c7bb0551eb', '1d4816c612e38dac86f2149af667a5581686cdef'}",46,set(),0,"['J. Chow', 'Zi-Ren Su', 'J. Wu', 'P. S. Tan', 'X. Mao', 'Yu-Hsing Wang']",J. Chow,"J. Chow, Zi-Ren Su, J. Wu, P. S. Tan, X. Mao, Yu-Hsing Wang",0.0
79c7962f9eaa9a84c8257637e27849d84c6814d5,DSR - A dual subspace re-projection network for surface anomaly detection,2022-08-02,". The state-of-the-art in discriminative unsupervised surface anomaly detection relies on external datasets for synthesizing anomaly-augmented training images. Such approaches are prone to failure on near-in-distribution anomalies since these are difficult to be synthesized real-istically due to their similarity to anomaly-free regions. We propose an architecture based on quantized feature space representation with dual decoders, DSR, that avoids the image-level anomaly synthesis require-ment. Without making any assumptions about the visual properties of anomalies, DSR generates the anomalies at the feature level by sampling the learned quantized feature space, which allows a controlled generation of near-in-distribution anomalies. DSR achieves state-of-the-art results on the KSDD2 and MVTec anomaly detection datasets. The experiments on the challenging real-world KSDD2 dataset show that DSR significantly outperforms other unsupervised surface anomaly detection methods, improving the previous top-performing methods by 10% AP in anomaly detection and 35% AP in anomaly localization. Code is available at: https://github.com/VitjanZ/DSR anomaly detection.",https://www.semanticscholar.org/paper/79c7962f9eaa9a84c8257637e27849d84c6814d5,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6be216d93421bf19c1659e7721241ae73d483baf', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'd67b9dafcf94017784c266e021fe29baf2ffd572', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', 'f466157848d1a7772fb6d02cdac9a7a5e7ef982e', '5435a9ab36a308cef10bc725104e8f778ed3a328', '37595f7a51982d776e57c7280b9445474d90f0be', '4dd78b8d466b4cfe55a1bbdc694291197ce62541', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '7eb24c2109f75c614cc7aa4c1cac8b643c05e70c', '47f7ec3d0a5e6e83b6768ece35206a94dc81919c', None, '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', 'a414c2111a042c0e53f4cb4297ddb39a3801fc1e', '73dc91ef5228dabe1d8ae0ac82c9c708bcae67ba', 'eae2e0fa72e898c289365c0af16daf57a7a6cf40', 'd2c733e34d48784a37d717fe43d9e93277a8c53e', '2cd605106b88c85d7d8b865b1ef0f8c8293debf1', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",23,"{'d67b9dafcf94017784c266e021fe29baf2ffd572', '2c89b183df320c3ef698989bdc5d1d4731c4d65d', '7eb24c2109f75c614cc7aa4c1cac8b643c05e70c', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '95a26eafabf06b1fc5dec6c460a927cf5964e97e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '37595f7a51982d776e57c7280b9445474d90f0be', '41747cbdbed84762dfbfc305254c97021279dc6e', '4dd78b8d466b4cfe55a1bbdc694291197ce62541'}",9,"['Vitjan Zavrtanik', 'M. Kristan', 'D. Skočaj']",Vitjan Zavrtanik,"Vitjan Zavrtanik, M. Kristan, D. Skočaj",39.130434782608695
11709bfadfd6bbb371f4077bccb7c26d93c39cdd,FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows,2021-11-15,"Unsupervised anomaly detection and localization is crucial to the practical application when collecting and labeling sufficient anomaly data is infeasible. Most existing representation-based approaches extract normal image features with a deep convolutional neural network and characterize the corresponding distribution through non-parametric distribution estimation methods. The anomaly score is calculated by measuring the distance between the feature of the test image and the estimated distribution. However, current methods can not effectively map image features to a tractable base distribution and ignore the relationship between local and global features which are important to identify anomalies. To this end, we propose FastFlow implemented with 2D normalizing flows and use it as the probability distribution estimator. Our FastFlow can be used as a plug-in module with arbitrary deep feature extractors such as ResNet and vision transformer for unsupervised anomaly detection and localization. In training phase, FastFlow learns to transform the input visual feature into a tractable distribution and obtains the likelihood to recognize anomalies in inference phase. Extensive experimental results on the MVTec AD dataset show that FastFlow surpasses previous state-of-the-art methods in terms of accuracy and inference efficiency with various backbone networks. Our approach achieves 99.4% AUC in anomaly detection with high inference efficiency.",https://www.semanticscholar.org/paper/11709bfadfd6bbb371f4077bccb7c26d93c39cdd,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'ad7ddcc14984caae308c397f1a589aae75d4ab71', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', '061146b1d7938d7a8dae70e3531a00fceb3c78e8', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', '4758baad6b22c61682e7f7182bb93723046f36f5', '62b77e5cb85fc61b84edd532f6d65714be152596', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '9277dc70c74bcadf80dab11c28ead83fd085deec', 'b364cdb02d18b9d9a3c097f5ea446f7e9ab10325', '04513c7c0b3a63fde81a996dae064a28d453c17a', '268d347e8a55b5eb82fb5e7d2f800e33c75ab18a', '37595f7a51982d776e57c7280b9445474d90f0be', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', 'b1464ca857593c049873421db2f37bf2d0ff676d', '21b786b3f870fc7fa247c143aa41de88b1fc6141', '6af440915b8a0718c93be1cf61905e41e620484a', None, 'ca23e7a71ace53d6a5b2a553ff37c63365d22b8a', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '46f30e94dd3d5902141c5fbe58d0bc9189545c76', 'dc8301b67f98accbb331190dd7bd987952a692af', '0936352b78a52bc5d2b5e3f04233efc56664af51', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",34,"{'4758baad6b22c61682e7f7182bb93723046f36f5', 'fc086bf5f6d1627153b68abdd5a4450e141b4ca3', '8ee35ed698527d9695c872e3b76715fec4ef69ad', '62b77e5cb85fc61b84edd532f6d65714be152596', '9277dc70c74bcadf80dab11c28ead83fd085deec', '78d80c343d36baaf89f18e12d325cf6309fb6c8f', '913d43b69fd4ddee2ff64d3a1e6402d3787e2b7e', '37595f7a51982d776e57c7280b9445474d90f0be', '78661cecf81340be9bd5720ac5ae97dc0e037bb9', 'b1464ca857593c049873421db2f37bf2d0ff676d', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",12,"['Jiawei Yu1', 'Ye Zheng', 'Xiang Wang', 'Wei Li', 'Yushuang Wu', 'Rui Zhao', 'Liwei Wu']",Jiawei Yu1,"Jiawei Yu1, Ye Zheng, Xiang Wang, Wei Li, Yushuang Wu, Rui Zhao, Liwei Wu",35.294117647058826
49ae00b9a8539ba1a2a7d77408daad850fd33095,Image/Video Deep Anomaly Detection: A Survey,2021-03-02,"The considerable significance of Anomaly Detection (AD) problem has recently drawn the attention of many researchers. Consequently, the number of proposed methods in this research field has been increased steadily. AD strongly correlates with the important computer vision and image processing tasks such as image/video anomaly, irregularity and sudden event detection. More recently, Deep Neural Networks (DNNs) offer a high performance set of solutions, but at the expense of a heavy computational cost. However, there is a noticeable gap between the previously proposed methods and an applicable real-word approach. Regarding the raised concerns about AD as an ongoing challenging problem, notably in images and videos, the time has come to argue over the pitfalls and prospects of methods have attempted to deal with visual AD tasks. Hereupon, in this survey we intend to conduct an in-depth investigation into the images/videos deep learning based AD methods. We also discuss current challenges and future research directions thoroughly.",https://www.semanticscholar.org/paper/49ae00b9a8539ba1a2a7d77408daad850fd33095,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '6a83ce3a5604e3dad44c6b5fe992056add6c605f', '14edcd37e697f0bbb495962c3b5a3c141410bf37', 'b78b2e97a86ecc262b02024d31d0446d7cc3795c', '79ea477048cb4c3116d0b001df5485069e8edcca', '1c06870e1ecc63e120e45a2283ca4b72c153e867', '4c1abd8969fc1c360f50373f6552bcfb3cc408b7', '5db790198b9acf4e5efe350acdd814238fcacaa7', '2451c83127c623d6b9456c9e716fb8ca548ffbfb', '99dff291f260b3cc3ff190106b0c2e3e685223a4', '97602b63ea3fa4f43e396f1dda19ed48bf62d646', '8bedee52bf14e326d7fe2b1f1c1d0cb256aa53f6', '1a00dc525da31292e3734cbae2de681f114e30b1', 'f30753abbad51d33722397988825902873776d45', 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803', 'bc6dff14a130c57a91d5a21339c23471faf1d46f', 'd82800c79dd335297336fe10b1a60d47706e4296', '10a498003e9204f5fc1328e706510a37e514d8c7', '6364fdaa0a0eccd823a779fcdd489173f938e91a', 'c48def9076e58095c4aea49a8daa931af1990701', 'aae932cf9c2434f52b03991fcab050a61a960d48', None, '68f861693fbcb52f9bf1c6709f0d59d7ec28d759', 'ccf6a69a7f33bcf052aa7def176d3b9de495beb7', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', 'bee044c8e8903fb67523c1f8c105ab4718600cdb', '427e859813693d880f1e793e3ee8bd0cb8e22484', '83cbd79c00fab69033f124cf9f2a822e27562ce7', '5d90f06bb70a0a3dced62413346235c02b1aa086', '73ceefaa861d5e1ad6a06996fa3793a8b0417bff', '8f45d7624129a7d5fcd0e18354ee4a396c74d6c2', '91e46a251a17088fcfebc85b999ed4d84ed5e4f3', '869b17632ed4f19f93b3b58dcaa9f0b8e92108f3', '8a6acba7fb2aad1299fcf35701417e063d410ed4', '8b7fc929487bf2895a361148ff21899e4c15d313', 'e5366a704ffa3b41aacd385f3c087ec3fd566934', 'fe09f7a379944444201552e952b910188c0aeaca', '6f68ce1e03c56c186256dac689a21f6405ae8d96', '30895c61bb836f2cae7ef5ba6516886f746a7153'}",39,set(),0,"['Bahram Mohammadi', 'M. Fathy', 'M. Sabokrou']",Bahram Mohammadi,"Bahram Mohammadi, M. Fathy, M. Sabokrou",0.0
9c938122c85d655b81ebba0715eac5f4508a9103,Surface Defects Detection Using Non-convex Total Variation Regularized RPCA With Kernelization,,"Surface defects have an adverse effect on the quality of industrial products, and vision-based defect detection is widely researched due to its objective and stable performance. However, the task is still challenging due to diversified defect types and complex background texture. The robust principal component analysis (RPCA) has proven applicable in defect inspection by regarding nondefective background as the low-rank part and defective area as the sparse part. However, such methods cannot sufficiently detect defects due to complex cluttered background, noise interference, and limited features available. To address these issues, in this article, we proposed an unsupervised surface defect detection method based on nonconvex total variation (TV) regularized RPCA with kernelization, named KRPCA-NTV. Specifically, the kernel method is integrated into RPCA to better handle complex cluttered background lying in a nonstrict low-rank subspace. Furthermore, nonconvex TV regularization is introduced to prevent the noise pixel from being separated into the defect region; meanwhile, nonconvex optimization promotes higher solution accuracy. In addition, the kernel canonical correlation analysis (KCCA) is utilized to fuse complementary features for boosting feature representation ability. To demonstrate the superiority and robustness of the proposed method, we compare it with the state of the art on five defect data sets; the results show that the proposed method outperforms competing methods in terms of accuracy and generalizability.",https://www.semanticscholar.org/paper/9c938122c85d655b81ebba0715eac5f4508a9103,"{'868e4d8a6583f2b253d8f3c96d7ca11b93cd433d', 'c8831d7d318b8d59f9b958d250a58f253f08bd8a', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '1aaa5078ddd641a64e6e0d580199bc5ae1a9002c', 'a027e3264e4a5bcdcf8d908fb7061e82860af05b', '57ea5292caabc5e0d7fb1de2734b81ba5be76d27', 'cb308b926ef4451475eda734f99eeff15e627830', '623c56690af31b33189b149e2c0dd8992d4b1aa5', '1d8008233cb89bd83f58fcdb814d5209b34cd5cb', 'ee92ba8887f2df27a655f82dd8aeec194424865d', '538bc3f686df0e04fa531d4d31658b301fc093f1', '6fbd7212ecc15ac4336c09d0debd3887856e9d7f', 'f6a525acc50e55deaf35f72981d20e24da8875ff', '14e56ca931d53bb7fe86dd7a895e26ecf99e18ba', '73073577c56cd93dd3bdde0f8cb31d2518cd7ca5', 'bcbbf3cb7e05191f30fc6681eb493511d899393a', 'f5b9b024b3e3d7207225365bd52a4a0666e0f9a6', '92b501b524160685f39e8fbfab58e01fd6d1adce', '900a1ec34688b46ad544751c3098e55a5e009a99', 'bdb53422adafc2d7f947f7512ff8c246aada9d5b', 'c944f84bbfaf1e63617b4fabdfd41322f497cfc7', '31bc0d4ec9a5bfc2152c4928ac2c3864959c0342', '6f4085f3c31720f3e83d2fe911e4d9cb6901ea9c', '7342236608a62494ce357e95d5ebecdf8657c357', 'd32e2cfcf6841202edd79888f04f880d2b867413', 'e4b81e33c4e48d5d8f7cb2a025215362d2871321', 'd8e7895c3175c9723bc27dfda7cf094291853512', 'f3e7f64f8552eab9d5bf4670a92662fa24a1a339', 'f958765b6d8a8ffdd168a32eb25309a220a579bd', '9b957f916d62280053cad13fc40f7e7f2ec9434e', 'c04a5cf423105c20810c059fee14fa098cfb5c17', '3339faa058203be9f11d2ab56258cca21d3db53a', 'd81421695d5d429a47eefe266986d197d7b313f2', '1eceddd77c5dab655e49bbc3cae69773646a735a', '0d3b2db9af4a72f2e0ec6f15a7f0bc6fe6e97cdb', '42673cfa24b7f3f0e89388b93b3df1a4f7e41d80', '912f31cd82bf70b53ff411dc331896b2a26b433b', '54bc694fd7ec4690975e98eee5bed95b5d506254', '40cce65a38c3c080bec58d16292324a549acbd9f', 'a62b0b8ff07bdbcf4fd1c8449acac1f24d8434c4', 'c09a4d90754628015c311e9c51f4b3ab888c796e', '8bfd710b2bc52f97e04f25665756ee864338d1a8', 'e93eeb399b69efb11a30ae68259ce03e18069c6a', 'ed915bb64ac5f208dc8b9c7dbc8f84fb0481e085', '0e90653de7770b245a20151d4b9409f2530a551e', '2c1198fab3d4f2215bde35ee8b41dd2cb2e9b40d', 'bb48ed21ffc9399db166a0c58d1e7a9b784a58d7', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', 'da18e4cfbeb4c5fd8a6a69d3fbbeca29f73d7a38', 'dad0cb16329b95b1f756086d07cc87027df7e381', 'd2e5962c5aac88d332dcec4074c608dde790242d', 'ab36571b1a887f921a70d1258e2fc6bd62aa168d', 'd30fc01959b0aa4fc7ecf84c8e88fb712c4ba86d', '3c718363c22221fd16771672da3bfd5f67d2c34c', 'e0bbcb3ecf40047a27f9476011af64e111e79ee6', 'f81bfd1ea3ca105ca9305d2e7e3c74bbece0957c', 'ed4a3c68fc748ebb4ac8872b745708d79dc543d7', '3cd7b551ce6e96298429060506732478a58a2478'}",58,set(),0,"['Junpu Wang', 'Guili Xu', 'Chunlei Li', 'Zhengsheng Wang', 'Fuju Yan']",Junpu Wang,"Junpu Wang, Guili Xu, Chunlei Li, Zhengsheng Wang, Fuju Yan",0.0
46786ce31ff75adc402cabd0df489bba43b5643b,An Anomaly Feature-Editing-Based Adversarial Network for Texture Defect Visual Inspection,2021-03-01,"Establishing a unified model for the defect inspection of different texture surfaces remains a challenge in the industrial automation field because these surfaces can vary in regular and irregular ways. Current unsupervised learning methods are trained on defect-free samples only and cannot directly address anomalies during testing, which precludes these methods from simultaneously inspecting for various texture defects. In this article, we propose a novel unsupervised anomaly feature-editing-based adversarial network (AFEAN) to accurately inspect various texture defects. To impart the AFEAN with the ability to address anomalies, a paired input, consisting of a defect-free image and an artificially defective image, is utilized for training. First, the AFEAN employs a feature extraction module (FEM) to extract latent features for the paired input. Subsequently, a novel anomaly feature detection module (AFDM) is proposed to detect anomaly features of the artificially defective image in the latent space. In the proposed AFDM, a novel central-constraint-based clustering method is proposed to detect anomaly features by learning the distribution of the latent features. Next, a novel global context feature editing module (GCFEM) is proposed to convert the detected anomaly features to normal features to suppress the reconstruction of defects. Finally, a feature decoding module (FDM) utilizes the edited features to reconstruct the texture background. Through the AFDM and GCFEM, the AFEAN achieves the ability to address anomaly features, effectively suppressing the reconstruction of defects on the texture background. In addition, to further improve the texture reconstruction accuracy, a pixel-level discrimination module (PDM) is employed to reconstruct texture details. In the testing phase, the defects are segmented by the residual image between the input image and the reconstructed texture background. The extensive experimental results demonstrate that the AFEAN achieves the state-of-the-art inspection accuracy.",https://www.semanticscholar.org/paper/46786ce31ff75adc402cabd0df489bba43b5643b,"{'a71383362e299a44e8852a2772fd2767721e6fe6', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'f5ada173e628caf97c25b20c16a219ed384a006e', '987156a80c8c054ec81335dec1c642ff071e20f2', '54b5b28e0a5a70d90d60260385f81b58dea6c40f', '54e325aee6b2d476bbbb88615ac15e251c6e8214', '599fd051c9438011ec5b581983c89e8922b4a5e6', 'c8c04ed972d38e2326a53d322a6f2d7e0f8218c1', '338e59d667e871ff4507e38c3ff9ca7d616b97cd', '904decf94f5495d1488e2bf22e3ed4df500ce4d5', '10aabf4c13ea57d7106cf809c9edbab63819c277', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', 'e8180ad45ed5ca732e492db32aa85e769836132e', 'f44ff4fc0ed0142cb18472a5ba421bb538aa837e', '83083c5760bd1b58e5f827e57415e5ed676ef3bc', '46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e', '484d1e02b5c47c0245a41acb97d32bf7a70d0737', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '656d86b2593f87575bcc4f056dad3d18db29eb0c', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '1d2105616d122389efbd1b0ac7c04c0c2f8ac996', '70f9968a356d840040a1c9207906f60376dc6bd4', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', 'd81421695d5d429a47eefe266986d197d7b313f2', None, 'd9e9ef4c91134a90704f2fe0722fbec8995734ab', '1aad901be51dcfd453de65eaaa6550eda3d0858f', '5db1b742cd18678ed08a813970bfaba3527df037', '66ccd943eebb652af13b6096c6edc3407eb510e5'}",29,set(),0,"['Hua Yang', 'Qinyuan Zhou', 'Kaiyou Song', 'Z. Yin']",Hua Yang,"Hua Yang, Qinyuan Zhou, Kaiyou Song, Z. Yin",0.0
409885fe203ddb22bed6d43bc749e808d6a653a6,Unsupervised Anomaly Detection in Printed Circuit Boards through Student–Teacher Feature Pyramid Matching,2021-12-20,"Deep learning methods are currently used in industries to improve the efficiency and quality of the product. Detecting defects on printed circuit boards (PCBs) is a challenging task and is usually solved by automated visual inspection, automated optical inspection, manual inspection, and supervised learning methods, such as you only look once (YOLO) of tiny YOLO, YOLOv2, YOLOv3, YOLOv4, and YOLOv5. Previously described methods for defect detection in PCBs require large numbers of labeled images, which is computationally expensive in training and requires a great deal of human effort to label the data. This paper introduces a new unsupervised learning method for the detection of defects in PCB using student–teacher feature pyramid matching as a pre-trained image classification model used to learn the distribution of images without anomalies. Hence, we extracted the knowledge into a student network which had same architecture as the teacher network. This one-step transfer retains key clues as much as possible. In addition, we incorporated a multi-scale feature matching strategy into the framework. A mixture of multi-level knowledge from the features pyramid passes through a better supervision, known as hierarchical feature alignment, which allows the student network to receive it, thereby allowing for the detection of various sizes of anomalies. A scoring function reflects the probability of the occurrence of anomalies. This framework helped us to achieve accurate anomaly detection. Apart from accuracy, its inference speed also reached around 100 frames per second.",https://www.semanticscholar.org/paper/409885fe203ddb22bed6d43bc749e808d6a653a6,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'b8c062674cd20858a2302f6c0209431cd55aa8ef', '0535625be630c6a67f4c244ebf3aa61ad088fc70', 'c7949f426c6849cc84cb4412842c83d460d065e8', 'dd8502990c6a7c40e95237be1f22c0fc3ac64e39', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '0cfb9c17edaabfc220e1ba8c6b9505eb884aa633', 'c7771f41941cf3a146ff61022594f9e5348bcf70', '5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d', 'a0dd32cc9d53d43dd068e40239f0aec4b2ee7344', '2f4df08d9072fc2ac181b7fced6a245315ce05c8', '2528a82dd2266600d4ee2b54165556a984de94d4', 'ba0efba16c77cd6ee03596fd39bb0f02ede4d13b', 'f758105945486ab89bb569130ef778ef9d43d5bd', 'b5c26ab8767d046cb6e32d959fdf726aee89bb62', '1d552c84152b278d4397d8efcfe108022038b646', '01ebc98c5df46afa505c029fc5fb930cf9569d00', '2ec1f92968fb7e6719b6da306919183f185f9d1c', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c', '38b6540ddd5beebffd05047c78183f7575559fb2', '68e7f5bcb2e2c628b15a96bfa72b612bd992a8e6', '38ec86557f805ec27e18e5517a34ca43b2bfa60f', None, '4919e477a67937ba2913b5758db0ff839bce992e', '27f119f7a6ee13b303c3c6ab269bbc31d2ca1292', '41747cbdbed84762dfbfc305254c97021279dc6e', '2e8d62277e40d465343e8dfb32ecc246f320540e', '2c03df8b48bf3fa39054345bafabfeff15bfd11d', 'eb42cf88027de515750f230b23b1a057dc782108', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'b3acb6f183b5f4b651f53c0eec5cb5c805224ac1', '184ac0766262312ba76bbdece4e7ffad0aa8180b', '563143c5f4fed0184c1f3e661917da94cfed1d46', '00f0e7e8c44f310a9c8fd88057d3826cfa89dc28', '464ddf99a5a69f51235eebaef403ce302d4565bc', '9a5105896d452c61ccf95bee5a6fad593aa0cb36', '1f07761d481d03d2dff9ea64ddf5ff5ffb3da445', 'c08f5fa876181fc040d76c75fe2433eee3c9b001', 'e15cf50aa89fee8535703b9f9512fca5bfc43327', '23ad8fc48530ce366f8192dfb48d0f7df1dba277'}",40,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '23ad8fc48530ce366f8192dfb48d0f7df1dba277', '2e8d62277e40d465343e8dfb32ecc246f320540e'}",3,"['Venkat Anil Adibhatla', 'Yu-Chieh Huang', 'Ming-Chung Chang', 'Hsu-Chi Kuo', 'Abhijeet Utekar', 'Huan-Chuang Chih', 'M. Abbod', 'J. Shieh']",Venkat Anil Adibhatla,"Venkat Anil Adibhatla, Yu-Chieh Huang, Ming-Chung Chang, Hsu-Chi Kuo, Abhijeet Utekar, Huan-Chuang Chih, M. Abbod, J. Shieh",7.5
11c98d5d27db5859d069217ca6114a9d5f09d6dc,Edge-enabled Federated Learning for Vision based Product Quality Inspection,2022-06-09,"Since the proliferation of Industry 4.0, manufacturing organisations are moving away from manual product quality inspection to a more digitized edge based inspection supported by sensor-actuator systems deployed at factory floor. Such edge based inspectors are equipped with trained machine learning (ML) models to infer the input data gathered from various sensor types and perform classification and/or detection of damaged products. In a dynamic scenario such as manufacturing, any unseen defects are marked as errors which are subsequently compiled at a back-end/cloud server for ML model re-training and re-deployed. Such model update and periodic release can prove to be costly in a time-critical manufacturing set-up. This paper proposes edge enabled federated learning (FL) based approach to enable visual inspectors recognize unseen defects by using on-device model fine-tuning and secure model exchange with each other. Preliminary results suggest proposed approach is able to improve edge based inspectors' accuracy to recognize previously unseen defects.",https://www.semanticscholar.org/paper/11c98d5d27db5859d069217ca6114a9d5f09d6dc,"{'7fef3e0a7f4f5a86e2a205d82e501591edf9faa9', 'a65f0d2e2748f4b779518bbdc2922e21c12d3ac7', '008ed8459e1267509ba4d028e9868dcc2cb673b8', '48f9a48aa5b1230b05a443d2d531e6441a541686', 'b587165627a09a90781ff0f816a2fc0b82a6b688', '90c738750e01cf71e7def4fc30997c63b129e731', '5b358dc586d9b2c36ede5e706dd563f029e95239'}",7,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Sourabh Bharti', 'A. Mcgibney', ""Tristan O'Gorman""]",Sourabh Bharti,"Sourabh Bharti, A. Mcgibney, Tristan O'Gorman",14.285714285714286
84d69ca72596297c9b2b0996c0df37dadcd659ea,Corruption synthétique d’image pour la détection d’anomalies à l’aide d’auto-encodeurs convolutifs,,"In order to detect anomalies, an autoencoder can be trained to perform an image-to-image mapping from an arbitrary image, i.e. with or without defect, towards a clean image, i.e. without defect. Then, the residual map of reconstruction can be interpreted as the likelihood that a region is abnormal. In a scenario where only clean images are available for training, we suggest to corrupt them with synthetic noise. We show that a structured stain-shaped noise, independent of the image content, combined with the addition of skip-connections to the autoencoder, generalizes to real defects and leads to better anomaly detection.",https://www.semanticscholar.org/paper/84d69ca72596297c9b2b0996c0df37dadcd659ea,"{'a70bc416b1124525499b0ac3d5b009637dc6c187', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '9acc51b06f54b07836fad4cc24633187dc21317f', '195d0a8233a7a46329c742eaff56c276f847fadc', 'a9e438c1e66917379509165fc40f335514870b56', '3c6599052623542f6e21a2cc45a6fde4fb2dc374', 'e021d59638966a6fbb36854cc2cf1045de7a62d2', '5435a9ab36a308cef10bc725104e8f778ed3a328', '25757e7819eeb8829d3524474f973b79befd7b59', '9c24454b071bc8e96ea46c5064a7bddf07cca464', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', None, 'c09a4d90754628015c311e9c51f4b3ab888c796e', 'fa62b0a1ef618ee2595f06f1af9744ad63938a63', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'eb60fe884c53b420edbce57059b242cfcbae0f7c', '8381157eae4fbf8908d0312a9642f8e69e944449', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",20,{'e021d59638966a6fbb36854cc2cf1045de7a62d2'},1,"['Anne-Sophie Collin', 'Christophe De Vleeschouwer']",Anne-Sophie Collin,"Anne-Sophie Collin, Christophe De Vleeschouwer",5.0
20f6fce7726e7b3ab4ca45ef40d92b79f093f825,AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models using Simplex Noise,,"Generative models have been shown to provide a power-ful mechanism for anomaly detection by learning to model healthy or normal reference data which can subsequently be used as a baseline for scoring anomalies. In this work we consider denoising diffusion probabilistic models (DDPMs) for unsupervised anomaly detection. DDPMs have superior mode coverage over generative adversarial networks (GANs) and higher sample quality than variational autoencoders (VAEs). However, this comes at the expense of poor scalability and increased sampling times due to the long Markov chain sequences required. We observe that within reconstruction-based anomaly detection a full-length Markov chain diffusion is not required. This leads us to develop a novel partial diffusion anomaly detection strategy that scales to high-resolution imagery, named AnoDDPM. A secondary problem is that Gaussian diffusion fails to capture larger anomalies; therefore we develop a multi-scale simplex noise diffusion process that gives control over the target anomaly size. AnoDDPM with simplex noise is shown to significantly outperform both f-AnoGAN and Gaussian diffusion for the tumorous dataset of 22 T1-weighted MRI scans (CCBS Edinburgh) qualitatively and quantitatively (improvement of +25.5% Sørensen–Dice co-efficient, +17.6% IoU and +7.4% AUC).",https://www.semanticscholar.org/paper/20f6fce7726e7b3ab4ca45ef40d92b79f093f825,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '0d4154cbd76c4753ba3cb7a5b89ab29bab53384f', '7fb831b897af4f351967f311dd2bc601004c5bfd', 'be8cdeafb6bcda28468fec7733cedc3259dbdf83', '54e325aee6b2d476bbbb88615ac15e251c6e8214', 'c5505f4c0fa9689cd2598231538bb08e9b06851f', '64ea8f180d0682e6c18d1eb688afdb2027c02794', '3a78adf9ec84c85a6414b7b31b2cb40e530ef256', 'ae97c81b45780dc91e18eb84236d8a40a290b329', '7d0effebfa4bed19b6ba41f3af5b7e5b6890de87', '1c4e9156ca07705531e45960b7a919dc473abb51', 'd07284a6811f1b2745d91bdb06b040b57f226882', '66386a946a04534275bd466862364d139790f41f', '744fe47157477235032f7bb3777800f9f2f45e52', 'f466157848d1a7772fb6d02cdac9a7a5e7ef982e', 'c6ce01f0ed874ba9c49effe523f65e221c29fb3a', 'acd87843a451d18b4dc6474ddce1ae946429eaf1', None, '289db3be7bf77e06e75541ba93269de3d604ac72', 'cb3d43139c682518b1e05e64df6239b7c26527ff', '87e9842de97fc610ba69f0e8bc3e13b9619787b9', 'bc519f58ae61afbf6318d6e4239d2d565c7ba467', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', 'de18baa4964804cf471d85a5a090498242d2e79f', 'a6fd5071b73f542c79bd08d409c5f73de38dac5d', '204e3073870fae3d05bcbc2f6a8e263d9b72e776', '2dcef55a07f8607a819c21fe84131ea269cc2e3c', 'f88cfc38dec02dcf050eb1f56d2d59d90b24e04c'}",28,set(),0,"['Julian Wyatt', 'Adam Leach', 'Sebastian M. Schmon', 'Chris G. Willcocks']",Julian Wyatt,"Julian Wyatt, Adam Leach, Sebastian M. Schmon, Chris G. Willcocks",0.0
ffa32955e977620a5d498884a6e3f8faa290c793,UzADL: Anomaly detection and localization using graph Laplacian matrix-based unsupervised learning method,2022-09-01,,https://www.semanticscholar.org/paper/ffa32955e977620a5d498884a6e3f8faa290c793,"{'732c21998e251d64cd58b6a86886ee5907efeaa5', '6180c1217c2c37d0b2f3e41930032d5f64b28af2', '96ba4e475a5df30f989ccf3833933a7b6f65a865', '8ca5c250cd3356eae5c3f02e5bce1380b18dde49', '5cbab8e9eb649b1a908208061e8fe135d9c91f43', 'a8af6d7a6fef6e2bfac76699316788570f7d6f65', '920e0e85ca67d487731a33a74dba1f13204cc102', 'f16841e022038e94a59f7e0a82002102b78d79a4', '09b91e8355d3f67847a4167e80a3a65d71952395', 'e578f5c997c4ccecd72f94ef120b221d57e38247', '9c24454b071bc8e96ea46c5064a7bddf07cca464', '746f70835f897ec52be420d3ed3c1e5736559661', 'b95e51429054997add0339f8267fa121f05c56a4', '7e68e476109adfe81bdcc287070c9c903876270c', '48f9a48aa5b1230b05a443d2d531e6441a541686', '27c42608ee7dfb233f1f9460c63dbccd65bed422', '97318bec68f056b1d887432260d94d29942dd565', '2a56bd89fd1a9457f0705142540ffc4396fad4f7', 'f53e8695c5672cb2f7a632b42c2f10e33bc9cafc', 'bd7727ca8d831efce11b0bbf695738494026b93e', 'fb2f91d175b66e2224d691443877c3d144b63293', '735d4220d5579cc6afe956d9f6ea501a96ae99e2', '46ee35aa53f5973de0d6d0af774cf4769d674ec1', '2d525d704253464d4506600782bea0934b7b3dfc', '354ae953df2b8ecb364904ffa4fb59ec6e861d1f', '2218101813eefb4957d6c864fe70f1c47135c0c0', '67ab1fbfe424f93e1432ee655682cb4a9243b4b1'}",27,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Bekhzod Olimov', 'K. Veluvolu', 'Anand Paul', 'Jeonghong Kim']",Bekhzod Olimov,"Bekhzod Olimov, K. Veluvolu, Anand Paul, Jeonghong Kim",3.7037037037037037
2c154b944817d1330e48208fbaff5ee92ab6461d,One-Class Classification with Noise-Based Data Augmentation for Industrial Anomaly Detection,,,https://www.semanticscholar.org/paper/2c154b944817d1330e48208fbaff5ee92ab6461d,"{'0535625be630c6a67f4c244ebf3aa61ad088fc70', '48f9a48aa5b1230b05a443d2d531e6441a541686', '11ad166a7c77a7afd814855f16788ea706262609', '9de4e9efeda53a366b17d9aa188b15604e6245c3', '9cc912ae25797e5f7c0d73300d3968ad8339b411'}",5,{'48f9a48aa5b1230b05a443d2d531e6441a541686'},1,"['Nguyen Thi Hong Anh', 'Do Ngoc Nhu Loan', 'L. Trang']",Nguyen Thi Hong Anh,"Nguyen Thi Hong Anh, Do Ngoc Nhu Loan, L. Trang",20.0
6ca9b2d8bd204c5b2c2f1cfa36f03da4992fc1a6,Computer Vision and Normalizing Flow Based Defect Detection,2020-12-12,"Surface defect detection is essential and necessary for controlling the qualities of the products during manufacturing. The challenges in this complex task include: 1) collecting defective samples and manually labeling for training is time-consuming; 2) the defects' characteristics are difficult to define as new types of defect can happen all the time; 3) and the real-world product images contain lots of background noise. In this paper, we present a two-stage defect detection network based on the object detection model YOLO, and the normalizing flow-based defect detection model DifferNet. Our model has high robustness and performance on defect detection using real-world video clips taken from a production line monitoring system. The normalizing flow-based anomaly detection model only requires a small number of good samples for training and then perform defect detection on the product images detected by YOLO. The model we invent employs two novel strategies: 1) a two-stage network using YOLO and a normalizing flow-based model to perform product defect detection, 2) multi-scale image transformations are implemented to solve the issue product image cropped by YOLO includes many background noise. Besides, extensive experiments are conducted on a new dataset collected from the real-world factory production line. We demonstrate that our proposed model can learn on a small number of defect-free samples of single or multiple product types. The dataset will also be made public to encourage further studies and research in surface defect detection.",https://www.semanticscholar.org/paper/6ca9b2d8bd204c5b2c2f1cfa36f03da4992fc1a6,"{'3aa681914a7da79f7d7293f51a058eefe61c8bb7', '82c7313ecc711537e9ce1e3c6abd678c9409448a', '0f899b92b7fb03b609fee887e4b6f3b633eaf30d', 'b77b1fc188f3834541efbb75add8f1ea80fd6225', 'e53a42b0eb3b1085c1c58de9194457417e7aa24a', '98269ed00775c50c64b94f492da2e3e3952bf7ba', '09879f7956dddc2a9328f5c1472feeb8402bcbcf', 'a381e58d8e28ab0fb61492463d8ea5f569c5eba6', 'f8e79ac0ea341056ef20f2616628b3e964764cfd', '7ffdbc358b63378f07311e883dddacc9faeeaf4b', '00ce9aa4fc7d688af71fd3a0a467ea99c9b8017b', 'b1464ca857593c049873421db2f37bf2d0ff676d', '6b6360c6d2bdc55360925445b77d21126b477e9a', '2506cf222f0e05f2b9360fe1950dcc8033a1cd2b', '6364fdaa0a0eccd823a779fcdd489173f938e91a', '5a987c003262da601ab0356219c36951112dd015', '9c24454b071bc8e96ea46c5064a7bddf07cca464', None, '71d1ac92ad36b62a04f32ed75a10ad3259a7218d', 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '9ef18f83f7c355d0892e45772b9a6fa0c2616fd1', 'e79272fe3d65197100eae8be9fec6469107969ae', '689757a2c0443f2f98c1c99c9e71683a49b1b757', 'fd550b29c0efee17be5eb1447fddc3c8ce66e838', '1f476738e6d2950ab2ca08ac852764640c8e9d93'}",25,{'b1464ca857593c049873421db2f37bf2d0ff676d'},1,"['Zijian Kuang', 'Xinran Tie']",Zijian Kuang,"Zijian Kuang, Xinran Tie",4.0
3bc6573cfc5037541880977290094da71af64f42,Anomaly Detection Based on Selection and Weighting in Latent Space,2021-03-08,"With the high requirements of automation in the era of Industry 4.0, anomaly detection plays an increasingly important role in high safety and reliability in the production and manufacturing industry. Recently, autoencoders have been widely used as a backend algorithm for anomaly detection. Different techniques have been developed to improve the anomaly detection performance of autoencoders. Nonetheless, little attention has been paid to the latent representations learned by autoencoders. In this paper, we propose a novel selection-and-weighting-based anomaly detection framework called SWAD. In particular, the learned latent representations are individually selected and weighted. Experiments on both benchmark and real-world datasets have shown the effectiveness and superiority of SWAD. On the benchmark datasets, the SWAD framework has reached comparable or even better performance than the state-of-the-art approaches.",https://www.semanticscholar.org/paper/3bc6573cfc5037541880977290094da71af64f42,"{'162d958ff885f1462aeda91cd72582323fd6a1f4', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', 'c16835c8e535ebd9c10a550ca9455fe384a14449', '2b75ba7f75170b73d913c515cc0deefef6c88f5f', '5497fd7c820eeba3ab258eb1114ed4db6249ffef', '275aaca7621b2ee4ff81cd37162f6c9a90f306e4', 'b0da8fbc379df2c8b35000330d0e75576ae7d1f0', '00a1077d298f2917d764eb729ab1bc86af3bd241', '48ddd9101a90fe65e3061de69626741b843ff5e4', '8905ea0b3b3c8b43d618286fc10c20c6b8031b05', '6af440915b8a0718c93be1cf61905e41e620484a', '08933b9081561b28c95714ab177dffcfc056e96b', 'a6cb366736791bcccc5c8639de5a8f9636bf87e8', '43f2ad297941db230c089ba353efc3f281ab678c', 'aa9501f157cbeb1e977b8083c108605246eff860', '67b9c2b376a01d8757dc6d704be450d1c46c4ced', None, 'a2e667e4382aaa8e02a17d0522c1a910790ab65b', '55cfcafce02d0b9f5a65d979dcfea635eece46af', 'a7c828184693a453a6c2867dee233ed054b2012e', 'c8f24405f8c110ce2665a0cddb8e8458824f3217', '5d90f06bb70a0a3dced62413346235c02b1aa086', 'fbf26e1085ac3b038f47d4d1945ebda45d5e57fb', '8381157eae4fbf8908d0312a9642f8e69e944449', '34487c2ca9f7df7dc7dde7c60dabd6fabb414aca', 'bf5cf36407ece2569f0717f2b5593c4bd2140ebb', '9d868ed92f1c78d1f696a26c71176a6a33a72423', '7995dddea80c84c193aede353536f730e13fedca', '6f9fc6214b8e3c62f7669430743c61ba64f29192', '46200b99c40e8586c8a0f588488ab6414119fb28'}",30,set(),0,"['Yiwen Liao', 'Alexander Bartler', 'Binh Yang']",Yiwen Liao,"Yiwen Liao, Alexander Bartler, Binh Yang",0.0
3d4a9205306bd01149e13db325ad0f6d5814d49a,Application of optimal clustering and metric learning to patch-based anomaly detection,2022-01-01,,https://www.semanticscholar.org/paper/3d4a9205306bd01149e13db325ad0f6d5814d49a,"{'b452a856a3e3d4d37b1de837996aa6813bedfdcf', 'cfaae9b6857b834043606df3342d8dc97524aa9d', '3aa681914a7da79f7d7293f51a058eefe61c8bb7', '5aa26299435bdf7db874ef1640a6c3b5a4a2c394', 'e163a2e89c136cb4442e34c72f7173a0ff46dc79', '6af440915b8a0718c93be1cf61905e41e620484a', '62b77e5cb85fc61b84edd532f6d65714be152596', '90902e16f4e8ff5e3c4bf0f971380af5753aacdd', 'bf206bad6a74d27b40c8ea77ee54e98e492fb7f9', 'f16841e022038e94a59f7e0a82002102b78d79a4', '4cfd770ccecae1c0b4248bc800d7fd35c817bbbd', '41747cbdbed84762dfbfc305254c97021279dc6e'}",12,"{'41747cbdbed84762dfbfc305254c97021279dc6e', '62b77e5cb85fc61b84edd532f6d65714be152596'}",2,"['J. Ahn', 'Gyeonghwan Kim']",J. Ahn,"J. Ahn, Gyeonghwan Kim",16.666666666666668
